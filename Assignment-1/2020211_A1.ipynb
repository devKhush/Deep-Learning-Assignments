{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFfZVBtWMEk"
      },
      "source": [
        "# Khushdev Pandit\n",
        "# Roll no: 2020211"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJC5V5cESN_M"
      },
      "source": [
        "# Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzcG3NkOQa55",
        "outputId": "df2a8056-54e9-41f6-dcb8-510df63b6f63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/data/MNIST/raw/t10k-images-idx3-ubyte',\n",
              " '/content/data/MNIST/raw/t10k-images-idx3-ubyte.gz',\n",
              " '/content/data/MNIST/raw/t10k-labels-idx1-ubyte',\n",
              " '/content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz',\n",
              " '/content/data/MNIST/raw/train-images-idx3-ubyte',\n",
              " '/content/data/MNIST/raw/train-images-idx3-ubyte.gz',\n",
              " '/content/data/MNIST/raw/train-labels-idx1-ubyte',\n",
              " '/content/data/MNIST/raw/train-labels-idx1-ubyte.gz']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "url = 'https://drive.google.com/drive/folders/1eMPLhew1XrMo6mLHO8ySTv-n4Xydlui-?usp=sharing'\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrtXlfRUWMEn"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qs_ZMIe7WMEo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTxJNT1gWMEq"
      },
      "source": [
        "### Class for custom MNIST Dataset inherited from torch.utils.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dluLa6LSWMEq"
      },
      "outputs": [],
      "source": [
        "class MNISTCustomDataset(Dataset):\n",
        "    def __init__(self, root:str, train=True, transform=None, target_transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        images_path = 'train-images-idx3-ubyte' if train else 't10k-images-idx3-ubyte'\n",
        "        labels_path = 'train-labels-idx1-ubyte' if train else 't10k-labels-idx1-ubyte'\n",
        "        images_path = os.path.join(self.root, images_path)\n",
        "        labels_path = os.path.join(self.root, labels_path)\n",
        "        f_image = open(images_path, 'rb')\n",
        "        f_label = open(labels_path, 'rb')\n",
        "\n",
        "        magic_number, size, row, column = struct.unpack(\">IIII\", f_image.read(16))\n",
        "        image_data = np.fromfile(f_image, dtype=np.uint8)\n",
        "        magic_number, size = struct.unpack(\">II\", f_label.read(8))\n",
        "        image_label = np.fromfile(f_label, dtype=np.uint8)\n",
        "\n",
        "        self.images = torch.tensor(image_data, dtype=torch.float32).reshape((size, 1, row, column))\n",
        "        self.labels = torch.tensor(image_label, dtype=torch.int64)\n",
        "        self.length = size\n",
        "        print('MNIST Custom Dataset Initialized...')\n",
        "        print('MNIST Custom Dataset length: {}'.format(self.length))\n",
        "        print('Dataset image shape: {}'.format(self.images.shape))\n",
        "        print('Dataset label shape: {}\\n'.format(self.labels.shape))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EgTn9v4gWMEr",
        "outputId": "a8b23a77-2851-4d47-de5f-69f0c95a86c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n",
            "torch.Size([4, 1, 28, 28]) torch.Size([4])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.float32 torch.int64\n",
            "tensor(4)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# root = os.path.join(os.getcwd(), 'data', 'MNIST', 'raw')\n",
        "root = './data/MNIST/raw/'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "])\n",
        "# mnist_custom_dataset = MNIST(root='data/', download=True, train=True, transform=transform)\n",
        "mnist_custom_dataset = MNISTCustomDataset(root=root, train=True, transform=transform)\n",
        "print(mnist_custom_dataset.images.shape, mnist_custom_dataset.labels.shape)\n",
        "\n",
        "custom_dataloader = DataLoader(mnist_custom_dataset, batch_size=4, shuffle=True)\n",
        "for images, labels in custom_dataloader:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(type(images), type(labels))\n",
        "    print(images.dtype, labels.dtype)\n",
        "    print(labels[0])\n",
        "    plt.imshow(images[0].reshape((28, 28)), cmap='gray');plt.show()\n",
        "    print(labels[1])\n",
        "    plt.imshow(images[1].reshape((28, 28)), cmap='gray');plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oon9F9GGWMEr"
      },
      "source": [
        "### Class for Scratch MNIST Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZeII-6-WMEu"
      },
      "outputs": [],
      "source": [
        "class MNISTScratchDataset:\n",
        "    def __init__(self, root:str, train=True):\n",
        "        self.root = root\n",
        "        images_path = 'train-images-idx3-ubyte' if train else 't10k-images-idx3-ubyte'\n",
        "        labels_path = 'train-labels-idx1-ubyte' if train else 't10k-labels-idx1-ubyte'\n",
        "        images_path = os.path.join(self.root, images_path)\n",
        "        labels_path = os.path.join(self.root, labels_path)\n",
        "        f_image = open(images_path, 'rb')\n",
        "        f_label = open(labels_path, 'rb')\n",
        "\n",
        "        magic_number, size, row, column = struct.unpack(\">IIII\", f_image.read(16))\n",
        "        image_data = np.fromfile(f_image, dtype=np.uint8)\n",
        "        magic_number, size = struct.unpack(\">II\", f_label.read(8))\n",
        "        image_label = np.fromfile(f_label, dtype=np.uint8)\n",
        "\n",
        "        self.images = torch.tensor(image_data, dtype=torch.float32).reshape((size, 1, row, column))\n",
        "        self.labels = torch.tensor(image_label, dtype=torch.int64)\n",
        "        self.length = size\n",
        "        print('MNIST Scratch Dataset Initialized...')\n",
        "        print('MNIST Scratch Dataset length: {}'.format(self.length))\n",
        "        print('Dataset image shape: {}'.format(self.images.shape))\n",
        "        print('Dataset label shape: {}\\n'.format(self.labels.shape))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA4J_AjlWMEu"
      },
      "outputs": [],
      "source": [
        "class MNISTLoader:\n",
        "    def __init__(self, data, batch_size, shuffle=False):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n = len(self.data)\n",
        "        self.shuffle_data()\n",
        "\n",
        "    def shuffle_data(self):\n",
        "        self.i = 0\n",
        "        self.indices = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "\n",
        "    def __has_next__(self):\n",
        "        return self.i < self.n\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.shuffle_data()\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if not self.__has_next__():\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            batch_indices = self.indices[self.i : self.i + self.batch_size]\n",
        "            # Method-1\n",
        "            # batch_images = []\n",
        "            # batch_labels = []\n",
        "            # for i in batch_indices:\n",
        "            #     image, label = self.data[i]\n",
        "            #     batch_images.append(image)\n",
        "            #     batch_labels.append(label)\n",
        "            # Method-2 (Applies same transform to all images in batch)\n",
        "            # batch_images, batch_labels = self.data[batch_indices]\n",
        "            # self.i += self.batch_size\n",
        "            # return batch_images, batch_labels\n",
        "            # Method-3\n",
        "            batch_images, batch_labels = zip(*[self.data[i] for i in batch_indices])\n",
        "            self.i += self.batch_size\n",
        "            return torch.stack(batch_images), torch.stack(batch_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nhIcORzyWMEv",
        "outputId": "c1d5c6f4-a35f-4a85-8a55-3012e8a86187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Scratch Dataset Initialized...\n",
            "MNIST Scratch Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "tensor(7)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.MNISTLoader'>\n",
            "tensor([ 9611, 53346, 34036,  ..., 32002, 26787, 48491])\n",
            "tensor([26470, 31932, 12323,  ..., 38376, 32939, 28550])\n",
            "tensor([ 5923, 16728,  2858,  ..., 23672,   625, 17860])\n",
            "tensor([21927,  2487, 59450,  ..., 44184, 36681, 15326])\n",
            "tensor([27453, 45181,  9599,  ..., 35058, 10905, 22023])\n",
            "tensor([59088, 27200,  6820,  ..., 32764, 16921, 14193])\n",
            "tensor([ 8801, 39714, 38076,  ..., 41059, 44027, 57907])\n",
            "tensor([31422, 21287, 16154,  ..., 26769, 18708, 42038])\n",
            "tensor([ 6678, 33061, 35968,  ..., 14389, 45479,  3438])\n",
            "tensor([26977, 38369, 10913,  ..., 28724,  1160,  3690])\n"
          ]
        }
      ],
      "source": [
        "root = './data/MNIST/raw/'\n",
        "mnist_scratch_dataset = MNISTScratchDataset(root=root, train=True)\n",
        "print(mnist_scratch_dataset.images.shape, mnist_scratch_dataset.labels.shape)\n",
        "# print(mnist_scratch_dataset[0][1]); plt.imshow(mnist_scratch_dataset[0][0], cmap='gray'); plt.show()\n",
        "\n",
        "# scratch_loader = DataLoader(mnist_scratch_dataset, batch_size=64, shuffle=True)\n",
        "scratch_loader = MNISTLoader(mnist_scratch_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "for images, labels in scratch_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(labels[0])\n",
        "    plt.imshow(images[0][0], cmap='gray'); plt.show()\n",
        "    print(labels[1])\n",
        "    plt.imshow(images[1][0], cmap='gray'); plt.show()\n",
        "    break\n",
        "\n",
        "print(type(scratch_loader))\n",
        "for i in range(10):\n",
        "    for images, labels in scratch_loader:\n",
        "        print(scratch_loader.indices)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvVBD72_WMEv"
      },
      "source": [
        "### Custom DataLoader performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4b5GIWsWMEw",
        "outputId": "1a32f3b4-95f3-4d69-fc36-09a319fdac79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "Calculating loading time for Batch-size=128 and Shuffle=False\n",
            "Calculating loading time for Batch-size=256 and Shuffle=False\n",
            "Calculating loading time for Batch-size=512 and Shuffle=False\n",
            "Calculating loading time for Batch-size=1024 and Shuffle=False\n",
            "\n",
            "Mean Batch Loading time for custom DataLoaders: \n",
            "for batch Size 128: 0.0008399481458196253s\n",
            "for batch Size 256: 0.0016771539728692238s\n",
            "for batch Size 512: 0.004626019526336153s\n",
            "for batch Size 1024: 0.006417488647719561s\n",
            "\n",
            "Median Batch Loading time for custom DataLoaders: \n",
            "for batch Size 128: 0.0007965564727783203s\n",
            "for batch Size 256: 0.0015935897827148438s\n",
            "for batch Size 512: 0.0031644105911254883s\n",
            "for batch Size 1024: 0.006246089935302734s\n",
            "\n",
            "Standard Deviation of Batch Loading time for custom DataLoaders: \n",
            "for batch Size 128: 0.00020230442562127324s\n",
            "for batch Size 256: 0.000332358300082902s\n",
            "for batch Size 512: 0.013921124175179971s\n",
            "for batch Size 1024: 0.0007233158007022243s\n",
            "\n",
            "Total Loading time for custom DataLoaders: \n",
            "for batch Size 128: 0.3939659595489502s\n",
            "for batch Size 256: 0.3941636085510254s\n",
            "for batch Size 512: 0.5459063053131104s\n",
            "for batch Size 1024: 0.3786759376525879s\n"
          ]
        }
      ],
      "source": [
        "def get_custom_loader_timings(data, batch_size=64, shuffle=False):\n",
        "    import time\n",
        "    custom_dataloader = DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
        "    batch_loading_time = []\n",
        "    print(f'Calculating loading time for Batch-size={batch_size} and Shuffle={shuffle}')\n",
        "    start_time = time.time()\n",
        "    prev_time = start_time\n",
        "    for img, label in custom_dataloader:\n",
        "        curr_time = time.time()\n",
        "        batch_loading_time.append(curr_time - prev_time)\n",
        "        prev_time = curr_time\n",
        "\n",
        "    total_loading_time = time.time() - start_time\n",
        "    return batch_loading_time, total_loading_time\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])\n",
        "mnist_dataset = MNISTCustomDataset(root=root, train=True, transform=None, target_transform=None)\n",
        "\n",
        "cL_batchLoadingTime_b128, cL_totalLoadingTime_b128 = get_custom_loader_timings(mnist_dataset, batch_size=128)\n",
        "cL_batchLoadingTime_b256, cL_totalLoadingTime_b256 = get_custom_loader_timings(mnist_dataset, batch_size=256)\n",
        "cL_batchLoadingTime_b512, cL_totalLoadingTime_b512 = get_custom_loader_timings(mnist_dataset, batch_size=512)\n",
        "cL_batchLoadingTime_b1024, cL_totalLoadingTime_b1024  = get_custom_loader_timings(mnist_dataset, batch_size=1024)\n",
        "\n",
        "print('\\nMean Batch Loading time for custom DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.mean(cL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.mean(cL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.mean(cL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.mean(cL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nMedian Batch Loading time for custom DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.median(cL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.median(cL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.median(cL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.median(cL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nStandard Deviation of Batch Loading time for custom DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.std(cL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.std(cL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.std(cL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.std(cL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nTotal Loading time for custom DataLoaders: ')\n",
        "print(f'for batch Size 128: {cL_totalLoadingTime_b128}s')\n",
        "print(f'for batch Size 256: {cL_totalLoadingTime_b256}s')\n",
        "print(f'for batch Size 512: {cL_totalLoadingTime_b512}s')\n",
        "print(f'for batch Size 1024: {cL_totalLoadingTime_b1024}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ib0D5q9WMEw"
      },
      "source": [
        "### Scratch DataLoader performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxMfebERWMEw",
        "outputId": "eaefc330-bc5b-4dcc-cf4f-c98b36008716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Scratch Dataset Initialized...\n",
            "MNIST Scratch Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "Calculating loading time for Batch-size=128 and Shuffle=False\n",
            "Calculating loading time for Batch-size=256 and Shuffle=False\n",
            "Calculating loading time for Batch-size=512 and Shuffle=False\n",
            "Calculating loading time for Batch-size=1024 and Shuffle=False\n",
            "\n",
            "Mean Batch Loading time for scratch DataLoaders: \n",
            "for batch Size 128: 0.0010889156032472785s\n",
            "for batch Size 256: 0.002158319189193401s\n",
            "for batch Size 512: 0.005508544081348484s\n",
            "for batch Size 1024: 0.008498232243424756s\n",
            "\n",
            "Median Batch Loading time for scratch DataLoaders: \n",
            "for batch Size 128: 0.0010237693786621094s\n",
            "for batch Size 256: 0.002084493637084961s\n",
            "for batch Size 512: 0.004175662994384766s\n",
            "for batch Size 1024: 0.00829315185546875s\n",
            "\n",
            "Standard Deviation of Batch Loading time for scratch DataLoaders: \n",
            "for batch Size 128: 0.00021396604920232608s\n",
            "for batch Size 256: 0.0003037179592658344s\n",
            "for batch Size 512: 0.012658825265276822s\n",
            "for batch Size 1024: 0.0007112158438403313s\n",
            "\n",
            "Total Loading time for scratch DataLoaders: \n",
            "for batch Size 128: 0.5107083320617676s\n",
            "for batch Size 256: 0.5072112083435059s\n",
            "for batch Size 512: 0.6500139236450195s\n",
            "for batch Size 1024: 0.5014066696166992s\n"
          ]
        }
      ],
      "source": [
        "def get_scratch_loader_timings(data, batch_size=64, shuffle=False):\n",
        "    import time\n",
        "    scratch_loader = MNISTLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
        "    batch_loading_time = []\n",
        "    print(f'Calculating loading time for Batch-size={batch_size} and Shuffle={shuffle}')\n",
        "    start_time = time.time()\n",
        "    prev_time = start_time\n",
        "    for img, label in scratch_loader:\n",
        "        curr_time = time.time()\n",
        "        batch_loading_time.append(curr_time - prev_time)\n",
        "        prev_time = curr_time\n",
        "\n",
        "    total_loading_time = time.time() - start_time\n",
        "    return batch_loading_time, total_loading_time\n",
        "\n",
        "mnist_dataset = MNISTScratchDataset(root=root, train=True)\n",
        "\n",
        "sL_batchLoadingTime_b128, sL_totalLoadingTime_b128 = get_scratch_loader_timings(mnist_dataset, 128)\n",
        "sL_batchLoadingTime_b256, sL_totalLoadingTime_b256 = get_scratch_loader_timings(mnist_dataset, 256)\n",
        "sL_batchLoadingTime_b512, sL_totalLoadingTime_b512 = get_scratch_loader_timings(mnist_dataset, 512)\n",
        "sL_batchLoadingTime_b1024, sL_totalLoadingTime_b1024 = get_scratch_loader_timings(mnist_dataset, 1024)\n",
        "\n",
        "print('\\nMean Batch Loading time for scratch DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.mean(sL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.mean(sL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.mean(sL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.mean(sL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nMedian Batch Loading time for scratch DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.median(sL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.median(sL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.median(sL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.median(sL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nStandard Deviation of Batch Loading time for scratch DataLoaders: ')\n",
        "print(f'for batch Size 128: {np.std(sL_batchLoadingTime_b128)}s')\n",
        "print(f'for batch Size 256: {np.std(sL_batchLoadingTime_b256)}s')\n",
        "print(f'for batch Size 512: {np.std(sL_batchLoadingTime_b512)}s')\n",
        "print(f'for batch Size 1024: {np.std(sL_batchLoadingTime_b1024)}s')\n",
        "\n",
        "print('\\nTotal Loading time for scratch DataLoaders: ')\n",
        "print(f'for batch Size 128: {sL_totalLoadingTime_b128}s')\n",
        "print(f'for batch Size 256: {sL_totalLoadingTime_b256}s')\n",
        "print(f'for batch Size 512: {sL_totalLoadingTime_b512}s')\n",
        "print(f'for batch Size 1024: {sL_totalLoadingTime_b1024}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lb6b8qUWMEx"
      },
      "source": [
        "### Comparing Performance of Loading time v/s Batch size on Custom DataLoader and Scratch DataLoader without shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FcgRojNTWMEx",
        "outputId": "55833441-741c-4d52-badd-96ae4cedc5e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_sizes = [128, 256, 512, 1024]\n",
        "cL_meanBatchLoadingTime = [np.mean(cL_batchLoadingTime_b128), np.mean(cL_batchLoadingTime_b256),\n",
        "                            np.mean(cL_batchLoadingTime_b512), np.mean(cL_batchLoadingTime_b1024)]\n",
        "sL_meanBatchLoadingTime = [np.mean(sL_batchLoadingTime_b128), np.mean(sL_batchLoadingTime_b256),\n",
        "                            np.mean(sL_batchLoadingTime_b512), np.mean(sL_batchLoadingTime_b1024)]\n",
        "cL_totalLoadingTime = [cL_totalLoadingTime_b128, cL_totalLoadingTime_b256,\n",
        "                        cL_totalLoadingTime_b512, cL_totalLoadingTime_b1024]\n",
        "sL_totalLoadingTime = [sL_totalLoadingTime_b128, sL_totalLoadingTime_b256,\n",
        "                        sL_totalLoadingTime_b512, sL_totalLoadingTime_b1024]\n",
        "\n",
        "fig = plt.figure(figsize=(8, 10))\n",
        "has = ['left', 'left', 'left', 'right']\n",
        "vas = ['bottom', 'bottom', 'bottom', 'bottom']\n",
        "\n",
        "ax1 = fig.add_subplot(2, 1, 1)\n",
        "ax1.plot(batch_sizes, cL_meanBatchLoadingTime, label='Custom Dataloader', marker='o')\n",
        "ax1.plot(batch_sizes, sL_meanBatchLoadingTime, label='Scratch Dataloader', marker='o')\n",
        "# ax1.set_xscale('log')\n",
        "ax1.set_yscale('log')\n",
        "ax1.set_xticks(batch_sizes)\n",
        "for x, y in zip(batch_sizes, cL_meanBatchLoadingTime):\n",
        "    ax1.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "for x, y in zip(batch_sizes, sL_meanBatchLoadingTime):\n",
        "    ax1.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "ax1.set_xlabel('Batch Size')\n",
        "ax1.set_ylabel('Mean Batch Loading Time')\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = fig.add_subplot(2, 1, 2)\n",
        "ax2.plot(batch_sizes, cL_totalLoadingTime, label='Custom Dataloader', marker='o')\n",
        "ax2.plot(batch_sizes, sL_totalLoadingTime, label='Scratch Dataloader', marker='o')\n",
        "# ax2.set_xscale('log')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_xticks(batch_sizes)\n",
        "for x, y in zip(batch_sizes, cL_totalLoadingTime):\n",
        "    ax2.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "for x, y in zip(batch_sizes, sL_totalLoadingTime):\n",
        "    ax2.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "ax2.set_xlabel('Batch Size')\n",
        "ax2.set_ylabel('Total Loading Time')\n",
        "ax2.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAd5bF02WMEx"
      },
      "source": [
        "### Comparing Performance of Loading time v/s Batch size on Custom DataLoader and Scratch DataLoader with shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6XcQjVInWMEy",
        "outputId": "8e582912-90b6-434b-9116-fe4a09fcce09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "Calculating loading time for Batch-size=128 and Shuffle=True\n",
            "Calculating loading time for Batch-size=256 and Shuffle=True\n",
            "Calculating loading time for Batch-size=512 and Shuffle=True\n",
            "Calculating loading time for Batch-size=1024 and Shuffle=True\n",
            "\n",
            "MNIST Scratch Dataset Initialized...\n",
            "MNIST Scratch Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "Calculating loading time for Batch-size=128 and Shuffle=True\n",
            "Calculating loading time for Batch-size=256 and Shuffle=True\n",
            "Calculating loading time for Batch-size=512 and Shuffle=True\n",
            "Calculating loading time for Batch-size=1024 and Shuffle=True\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "# mnist_custom_dataset = MNIST(root='data/', download=True, train=True, transform=transform)\n",
        "mnist_custom_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "\n",
        "cL_batchLoadingTime_b128, cL_totalLoadingTime_b128 = get_custom_loader_timings(mnist_custom_dataset, batch_size=128, shuffle=True)\n",
        "cL_batchLoadingTime_b256, cL_totalLoadingTime_b256 = get_custom_loader_timings(mnist_custom_dataset, batch_size=256, shuffle=True)\n",
        "cL_batchLoadingTime_b512, cL_totalLoadingTime_b512 = get_custom_loader_timings(mnist_custom_dataset, batch_size=512, shuffle=True)\n",
        "cL_batchLoadingTime_b1024, cL_totalLoadingTime_b1024  = get_custom_loader_timings(mnist_custom_dataset, batch_size=1024, shuffle=True)\n",
        "print()\n",
        "\n",
        "mnist_scratch_dataset = MNISTScratchDataset(root=root, train=True)\n",
        "sL_batchLoadingTime_b128, sL_totalLoadingTime_b128 = get_scratch_loader_timings(mnist_scratch_dataset, batch_size=128, shuffle=True)\n",
        "sL_batchLoadingTime_b256, sL_totalLoadingTime_b256 = get_scratch_loader_timings(mnist_scratch_dataset, batch_size=256, shuffle=True)\n",
        "sL_batchLoadingTime_b512, sL_totalLoadingTime_b512 = get_scratch_loader_timings(mnist_scratch_dataset, batch_size=512, shuffle=True)\n",
        "sL_batchLoadingTime_b1024, sL_totalLoadingTime_b1024 = get_scratch_loader_timings(mnist_scratch_dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "\n",
        "batch_sizes = [128, 256, 512, 1024]\n",
        "cL_meanBatchLoadingTime = [np.mean(cL_batchLoadingTime_b128), np.mean(cL_batchLoadingTime_b256),\n",
        "                            np.mean(cL_batchLoadingTime_b512), np.mean(cL_batchLoadingTime_b1024)]\n",
        "sL_meanBatchLoadingTime = [np.mean(sL_batchLoadingTime_b128), np.mean(sL_batchLoadingTime_b256),\n",
        "                            np.mean(sL_batchLoadingTime_b512), np.mean(sL_batchLoadingTime_b1024)]\n",
        "cL_totalLoadingTime = [cL_totalLoadingTime_b128, cL_totalLoadingTime_b256,\n",
        "                        cL_totalLoadingTime_b512, cL_totalLoadingTime_b1024]\n",
        "sL_totalLoadingTime = [sL_totalLoadingTime_b128, sL_totalLoadingTime_b256,\n",
        "                        sL_totalLoadingTime_b512, sL_totalLoadingTime_b1024]\n",
        "\n",
        "fig = plt.figure(figsize=(8, 10))\n",
        "has = ['left', 'left', 'left', 'right']\n",
        "vas = ['bottom', 'bottom', 'bottom', 'bottom']\n",
        "\n",
        "ax1 = fig.add_subplot(2, 1, 1)\n",
        "ax1.plot(batch_sizes, cL_meanBatchLoadingTime, label='Custom Dataloader', marker='o')\n",
        "ax1.plot(batch_sizes, sL_meanBatchLoadingTime, label='Scratch Dataloader', marker='o')\n",
        "# ax1.set_xscale('log')\n",
        "ax1.set_yscale('log')\n",
        "ax1.set_xticks(batch_sizes)\n",
        "for x, y in zip(batch_sizes, cL_meanBatchLoadingTime):\n",
        "    ax1.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "for x, y in zip(batch_sizes, sL_meanBatchLoadingTime):\n",
        "    ax1.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "ax1.set_xlabel('Batch Size')\n",
        "ax1.set_ylabel('Mean Batch Loading Time')\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = fig.add_subplot(2, 1, 2)\n",
        "ax2.plot(batch_sizes, cL_totalLoadingTime, label='Custom Dataloader', marker='o')\n",
        "ax2.plot(batch_sizes, sL_totalLoadingTime, label='Scratch Dataloader', marker='o')\n",
        "# ax2.set_xscale('log')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_xticks(batch_sizes)\n",
        "for x, y in zip(batch_sizes, cL_totalLoadingTime):\n",
        "    ax2.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "for x, y in zip(batch_sizes, sL_totalLoadingTime):\n",
        "    ax2.text(x, y, '({}, {:.5f})'.format(x, y), ha=has[batch_sizes.index(x)], va=vas[batch_sizes.index(x)])\n",
        "ax2.set_xlabel('Batch Size')\n",
        "ax2.set_ylabel('Total Loading Time')\n",
        "ax2.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tKQt2TuWMEy"
      },
      "source": [
        "# Question-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4en5SL101baP"
      },
      "source": [
        "### Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QRt7d44WMEy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features:int=28*28, out_features:int=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=512, bias=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=256, out_features=128, bias=True)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(in_features=128, out_features=64, bias=True)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc5 = nn.Linear(in_features=64, out_features=out_features, bias=True)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.relu3(self.fc3(x))\n",
        "        x = self.relu4(self.fc4(x))\n",
        "        logits = self.fc5(x)\n",
        "        # probas = self.softmax(logits)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlIJMJ-e1UEN"
      },
      "source": [
        "### Initialize Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnaLYugcWMEy",
        "outputId": "d02e7493-6754-4ed6-febc-023ae1154e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 10000\n",
            "Dataset image shape: torch.Size([10000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([10000])\n",
            "\n",
            "Train Dataset Length: 54000\n",
            "Validation Dataset Length: 6000\n",
            "Test Dataset Length: 10000\n",
            "\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.float32 torch.int64\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Creating training and test datasets\n",
        "root = './data/MNIST/raw/'\n",
        "train_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "test_dataset = MNISTCustomDataset(root=root, train=False, transform=None)\n",
        "\n",
        "# splitting of training and validation set\n",
        "batch_size = 128\n",
        "valid_size = 0.1\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Train Dataset Length: {}'.format(len(train_sampler)))\n",
        "print('Validation Dataset Length: {}'.format(len(valid_sampler)))\n",
        "print('Test Dataset Length: {}\\n'.format(len(test_dataset)))\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(type(images), type(labels))\n",
        "    print(images.dtype, labels.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SECMexsl1vKW"
      },
      "source": [
        "### Initialize the model and other parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLTYI_NWMEy",
        "outputId": "472e5f11-d515-4d58-f3e7-70cd80d530b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = MLP()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0003)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPKujJt711Bz"
      },
      "source": [
        "### Training of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qa8GB3jWMEz",
        "outputId": "226a33d4-7868-48b1-ab80-eb8c8d09cd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Batch Loss: 2.600966,  Batch Accuracy: 14.06   [ 1280/54000]\n",
            "Batch Loss: 2.352406,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.244392,  Batch Accuracy: 23.44   [ 3840/54000]\n",
            "Batch Loss: 1.951872,  Batch Accuracy: 33.59   [ 5120/54000]\n",
            "Batch Loss: 1.998807,  Batch Accuracy: 30.47   [ 6400/54000]\n",
            "Batch Loss: 1.932410,  Batch Accuracy: 40.62   [ 7680/54000]\n",
            "Batch Loss: 1.829032,  Batch Accuracy: 43.75   [ 8960/54000]\n",
            "Batch Loss: 1.698252,  Batch Accuracy: 46.88   [10240/54000]\n",
            "Batch Loss: 1.629406,  Batch Accuracy: 48.44   [11520/54000]\n",
            "Batch Loss: 1.504729,  Batch Accuracy: 58.59   [12800/54000]\n",
            "Batch Loss: 1.386296,  Batch Accuracy: 61.72   [14080/54000]\n",
            "Batch Loss: 1.445437,  Batch Accuracy: 54.69   [15360/54000]\n",
            "Batch Loss: 1.471027,  Batch Accuracy: 57.03   [16640/54000]\n",
            "Batch Loss: 1.229615,  Batch Accuracy: 71.88   [17920/54000]\n",
            "Batch Loss: 1.224973,  Batch Accuracy: 68.75   [19200/54000]\n",
            "Batch Loss: 1.229690,  Batch Accuracy: 67.19   [20480/54000]\n",
            "Batch Loss: 1.147141,  Batch Accuracy: 68.75   [21760/54000]\n",
            "Batch Loss: 1.172231,  Batch Accuracy: 65.62   [23040/54000]\n",
            "Batch Loss: 1.118118,  Batch Accuracy: 71.09   [24320/54000]\n",
            "Batch Loss: 1.131376,  Batch Accuracy: 61.72   [25600/54000]\n",
            "Batch Loss: 0.943445,  Batch Accuracy: 75.00   [26880/54000]\n",
            "Batch Loss: 0.988782,  Batch Accuracy: 76.56   [28160/54000]\n",
            "Batch Loss: 1.049620,  Batch Accuracy: 71.09   [29440/54000]\n",
            "Batch Loss: 0.949580,  Batch Accuracy: 74.22   [30720/54000]\n",
            "Batch Loss: 0.807873,  Batch Accuracy: 76.56   [32000/54000]\n",
            "Batch Loss: 0.903188,  Batch Accuracy: 76.56   [33280/54000]\n",
            "Batch Loss: 0.879528,  Batch Accuracy: 75.00   [34560/54000]\n",
            "Batch Loss: 0.719383,  Batch Accuracy: 82.03   [35840/54000]\n",
            "Batch Loss: 0.783687,  Batch Accuracy: 75.78   [37120/54000]\n",
            "Batch Loss: 0.871534,  Batch Accuracy: 74.22   [38400/54000]\n",
            "Batch Loss: 0.731099,  Batch Accuracy: 82.81   [39680/54000]\n",
            "Batch Loss: 0.836514,  Batch Accuracy: 77.34   [40960/54000]\n",
            "Batch Loss: 0.833503,  Batch Accuracy: 77.34   [42240/54000]\n",
            "Batch Loss: 0.763172,  Batch Accuracy: 82.03   [43520/54000]\n",
            "Batch Loss: 0.859639,  Batch Accuracy: 74.22   [44800/54000]\n",
            "Batch Loss: 0.796635,  Batch Accuracy: 75.00   [46080/54000]\n",
            "Batch Loss: 0.706663,  Batch Accuracy: 79.69   [47360/54000]\n",
            "Batch Loss: 0.582439,  Batch Accuracy: 83.59   [48640/54000]\n",
            "Batch Loss: 0.824414,  Batch Accuracy: 73.44   [49920/54000]\n",
            "Batch Loss: 0.562711,  Batch Accuracy: 85.16   [51200/54000]\n",
            "Batch Loss: 0.565982,  Batch Accuracy: 83.59   [52480/54000]\n",
            "Batch Loss: 0.752497,  Batch Accuracy: 77.34   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 64.2%, Loss: 1.208602\n",
            "Validation performance: \n",
            " Accuracy: 83.0%, Loss: 0.641697\n",
            "Test performance: \n",
            " Accuracy: 83.2%, Loss: 0.614527 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Batch Loss: 0.557022,  Batch Accuracy: 87.50   [ 1280/54000]\n",
            "Batch Loss: 0.720816,  Batch Accuracy: 79.69   [ 2560/54000]\n",
            "Batch Loss: 0.579143,  Batch Accuracy: 82.03   [ 3840/54000]\n",
            "Batch Loss: 0.611210,  Batch Accuracy: 83.59   [ 5120/54000]\n",
            "Batch Loss: 0.529639,  Batch Accuracy: 84.38   [ 6400/54000]\n",
            "Batch Loss: 0.587002,  Batch Accuracy: 87.50   [ 7680/54000]\n",
            "Batch Loss: 0.728063,  Batch Accuracy: 81.25   [ 8960/54000]\n",
            "Batch Loss: 0.614528,  Batch Accuracy: 81.25   [10240/54000]\n",
            "Batch Loss: 0.470950,  Batch Accuracy: 89.06   [11520/54000]\n",
            "Batch Loss: 0.515726,  Batch Accuracy: 85.16   [12800/54000]\n",
            "Batch Loss: 0.581480,  Batch Accuracy: 82.81   [14080/54000]\n",
            "Batch Loss: 0.449598,  Batch Accuracy: 89.06   [15360/54000]\n",
            "Batch Loss: 0.531959,  Batch Accuracy: 84.38   [16640/54000]\n",
            "Batch Loss: 0.457461,  Batch Accuracy: 89.06   [17920/54000]\n",
            "Batch Loss: 0.466946,  Batch Accuracy: 87.50   [19200/54000]\n",
            "Batch Loss: 0.487522,  Batch Accuracy: 89.06   [20480/54000]\n",
            "Batch Loss: 0.477949,  Batch Accuracy: 85.94   [21760/54000]\n",
            "Batch Loss: 0.449392,  Batch Accuracy: 85.94   [23040/54000]\n",
            "Batch Loss: 0.510499,  Batch Accuracy: 85.16   [24320/54000]\n",
            "Batch Loss: 0.501393,  Batch Accuracy: 85.16   [25600/54000]\n",
            "Batch Loss: 0.484993,  Batch Accuracy: 84.38   [26880/54000]\n",
            "Batch Loss: 0.420946,  Batch Accuracy: 90.62   [28160/54000]\n",
            "Batch Loss: 0.579060,  Batch Accuracy: 79.69   [29440/54000]\n",
            "Batch Loss: 0.576647,  Batch Accuracy: 85.16   [30720/54000]\n",
            "Batch Loss: 0.506687,  Batch Accuracy: 85.16   [32000/54000]\n",
            "Batch Loss: 0.521159,  Batch Accuracy: 87.50   [33280/54000]\n",
            "Batch Loss: 0.589338,  Batch Accuracy: 80.47   [34560/54000]\n",
            "Batch Loss: 0.500565,  Batch Accuracy: 86.72   [35840/54000]\n",
            "Batch Loss: 0.379691,  Batch Accuracy: 89.84   [37120/54000]\n",
            "Batch Loss: 0.477903,  Batch Accuracy: 88.28   [38400/54000]\n",
            "Batch Loss: 0.462364,  Batch Accuracy: 87.50   [39680/54000]\n",
            "Batch Loss: 0.343228,  Batch Accuracy: 91.41   [40960/54000]\n",
            "Batch Loss: 0.485992,  Batch Accuracy: 87.50   [42240/54000]\n",
            "Batch Loss: 0.452595,  Batch Accuracy: 88.28   [43520/54000]\n",
            "Batch Loss: 0.433963,  Batch Accuracy: 88.28   [44800/54000]\n",
            "Batch Loss: 0.331468,  Batch Accuracy: 90.62   [46080/54000]\n",
            "Batch Loss: 0.478549,  Batch Accuracy: 85.16   [47360/54000]\n",
            "Batch Loss: 0.414964,  Batch Accuracy: 92.19   [48640/54000]\n",
            "Batch Loss: 0.486705,  Batch Accuracy: 85.16   [49920/54000]\n",
            "Batch Loss: 0.381788,  Batch Accuracy: 88.28   [51200/54000]\n",
            "Batch Loss: 0.305920,  Batch Accuracy: 92.97   [52480/54000]\n",
            "Batch Loss: 0.436711,  Batch Accuracy: 90.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 86.0%, Loss: 0.509672\n",
            "Validation performance: \n",
            " Accuracy: 88.1%, Loss: 0.428305\n",
            "Test performance: \n",
            " Accuracy: 88.5%, Loss: 0.406180 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Batch Loss: 0.425223,  Batch Accuracy: 90.62   [ 1280/54000]\n",
            "Batch Loss: 0.397746,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.537039,  Batch Accuracy: 81.25   [ 3840/54000]\n",
            "Batch Loss: 0.485177,  Batch Accuracy: 89.06   [ 5120/54000]\n",
            "Batch Loss: 0.399552,  Batch Accuracy: 87.50   [ 6400/54000]\n",
            "Batch Loss: 0.341861,  Batch Accuracy: 91.41   [ 7680/54000]\n",
            "Batch Loss: 0.438691,  Batch Accuracy: 87.50   [ 8960/54000]\n",
            "Batch Loss: 0.261886,  Batch Accuracy: 93.75   [10240/54000]\n",
            "Batch Loss: 0.311745,  Batch Accuracy: 90.62   [11520/54000]\n",
            "Batch Loss: 0.374780,  Batch Accuracy: 89.84   [12800/54000]\n",
            "Batch Loss: 0.380919,  Batch Accuracy: 87.50   [14080/54000]\n",
            "Batch Loss: 0.330560,  Batch Accuracy: 90.62   [15360/54000]\n",
            "Batch Loss: 0.355850,  Batch Accuracy: 86.72   [16640/54000]\n",
            "Batch Loss: 0.330088,  Batch Accuracy: 89.84   [17920/54000]\n",
            "Batch Loss: 0.305110,  Batch Accuracy: 91.41   [19200/54000]\n",
            "Batch Loss: 0.372985,  Batch Accuracy: 90.62   [20480/54000]\n",
            "Batch Loss: 0.617763,  Batch Accuracy: 84.38   [21760/54000]\n",
            "Batch Loss: 0.396399,  Batch Accuracy: 88.28   [23040/54000]\n",
            "Batch Loss: 0.345007,  Batch Accuracy: 92.19   [24320/54000]\n",
            "Batch Loss: 0.368083,  Batch Accuracy: 89.84   [25600/54000]\n",
            "Batch Loss: 0.288665,  Batch Accuracy: 91.41   [26880/54000]\n",
            "Batch Loss: 0.326273,  Batch Accuracy: 89.84   [28160/54000]\n",
            "Batch Loss: 0.500672,  Batch Accuracy: 84.38   [29440/54000]\n",
            "Batch Loss: 0.495142,  Batch Accuracy: 85.94   [30720/54000]\n",
            "Batch Loss: 0.379720,  Batch Accuracy: 92.19   [32000/54000]\n",
            "Batch Loss: 0.511872,  Batch Accuracy: 82.81   [33280/54000]\n",
            "Batch Loss: 0.340549,  Batch Accuracy: 90.62   [34560/54000]\n",
            "Batch Loss: 0.347240,  Batch Accuracy: 89.06   [35840/54000]\n",
            "Batch Loss: 0.354343,  Batch Accuracy: 91.41   [37120/54000]\n",
            "Batch Loss: 0.403840,  Batch Accuracy: 89.06   [38400/54000]\n",
            "Batch Loss: 0.429374,  Batch Accuracy: 90.62   [39680/54000]\n",
            "Batch Loss: 0.249232,  Batch Accuracy: 95.31   [40960/54000]\n",
            "Batch Loss: 0.314623,  Batch Accuracy: 92.19   [42240/54000]\n",
            "Batch Loss: 0.349509,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.400098,  Batch Accuracy: 88.28   [44800/54000]\n",
            "Batch Loss: 0.347039,  Batch Accuracy: 89.84   [46080/54000]\n",
            "Batch Loss: 0.433625,  Batch Accuracy: 85.94   [47360/54000]\n",
            "Batch Loss: 0.278664,  Batch Accuracy: 93.75   [48640/54000]\n",
            "Batch Loss: 0.369405,  Batch Accuracy: 90.62   [49920/54000]\n",
            "Batch Loss: 0.243644,  Batch Accuracy: 92.19   [51200/54000]\n",
            "Batch Loss: 0.390016,  Batch Accuracy: 87.50   [52480/54000]\n",
            "Batch Loss: 0.475459,  Batch Accuracy: 87.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 89.2%, Loss: 0.384169\n",
            "Validation performance: \n",
            " Accuracy: 89.9%, Loss: 0.352077\n",
            "Test performance: \n",
            " Accuracy: 90.4%, Loss: 0.337580 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Batch Loss: 0.380286,  Batch Accuracy: 89.06   [ 1280/54000]\n",
            "Batch Loss: 0.455105,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.399013,  Batch Accuracy: 89.06   [ 3840/54000]\n",
            "Batch Loss: 0.304922,  Batch Accuracy: 90.62   [ 5120/54000]\n",
            "Batch Loss: 0.341906,  Batch Accuracy: 91.41   [ 6400/54000]\n",
            "Batch Loss: 0.275453,  Batch Accuracy: 92.97   [ 7680/54000]\n",
            "Batch Loss: 0.360192,  Batch Accuracy: 91.41   [ 8960/54000]\n",
            "Batch Loss: 0.411754,  Batch Accuracy: 88.28   [10240/54000]\n",
            "Batch Loss: 0.234346,  Batch Accuracy: 93.75   [11520/54000]\n",
            "Batch Loss: 0.408499,  Batch Accuracy: 87.50   [12800/54000]\n",
            "Batch Loss: 0.392492,  Batch Accuracy: 88.28   [14080/54000]\n",
            "Batch Loss: 0.303490,  Batch Accuracy: 91.41   [15360/54000]\n",
            "Batch Loss: 0.352682,  Batch Accuracy: 90.62   [16640/54000]\n",
            "Batch Loss: 0.425870,  Batch Accuracy: 87.50   [17920/54000]\n",
            "Batch Loss: 0.318840,  Batch Accuracy: 92.19   [19200/54000]\n",
            "Batch Loss: 0.341699,  Batch Accuracy: 89.06   [20480/54000]\n",
            "Batch Loss: 0.341649,  Batch Accuracy: 89.06   [21760/54000]\n",
            "Batch Loss: 0.332582,  Batch Accuracy: 91.41   [23040/54000]\n",
            "Batch Loss: 0.376981,  Batch Accuracy: 86.72   [24320/54000]\n",
            "Batch Loss: 0.280187,  Batch Accuracy: 90.62   [25600/54000]\n",
            "Batch Loss: 0.273515,  Batch Accuracy: 90.62   [26880/54000]\n",
            "Batch Loss: 0.404399,  Batch Accuracy: 85.94   [28160/54000]\n",
            "Batch Loss: 0.422199,  Batch Accuracy: 86.72   [29440/54000]\n",
            "Batch Loss: 0.548286,  Batch Accuracy: 84.38   [30720/54000]\n",
            "Batch Loss: 0.196257,  Batch Accuracy: 96.09   [32000/54000]\n",
            "Batch Loss: 0.352728,  Batch Accuracy: 90.62   [33280/54000]\n",
            "Batch Loss: 0.262125,  Batch Accuracy: 92.19   [34560/54000]\n",
            "Batch Loss: 0.291423,  Batch Accuracy: 91.41   [35840/54000]\n",
            "Batch Loss: 0.206684,  Batch Accuracy: 92.97   [37120/54000]\n",
            "Batch Loss: 0.344505,  Batch Accuracy: 91.41   [38400/54000]\n",
            "Batch Loss: 0.407685,  Batch Accuracy: 87.50   [39680/54000]\n",
            "Batch Loss: 0.351656,  Batch Accuracy: 90.62   [40960/54000]\n",
            "Batch Loss: 0.350910,  Batch Accuracy: 90.62   [42240/54000]\n",
            "Batch Loss: 0.398332,  Batch Accuracy: 90.62   [43520/54000]\n",
            "Batch Loss: 0.444807,  Batch Accuracy: 87.50   [44800/54000]\n",
            "Batch Loss: 0.379104,  Batch Accuracy: 89.06   [46080/54000]\n",
            "Batch Loss: 0.335573,  Batch Accuracy: 90.62   [47360/54000]\n",
            "Batch Loss: 0.292239,  Batch Accuracy: 90.62   [48640/54000]\n",
            "Batch Loss: 0.418974,  Batch Accuracy: 89.06   [49920/54000]\n",
            "Batch Loss: 0.357476,  Batch Accuracy: 89.06   [51200/54000]\n",
            "Batch Loss: 0.273622,  Batch Accuracy: 93.75   [52480/54000]\n",
            "Batch Loss: 0.307431,  Batch Accuracy: 92.19   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 90.8%, Loss: 0.328102\n",
            "Validation performance: \n",
            " Accuracy: 91.0%, Loss: 0.314116\n",
            "Test performance: \n",
            " Accuracy: 91.4%, Loss: 0.301368 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Batch Loss: 0.383646,  Batch Accuracy: 89.06   [ 1280/54000]\n",
            "Batch Loss: 0.326005,  Batch Accuracy: 89.06   [ 2560/54000]\n",
            "Batch Loss: 0.295922,  Batch Accuracy: 89.06   [ 3840/54000]\n",
            "Batch Loss: 0.306590,  Batch Accuracy: 89.06   [ 5120/54000]\n",
            "Batch Loss: 0.288762,  Batch Accuracy: 90.62   [ 6400/54000]\n",
            "Batch Loss: 0.328545,  Batch Accuracy: 93.75   [ 7680/54000]\n",
            "Batch Loss: 0.308319,  Batch Accuracy: 91.41   [ 8960/54000]\n",
            "Batch Loss: 0.260337,  Batch Accuracy: 90.62   [10240/54000]\n",
            "Batch Loss: 0.307618,  Batch Accuracy: 91.41   [11520/54000]\n",
            "Batch Loss: 0.285868,  Batch Accuracy: 92.19   [12800/54000]\n",
            "Batch Loss: 0.204837,  Batch Accuracy: 92.97   [14080/54000]\n",
            "Batch Loss: 0.335290,  Batch Accuracy: 89.84   [15360/54000]\n",
            "Batch Loss: 0.299780,  Batch Accuracy: 91.41   [16640/54000]\n",
            "Batch Loss: 0.241497,  Batch Accuracy: 92.97   [17920/54000]\n",
            "Batch Loss: 0.258390,  Batch Accuracy: 91.41   [19200/54000]\n",
            "Batch Loss: 0.431032,  Batch Accuracy: 89.84   [20480/54000]\n",
            "Batch Loss: 0.426755,  Batch Accuracy: 88.28   [21760/54000]\n",
            "Batch Loss: 0.322800,  Batch Accuracy: 91.41   [23040/54000]\n",
            "Batch Loss: 0.155974,  Batch Accuracy: 94.53   [24320/54000]\n",
            "Batch Loss: 0.292607,  Batch Accuracy: 91.41   [25600/54000]\n",
            "Batch Loss: 0.271705,  Batch Accuracy: 93.75   [26880/54000]\n",
            "Batch Loss: 0.369251,  Batch Accuracy: 89.84   [28160/54000]\n",
            "Batch Loss: 0.428004,  Batch Accuracy: 87.50   [29440/54000]\n",
            "Batch Loss: 0.323720,  Batch Accuracy: 89.06   [30720/54000]\n",
            "Batch Loss: 0.243565,  Batch Accuracy: 94.53   [32000/54000]\n",
            "Batch Loss: 0.277215,  Batch Accuracy: 92.97   [33280/54000]\n",
            "Batch Loss: 0.218510,  Batch Accuracy: 92.97   [34560/54000]\n",
            "Batch Loss: 0.227441,  Batch Accuracy: 93.75   [35840/54000]\n",
            "Batch Loss: 0.318407,  Batch Accuracy: 89.06   [37120/54000]\n",
            "Batch Loss: 0.289611,  Batch Accuracy: 92.19   [38400/54000]\n",
            "Batch Loss: 0.180070,  Batch Accuracy: 95.31   [39680/54000]\n",
            "Batch Loss: 0.261853,  Batch Accuracy: 93.75   [40960/54000]\n",
            "Batch Loss: 0.165404,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.463027,  Batch Accuracy: 89.06   [43520/54000]\n",
            "Batch Loss: 0.380664,  Batch Accuracy: 91.41   [44800/54000]\n",
            "Batch Loss: 0.258357,  Batch Accuracy: 90.62   [46080/54000]\n",
            "Batch Loss: 0.170634,  Batch Accuracy: 92.97   [47360/54000]\n",
            "Batch Loss: 0.303650,  Batch Accuracy: 91.41   [48640/54000]\n",
            "Batch Loss: 0.187538,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.275194,  Batch Accuracy: 90.62   [51200/54000]\n",
            "Batch Loss: 0.222148,  Batch Accuracy: 93.75   [52480/54000]\n",
            "Batch Loss: 0.368945,  Batch Accuracy: 89.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 91.6%, Loss: 0.293948\n",
            "Validation performance: \n",
            " Accuracy: 91.8%, Loss: 0.286280\n",
            "Test performance: \n",
            " Accuracy: 91.8%, Loss: 0.275575 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Batch Loss: 0.229875,  Batch Accuracy: 93.75   [ 1280/54000]\n",
            "Batch Loss: 0.251231,  Batch Accuracy: 91.41   [ 2560/54000]\n",
            "Batch Loss: 0.266124,  Batch Accuracy: 92.97   [ 3840/54000]\n",
            "Batch Loss: 0.254164,  Batch Accuracy: 92.97   [ 5120/54000]\n",
            "Batch Loss: 0.255063,  Batch Accuracy: 93.75   [ 6400/54000]\n",
            "Batch Loss: 0.334714,  Batch Accuracy: 92.19   [ 7680/54000]\n",
            "Batch Loss: 0.242913,  Batch Accuracy: 92.19   [ 8960/54000]\n",
            "Batch Loss: 0.164734,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.271731,  Batch Accuracy: 93.75   [11520/54000]\n",
            "Batch Loss: 0.219750,  Batch Accuracy: 92.19   [12800/54000]\n",
            "Batch Loss: 0.248978,  Batch Accuracy: 92.19   [14080/54000]\n",
            "Batch Loss: 0.189469,  Batch Accuracy: 96.88   [15360/54000]\n",
            "Batch Loss: 0.271509,  Batch Accuracy: 92.19   [16640/54000]\n",
            "Batch Loss: 0.219401,  Batch Accuracy: 92.19   [17920/54000]\n",
            "Batch Loss: 0.259522,  Batch Accuracy: 89.84   [19200/54000]\n",
            "Batch Loss: 0.225371,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.299798,  Batch Accuracy: 93.75   [21760/54000]\n",
            "Batch Loss: 0.284371,  Batch Accuracy: 92.97   [23040/54000]\n",
            "Batch Loss: 0.349337,  Batch Accuracy: 89.84   [24320/54000]\n",
            "Batch Loss: 0.135237,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.246577,  Batch Accuracy: 93.75   [26880/54000]\n",
            "Batch Loss: 0.319265,  Batch Accuracy: 90.62   [28160/54000]\n",
            "Batch Loss: 0.265406,  Batch Accuracy: 92.97   [29440/54000]\n",
            "Batch Loss: 0.226578,  Batch Accuracy: 92.19   [30720/54000]\n",
            "Batch Loss: 0.246498,  Batch Accuracy: 92.19   [32000/54000]\n",
            "Batch Loss: 0.242526,  Batch Accuracy: 91.41   [33280/54000]\n",
            "Batch Loss: 0.384466,  Batch Accuracy: 89.84   [34560/54000]\n",
            "Batch Loss: 0.340290,  Batch Accuracy: 92.97   [35840/54000]\n",
            "Batch Loss: 0.162487,  Batch Accuracy: 93.75   [37120/54000]\n",
            "Batch Loss: 0.210523,  Batch Accuracy: 93.75   [38400/54000]\n",
            "Batch Loss: 0.249939,  Batch Accuracy: 91.41   [39680/54000]\n",
            "Batch Loss: 0.340383,  Batch Accuracy: 88.28   [40960/54000]\n",
            "Batch Loss: 0.189675,  Batch Accuracy: 90.62   [42240/54000]\n",
            "Batch Loss: 0.209660,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.307328,  Batch Accuracy: 90.62   [44800/54000]\n",
            "Batch Loss: 0.205568,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.400111,  Batch Accuracy: 85.94   [47360/54000]\n",
            "Batch Loss: 0.313107,  Batch Accuracy: 88.28   [48640/54000]\n",
            "Batch Loss: 0.345546,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.269486,  Batch Accuracy: 92.97   [51200/54000]\n",
            "Batch Loss: 0.228246,  Batch Accuracy: 92.19   [52480/54000]\n",
            "Batch Loss: 0.205007,  Batch Accuracy: 92.97   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 92.4%, Loss: 0.269174\n",
            "Validation performance: \n",
            " Accuracy: 92.5%, Loss: 0.265826\n",
            "Test performance: \n",
            " Accuracy: 92.3%, Loss: 0.256523 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Batch Loss: 0.172798,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.255040,  Batch Accuracy: 92.19   [ 2560/54000]\n",
            "Batch Loss: 0.199998,  Batch Accuracy: 94.53   [ 3840/54000]\n",
            "Batch Loss: 0.274891,  Batch Accuracy: 92.19   [ 5120/54000]\n",
            "Batch Loss: 0.133030,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.196955,  Batch Accuracy: 93.75   [ 7680/54000]\n",
            "Batch Loss: 0.280308,  Batch Accuracy: 96.09   [ 8960/54000]\n",
            "Batch Loss: 0.343820,  Batch Accuracy: 89.06   [10240/54000]\n",
            "Batch Loss: 0.250819,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.274656,  Batch Accuracy: 93.75   [12800/54000]\n",
            "Batch Loss: 0.221773,  Batch Accuracy: 92.97   [14080/54000]\n",
            "Batch Loss: 0.238249,  Batch Accuracy: 92.19   [15360/54000]\n",
            "Batch Loss: 0.208865,  Batch Accuracy: 93.75   [16640/54000]\n",
            "Batch Loss: 0.277589,  Batch Accuracy: 92.19   [17920/54000]\n",
            "Batch Loss: 0.194172,  Batch Accuracy: 95.31   [19200/54000]\n",
            "Batch Loss: 0.204179,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.244860,  Batch Accuracy: 92.97   [21760/54000]\n",
            "Batch Loss: 0.247624,  Batch Accuracy: 95.31   [23040/54000]\n",
            "Batch Loss: 0.386499,  Batch Accuracy: 89.06   [24320/54000]\n",
            "Batch Loss: 0.277009,  Batch Accuracy: 90.62   [25600/54000]\n",
            "Batch Loss: 0.289280,  Batch Accuracy: 92.97   [26880/54000]\n",
            "Batch Loss: 0.350963,  Batch Accuracy: 89.84   [28160/54000]\n",
            "Batch Loss: 0.276095,  Batch Accuracy: 90.62   [29440/54000]\n",
            "Batch Loss: 0.433846,  Batch Accuracy: 86.72   [30720/54000]\n",
            "Batch Loss: 0.209067,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.176878,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.181359,  Batch Accuracy: 95.31   [34560/54000]\n",
            "Batch Loss: 0.233050,  Batch Accuracy: 94.53   [35840/54000]\n",
            "Batch Loss: 0.152702,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.225798,  Batch Accuracy: 92.97   [38400/54000]\n",
            "Batch Loss: 0.170694,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.371315,  Batch Accuracy: 89.84   [40960/54000]\n",
            "Batch Loss: 0.192107,  Batch Accuracy: 92.97   [42240/54000]\n",
            "Batch Loss: 0.173754,  Batch Accuracy: 93.75   [43520/54000]\n",
            "Batch Loss: 0.278330,  Batch Accuracy: 91.41   [44800/54000]\n",
            "Batch Loss: 0.223985,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.119500,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.228728,  Batch Accuracy: 92.97   [48640/54000]\n",
            "Batch Loss: 0.360923,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.326505,  Batch Accuracy: 89.84   [51200/54000]\n",
            "Batch Loss: 0.243598,  Batch Accuracy: 92.97   [52480/54000]\n",
            "Batch Loss: 0.245245,  Batch Accuracy: 92.97   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 92.9%, Loss: 0.249964\n",
            "Validation performance: \n",
            " Accuracy: 92.8%, Loss: 0.249532\n",
            "Test performance: \n",
            " Accuracy: 93.0%, Loss: 0.241534 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Batch Loss: 0.302804,  Batch Accuracy: 92.19   [ 1280/54000]\n",
            "Batch Loss: 0.285236,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.337946,  Batch Accuracy: 89.06   [ 3840/54000]\n",
            "Batch Loss: 0.321881,  Batch Accuracy: 89.06   [ 5120/54000]\n",
            "Batch Loss: 0.161208,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.165584,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.224928,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.176444,  Batch Accuracy: 94.53   [10240/54000]\n",
            "Batch Loss: 0.306935,  Batch Accuracy: 90.62   [11520/54000]\n",
            "Batch Loss: 0.182119,  Batch Accuracy: 94.53   [12800/54000]\n",
            "Batch Loss: 0.279607,  Batch Accuracy: 92.97   [14080/54000]\n",
            "Batch Loss: 0.257308,  Batch Accuracy: 92.97   [15360/54000]\n",
            "Batch Loss: 0.183326,  Batch Accuracy: 92.97   [16640/54000]\n",
            "Batch Loss: 0.189660,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.259921,  Batch Accuracy: 92.19   [19200/54000]\n",
            "Batch Loss: 0.229362,  Batch Accuracy: 92.97   [20480/54000]\n",
            "Batch Loss: 0.257359,  Batch Accuracy: 92.97   [21760/54000]\n",
            "Batch Loss: 0.210572,  Batch Accuracy: 96.09   [23040/54000]\n",
            "Batch Loss: 0.307488,  Batch Accuracy: 90.62   [24320/54000]\n",
            "Batch Loss: 0.311915,  Batch Accuracy: 91.41   [25600/54000]\n",
            "Batch Loss: 0.174979,  Batch Accuracy: 94.53   [26880/54000]\n",
            "Batch Loss: 0.354976,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.225621,  Batch Accuracy: 94.53   [29440/54000]\n",
            "Batch Loss: 0.258270,  Batch Accuracy: 93.75   [30720/54000]\n",
            "Batch Loss: 0.250708,  Batch Accuracy: 96.09   [32000/54000]\n",
            "Batch Loss: 0.260277,  Batch Accuracy: 92.19   [33280/54000]\n",
            "Batch Loss: 0.272760,  Batch Accuracy: 92.19   [34560/54000]\n",
            "Batch Loss: 0.209618,  Batch Accuracy: 92.19   [35840/54000]\n",
            "Batch Loss: 0.176301,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.251166,  Batch Accuracy: 93.75   [38400/54000]\n",
            "Batch Loss: 0.140329,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.177301,  Batch Accuracy: 92.97   [40960/54000]\n",
            "Batch Loss: 0.222690,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.243905,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.230528,  Batch Accuracy: 94.53   [44800/54000]\n",
            "Batch Loss: 0.161040,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.259208,  Batch Accuracy: 90.62   [47360/54000]\n",
            "Batch Loss: 0.224521,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.319492,  Batch Accuracy: 93.75   [49920/54000]\n",
            "Batch Loss: 0.205801,  Batch Accuracy: 93.75   [51200/54000]\n",
            "Batch Loss: 0.216961,  Batch Accuracy: 92.19   [52480/54000]\n",
            "Batch Loss: 0.205546,  Batch Accuracy: 91.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 93.3%, Loss: 0.234553\n",
            "Validation performance: \n",
            " Accuracy: 93.2%, Loss: 0.238406\n",
            "Test performance: \n",
            " Accuracy: 93.2%, Loss: 0.231593 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Batch Loss: 0.336262,  Batch Accuracy: 89.84   [ 1280/54000]\n",
            "Batch Loss: 0.304196,  Batch Accuracy: 92.19   [ 2560/54000]\n",
            "Batch Loss: 0.339527,  Batch Accuracy: 88.28   [ 3840/54000]\n",
            "Batch Loss: 0.288335,  Batch Accuracy: 91.41   [ 5120/54000]\n",
            "Batch Loss: 0.224589,  Batch Accuracy: 94.53   [ 6400/54000]\n",
            "Batch Loss: 0.216306,  Batch Accuracy: 92.97   [ 7680/54000]\n",
            "Batch Loss: 0.157243,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.167428,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.176243,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.170136,  Batch Accuracy: 95.31   [12800/54000]\n",
            "Batch Loss: 0.171866,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.194429,  Batch Accuracy: 93.75   [15360/54000]\n",
            "Batch Loss: 0.232718,  Batch Accuracy: 92.97   [16640/54000]\n",
            "Batch Loss: 0.230585,  Batch Accuracy: 91.41   [17920/54000]\n",
            "Batch Loss: 0.211449,  Batch Accuracy: 93.75   [19200/54000]\n",
            "Batch Loss: 0.284009,  Batch Accuracy: 92.97   [20480/54000]\n",
            "Batch Loss: 0.207340,  Batch Accuracy: 93.75   [21760/54000]\n",
            "Batch Loss: 0.166866,  Batch Accuracy: 94.53   [23040/54000]\n",
            "Batch Loss: 0.209560,  Batch Accuracy: 92.19   [24320/54000]\n",
            "Batch Loss: 0.143988,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.131518,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.284393,  Batch Accuracy: 90.62   [28160/54000]\n",
            "Batch Loss: 0.221879,  Batch Accuracy: 93.75   [29440/54000]\n",
            "Batch Loss: 0.261935,  Batch Accuracy: 92.97   [30720/54000]\n",
            "Batch Loss: 0.180942,  Batch Accuracy: 94.53   [32000/54000]\n",
            "Batch Loss: 0.209726,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.200244,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.263970,  Batch Accuracy: 92.19   [35840/54000]\n",
            "Batch Loss: 0.181517,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.141519,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.223556,  Batch Accuracy: 92.97   [39680/54000]\n",
            "Batch Loss: 0.091412,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.295437,  Batch Accuracy: 89.06   [42240/54000]\n",
            "Batch Loss: 0.197798,  Batch Accuracy: 93.75   [43520/54000]\n",
            "Batch Loss: 0.226785,  Batch Accuracy: 91.41   [44800/54000]\n",
            "Batch Loss: 0.341403,  Batch Accuracy: 91.41   [46080/54000]\n",
            "Batch Loss: 0.204180,  Batch Accuracy: 95.31   [47360/54000]\n",
            "Batch Loss: 0.290502,  Batch Accuracy: 92.97   [48640/54000]\n",
            "Batch Loss: 0.173256,  Batch Accuracy: 94.53   [49920/54000]\n",
            "Batch Loss: 0.204791,  Batch Accuracy: 92.97   [51200/54000]\n",
            "Batch Loss: 0.137738,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.239254,  Batch Accuracy: 93.75   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 93.7%, Loss: 0.221435\n",
            "Validation performance: \n",
            " Accuracy: 93.5%, Loss: 0.227770\n",
            "Test performance: \n",
            " Accuracy: 93.7%, Loss: 0.219609 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Batch Loss: 0.292042,  Batch Accuracy: 92.97   [ 1280/54000]\n",
            "Batch Loss: 0.128293,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.173208,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.163813,  Batch Accuracy: 92.19   [ 5120/54000]\n",
            "Batch Loss: 0.230401,  Batch Accuracy: 92.19   [ 6400/54000]\n",
            "Batch Loss: 0.193904,  Batch Accuracy: 95.31   [ 7680/54000]\n",
            "Batch Loss: 0.210566,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.288235,  Batch Accuracy: 91.41   [10240/54000]\n",
            "Batch Loss: 0.277711,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.187540,  Batch Accuracy: 94.53   [12800/54000]\n",
            "Batch Loss: 0.212455,  Batch Accuracy: 93.75   [14080/54000]\n",
            "Batch Loss: 0.124936,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.259136,  Batch Accuracy: 93.75   [16640/54000]\n",
            "Batch Loss: 0.377520,  Batch Accuracy: 88.28   [17920/54000]\n",
            "Batch Loss: 0.198603,  Batch Accuracy: 95.31   [19200/54000]\n",
            "Batch Loss: 0.341205,  Batch Accuracy: 89.84   [20480/54000]\n",
            "Batch Loss: 0.218663,  Batch Accuracy: 92.97   [21760/54000]\n",
            "Batch Loss: 0.184361,  Batch Accuracy: 96.09   [23040/54000]\n",
            "Batch Loss: 0.201786,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.179862,  Batch Accuracy: 93.75   [25600/54000]\n",
            "Batch Loss: 0.121534,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.243110,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.275038,  Batch Accuracy: 93.75   [29440/54000]\n",
            "Batch Loss: 0.249859,  Batch Accuracy: 92.97   [30720/54000]\n",
            "Batch Loss: 0.222035,  Batch Accuracy: 91.41   [32000/54000]\n",
            "Batch Loss: 0.248653,  Batch Accuracy: 92.19   [33280/54000]\n",
            "Batch Loss: 0.288526,  Batch Accuracy: 91.41   [34560/54000]\n",
            "Batch Loss: 0.445375,  Batch Accuracy: 90.62   [35840/54000]\n",
            "Batch Loss: 0.214334,  Batch Accuracy: 92.19   [37120/54000]\n",
            "Batch Loss: 0.212868,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.196821,  Batch Accuracy: 95.31   [39680/54000]\n",
            "Batch Loss: 0.138210,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.152327,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.210389,  Batch Accuracy: 93.75   [43520/54000]\n",
            "Batch Loss: 0.184184,  Batch Accuracy: 95.31   [44800/54000]\n",
            "Batch Loss: 0.100963,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.183872,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.241757,  Batch Accuracy: 92.97   [48640/54000]\n",
            "Batch Loss: 0.099142,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.190514,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.296459,  Batch Accuracy: 89.84   [52480/54000]\n",
            "Batch Loss: 0.213497,  Batch Accuracy: 93.75   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 94.0%, Loss: 0.210250\n",
            "Validation performance: \n",
            " Accuracy: 93.8%, Loss: 0.217656\n",
            "Test performance: \n",
            " Accuracy: 93.8%, Loss: 0.210593 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Batch Loss: 0.310639,  Batch Accuracy: 90.62   [ 1280/54000]\n",
            "Batch Loss: 0.248187,  Batch Accuracy: 90.62   [ 2560/54000]\n",
            "Batch Loss: 0.080132,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.177604,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.149350,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.192958,  Batch Accuracy: 93.75   [ 7680/54000]\n",
            "Batch Loss: 0.234457,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.234993,  Batch Accuracy: 92.97   [10240/54000]\n",
            "Batch Loss: 0.308570,  Batch Accuracy: 90.62   [11520/54000]\n",
            "Batch Loss: 0.171025,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.139532,  Batch Accuracy: 95.31   [14080/54000]\n",
            "Batch Loss: 0.210914,  Batch Accuracy: 96.88   [15360/54000]\n",
            "Batch Loss: 0.309921,  Batch Accuracy: 90.62   [16640/54000]\n",
            "Batch Loss: 0.262327,  Batch Accuracy: 92.19   [17920/54000]\n",
            "Batch Loss: 0.198307,  Batch Accuracy: 95.31   [19200/54000]\n",
            "Batch Loss: 0.286811,  Batch Accuracy: 91.41   [20480/54000]\n",
            "Batch Loss: 0.314190,  Batch Accuracy: 89.06   [21760/54000]\n",
            "Batch Loss: 0.207382,  Batch Accuracy: 93.75   [23040/54000]\n",
            "Batch Loss: 0.258632,  Batch Accuracy: 91.41   [24320/54000]\n",
            "Batch Loss: 0.134259,  Batch Accuracy: 94.53   [25600/54000]\n",
            "Batch Loss: 0.095737,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.298803,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.139607,  Batch Accuracy: 94.53   [29440/54000]\n",
            "Batch Loss: 0.258970,  Batch Accuracy: 93.75   [30720/54000]\n",
            "Batch Loss: 0.215371,  Batch Accuracy: 93.75   [32000/54000]\n",
            "Batch Loss: 0.198879,  Batch Accuracy: 93.75   [33280/54000]\n",
            "Batch Loss: 0.223511,  Batch Accuracy: 92.19   [34560/54000]\n",
            "Batch Loss: 0.303062,  Batch Accuracy: 92.97   [35840/54000]\n",
            "Batch Loss: 0.218206,  Batch Accuracy: 96.88   [37120/54000]\n",
            "Batch Loss: 0.140484,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.270462,  Batch Accuracy: 92.19   [39680/54000]\n",
            "Batch Loss: 0.193155,  Batch Accuracy: 94.53   [40960/54000]\n",
            "Batch Loss: 0.258779,  Batch Accuracy: 93.75   [42240/54000]\n",
            "Batch Loss: 0.189901,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.228942,  Batch Accuracy: 93.75   [44800/54000]\n",
            "Batch Loss: 0.185932,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.118882,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.158725,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.209312,  Batch Accuracy: 93.75   [49920/54000]\n",
            "Batch Loss: 0.297620,  Batch Accuracy: 93.75   [51200/54000]\n",
            "Batch Loss: 0.125571,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.189569,  Batch Accuracy: 94.53   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 94.3%, Loss: 0.200284\n",
            "Validation performance: \n",
            " Accuracy: 93.9%, Loss: 0.210800\n",
            "Test performance: \n",
            " Accuracy: 94.1%, Loss: 0.203019 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Batch Loss: 0.148186,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.139946,  Batch Accuracy: 95.31   [ 2560/54000]\n",
            "Batch Loss: 0.175686,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.207422,  Batch Accuracy: 93.75   [ 5120/54000]\n",
            "Batch Loss: 0.120681,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.212131,  Batch Accuracy: 92.97   [ 7680/54000]\n",
            "Batch Loss: 0.212932,  Batch Accuracy: 93.75   [ 8960/54000]\n",
            "Batch Loss: 0.171931,  Batch Accuracy: 93.75   [10240/54000]\n",
            "Batch Loss: 0.143064,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.178481,  Batch Accuracy: 94.53   [12800/54000]\n",
            "Batch Loss: 0.187839,  Batch Accuracy: 95.31   [14080/54000]\n",
            "Batch Loss: 0.102869,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.118579,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.209922,  Batch Accuracy: 93.75   [17920/54000]\n",
            "Batch Loss: 0.144548,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.137994,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.138522,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.188248,  Batch Accuracy: 94.53   [23040/54000]\n",
            "Batch Loss: 0.161057,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.260857,  Batch Accuracy: 92.97   [25600/54000]\n",
            "Batch Loss: 0.099548,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.130698,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.170512,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.149660,  Batch Accuracy: 94.53   [30720/54000]\n",
            "Batch Loss: 0.188280,  Batch Accuracy: 92.97   [32000/54000]\n",
            "Batch Loss: 0.108465,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.086692,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.252624,  Batch Accuracy: 93.75   [35840/54000]\n",
            "Batch Loss: 0.156115,  Batch Accuracy: 95.31   [37120/54000]\n",
            "Batch Loss: 0.187089,  Batch Accuracy: 94.53   [38400/54000]\n",
            "Batch Loss: 0.243141,  Batch Accuracy: 92.97   [39680/54000]\n",
            "Batch Loss: 0.185293,  Batch Accuracy: 95.31   [40960/54000]\n",
            "Batch Loss: 0.307898,  Batch Accuracy: 90.62   [42240/54000]\n",
            "Batch Loss: 0.140836,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.225249,  Batch Accuracy: 93.75   [44800/54000]\n",
            "Batch Loss: 0.127309,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.187157,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.270392,  Batch Accuracy: 91.41   [48640/54000]\n",
            "Batch Loss: 0.181832,  Batch Accuracy: 93.75   [49920/54000]\n",
            "Batch Loss: 0.231593,  Batch Accuracy: 92.19   [51200/54000]\n",
            "Batch Loss: 0.182147,  Batch Accuracy: 93.75   [52480/54000]\n",
            "Batch Loss: 0.195038,  Batch Accuracy: 95.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 94.5%, Loss: 0.191313\n",
            "Validation performance: \n",
            " Accuracy: 94.0%, Loss: 0.205543\n",
            "Test performance: \n",
            " Accuracy: 94.2%, Loss: 0.198391 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Batch Loss: 0.193364,  Batch Accuracy: 94.53   [ 1280/54000]\n",
            "Batch Loss: 0.205908,  Batch Accuracy: 92.97   [ 2560/54000]\n",
            "Batch Loss: 0.151155,  Batch Accuracy: 95.31   [ 3840/54000]\n",
            "Batch Loss: 0.138168,  Batch Accuracy: 94.53   [ 5120/54000]\n",
            "Batch Loss: 0.194070,  Batch Accuracy: 92.19   [ 6400/54000]\n",
            "Batch Loss: 0.094662,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.221243,  Batch Accuracy: 92.19   [ 8960/54000]\n",
            "Batch Loss: 0.279837,  Batch Accuracy: 92.19   [10240/54000]\n",
            "Batch Loss: 0.177003,  Batch Accuracy: 94.53   [11520/54000]\n",
            "Batch Loss: 0.222232,  Batch Accuracy: 92.19   [12800/54000]\n",
            "Batch Loss: 0.108135,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.147718,  Batch Accuracy: 96.09   [15360/54000]\n",
            "Batch Loss: 0.147967,  Batch Accuracy: 93.75   [16640/54000]\n",
            "Batch Loss: 0.140720,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.119319,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.151006,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.239084,  Batch Accuracy: 91.41   [21760/54000]\n",
            "Batch Loss: 0.198809,  Batch Accuracy: 96.09   [23040/54000]\n",
            "Batch Loss: 0.146692,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.277823,  Batch Accuracy: 92.19   [25600/54000]\n",
            "Batch Loss: 0.226563,  Batch Accuracy: 93.75   [26880/54000]\n",
            "Batch Loss: 0.109629,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.104904,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.210822,  Batch Accuracy: 92.97   [30720/54000]\n",
            "Batch Loss: 0.305510,  Batch Accuracy: 93.75   [32000/54000]\n",
            "Batch Loss: 0.174255,  Batch Accuracy: 93.75   [33280/54000]\n",
            "Batch Loss: 0.232013,  Batch Accuracy: 93.75   [34560/54000]\n",
            "Batch Loss: 0.232113,  Batch Accuracy: 91.41   [35840/54000]\n",
            "Batch Loss: 0.151119,  Batch Accuracy: 95.31   [37120/54000]\n",
            "Batch Loss: 0.172410,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.208520,  Batch Accuracy: 93.75   [39680/54000]\n",
            "Batch Loss: 0.107485,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.106796,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.327323,  Batch Accuracy: 91.41   [43520/54000]\n",
            "Batch Loss: 0.181356,  Batch Accuracy: 95.31   [44800/54000]\n",
            "Batch Loss: 0.117258,  Batch Accuracy: 96.88   [46080/54000]\n",
            "Batch Loss: 0.148249,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.231608,  Batch Accuracy: 93.75   [48640/54000]\n",
            "Batch Loss: 0.277042,  Batch Accuracy: 91.41   [49920/54000]\n",
            "Batch Loss: 0.139050,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.155589,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.325937,  Batch Accuracy: 90.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 94.8%, Loss: 0.183618\n",
            "Validation performance: \n",
            " Accuracy: 94.1%, Loss: 0.201206\n",
            "Test performance: \n",
            " Accuracy: 94.3%, Loss: 0.194716 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Batch Loss: 0.272025,  Batch Accuracy: 94.53   [ 1280/54000]\n",
            "Batch Loss: 0.196114,  Batch Accuracy: 91.41   [ 2560/54000]\n",
            "Batch Loss: 0.141147,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.177577,  Batch Accuracy: 95.31   [ 5120/54000]\n",
            "Batch Loss: 0.185160,  Batch Accuracy: 94.53   [ 6400/54000]\n",
            "Batch Loss: 0.213294,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.216411,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.173463,  Batch Accuracy: 94.53   [10240/54000]\n",
            "Batch Loss: 0.174558,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.088317,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.212852,  Batch Accuracy: 92.97   [14080/54000]\n",
            "Batch Loss: 0.184834,  Batch Accuracy: 92.97   [15360/54000]\n",
            "Batch Loss: 0.127031,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.164361,  Batch Accuracy: 92.97   [17920/54000]\n",
            "Batch Loss: 0.235692,  Batch Accuracy: 94.53   [19200/54000]\n",
            "Batch Loss: 0.111493,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.109000,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.248019,  Batch Accuracy: 94.53   [23040/54000]\n",
            "Batch Loss: 0.237450,  Batch Accuracy: 92.19   [24320/54000]\n",
            "Batch Loss: 0.135723,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.121960,  Batch Accuracy: 96.88   [26880/54000]\n",
            "Batch Loss: 0.157342,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.158683,  Batch Accuracy: 95.31   [29440/54000]\n",
            "Batch Loss: 0.112006,  Batch Accuracy: 95.31   [30720/54000]\n",
            "Batch Loss: 0.106524,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.161702,  Batch Accuracy: 93.75   [33280/54000]\n",
            "Batch Loss: 0.203537,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.232767,  Batch Accuracy: 92.19   [35840/54000]\n",
            "Batch Loss: 0.188628,  Batch Accuracy: 92.97   [37120/54000]\n",
            "Batch Loss: 0.101621,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.153075,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.100487,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.130645,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.221818,  Batch Accuracy: 92.19   [43520/54000]\n",
            "Batch Loss: 0.178612,  Batch Accuracy: 92.97   [44800/54000]\n",
            "Batch Loss: 0.149868,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.104971,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.117092,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.145188,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.162571,  Batch Accuracy: 91.41   [51200/54000]\n",
            "Batch Loss: 0.127722,  Batch Accuracy: 96.09   [52480/54000]\n",
            "Batch Loss: 0.177784,  Batch Accuracy: 94.53   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 94.9%, Loss: 0.176401\n",
            "Validation performance: \n",
            " Accuracy: 94.4%, Loss: 0.190716\n",
            "Test performance: \n",
            " Accuracy: 94.5%, Loss: 0.185597 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Batch Loss: 0.133522,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.152522,  Batch Accuracy: 95.31   [ 2560/54000]\n",
            "Batch Loss: 0.110772,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.160663,  Batch Accuracy: 94.53   [ 5120/54000]\n",
            "Batch Loss: 0.155703,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.105750,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.270729,  Batch Accuracy: 89.84   [ 8960/54000]\n",
            "Batch Loss: 0.194488,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.213601,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.162805,  Batch Accuracy: 94.53   [12800/54000]\n",
            "Batch Loss: 0.146375,  Batch Accuracy: 94.53   [14080/54000]\n",
            "Batch Loss: 0.173941,  Batch Accuracy: 92.19   [15360/54000]\n",
            "Batch Loss: 0.114847,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.143295,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.221359,  Batch Accuracy: 91.41   [19200/54000]\n",
            "Batch Loss: 0.282997,  Batch Accuracy: 92.19   [20480/54000]\n",
            "Batch Loss: 0.214483,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.196801,  Batch Accuracy: 95.31   [23040/54000]\n",
            "Batch Loss: 0.161865,  Batch Accuracy: 94.53   [24320/54000]\n",
            "Batch Loss: 0.185478,  Batch Accuracy: 94.53   [25600/54000]\n",
            "Batch Loss: 0.187850,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.252051,  Batch Accuracy: 90.62   [28160/54000]\n",
            "Batch Loss: 0.220581,  Batch Accuracy: 92.97   [29440/54000]\n",
            "Batch Loss: 0.247144,  Batch Accuracy: 92.19   [30720/54000]\n",
            "Batch Loss: 0.068321,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.218812,  Batch Accuracy: 93.75   [33280/54000]\n",
            "Batch Loss: 0.148688,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.139507,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.238859,  Batch Accuracy: 92.97   [37120/54000]\n",
            "Batch Loss: 0.152274,  Batch Accuracy: 94.53   [38400/54000]\n",
            "Batch Loss: 0.114612,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.134474,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.228937,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.150352,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.251206,  Batch Accuracy: 92.97   [44800/54000]\n",
            "Batch Loss: 0.174051,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.179142,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.152002,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.117011,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.088659,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.085239,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.150670,  Batch Accuracy: 95.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.1%, Loss: 0.170066\n",
            "Validation performance: \n",
            " Accuracy: 94.6%, Loss: 0.187665\n",
            "Test performance: \n",
            " Accuracy: 94.6%, Loss: 0.180567 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Batch Loss: 0.227023,  Batch Accuracy: 91.41   [ 1280/54000]\n",
            "Batch Loss: 0.108668,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.134729,  Batch Accuracy: 94.53   [ 3840/54000]\n",
            "Batch Loss: 0.143714,  Batch Accuracy: 93.75   [ 5120/54000]\n",
            "Batch Loss: 0.202247,  Batch Accuracy: 92.19   [ 6400/54000]\n",
            "Batch Loss: 0.195954,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.143438,  Batch Accuracy: 92.97   [ 8960/54000]\n",
            "Batch Loss: 0.127369,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.177922,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.138673,  Batch Accuracy: 95.31   [12800/54000]\n",
            "Batch Loss: 0.161365,  Batch Accuracy: 95.31   [14080/54000]\n",
            "Batch Loss: 0.171323,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.290763,  Batch Accuracy: 92.19   [16640/54000]\n",
            "Batch Loss: 0.205671,  Batch Accuracy: 93.75   [17920/54000]\n",
            "Batch Loss: 0.184404,  Batch Accuracy: 95.31   [19200/54000]\n",
            "Batch Loss: 0.140584,  Batch Accuracy: 95.31   [20480/54000]\n",
            "Batch Loss: 0.120701,  Batch Accuracy: 95.31   [21760/54000]\n",
            "Batch Loss: 0.124932,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.136924,  Batch Accuracy: 94.53   [24320/54000]\n",
            "Batch Loss: 0.128613,  Batch Accuracy: 95.31   [25600/54000]\n",
            "Batch Loss: 0.217161,  Batch Accuracy: 94.53   [26880/54000]\n",
            "Batch Loss: 0.187589,  Batch Accuracy: 93.75   [28160/54000]\n",
            "Batch Loss: 0.220931,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.238897,  Batch Accuracy: 92.97   [30720/54000]\n",
            "Batch Loss: 0.142834,  Batch Accuracy: 96.09   [32000/54000]\n",
            "Batch Loss: 0.215430,  Batch Accuracy: 91.41   [33280/54000]\n",
            "Batch Loss: 0.243446,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.160720,  Batch Accuracy: 95.31   [35840/54000]\n",
            "Batch Loss: 0.198045,  Batch Accuracy: 93.75   [37120/54000]\n",
            "Batch Loss: 0.097779,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.168863,  Batch Accuracy: 95.31   [39680/54000]\n",
            "Batch Loss: 0.158077,  Batch Accuracy: 94.53   [40960/54000]\n",
            "Batch Loss: 0.142681,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.187020,  Batch Accuracy: 93.75   [43520/54000]\n",
            "Batch Loss: 0.211055,  Batch Accuracy: 94.53   [44800/54000]\n",
            "Batch Loss: 0.180975,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.239878,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.149271,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.129963,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.149562,  Batch Accuracy: 96.88   [51200/54000]\n",
            "Batch Loss: 0.077039,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.086302,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.3%, Loss: 0.163991\n",
            "Validation performance: \n",
            " Accuracy: 94.7%, Loss: 0.180763\n",
            "Test performance: \n",
            " Accuracy: 94.7%, Loss: 0.175433 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Batch Loss: 0.142398,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.105392,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.259987,  Batch Accuracy: 94.53   [ 3840/54000]\n",
            "Batch Loss: 0.193021,  Batch Accuracy: 95.31   [ 5120/54000]\n",
            "Batch Loss: 0.092072,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.166047,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.120952,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.286411,  Batch Accuracy: 91.41   [10240/54000]\n",
            "Batch Loss: 0.188219,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.170342,  Batch Accuracy: 92.97   [12800/54000]\n",
            "Batch Loss: 0.082986,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.292555,  Batch Accuracy: 93.75   [15360/54000]\n",
            "Batch Loss: 0.096403,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.142375,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.098597,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.165519,  Batch Accuracy: 93.75   [20480/54000]\n",
            "Batch Loss: 0.089578,  Batch Accuracy: 96.88   [21760/54000]\n",
            "Batch Loss: 0.202453,  Batch Accuracy: 92.97   [23040/54000]\n",
            "Batch Loss: 0.188197,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.129128,  Batch Accuracy: 95.31   [25600/54000]\n",
            "Batch Loss: 0.079094,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.104816,  Batch Accuracy: 99.22   [28160/54000]\n",
            "Batch Loss: 0.254490,  Batch Accuracy: 94.53   [29440/54000]\n",
            "Batch Loss: 0.148163,  Batch Accuracy: 94.53   [30720/54000]\n",
            "Batch Loss: 0.115988,  Batch Accuracy: 94.53   [32000/54000]\n",
            "Batch Loss: 0.055925,  Batch Accuracy: 100.00   [33280/54000]\n",
            "Batch Loss: 0.197868,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.237819,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.138551,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.191377,  Batch Accuracy: 94.53   [38400/54000]\n",
            "Batch Loss: 0.249971,  Batch Accuracy: 92.19   [39680/54000]\n",
            "Batch Loss: 0.107343,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.100592,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.077529,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.213845,  Batch Accuracy: 94.53   [44800/54000]\n",
            "Batch Loss: 0.178105,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.187074,  Batch Accuracy: 92.97   [47360/54000]\n",
            "Batch Loss: 0.113327,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.071295,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.266747,  Batch Accuracy: 93.75   [51200/54000]\n",
            "Batch Loss: 0.131451,  Batch Accuracy: 96.09   [52480/54000]\n",
            "Batch Loss: 0.089181,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.5%, Loss: 0.158146\n",
            "Validation performance: \n",
            " Accuracy: 94.7%, Loss: 0.179377\n",
            "Test performance: \n",
            " Accuracy: 94.7%, Loss: 0.172991 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Batch Loss: 0.086548,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.183314,  Batch Accuracy: 92.97   [ 2560/54000]\n",
            "Batch Loss: 0.116178,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.123845,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.143685,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.283585,  Batch Accuracy: 93.75   [ 7680/54000]\n",
            "Batch Loss: 0.161212,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.180924,  Batch Accuracy: 96.09   [10240/54000]\n",
            "Batch Loss: 0.304918,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.083479,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.085147,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.118935,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.140556,  Batch Accuracy: 95.31   [16640/54000]\n",
            "Batch Loss: 0.141241,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.119467,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.092674,  Batch Accuracy: 95.31   [20480/54000]\n",
            "Batch Loss: 0.116428,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.094426,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.181504,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.116808,  Batch Accuracy: 95.31   [25600/54000]\n",
            "Batch Loss: 0.106973,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.173652,  Batch Accuracy: 95.31   [28160/54000]\n",
            "Batch Loss: 0.175640,  Batch Accuracy: 94.53   [29440/54000]\n",
            "Batch Loss: 0.175091,  Batch Accuracy: 92.97   [30720/54000]\n",
            "Batch Loss: 0.149620,  Batch Accuracy: 96.09   [32000/54000]\n",
            "Batch Loss: 0.180855,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.135440,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.124975,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.156134,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.127628,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.102126,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.273414,  Batch Accuracy: 90.62   [40960/54000]\n",
            "Batch Loss: 0.125998,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.100416,  Batch Accuracy: 97.66   [43520/54000]\n",
            "Batch Loss: 0.193115,  Batch Accuracy: 92.97   [44800/54000]\n",
            "Batch Loss: 0.135325,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.169963,  Batch Accuracy: 96.09   [47360/54000]\n",
            "Batch Loss: 0.193512,  Batch Accuracy: 94.53   [48640/54000]\n",
            "Batch Loss: 0.295685,  Batch Accuracy: 90.62   [49920/54000]\n",
            "Batch Loss: 0.139474,  Batch Accuracy: 94.53   [51200/54000]\n",
            "Batch Loss: 0.107434,  Batch Accuracy: 96.09   [52480/54000]\n",
            "Batch Loss: 0.141234,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.6%, Loss: 0.153258\n",
            "Validation performance: \n",
            " Accuracy: 94.9%, Loss: 0.172652\n",
            "Test performance: \n",
            " Accuracy: 94.9%, Loss: 0.167326 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Batch Loss: 0.133316,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.281607,  Batch Accuracy: 89.84   [ 2560/54000]\n",
            "Batch Loss: 0.058543,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.124923,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.116153,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.152861,  Batch Accuracy: 93.75   [ 7680/54000]\n",
            "Batch Loss: 0.205312,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.159928,  Batch Accuracy: 96.09   [10240/54000]\n",
            "Batch Loss: 0.121203,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.178615,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.296173,  Batch Accuracy: 91.41   [14080/54000]\n",
            "Batch Loss: 0.111027,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.142119,  Batch Accuracy: 95.31   [16640/54000]\n",
            "Batch Loss: 0.094832,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.159689,  Batch Accuracy: 94.53   [19200/54000]\n",
            "Batch Loss: 0.282433,  Batch Accuracy: 94.53   [20480/54000]\n",
            "Batch Loss: 0.126588,  Batch Accuracy: 96.88   [21760/54000]\n",
            "Batch Loss: 0.134610,  Batch Accuracy: 96.09   [23040/54000]\n",
            "Batch Loss: 0.139827,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.171137,  Batch Accuracy: 93.75   [25600/54000]\n",
            "Batch Loss: 0.149219,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.092333,  Batch Accuracy: 96.88   [28160/54000]\n",
            "Batch Loss: 0.225744,  Batch Accuracy: 91.41   [29440/54000]\n",
            "Batch Loss: 0.229195,  Batch Accuracy: 91.41   [30720/54000]\n",
            "Batch Loss: 0.112822,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.065446,  Batch Accuracy: 98.44   [33280/54000]\n",
            "Batch Loss: 0.322140,  Batch Accuracy: 92.19   [34560/54000]\n",
            "Batch Loss: 0.120526,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.094475,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.099173,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.108005,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.111890,  Batch Accuracy: 95.31   [40960/54000]\n",
            "Batch Loss: 0.179793,  Batch Accuracy: 94.53   [42240/54000]\n",
            "Batch Loss: 0.157339,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.129949,  Batch Accuracy: 96.09   [44800/54000]\n",
            "Batch Loss: 0.181012,  Batch Accuracy: 92.19   [46080/54000]\n",
            "Batch Loss: 0.121295,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.163235,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.138411,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.112998,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.147075,  Batch Accuracy: 93.75   [52480/54000]\n",
            "Batch Loss: 0.166808,  Batch Accuracy: 94.53   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.7%, Loss: 0.148394\n",
            "Validation performance: \n",
            " Accuracy: 94.9%, Loss: 0.171190\n",
            "Test performance: \n",
            " Accuracy: 95.1%, Loss: 0.165846 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Batch Loss: 0.179306,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.128660,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.101187,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.124709,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.157251,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.108349,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.161583,  Batch Accuracy: 97.66   [ 8960/54000]\n",
            "Batch Loss: 0.094282,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.137282,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.156573,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.161867,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.062030,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.134987,  Batch Accuracy: 94.53   [16640/54000]\n",
            "Batch Loss: 0.124651,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.151938,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.097399,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.241581,  Batch Accuracy: 92.97   [21760/54000]\n",
            "Batch Loss: 0.147372,  Batch Accuracy: 96.09   [23040/54000]\n",
            "Batch Loss: 0.086076,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.167659,  Batch Accuracy: 94.53   [25600/54000]\n",
            "Batch Loss: 0.153371,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.127018,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.203691,  Batch Accuracy: 92.97   [29440/54000]\n",
            "Batch Loss: 0.087318,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.099429,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.089527,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.175373,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.067086,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.143875,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.176879,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.138920,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.119781,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.195775,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.236095,  Batch Accuracy: 92.19   [43520/54000]\n",
            "Batch Loss: 0.065483,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.155287,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.102016,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.120772,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.081107,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.087832,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.195792,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.092711,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 95.9%, Loss: 0.143957\n",
            "Validation performance: \n",
            " Accuracy: 95.0%, Loss: 0.166209\n",
            "Test performance: \n",
            " Accuracy: 95.2%, Loss: 0.161741 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Batch Loss: 0.147848,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.058595,  Batch Accuracy: 99.22   [ 2560/54000]\n",
            "Batch Loss: 0.073416,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.043371,  Batch Accuracy: 99.22   [ 5120/54000]\n",
            "Batch Loss: 0.079155,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.167963,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.168146,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.141983,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.130631,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.140611,  Batch Accuracy: 95.31   [12800/54000]\n",
            "Batch Loss: 0.139328,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.145309,  Batch Accuracy: 93.75   [15360/54000]\n",
            "Batch Loss: 0.102239,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.146527,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.125259,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.097565,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.085167,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.128872,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.108100,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.124501,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.115713,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.140185,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.058248,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.169098,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.180018,  Batch Accuracy: 91.41   [32000/54000]\n",
            "Batch Loss: 0.187419,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.059579,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.107396,  Batch Accuracy: 94.53   [35840/54000]\n",
            "Batch Loss: 0.235316,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.197586,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.128786,  Batch Accuracy: 94.53   [39680/54000]\n",
            "Batch Loss: 0.082480,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.189115,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.224783,  Batch Accuracy: 93.75   [43520/54000]\n",
            "Batch Loss: 0.138257,  Batch Accuracy: 94.53   [44800/54000]\n",
            "Batch Loss: 0.154144,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.124861,  Batch Accuracy: 92.97   [47360/54000]\n",
            "Batch Loss: 0.143035,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.077476,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.124934,  Batch Accuracy: 96.88   [51200/54000]\n",
            "Batch Loss: 0.086907,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.105749,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.0%, Loss: 0.139564\n",
            "Validation performance: \n",
            " Accuracy: 95.2%, Loss: 0.163365\n",
            "Test performance: \n",
            " Accuracy: 95.2%, Loss: 0.158348 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Batch Loss: 0.237913,  Batch Accuracy: 92.19   [ 1280/54000]\n",
            "Batch Loss: 0.093368,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.093859,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.100079,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.118558,  Batch Accuracy: 95.31   [ 6400/54000]\n",
            "Batch Loss: 0.166604,  Batch Accuracy: 95.31   [ 7680/54000]\n",
            "Batch Loss: 0.187500,  Batch Accuracy: 92.97   [ 8960/54000]\n",
            "Batch Loss: 0.144899,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.139789,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.102837,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.072419,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.117427,  Batch Accuracy: 96.09   [15360/54000]\n",
            "Batch Loss: 0.115243,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.097370,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.099407,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.101921,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.164560,  Batch Accuracy: 93.75   [21760/54000]\n",
            "Batch Loss: 0.084581,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.144167,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.102001,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.175534,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.227255,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.122651,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.079392,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.151511,  Batch Accuracy: 96.09   [32000/54000]\n",
            "Batch Loss: 0.083804,  Batch Accuracy: 96.88   [33280/54000]\n",
            "Batch Loss: 0.117868,  Batch Accuracy: 95.31   [34560/54000]\n",
            "Batch Loss: 0.067921,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.095486,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.145918,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.131400,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.160792,  Batch Accuracy: 92.97   [40960/54000]\n",
            "Batch Loss: 0.118412,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.213007,  Batch Accuracy: 92.97   [43520/54000]\n",
            "Batch Loss: 0.150157,  Batch Accuracy: 94.53   [44800/54000]\n",
            "Batch Loss: 0.215601,  Batch Accuracy: 93.75   [46080/54000]\n",
            "Batch Loss: 0.207233,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.107249,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.128994,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.143400,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.167345,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.152089,  Batch Accuracy: 95.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.1%, Loss: 0.135423\n",
            "Validation performance: \n",
            " Accuracy: 95.3%, Loss: 0.160744\n",
            "Test performance: \n",
            " Accuracy: 95.1%, Loss: 0.155388 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Batch Loss: 0.132884,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.215959,  Batch Accuracy: 94.53   [ 2560/54000]\n",
            "Batch Loss: 0.057256,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.159713,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.144020,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.113445,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.074571,  Batch Accuracy: 97.66   [ 8960/54000]\n",
            "Batch Loss: 0.124690,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.114689,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.089857,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.184271,  Batch Accuracy: 93.75   [14080/54000]\n",
            "Batch Loss: 0.100197,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.102194,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.136708,  Batch Accuracy: 94.53   [17920/54000]\n",
            "Batch Loss: 0.135661,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.089202,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.097454,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.129757,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.094669,  Batch Accuracy: 97.66   [24320/54000]\n",
            "Batch Loss: 0.108420,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.135305,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.088052,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.065649,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.039439,  Batch Accuracy: 100.00   [30720/54000]\n",
            "Batch Loss: 0.103929,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.163968,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.080413,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.202404,  Batch Accuracy: 94.53   [35840/54000]\n",
            "Batch Loss: 0.084792,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.107167,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.144433,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.105486,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.207141,  Batch Accuracy: 93.75   [42240/54000]\n",
            "Batch Loss: 0.150913,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.098830,  Batch Accuracy: 95.31   [44800/54000]\n",
            "Batch Loss: 0.152926,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.089819,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.132908,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.100295,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.135930,  Batch Accuracy: 96.88   [51200/54000]\n",
            "Batch Loss: 0.184949,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.089185,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.2%, Loss: 0.131578\n",
            "Validation performance: \n",
            " Accuracy: 95.3%, Loss: 0.156982\n",
            "Test performance: \n",
            " Accuracy: 95.5%, Loss: 0.151400 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Batch Loss: 0.065843,  Batch Accuracy: 99.22   [ 1280/54000]\n",
            "Batch Loss: 0.194856,  Batch Accuracy: 95.31   [ 2560/54000]\n",
            "Batch Loss: 0.202645,  Batch Accuracy: 92.19   [ 3840/54000]\n",
            "Batch Loss: 0.093448,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.104978,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.169100,  Batch Accuracy: 95.31   [ 7680/54000]\n",
            "Batch Loss: 0.138843,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.151313,  Batch Accuracy: 96.09   [10240/54000]\n",
            "Batch Loss: 0.189221,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.102583,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.098783,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.097078,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.104781,  Batch Accuracy: 95.31   [16640/54000]\n",
            "Batch Loss: 0.139785,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.076504,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.166738,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.106341,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.042673,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.123782,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.154726,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.125590,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.089186,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.100009,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.106306,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.117621,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.150588,  Batch Accuracy: 96.09   [33280/54000]\n",
            "Batch Loss: 0.055273,  Batch Accuracy: 99.22   [34560/54000]\n",
            "Batch Loss: 0.163630,  Batch Accuracy: 96.09   [35840/54000]\n",
            "Batch Loss: 0.061244,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.110566,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.109070,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.121111,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.151115,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.158484,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.130005,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.274641,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.111665,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.079272,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.169551,  Batch Accuracy: 94.53   [49920/54000]\n",
            "Batch Loss: 0.072054,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.141475,  Batch Accuracy: 96.09   [52480/54000]\n",
            "Batch Loss: 0.083885,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.4%, Loss: 0.128097\n",
            "Validation performance: \n",
            " Accuracy: 95.5%, Loss: 0.155211\n",
            "Test performance: \n",
            " Accuracy: 95.5%, Loss: 0.151292 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Batch Loss: 0.078615,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.084423,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.189294,  Batch Accuracy: 95.31   [ 3840/54000]\n",
            "Batch Loss: 0.123137,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.161566,  Batch Accuracy: 95.31   [ 6400/54000]\n",
            "Batch Loss: 0.157594,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.181100,  Batch Accuracy: 93.75   [ 8960/54000]\n",
            "Batch Loss: 0.121887,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.067637,  Batch Accuracy: 99.22   [11520/54000]\n",
            "Batch Loss: 0.092949,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.118133,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.087187,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.125411,  Batch Accuracy: 96.09   [16640/54000]\n",
            "Batch Loss: 0.118327,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.134121,  Batch Accuracy: 92.19   [19200/54000]\n",
            "Batch Loss: 0.195426,  Batch Accuracy: 95.31   [20480/54000]\n",
            "Batch Loss: 0.129592,  Batch Accuracy: 95.31   [21760/54000]\n",
            "Batch Loss: 0.222177,  Batch Accuracy: 95.31   [23040/54000]\n",
            "Batch Loss: 0.073278,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.126304,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.171957,  Batch Accuracy: 93.75   [26880/54000]\n",
            "Batch Loss: 0.104631,  Batch Accuracy: 95.31   [28160/54000]\n",
            "Batch Loss: 0.132660,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.094009,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.109424,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.077346,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.097690,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.096270,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.191220,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.136270,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.089918,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.096545,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.175396,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.146574,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.151951,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.107177,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.094530,  Batch Accuracy: 96.09   [47360/54000]\n",
            "Batch Loss: 0.076434,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.151346,  Batch Accuracy: 95.31   [49920/54000]\n",
            "Batch Loss: 0.173572,  Batch Accuracy: 95.31   [51200/54000]\n",
            "Batch Loss: 0.085563,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.088353,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.5%, Loss: 0.124595\n",
            "Validation performance: \n",
            " Accuracy: 95.5%, Loss: 0.153083\n",
            "Test performance: \n",
            " Accuracy: 95.5%, Loss: 0.147579 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Batch Loss: 0.142952,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.083044,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.168908,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.181580,  Batch Accuracy: 93.75   [ 5120/54000]\n",
            "Batch Loss: 0.143524,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.100489,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.141331,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.105396,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.099140,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.114744,  Batch Accuracy: 95.31   [12800/54000]\n",
            "Batch Loss: 0.074418,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.085734,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.141399,  Batch Accuracy: 95.31   [16640/54000]\n",
            "Batch Loss: 0.070334,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.121906,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.067601,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.068724,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.077464,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.122198,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.054941,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.070019,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.233658,  Batch Accuracy: 94.53   [28160/54000]\n",
            "Batch Loss: 0.092911,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.106699,  Batch Accuracy: 95.31   [30720/54000]\n",
            "Batch Loss: 0.097731,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.151936,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.212047,  Batch Accuracy: 92.97   [34560/54000]\n",
            "Batch Loss: 0.208616,  Batch Accuracy: 93.75   [35840/54000]\n",
            "Batch Loss: 0.070072,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.096762,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.087647,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.113678,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.097550,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.107435,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.075094,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.090593,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.140507,  Batch Accuracy: 94.53   [47360/54000]\n",
            "Batch Loss: 0.104779,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.173349,  Batch Accuracy: 94.53   [49920/54000]\n",
            "Batch Loss: 0.082945,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.121087,  Batch Accuracy: 96.88   [52480/54000]\n",
            "Batch Loss: 0.137699,  Batch Accuracy: 96.09   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.5%, Loss: 0.121407\n",
            "Validation performance: \n",
            " Accuracy: 95.6%, Loss: 0.150107\n",
            "Test performance: \n",
            " Accuracy: 95.6%, Loss: 0.144377 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Batch Loss: 0.103396,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.128863,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.155695,  Batch Accuracy: 94.53   [ 3840/54000]\n",
            "Batch Loss: 0.120328,  Batch Accuracy: 95.31   [ 5120/54000]\n",
            "Batch Loss: 0.133171,  Batch Accuracy: 95.31   [ 6400/54000]\n",
            "Batch Loss: 0.211938,  Batch Accuracy: 92.19   [ 7680/54000]\n",
            "Batch Loss: 0.080295,  Batch Accuracy: 97.66   [ 8960/54000]\n",
            "Batch Loss: 0.118900,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.161470,  Batch Accuracy: 94.53   [11520/54000]\n",
            "Batch Loss: 0.110948,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.110400,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.173531,  Batch Accuracy: 93.75   [15360/54000]\n",
            "Batch Loss: 0.108749,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.151266,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.186632,  Batch Accuracy: 95.31   [19200/54000]\n",
            "Batch Loss: 0.108942,  Batch Accuracy: 97.66   [20480/54000]\n",
            "Batch Loss: 0.044495,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.068766,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.086746,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.114128,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.077259,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.054722,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.084430,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.107357,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.115484,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.170047,  Batch Accuracy: 92.97   [33280/54000]\n",
            "Batch Loss: 0.185850,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.068443,  Batch Accuracy: 99.22   [35840/54000]\n",
            "Batch Loss: 0.080951,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.063958,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.082554,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.098888,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.077894,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.122646,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.117011,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.107795,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.135123,  Batch Accuracy: 96.09   [47360/54000]\n",
            "Batch Loss: 0.102564,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.157739,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.103688,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.150889,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.112349,  Batch Accuracy: 95.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.6%, Loss: 0.118273\n",
            "Validation performance: \n",
            " Accuracy: 95.7%, Loss: 0.148369\n",
            "Test performance: \n",
            " Accuracy: 95.7%, Loss: 0.142873 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Batch Loss: 0.155345,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.105964,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.155252,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.097246,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.090040,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.138858,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.131782,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.102186,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.081748,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.110256,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.094429,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.186219,  Batch Accuracy: 94.53   [15360/54000]\n",
            "Batch Loss: 0.088506,  Batch Accuracy: 96.09   [16640/54000]\n",
            "Batch Loss: 0.121961,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.157718,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.129441,  Batch Accuracy: 94.53   [20480/54000]\n",
            "Batch Loss: 0.073669,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.115309,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.102376,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.072013,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.094952,  Batch Accuracy: 96.88   [26880/54000]\n",
            "Batch Loss: 0.110163,  Batch Accuracy: 93.75   [28160/54000]\n",
            "Batch Loss: 0.132955,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.094933,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.138738,  Batch Accuracy: 94.53   [32000/54000]\n",
            "Batch Loss: 0.077136,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.142160,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.111708,  Batch Accuracy: 95.31   [35840/54000]\n",
            "Batch Loss: 0.104083,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.100860,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.161433,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.122281,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.133574,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.171111,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.096854,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.200279,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.153472,  Batch Accuracy: 95.31   [47360/54000]\n",
            "Batch Loss: 0.153794,  Batch Accuracy: 93.75   [48640/54000]\n",
            "Batch Loss: 0.109218,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.125129,  Batch Accuracy: 95.31   [51200/54000]\n",
            "Batch Loss: 0.142049,  Batch Accuracy: 96.88   [52480/54000]\n",
            "Batch Loss: 0.165561,  Batch Accuracy: 94.53   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.7%, Loss: 0.115119\n",
            "Validation performance: \n",
            " Accuracy: 95.7%, Loss: 0.147123\n",
            "Test performance: \n",
            " Accuracy: 95.7%, Loss: 0.141681 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Batch Loss: 0.099038,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.103786,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.065266,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.100904,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.086156,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.096284,  Batch Accuracy: 97.66   [ 7680/54000]\n",
            "Batch Loss: 0.187517,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.086416,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.127717,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.191275,  Batch Accuracy: 92.19   [12800/54000]\n",
            "Batch Loss: 0.147706,  Batch Accuracy: 95.31   [14080/54000]\n",
            "Batch Loss: 0.144650,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.102693,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.094154,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.104415,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.061753,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.109066,  Batch Accuracy: 96.88   [21760/54000]\n",
            "Batch Loss: 0.074186,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.188516,  Batch Accuracy: 92.19   [24320/54000]\n",
            "Batch Loss: 0.157527,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.082737,  Batch Accuracy: 96.88   [26880/54000]\n",
            "Batch Loss: 0.081007,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.119374,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.078989,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.126739,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.135917,  Batch Accuracy: 96.09   [33280/54000]\n",
            "Batch Loss: 0.060061,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.128791,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.104553,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.056751,  Batch Accuracy: 100.00   [38400/54000]\n",
            "Batch Loss: 0.138287,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.124835,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.092869,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.155306,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.072304,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.142177,  Batch Accuracy: 96.88   [46080/54000]\n",
            "Batch Loss: 0.103725,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.094204,  Batch Accuracy: 96.09   [48640/54000]\n",
            "Batch Loss: 0.122102,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.132505,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.065645,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.185977,  Batch Accuracy: 93.75   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.8%, Loss: 0.112535\n",
            "Validation performance: \n",
            " Accuracy: 95.8%, Loss: 0.143918\n",
            "Test performance: \n",
            " Accuracy: 95.7%, Loss: 0.140072 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Batch Loss: 0.133545,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.155229,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.161397,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.138357,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.108264,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.149189,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.141647,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.116455,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.094785,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.109245,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.090261,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.131869,  Batch Accuracy: 92.97   [15360/54000]\n",
            "Batch Loss: 0.094396,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.056663,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.049385,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.083622,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.143811,  Batch Accuracy: 94.53   [21760/54000]\n",
            "Batch Loss: 0.066600,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.075861,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.110628,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.099367,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.139389,  Batch Accuracy: 94.53   [28160/54000]\n",
            "Batch Loss: 0.068349,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.100216,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.121730,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.097120,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.117249,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.092348,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.064667,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.087179,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.064595,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.077856,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.113395,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.101574,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.134336,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.060215,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.180357,  Batch Accuracy: 93.75   [47360/54000]\n",
            "Batch Loss: 0.154032,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.238637,  Batch Accuracy: 95.31   [49920/54000]\n",
            "Batch Loss: 0.088819,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.107575,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.175031,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 96.9%, Loss: 0.109780\n",
            "Validation performance: \n",
            " Accuracy: 95.8%, Loss: 0.141427\n",
            "Test performance: \n",
            " Accuracy: 95.9%, Loss: 0.137127 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Batch Loss: 0.182760,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.163970,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.104238,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.182904,  Batch Accuracy: 93.75   [ 5120/54000]\n",
            "Batch Loss: 0.108214,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.124024,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.111943,  Batch Accuracy: 96.09   [ 8960/54000]\n",
            "Batch Loss: 0.107808,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.113706,  Batch Accuracy: 99.22   [11520/54000]\n",
            "Batch Loss: 0.116108,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.108439,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.154334,  Batch Accuracy: 93.75   [15360/54000]\n",
            "Batch Loss: 0.146851,  Batch Accuracy: 93.75   [16640/54000]\n",
            "Batch Loss: 0.210510,  Batch Accuracy: 93.75   [17920/54000]\n",
            "Batch Loss: 0.111492,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.075516,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.123131,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.120075,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.088993,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.094205,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.158588,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.149135,  Batch Accuracy: 95.31   [28160/54000]\n",
            "Batch Loss: 0.093294,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.052549,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.069945,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.095625,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.077213,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.105275,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.112642,  Batch Accuracy: 96.88   [37120/54000]\n",
            "Batch Loss: 0.089495,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.066971,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.139569,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.170934,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.105881,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.078679,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.092020,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.091047,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.099465,  Batch Accuracy: 96.09   [48640/54000]\n",
            "Batch Loss: 0.130294,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.073399,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.067278,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.062926,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.0%, Loss: 0.107133\n",
            "Validation performance: \n",
            " Accuracy: 96.0%, Loss: 0.141081\n",
            "Test performance: \n",
            " Accuracy: 95.9%, Loss: 0.135815 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Batch Loss: 0.103665,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.049302,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.057277,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.172609,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.150404,  Batch Accuracy: 95.31   [ 6400/54000]\n",
            "Batch Loss: 0.172958,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.073657,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.127283,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.154294,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.124151,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.118347,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.185742,  Batch Accuracy: 94.53   [15360/54000]\n",
            "Batch Loss: 0.028045,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.096782,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.046238,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.065260,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.229400,  Batch Accuracy: 94.53   [21760/54000]\n",
            "Batch Loss: 0.143610,  Batch Accuracy: 95.31   [23040/54000]\n",
            "Batch Loss: 0.118952,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.050432,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.210611,  Batch Accuracy: 92.19   [26880/54000]\n",
            "Batch Loss: 0.122027,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.052992,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.154554,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.104555,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.131737,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.159913,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.107839,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.150924,  Batch Accuracy: 95.31   [37120/54000]\n",
            "Batch Loss: 0.204194,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.113090,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.097569,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.050396,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.074672,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.143954,  Batch Accuracy: 96.09   [44800/54000]\n",
            "Batch Loss: 0.100539,  Batch Accuracy: 96.88   [46080/54000]\n",
            "Batch Loss: 0.168965,  Batch Accuracy: 96.09   [47360/54000]\n",
            "Batch Loss: 0.165312,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.133868,  Batch Accuracy: 94.53   [49920/54000]\n",
            "Batch Loss: 0.200714,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.046341,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.092364,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.0%, Loss: 0.104728\n",
            "Validation performance: \n",
            " Accuracy: 96.0%, Loss: 0.138898\n",
            "Test performance: \n",
            " Accuracy: 96.0%, Loss: 0.133663 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Batch Loss: 0.107216,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.125243,  Batch Accuracy: 95.31   [ 2560/54000]\n",
            "Batch Loss: 0.177002,  Batch Accuracy: 94.53   [ 3840/54000]\n",
            "Batch Loss: 0.143594,  Batch Accuracy: 96.09   [ 5120/54000]\n",
            "Batch Loss: 0.081416,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.079445,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.156319,  Batch Accuracy: 92.97   [ 8960/54000]\n",
            "Batch Loss: 0.042309,  Batch Accuracy: 99.22   [10240/54000]\n",
            "Batch Loss: 0.102530,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.173951,  Batch Accuracy: 95.31   [12800/54000]\n",
            "Batch Loss: 0.080518,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.108336,  Batch Accuracy: 96.88   [15360/54000]\n",
            "Batch Loss: 0.083068,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.089107,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.060930,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.110619,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.100908,  Batch Accuracy: 96.88   [21760/54000]\n",
            "Batch Loss: 0.075966,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.101442,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.157350,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.126847,  Batch Accuracy: 96.88   [26880/54000]\n",
            "Batch Loss: 0.144569,  Batch Accuracy: 96.88   [28160/54000]\n",
            "Batch Loss: 0.168232,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.179132,  Batch Accuracy: 94.53   [30720/54000]\n",
            "Batch Loss: 0.105274,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.112782,  Batch Accuracy: 96.88   [33280/54000]\n",
            "Batch Loss: 0.074782,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.139596,  Batch Accuracy: 94.53   [35840/54000]\n",
            "Batch Loss: 0.124844,  Batch Accuracy: 96.09   [37120/54000]\n",
            "Batch Loss: 0.119341,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.191039,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.099890,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.118938,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.112109,  Batch Accuracy: 99.22   [43520/54000]\n",
            "Batch Loss: 0.077615,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.092750,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.067525,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.068694,  Batch Accuracy: 96.09   [48640/54000]\n",
            "Batch Loss: 0.085043,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.112607,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.076429,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.096289,  Batch Accuracy: 95.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.1%, Loss: 0.102385\n",
            "Validation performance: \n",
            " Accuracy: 96.0%, Loss: 0.137254\n",
            "Test performance: \n",
            " Accuracy: 96.0%, Loss: 0.132506 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Batch Loss: 0.105524,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.092003,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.102669,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.077598,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.105341,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.104063,  Batch Accuracy: 97.66   [ 7680/54000]\n",
            "Batch Loss: 0.051106,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.110383,  Batch Accuracy: 94.53   [10240/54000]\n",
            "Batch Loss: 0.114345,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.109894,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.186562,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.154565,  Batch Accuracy: 96.88   [15360/54000]\n",
            "Batch Loss: 0.106828,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.140701,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.085285,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.102852,  Batch Accuracy: 97.66   [20480/54000]\n",
            "Batch Loss: 0.065982,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.101070,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.098509,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.065496,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.108565,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.102943,  Batch Accuracy: 96.88   [28160/54000]\n",
            "Batch Loss: 0.120832,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.077029,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.133906,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.056309,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.102283,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.117697,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.107715,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.087339,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.068479,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.170727,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.123831,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.133997,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.102115,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.064550,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.056384,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.091813,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.057031,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.147993,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.071140,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.122085,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.2%, Loss: 0.099934\n",
            "Validation performance: \n",
            " Accuracy: 96.1%, Loss: 0.135252\n",
            "Test performance: \n",
            " Accuracy: 96.1%, Loss: 0.131607 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Batch Loss: 0.267783,  Batch Accuracy: 93.75   [ 1280/54000]\n",
            "Batch Loss: 0.077793,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.058240,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.091694,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.103445,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.072863,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.131997,  Batch Accuracy: 96.09   [ 8960/54000]\n",
            "Batch Loss: 0.110433,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.071351,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.082307,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.159974,  Batch Accuracy: 94.53   [14080/54000]\n",
            "Batch Loss: 0.150850,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.067990,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.063903,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.131644,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.041500,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.101032,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.082995,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.095948,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.091182,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.072057,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.110443,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.067681,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.066673,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.178522,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.118342,  Batch Accuracy: 96.09   [33280/54000]\n",
            "Batch Loss: 0.074843,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.133871,  Batch Accuracy: 96.09   [35840/54000]\n",
            "Batch Loss: 0.084200,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.105078,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.164178,  Batch Accuracy: 94.53   [39680/54000]\n",
            "Batch Loss: 0.122478,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.101292,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.057954,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.097461,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.076138,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.090801,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.113737,  Batch Accuracy: 95.31   [48640/54000]\n",
            "Batch Loss: 0.061183,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.066392,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.088343,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.061831,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.3%, Loss: 0.097747\n",
            "Validation performance: \n",
            " Accuracy: 96.2%, Loss: 0.134665\n",
            "Test performance: \n",
            " Accuracy: 96.1%, Loss: 0.128901 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Batch Loss: 0.104888,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.094012,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.068844,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.086385,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.085186,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.092552,  Batch Accuracy: 97.66   [ 7680/54000]\n",
            "Batch Loss: 0.118710,  Batch Accuracy: 96.09   [ 8960/54000]\n",
            "Batch Loss: 0.060882,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.174092,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.112424,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.092864,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.053210,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.062280,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.053349,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.068703,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.167728,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.073257,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.058469,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.171685,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.158119,  Batch Accuracy: 93.75   [25600/54000]\n",
            "Batch Loss: 0.106844,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.098401,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.105457,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.164488,  Batch Accuracy: 93.75   [30720/54000]\n",
            "Batch Loss: 0.103694,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.043602,  Batch Accuracy: 100.00   [33280/54000]\n",
            "Batch Loss: 0.103348,  Batch Accuracy: 94.53   [34560/54000]\n",
            "Batch Loss: 0.040762,  Batch Accuracy: 99.22   [35840/54000]\n",
            "Batch Loss: 0.036772,  Batch Accuracy: 100.00   [37120/54000]\n",
            "Batch Loss: 0.102904,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.064613,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.075622,  Batch Accuracy: 99.22   [40960/54000]\n",
            "Batch Loss: 0.042047,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.094182,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.044597,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.053174,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.042401,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.092602,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.077437,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.157620,  Batch Accuracy: 94.53   [51200/54000]\n",
            "Batch Loss: 0.117309,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.060005,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.3%, Loss: 0.095604\n",
            "Validation performance: \n",
            " Accuracy: 96.2%, Loss: 0.132815\n",
            "Test performance: \n",
            " Accuracy: 96.1%, Loss: 0.128068 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Batch Loss: 0.124032,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.059827,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.152796,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.059665,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.046095,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.093199,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.133120,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.154582,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.084673,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.071621,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.073958,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.081700,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.062437,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.124173,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.067817,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.029382,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.071216,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.161226,  Batch Accuracy: 93.75   [23040/54000]\n",
            "Batch Loss: 0.076065,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.145251,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.065062,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.165579,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.141517,  Batch Accuracy: 95.31   [29440/54000]\n",
            "Batch Loss: 0.052785,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.132147,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.048174,  Batch Accuracy: 99.22   [33280/54000]\n",
            "Batch Loss: 0.087494,  Batch Accuracy: 99.22   [34560/54000]\n",
            "Batch Loss: 0.091083,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.143273,  Batch Accuracy: 94.53   [37120/54000]\n",
            "Batch Loss: 0.072224,  Batch Accuracy: 98.44   [38400/54000]\n",
            "Batch Loss: 0.076071,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.134410,  Batch Accuracy: 93.75   [40960/54000]\n",
            "Batch Loss: 0.126170,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.049905,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.070705,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.069617,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.078623,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.090417,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.101501,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.058053,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.061024,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.095738,  Batch Accuracy: 96.09   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.4%, Loss: 0.093375\n",
            "Validation performance: \n",
            " Accuracy: 96.2%, Loss: 0.133658\n",
            "Test performance: \n",
            " Accuracy: 96.2%, Loss: 0.127956 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Batch Loss: 0.075049,  Batch Accuracy: 98.44   [ 1280/54000]\n",
            "Batch Loss: 0.120497,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.020132,  Batch Accuracy: 100.00   [ 3840/54000]\n",
            "Batch Loss: 0.088020,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.050338,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.068196,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.122331,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.065291,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.075460,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.192692,  Batch Accuracy: 94.53   [12800/54000]\n",
            "Batch Loss: 0.028300,  Batch Accuracy: 100.00   [14080/54000]\n",
            "Batch Loss: 0.070140,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.074034,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.097509,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.067953,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.133349,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.075689,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.095266,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.038229,  Batch Accuracy: 100.00   [24320/54000]\n",
            "Batch Loss: 0.098179,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.060843,  Batch Accuracy: 99.22   [26880/54000]\n",
            "Batch Loss: 0.047332,  Batch Accuracy: 99.22   [28160/54000]\n",
            "Batch Loss: 0.122069,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.062570,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.176211,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.089201,  Batch Accuracy: 96.88   [33280/54000]\n",
            "Batch Loss: 0.051185,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.095741,  Batch Accuracy: 96.09   [35840/54000]\n",
            "Batch Loss: 0.148722,  Batch Accuracy: 96.88   [37120/54000]\n",
            "Batch Loss: 0.063091,  Batch Accuracy: 98.44   [38400/54000]\n",
            "Batch Loss: 0.099572,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.067986,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.076431,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.169032,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.036362,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.075422,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.141744,  Batch Accuracy: 95.31   [47360/54000]\n",
            "Batch Loss: 0.056547,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.070057,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.100105,  Batch Accuracy: 94.53   [51200/54000]\n",
            "Batch Loss: 0.152807,  Batch Accuracy: 96.09   [52480/54000]\n",
            "Batch Loss: 0.099016,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.5%, Loss: 0.091443\n",
            "Validation performance: \n",
            " Accuracy: 96.2%, Loss: 0.130221\n",
            "Test performance: \n",
            " Accuracy: 96.2%, Loss: 0.125109 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Batch Loss: 0.073491,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.067709,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.114071,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.055934,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.051606,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.086508,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.140725,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.087575,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.078560,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.043845,  Batch Accuracy: 99.22   [12800/54000]\n",
            "Batch Loss: 0.055149,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.138797,  Batch Accuracy: 96.09   [15360/54000]\n",
            "Batch Loss: 0.057525,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.054573,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.156509,  Batch Accuracy: 93.75   [19200/54000]\n",
            "Batch Loss: 0.079226,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.191910,  Batch Accuracy: 93.75   [21760/54000]\n",
            "Batch Loss: 0.100722,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.078188,  Batch Accuracy: 97.66   [24320/54000]\n",
            "Batch Loss: 0.041108,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.094248,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.162540,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.154331,  Batch Accuracy: 95.31   [29440/54000]\n",
            "Batch Loss: 0.087348,  Batch Accuracy: 96.09   [30720/54000]\n",
            "Batch Loss: 0.076638,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.138021,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.150409,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.103480,  Batch Accuracy: 95.31   [35840/54000]\n",
            "Batch Loss: 0.061507,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.113280,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.030699,  Batch Accuracy: 100.00   [39680/54000]\n",
            "Batch Loss: 0.058215,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.118579,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.063730,  Batch Accuracy: 97.66   [43520/54000]\n",
            "Batch Loss: 0.085169,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.118450,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.084283,  Batch Accuracy: 97.66   [47360/54000]\n",
            "Batch Loss: 0.103600,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.137771,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.147625,  Batch Accuracy: 96.09   [51200/54000]\n",
            "Batch Loss: 0.033731,  Batch Accuracy: 100.00   [52480/54000]\n",
            "Batch Loss: 0.079481,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.5%, Loss: 0.089444\n",
            "Validation performance: \n",
            " Accuracy: 96.4%, Loss: 0.129599\n",
            "Test performance: \n",
            " Accuracy: 96.3%, Loss: 0.123459 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Batch Loss: 0.084186,  Batch Accuracy: 98.44   [ 1280/54000]\n",
            "Batch Loss: 0.079951,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.106605,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.075004,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.044710,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.058246,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.052484,  Batch Accuracy: 100.00   [ 8960/54000]\n",
            "Batch Loss: 0.049046,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.132694,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.064682,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.087456,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.075803,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.076510,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.074628,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.061583,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.055139,  Batch Accuracy: 99.22   [20480/54000]\n",
            "Batch Loss: 0.063752,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.073289,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.101237,  Batch Accuracy: 99.22   [24320/54000]\n",
            "Batch Loss: 0.028990,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.073164,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.067600,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.091216,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.062408,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.038654,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.078931,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.079036,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.138101,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.125570,  Batch Accuracy: 95.31   [37120/54000]\n",
            "Batch Loss: 0.041737,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.150875,  Batch Accuracy: 96.88   [39680/54000]\n",
            "Batch Loss: 0.204923,  Batch Accuracy: 95.31   [40960/54000]\n",
            "Batch Loss: 0.100548,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.073879,  Batch Accuracy: 99.22   [43520/54000]\n",
            "Batch Loss: 0.069598,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.076490,  Batch Accuracy: 96.09   [46080/54000]\n",
            "Batch Loss: 0.081716,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.054652,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.064743,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.168186,  Batch Accuracy: 95.31   [51200/54000]\n",
            "Batch Loss: 0.040291,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.084802,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.6%, Loss: 0.087545\n",
            "Validation performance: \n",
            " Accuracy: 96.3%, Loss: 0.127050\n",
            "Test performance: \n",
            " Accuracy: 96.3%, Loss: 0.123264 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Batch Loss: 0.074323,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.030932,  Batch Accuracy: 100.00   [ 2560/54000]\n",
            "Batch Loss: 0.091319,  Batch Accuracy: 96.09   [ 3840/54000]\n",
            "Batch Loss: 0.065533,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.099893,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.072680,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.061898,  Batch Accuracy: 99.22   [ 8960/54000]\n",
            "Batch Loss: 0.036818,  Batch Accuracy: 100.00   [10240/54000]\n",
            "Batch Loss: 0.069261,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.098619,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.064396,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.099369,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.122019,  Batch Accuracy: 96.09   [16640/54000]\n",
            "Batch Loss: 0.121687,  Batch Accuracy: 95.31   [17920/54000]\n",
            "Batch Loss: 0.052261,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.152342,  Batch Accuracy: 94.53   [20480/54000]\n",
            "Batch Loss: 0.084617,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.113833,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.136568,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.033700,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.055297,  Batch Accuracy: 99.22   [26880/54000]\n",
            "Batch Loss: 0.077701,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.086436,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.072578,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.050501,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.070720,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.139317,  Batch Accuracy: 95.31   [34560/54000]\n",
            "Batch Loss: 0.102594,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.040066,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.107581,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.071850,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.046021,  Batch Accuracy: 99.22   [40960/54000]\n",
            "Batch Loss: 0.117656,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.167760,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.061740,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.065638,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.044248,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.036910,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.022670,  Batch Accuracy: 100.00   [49920/54000]\n",
            "Batch Loss: 0.053813,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.062306,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.068744,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.7%, Loss: 0.085785\n",
            "Validation performance: \n",
            " Accuracy: 96.3%, Loss: 0.126877\n",
            "Test performance: \n",
            " Accuracy: 96.3%, Loss: 0.121406 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Batch Loss: 0.122825,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.088381,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.050658,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.074216,  Batch Accuracy: 99.22   [ 5120/54000]\n",
            "Batch Loss: 0.072285,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.042950,  Batch Accuracy: 100.00   [ 7680/54000]\n",
            "Batch Loss: 0.221466,  Batch Accuracy: 94.53   [ 8960/54000]\n",
            "Batch Loss: 0.041934,  Batch Accuracy: 100.00   [10240/54000]\n",
            "Batch Loss: 0.105275,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.052621,  Batch Accuracy: 99.22   [12800/54000]\n",
            "Batch Loss: 0.101727,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.094493,  Batch Accuracy: 96.88   [15360/54000]\n",
            "Batch Loss: 0.074447,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.090547,  Batch Accuracy: 95.31   [17920/54000]\n",
            "Batch Loss: 0.082438,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.094690,  Batch Accuracy: 97.66   [20480/54000]\n",
            "Batch Loss: 0.126096,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.025484,  Batch Accuracy: 100.00   [23040/54000]\n",
            "Batch Loss: 0.080567,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.062234,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.070469,  Batch Accuracy: 96.88   [26880/54000]\n",
            "Batch Loss: 0.106275,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.170480,  Batch Accuracy: 94.53   [29440/54000]\n",
            "Batch Loss: 0.056506,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.111069,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.088423,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.127417,  Batch Accuracy: 96.09   [34560/54000]\n",
            "Batch Loss: 0.077748,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.025592,  Batch Accuracy: 100.00   [37120/54000]\n",
            "Batch Loss: 0.125020,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.069445,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.085866,  Batch Accuracy: 96.09   [40960/54000]\n",
            "Batch Loss: 0.094158,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.064266,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.088437,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.128434,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.087095,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.067689,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.071044,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.168765,  Batch Accuracy: 95.31   [51200/54000]\n",
            "Batch Loss: 0.075020,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.059597,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.7%, Loss: 0.084147\n",
            "Validation performance: \n",
            " Accuracy: 96.4%, Loss: 0.126651\n",
            "Test performance: \n",
            " Accuracy: 96.4%, Loss: 0.120695 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Batch Loss: 0.054614,  Batch Accuracy: 98.44   [ 1280/54000]\n",
            "Batch Loss: 0.077153,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.047493,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.063749,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.106714,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.050368,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.042217,  Batch Accuracy: 100.00   [ 8960/54000]\n",
            "Batch Loss: 0.123133,  Batch Accuracy: 93.75   [10240/54000]\n",
            "Batch Loss: 0.119504,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.054874,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.100426,  Batch Accuracy: 96.09   [14080/54000]\n",
            "Batch Loss: 0.145778,  Batch Accuracy: 96.09   [15360/54000]\n",
            "Batch Loss: 0.051479,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.103278,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.067968,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.117549,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.148851,  Batch Accuracy: 96.09   [21760/54000]\n",
            "Batch Loss: 0.028871,  Batch Accuracy: 100.00   [23040/54000]\n",
            "Batch Loss: 0.124159,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.092872,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.119790,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.047299,  Batch Accuracy: 99.22   [28160/54000]\n",
            "Batch Loss: 0.148778,  Batch Accuracy: 96.09   [29440/54000]\n",
            "Batch Loss: 0.112450,  Batch Accuracy: 96.09   [30720/54000]\n",
            "Batch Loss: 0.062534,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.035888,  Batch Accuracy: 99.22   [33280/54000]\n",
            "Batch Loss: 0.057398,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.081198,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.046581,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.082448,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.204616,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.064207,  Batch Accuracy: 99.22   [40960/54000]\n",
            "Batch Loss: 0.072824,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.103390,  Batch Accuracy: 95.31   [43520/54000]\n",
            "Batch Loss: 0.078652,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.054497,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.062259,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.054632,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.062915,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.054377,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.122806,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.064146,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.7%, Loss: 0.082240\n",
            "Validation performance: \n",
            " Accuracy: 96.5%, Loss: 0.124470\n",
            "Test performance: \n",
            " Accuracy: 96.4%, Loss: 0.120759 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Batch Loss: 0.072787,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.064768,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.047789,  Batch Accuracy: 100.00   [ 3840/54000]\n",
            "Batch Loss: 0.048741,  Batch Accuracy: 99.22   [ 5120/54000]\n",
            "Batch Loss: 0.065120,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.053191,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.160561,  Batch Accuracy: 95.31   [ 8960/54000]\n",
            "Batch Loss: 0.042126,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.063609,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.107899,  Batch Accuracy: 96.09   [12800/54000]\n",
            "Batch Loss: 0.040338,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.075410,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.067944,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.087514,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.067522,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.134244,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.052050,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.049295,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.129927,  Batch Accuracy: 95.31   [24320/54000]\n",
            "Batch Loss: 0.094871,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.102820,  Batch Accuracy: 96.09   [26880/54000]\n",
            "Batch Loss: 0.115616,  Batch Accuracy: 96.88   [28160/54000]\n",
            "Batch Loss: 0.049134,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.089571,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.096533,  Batch Accuracy: 94.53   [32000/54000]\n",
            "Batch Loss: 0.038180,  Batch Accuracy: 99.22   [33280/54000]\n",
            "Batch Loss: 0.119117,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.055613,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.093230,  Batch Accuracy: 96.88   [37120/54000]\n",
            "Batch Loss: 0.094720,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.047006,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.055508,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.136395,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.103338,  Batch Accuracy: 97.66   [43520/54000]\n",
            "Batch Loss: 0.056527,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.062239,  Batch Accuracy: 99.22   [46080/54000]\n",
            "Batch Loss: 0.097115,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.058911,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.127401,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.067262,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.045112,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.084805,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.8%, Loss: 0.080718\n",
            "Validation performance: \n",
            " Accuracy: 96.4%, Loss: 0.122218\n",
            "Test performance: \n",
            " Accuracy: 96.4%, Loss: 0.118042 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Batch Loss: 0.111868,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.051091,  Batch Accuracy: 99.22   [ 2560/54000]\n",
            "Batch Loss: 0.163604,  Batch Accuracy: 95.31   [ 3840/54000]\n",
            "Batch Loss: 0.046611,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.038754,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.059689,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.167377,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.107628,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.053483,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.048728,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.084275,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.032484,  Batch Accuracy: 100.00   [15360/54000]\n",
            "Batch Loss: 0.064829,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.052774,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.088580,  Batch Accuracy: 96.09   [19200/54000]\n",
            "Batch Loss: 0.059178,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.105987,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.037163,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.045714,  Batch Accuracy: 100.00   [24320/54000]\n",
            "Batch Loss: 0.072835,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.041183,  Batch Accuracy: 99.22   [26880/54000]\n",
            "Batch Loss: 0.144255,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.147826,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.094903,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.097408,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.060842,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.051264,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.144556,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.022238,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.135341,  Batch Accuracy: 95.31   [38400/54000]\n",
            "Batch Loss: 0.078434,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.081418,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.150071,  Batch Accuracy: 94.53   [42240/54000]\n",
            "Batch Loss: 0.139410,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.122175,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.045175,  Batch Accuracy: 99.22   [46080/54000]\n",
            "Batch Loss: 0.071737,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.072860,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.154629,  Batch Accuracy: 96.09   [49920/54000]\n",
            "Batch Loss: 0.080959,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.165215,  Batch Accuracy: 96.88   [52480/54000]\n",
            "Batch Loss: 0.089697,  Batch Accuracy: 96.09   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.9%, Loss: 0.079004\n",
            "Validation performance: \n",
            " Accuracy: 96.5%, Loss: 0.121155\n",
            "Test performance: \n",
            " Accuracy: 96.5%, Loss: 0.116486 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Batch Loss: 0.122524,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.051541,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.051352,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.090367,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.053781,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.082348,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.053630,  Batch Accuracy: 97.66   [ 8960/54000]\n",
            "Batch Loss: 0.063324,  Batch Accuracy: 96.88   [10240/54000]\n",
            "Batch Loss: 0.036294,  Batch Accuracy: 99.22   [11520/54000]\n",
            "Batch Loss: 0.061457,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.069886,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.070990,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.081260,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.080056,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.098260,  Batch Accuracy: 96.88   [19200/54000]\n",
            "Batch Loss: 0.046057,  Batch Accuracy: 99.22   [20480/54000]\n",
            "Batch Loss: 0.113181,  Batch Accuracy: 96.88   [21760/54000]\n",
            "Batch Loss: 0.061748,  Batch Accuracy: 96.88   [23040/54000]\n",
            "Batch Loss: 0.150753,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.065073,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.072102,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.082211,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.040219,  Batch Accuracy: 100.00   [29440/54000]\n",
            "Batch Loss: 0.048922,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.073385,  Batch Accuracy: 96.88   [32000/54000]\n",
            "Batch Loss: 0.044738,  Batch Accuracy: 98.44   [33280/54000]\n",
            "Batch Loss: 0.046586,  Batch Accuracy: 99.22   [34560/54000]\n",
            "Batch Loss: 0.100203,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.075971,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.039537,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.081185,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.066048,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.078742,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.105255,  Batch Accuracy: 97.66   [43520/54000]\n",
            "Batch Loss: 0.074658,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.076852,  Batch Accuracy: 96.88   [46080/54000]\n",
            "Batch Loss: 0.096856,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.051085,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.051946,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.064347,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.087812,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.088442,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.9%, Loss: 0.077422\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.121662\n",
            "Test performance: \n",
            " Accuracy: 96.5%, Loss: 0.116961 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Batch Loss: 0.062129,  Batch Accuracy: 98.44   [ 1280/54000]\n",
            "Batch Loss: 0.045326,  Batch Accuracy: 99.22   [ 2560/54000]\n",
            "Batch Loss: 0.151061,  Batch Accuracy: 95.31   [ 3840/54000]\n",
            "Batch Loss: 0.058989,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.066785,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.082749,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.076694,  Batch Accuracy: 99.22   [ 8960/54000]\n",
            "Batch Loss: 0.035131,  Batch Accuracy: 99.22   [10240/54000]\n",
            "Batch Loss: 0.142552,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.030634,  Batch Accuracy: 100.00   [12800/54000]\n",
            "Batch Loss: 0.082083,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.125212,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.058021,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.058183,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.045515,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.111432,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.028657,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.061043,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.061342,  Batch Accuracy: 99.22   [24320/54000]\n",
            "Batch Loss: 0.087170,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.048701,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.071563,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.059246,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.088947,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.045969,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.099271,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.110310,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.045176,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.132362,  Batch Accuracy: 95.31   [37120/54000]\n",
            "Batch Loss: 0.114632,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.042958,  Batch Accuracy: 99.22   [39680/54000]\n",
            "Batch Loss: 0.124536,  Batch Accuracy: 95.31   [40960/54000]\n",
            "Batch Loss: 0.061756,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.122241,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.055049,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.070010,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.172508,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.024416,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.042556,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.069383,  Batch Accuracy: 97.66   [51200/54000]\n",
            "Batch Loss: 0.055345,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.046895,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 97.9%, Loss: 0.075947\n",
            "Validation performance: \n",
            " Accuracy: 96.5%, Loss: 0.121099\n",
            "Test performance: \n",
            " Accuracy: 96.4%, Loss: 0.116786 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Batch Loss: 0.058176,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.055199,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.047759,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.131566,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.089256,  Batch Accuracy: 96.88   [ 6400/54000]\n",
            "Batch Loss: 0.036496,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.079542,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.058294,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.095595,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.070703,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.075670,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.074448,  Batch Accuracy: 99.22   [15360/54000]\n",
            "Batch Loss: 0.124391,  Batch Accuracy: 95.31   [16640/54000]\n",
            "Batch Loss: 0.107262,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.044584,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.081098,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.052950,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.038332,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.086096,  Batch Accuracy: 97.66   [24320/54000]\n",
            "Batch Loss: 0.129788,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.053166,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.042521,  Batch Accuracy: 99.22   [28160/54000]\n",
            "Batch Loss: 0.117912,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.092687,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.037160,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.166575,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.091922,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.093604,  Batch Accuracy: 97.66   [35840/54000]\n",
            "Batch Loss: 0.045290,  Batch Accuracy: 100.00   [37120/54000]\n",
            "Batch Loss: 0.125593,  Batch Accuracy: 96.09   [38400/54000]\n",
            "Batch Loss: 0.055275,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.116973,  Batch Accuracy: 96.88   [40960/54000]\n",
            "Batch Loss: 0.132304,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.042715,  Batch Accuracy: 99.22   [43520/54000]\n",
            "Batch Loss: 0.101572,  Batch Accuracy: 96.88   [44800/54000]\n",
            "Batch Loss: 0.028550,  Batch Accuracy: 100.00   [46080/54000]\n",
            "Batch Loss: 0.146058,  Batch Accuracy: 95.31   [47360/54000]\n",
            "Batch Loss: 0.037144,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.086308,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.057987,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.077021,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.070831,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.0%, Loss: 0.074021\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.119181\n",
            "Test performance: \n",
            " Accuracy: 96.6%, Loss: 0.115021 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Batch Loss: 0.061983,  Batch Accuracy: 98.44   [ 1280/54000]\n",
            "Batch Loss: 0.094488,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.092991,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.079056,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.064221,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.092167,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.088894,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.121053,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.110238,  Batch Accuracy: 96.09   [11520/54000]\n",
            "Batch Loss: 0.074702,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.054609,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.082673,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.111759,  Batch Accuracy: 96.88   [16640/54000]\n",
            "Batch Loss: 0.079103,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.063843,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.025516,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.052775,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.044075,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.068585,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.074929,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.135856,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.042107,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.074841,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.047235,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.053252,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.053883,  Batch Accuracy: 98.44   [33280/54000]\n",
            "Batch Loss: 0.074179,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.086370,  Batch Accuracy: 95.31   [35840/54000]\n",
            "Batch Loss: 0.093387,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.048716,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.094153,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.088308,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.051622,  Batch Accuracy: 99.22   [42240/54000]\n",
            "Batch Loss: 0.044498,  Batch Accuracy: 99.22   [43520/54000]\n",
            "Batch Loss: 0.083694,  Batch Accuracy: 96.09   [44800/54000]\n",
            "Batch Loss: 0.087630,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.045390,  Batch Accuracy: 100.00   [47360/54000]\n",
            "Batch Loss: 0.099092,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.074454,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.050533,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.051601,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.144838,  Batch Accuracy: 94.53   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.0%, Loss: 0.072958\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.118337\n",
            "Test performance: \n",
            " Accuracy: 96.6%, Loss: 0.113176 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Batch Loss: 0.119703,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.088236,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.093417,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.113746,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.065447,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.068762,  Batch Accuracy: 97.66   [ 7680/54000]\n",
            "Batch Loss: 0.044936,  Batch Accuracy: 99.22   [ 8960/54000]\n",
            "Batch Loss: 0.102487,  Batch Accuracy: 97.66   [10240/54000]\n",
            "Batch Loss: 0.060454,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.112937,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.056741,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.088528,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.043008,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.107746,  Batch Accuracy: 95.31   [17920/54000]\n",
            "Batch Loss: 0.066874,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.031478,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.067451,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.092984,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.059269,  Batch Accuracy: 97.66   [24320/54000]\n",
            "Batch Loss: 0.123366,  Batch Accuracy: 95.31   [25600/54000]\n",
            "Batch Loss: 0.145423,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.089492,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.060378,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.066821,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.064620,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.068424,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.083676,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.038915,  Batch Accuracy: 99.22   [35840/54000]\n",
            "Batch Loss: 0.085551,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.020607,  Batch Accuracy: 100.00   [38400/54000]\n",
            "Batch Loss: 0.097247,  Batch Accuracy: 96.09   [39680/54000]\n",
            "Batch Loss: 0.073150,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.043752,  Batch Accuracy: 99.22   [42240/54000]\n",
            "Batch Loss: 0.066384,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.052072,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.067767,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.039788,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.164261,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.051315,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.025217,  Batch Accuracy: 100.00   [51200/54000]\n",
            "Batch Loss: 0.042196,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.059478,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.1%, Loss: 0.071459\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.117545\n",
            "Test performance: \n",
            " Accuracy: 96.6%, Loss: 0.112969 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Batch Loss: 0.094215,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.025558,  Batch Accuracy: 100.00   [ 2560/54000]\n",
            "Batch Loss: 0.092827,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.052250,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.057753,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.073838,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.092706,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.028447,  Batch Accuracy: 100.00   [10240/54000]\n",
            "Batch Loss: 0.126580,  Batch Accuracy: 95.31   [11520/54000]\n",
            "Batch Loss: 0.066025,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.067426,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.046627,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.046587,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.125709,  Batch Accuracy: 96.09   [17920/54000]\n",
            "Batch Loss: 0.046993,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.121019,  Batch Accuracy: 96.09   [20480/54000]\n",
            "Batch Loss: 0.054788,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.051598,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.040464,  Batch Accuracy: 99.22   [24320/54000]\n",
            "Batch Loss: 0.132112,  Batch Accuracy: 96.09   [25600/54000]\n",
            "Batch Loss: 0.047446,  Batch Accuracy: 99.22   [26880/54000]\n",
            "Batch Loss: 0.069687,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.102285,  Batch Accuracy: 95.31   [29440/54000]\n",
            "Batch Loss: 0.133152,  Batch Accuracy: 95.31   [30720/54000]\n",
            "Batch Loss: 0.053146,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.134775,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.093176,  Batch Accuracy: 95.31   [34560/54000]\n",
            "Batch Loss: 0.019727,  Batch Accuracy: 100.00   [35840/54000]\n",
            "Batch Loss: 0.047399,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.089747,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.042283,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.054424,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.053695,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.049931,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.077883,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.149971,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.026873,  Batch Accuracy: 100.00   [47360/54000]\n",
            "Batch Loss: 0.091037,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.033773,  Batch Accuracy: 99.22   [49920/54000]\n",
            "Batch Loss: 0.048220,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.037323,  Batch Accuracy: 100.00   [52480/54000]\n",
            "Batch Loss: 0.057822,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.1%, Loss: 0.070126\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.116904\n",
            "Test performance: \n",
            " Accuracy: 96.6%, Loss: 0.111740 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Batch Loss: 0.047963,  Batch Accuracy: 99.22   [ 1280/54000]\n",
            "Batch Loss: 0.086883,  Batch Accuracy: 96.88   [ 2560/54000]\n",
            "Batch Loss: 0.116747,  Batch Accuracy: 96.88   [ 3840/54000]\n",
            "Batch Loss: 0.082074,  Batch Accuracy: 97.66   [ 5120/54000]\n",
            "Batch Loss: 0.094249,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.088227,  Batch Accuracy: 96.09   [ 7680/54000]\n",
            "Batch Loss: 0.120213,  Batch Accuracy: 96.09   [ 8960/54000]\n",
            "Batch Loss: 0.044260,  Batch Accuracy: 99.22   [10240/54000]\n",
            "Batch Loss: 0.092298,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.051840,  Batch Accuracy: 99.22   [12800/54000]\n",
            "Batch Loss: 0.062930,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.059323,  Batch Accuracy: 97.66   [15360/54000]\n",
            "Batch Loss: 0.101921,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.100165,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.101722,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.045855,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.075818,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.060831,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.094553,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.055560,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.060018,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.066058,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.064978,  Batch Accuracy: 96.88   [29440/54000]\n",
            "Batch Loss: 0.038629,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.058561,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.104835,  Batch Accuracy: 95.31   [33280/54000]\n",
            "Batch Loss: 0.049306,  Batch Accuracy: 99.22   [34560/54000]\n",
            "Batch Loss: 0.042539,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.114401,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.045946,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.046243,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.025197,  Batch Accuracy: 100.00   [40960/54000]\n",
            "Batch Loss: 0.142375,  Batch Accuracy: 95.31   [42240/54000]\n",
            "Batch Loss: 0.040301,  Batch Accuracy: 100.00   [43520/54000]\n",
            "Batch Loss: 0.063305,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.079481,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.072516,  Batch Accuracy: 96.88   [47360/54000]\n",
            "Batch Loss: 0.068006,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.112978,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.025943,  Batch Accuracy: 100.00   [51200/54000]\n",
            "Batch Loss: 0.055420,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.057983,  Batch Accuracy: 100.00   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.2%, Loss: 0.068825\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.115484\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.111030 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Batch Loss: 0.075974,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.037300,  Batch Accuracy: 100.00   [ 2560/54000]\n",
            "Batch Loss: 0.081168,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.052809,  Batch Accuracy: 99.22   [ 5120/54000]\n",
            "Batch Loss: 0.083365,  Batch Accuracy: 96.09   [ 6400/54000]\n",
            "Batch Loss: 0.080527,  Batch Accuracy: 97.66   [ 7680/54000]\n",
            "Batch Loss: 0.069141,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.056616,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.066458,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.053639,  Batch Accuracy: 99.22   [12800/54000]\n",
            "Batch Loss: 0.128173,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.026353,  Batch Accuracy: 99.22   [15360/54000]\n",
            "Batch Loss: 0.030377,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.041221,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.062997,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.100482,  Batch Accuracy: 97.66   [20480/54000]\n",
            "Batch Loss: 0.082874,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.061653,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.021642,  Batch Accuracy: 100.00   [24320/54000]\n",
            "Batch Loss: 0.046745,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.091449,  Batch Accuracy: 95.31   [26880/54000]\n",
            "Batch Loss: 0.112811,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.044116,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.080470,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.022993,  Batch Accuracy: 100.00   [32000/54000]\n",
            "Batch Loss: 0.022864,  Batch Accuracy: 100.00   [33280/54000]\n",
            "Batch Loss: 0.067060,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.099416,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.078429,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.061628,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.071945,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.020161,  Batch Accuracy: 99.22   [40960/54000]\n",
            "Batch Loss: 0.101431,  Batch Accuracy: 96.88   [42240/54000]\n",
            "Batch Loss: 0.023073,  Batch Accuracy: 100.00   [43520/54000]\n",
            "Batch Loss: 0.099944,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.076915,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.023970,  Batch Accuracy: 100.00   [47360/54000]\n",
            "Batch Loss: 0.077015,  Batch Accuracy: 96.09   [48640/54000]\n",
            "Batch Loss: 0.048441,  Batch Accuracy: 99.22   [49920/54000]\n",
            "Batch Loss: 0.031370,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.065133,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.105065,  Batch Accuracy: 97.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.2%, Loss: 0.067344\n",
            "Validation performance: \n",
            " Accuracy: 96.6%, Loss: 0.114880\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.111179 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Batch Loss: 0.049518,  Batch Accuracy: 99.22   [ 1280/54000]\n",
            "Batch Loss: 0.057687,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.150384,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.140564,  Batch Accuracy: 95.31   [ 5120/54000]\n",
            "Batch Loss: 0.065319,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.048132,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.059830,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.052346,  Batch Accuracy: 99.22   [10240/54000]\n",
            "Batch Loss: 0.121078,  Batch Accuracy: 96.88   [11520/54000]\n",
            "Batch Loss: 0.084831,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.049233,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.056357,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.054218,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.062547,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.057661,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.044711,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.076156,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.021843,  Batch Accuracy: 100.00   [23040/54000]\n",
            "Batch Loss: 0.098352,  Batch Accuracy: 96.09   [24320/54000]\n",
            "Batch Loss: 0.093442,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.063028,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.136067,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.034556,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.094631,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.044395,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.048972,  Batch Accuracy: 98.44   [33280/54000]\n",
            "Batch Loss: 0.048990,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.079465,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.046661,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.081576,  Batch Accuracy: 97.66   [38400/54000]\n",
            "Batch Loss: 0.023897,  Batch Accuracy: 100.00   [39680/54000]\n",
            "Batch Loss: 0.040684,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.056997,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.044513,  Batch Accuracy: 99.22   [43520/54000]\n",
            "Batch Loss: 0.033610,  Batch Accuracy: 100.00   [44800/54000]\n",
            "Batch Loss: 0.038223,  Batch Accuracy: 99.22   [46080/54000]\n",
            "Batch Loss: 0.033940,  Batch Accuracy: 99.22   [47360/54000]\n",
            "Batch Loss: 0.036567,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.043606,  Batch Accuracy: 99.22   [49920/54000]\n",
            "Batch Loss: 0.061741,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.046738,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.047683,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.2%, Loss: 0.066275\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.115451\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.109969 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Batch Loss: 0.075096,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.041896,  Batch Accuracy: 99.22   [ 2560/54000]\n",
            "Batch Loss: 0.057511,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.078697,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.036418,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.063915,  Batch Accuracy: 98.44   [ 7680/54000]\n",
            "Batch Loss: 0.055927,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.050023,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.047768,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.045110,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.081613,  Batch Accuracy: 96.88   [14080/54000]\n",
            "Batch Loss: 0.135732,  Batch Accuracy: 95.31   [15360/54000]\n",
            "Batch Loss: 0.070161,  Batch Accuracy: 97.66   [16640/54000]\n",
            "Batch Loss: 0.039529,  Batch Accuracy: 98.44   [17920/54000]\n",
            "Batch Loss: 0.080031,  Batch Accuracy: 98.44   [19200/54000]\n",
            "Batch Loss: 0.059644,  Batch Accuracy: 99.22   [20480/54000]\n",
            "Batch Loss: 0.084771,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.056952,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.057760,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.159915,  Batch Accuracy: 96.88   [25600/54000]\n",
            "Batch Loss: 0.024605,  Batch Accuracy: 100.00   [26880/54000]\n",
            "Batch Loss: 0.067809,  Batch Accuracy: 97.66   [28160/54000]\n",
            "Batch Loss: 0.057065,  Batch Accuracy: 99.22   [29440/54000]\n",
            "Batch Loss: 0.060540,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.110542,  Batch Accuracy: 98.44   [32000/54000]\n",
            "Batch Loss: 0.071156,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.039828,  Batch Accuracy: 99.22   [34560/54000]\n",
            "Batch Loss: 0.051107,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.111033,  Batch Accuracy: 96.88   [37120/54000]\n",
            "Batch Loss: 0.044530,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.086632,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.051620,  Batch Accuracy: 98.44   [40960/54000]\n",
            "Batch Loss: 0.063991,  Batch Accuracy: 99.22   [42240/54000]\n",
            "Batch Loss: 0.073197,  Batch Accuracy: 96.88   [43520/54000]\n",
            "Batch Loss: 0.070411,  Batch Accuracy: 97.66   [44800/54000]\n",
            "Batch Loss: 0.063736,  Batch Accuracy: 97.66   [46080/54000]\n",
            "Batch Loss: 0.033550,  Batch Accuracy: 100.00   [47360/54000]\n",
            "Batch Loss: 0.073055,  Batch Accuracy: 98.44   [48640/54000]\n",
            "Batch Loss: 0.058771,  Batch Accuracy: 99.22   [49920/54000]\n",
            "Batch Loss: 0.035819,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.033394,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.068215,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.3%, Loss: 0.064918\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.113737\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.108835 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Batch Loss: 0.183544,  Batch Accuracy: 95.31   [ 1280/54000]\n",
            "Batch Loss: 0.058852,  Batch Accuracy: 99.22   [ 2560/54000]\n",
            "Batch Loss: 0.115683,  Batch Accuracy: 97.66   [ 3840/54000]\n",
            "Batch Loss: 0.111016,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.046557,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.033340,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.093019,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.023293,  Batch Accuracy: 99.22   [10240/54000]\n",
            "Batch Loss: 0.067809,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.054126,  Batch Accuracy: 97.66   [12800/54000]\n",
            "Batch Loss: 0.054613,  Batch Accuracy: 98.44   [14080/54000]\n",
            "Batch Loss: 0.035041,  Batch Accuracy: 100.00   [15360/54000]\n",
            "Batch Loss: 0.071788,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.028749,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.077459,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.115070,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.078265,  Batch Accuracy: 97.66   [21760/54000]\n",
            "Batch Loss: 0.051918,  Batch Accuracy: 98.44   [23040/54000]\n",
            "Batch Loss: 0.050342,  Batch Accuracy: 96.88   [24320/54000]\n",
            "Batch Loss: 0.064242,  Batch Accuracy: 98.44   [25600/54000]\n",
            "Batch Loss: 0.087476,  Batch Accuracy: 97.66   [26880/54000]\n",
            "Batch Loss: 0.060609,  Batch Accuracy: 96.88   [28160/54000]\n",
            "Batch Loss: 0.100439,  Batch Accuracy: 98.44   [29440/54000]\n",
            "Batch Loss: 0.054207,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.021596,  Batch Accuracy: 100.00   [32000/54000]\n",
            "Batch Loss: 0.039922,  Batch Accuracy: 100.00   [33280/54000]\n",
            "Batch Loss: 0.083524,  Batch Accuracy: 97.66   [34560/54000]\n",
            "Batch Loss: 0.028758,  Batch Accuracy: 100.00   [35840/54000]\n",
            "Batch Loss: 0.069342,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.030891,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.094834,  Batch Accuracy: 97.66   [39680/54000]\n",
            "Batch Loss: 0.083789,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.048681,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.097116,  Batch Accuracy: 97.66   [43520/54000]\n",
            "Batch Loss: 0.086853,  Batch Accuracy: 98.44   [44800/54000]\n",
            "Batch Loss: 0.075374,  Batch Accuracy: 96.88   [46080/54000]\n",
            "Batch Loss: 0.055974,  Batch Accuracy: 97.66   [47360/54000]\n",
            "Batch Loss: 0.030799,  Batch Accuracy: 100.00   [48640/54000]\n",
            "Batch Loss: 0.027325,  Batch Accuracy: 99.22   [49920/54000]\n",
            "Batch Loss: 0.044810,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.033864,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.057594,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.3%, Loss: 0.063765\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.113729\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.108236 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Batch Loss: 0.083110,  Batch Accuracy: 96.88   [ 1280/54000]\n",
            "Batch Loss: 0.128385,  Batch Accuracy: 96.09   [ 2560/54000]\n",
            "Batch Loss: 0.046709,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.050302,  Batch Accuracy: 99.22   [ 5120/54000]\n",
            "Batch Loss: 0.055214,  Batch Accuracy: 98.44   [ 6400/54000]\n",
            "Batch Loss: 0.126065,  Batch Accuracy: 96.88   [ 7680/54000]\n",
            "Batch Loss: 0.062342,  Batch Accuracy: 96.88   [ 8960/54000]\n",
            "Batch Loss: 0.110498,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.064559,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.071585,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.041683,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.038960,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.129121,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.033972,  Batch Accuracy: 99.22   [17920/54000]\n",
            "Batch Loss: 0.073770,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.053360,  Batch Accuracy: 97.66   [20480/54000]\n",
            "Batch Loss: 0.054017,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.069878,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.028787,  Batch Accuracy: 100.00   [24320/54000]\n",
            "Batch Loss: 0.027985,  Batch Accuracy: 100.00   [25600/54000]\n",
            "Batch Loss: 0.037701,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.055553,  Batch Accuracy: 96.09   [28160/54000]\n",
            "Batch Loss: 0.020749,  Batch Accuracy: 100.00   [29440/54000]\n",
            "Batch Loss: 0.109030,  Batch Accuracy: 96.88   [30720/54000]\n",
            "Batch Loss: 0.038321,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.056475,  Batch Accuracy: 99.22   [33280/54000]\n",
            "Batch Loss: 0.057838,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.055669,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.062902,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.041115,  Batch Accuracy: 98.44   [38400/54000]\n",
            "Batch Loss: 0.021649,  Batch Accuracy: 100.00   [39680/54000]\n",
            "Batch Loss: 0.092962,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.046673,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.085813,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.123246,  Batch Accuracy: 95.31   [44800/54000]\n",
            "Batch Loss: 0.044256,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.042124,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.038423,  Batch Accuracy: 99.22   [48640/54000]\n",
            "Batch Loss: 0.109936,  Batch Accuracy: 96.88   [49920/54000]\n",
            "Batch Loss: 0.033767,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.074102,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.155708,  Batch Accuracy: 96.88   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.4%, Loss: 0.062552\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.112516\n",
            "Test performance: \n",
            " Accuracy: 96.8%, Loss: 0.107674 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Batch Loss: 0.152086,  Batch Accuracy: 96.09   [ 1280/54000]\n",
            "Batch Loss: 0.082801,  Batch Accuracy: 97.66   [ 2560/54000]\n",
            "Batch Loss: 0.057052,  Batch Accuracy: 98.44   [ 3840/54000]\n",
            "Batch Loss: 0.066959,  Batch Accuracy: 96.88   [ 5120/54000]\n",
            "Batch Loss: 0.048925,  Batch Accuracy: 99.22   [ 6400/54000]\n",
            "Batch Loss: 0.038637,  Batch Accuracy: 99.22   [ 7680/54000]\n",
            "Batch Loss: 0.048945,  Batch Accuracy: 98.44   [ 8960/54000]\n",
            "Batch Loss: 0.050779,  Batch Accuracy: 98.44   [10240/54000]\n",
            "Batch Loss: 0.040699,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.062171,  Batch Accuracy: 96.88   [12800/54000]\n",
            "Batch Loss: 0.041173,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.023524,  Batch Accuracy: 99.22   [15360/54000]\n",
            "Batch Loss: 0.045637,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.073255,  Batch Accuracy: 97.66   [17920/54000]\n",
            "Batch Loss: 0.024695,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.028285,  Batch Accuracy: 100.00   [20480/54000]\n",
            "Batch Loss: 0.062971,  Batch Accuracy: 98.44   [21760/54000]\n",
            "Batch Loss: 0.077634,  Batch Accuracy: 97.66   [23040/54000]\n",
            "Batch Loss: 0.065487,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.031971,  Batch Accuracy: 99.22   [25600/54000]\n",
            "Batch Loss: 0.093126,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.059352,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.035897,  Batch Accuracy: 100.00   [29440/54000]\n",
            "Batch Loss: 0.057316,  Batch Accuracy: 97.66   [30720/54000]\n",
            "Batch Loss: 0.050772,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.094477,  Batch Accuracy: 96.88   [33280/54000]\n",
            "Batch Loss: 0.066004,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.061936,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.044178,  Batch Accuracy: 98.44   [37120/54000]\n",
            "Batch Loss: 0.081697,  Batch Accuracy: 96.88   [38400/54000]\n",
            "Batch Loss: 0.042814,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.033175,  Batch Accuracy: 99.22   [40960/54000]\n",
            "Batch Loss: 0.077056,  Batch Accuracy: 96.09   [42240/54000]\n",
            "Batch Loss: 0.025635,  Batch Accuracy: 100.00   [43520/54000]\n",
            "Batch Loss: 0.021328,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.055717,  Batch Accuracy: 98.44   [46080/54000]\n",
            "Batch Loss: 0.028452,  Batch Accuracy: 100.00   [47360/54000]\n",
            "Batch Loss: 0.096901,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.066932,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.047232,  Batch Accuracy: 98.44   [51200/54000]\n",
            "Batch Loss: 0.092344,  Batch Accuracy: 97.66   [52480/54000]\n",
            "Batch Loss: 0.054241,  Batch Accuracy: 98.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.4%, Loss: 0.061197\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.113921\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.109287 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Batch Loss: 0.016382,  Batch Accuracy: 100.00   [ 1280/54000]\n",
            "Batch Loss: 0.042225,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.032885,  Batch Accuracy: 99.22   [ 3840/54000]\n",
            "Batch Loss: 0.030670,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.072671,  Batch Accuracy: 97.66   [ 6400/54000]\n",
            "Batch Loss: 0.036199,  Batch Accuracy: 100.00   [ 7680/54000]\n",
            "Batch Loss: 0.054714,  Batch Accuracy: 99.22   [ 8960/54000]\n",
            "Batch Loss: 0.122096,  Batch Accuracy: 95.31   [10240/54000]\n",
            "Batch Loss: 0.061842,  Batch Accuracy: 97.66   [11520/54000]\n",
            "Batch Loss: 0.044117,  Batch Accuracy: 99.22   [12800/54000]\n",
            "Batch Loss: 0.045697,  Batch Accuracy: 99.22   [14080/54000]\n",
            "Batch Loss: 0.058594,  Batch Accuracy: 98.44   [15360/54000]\n",
            "Batch Loss: 0.041927,  Batch Accuracy: 99.22   [16640/54000]\n",
            "Batch Loss: 0.091239,  Batch Accuracy: 96.88   [17920/54000]\n",
            "Batch Loss: 0.029811,  Batch Accuracy: 99.22   [19200/54000]\n",
            "Batch Loss: 0.038958,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.042486,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.019886,  Batch Accuracy: 100.00   [23040/54000]\n",
            "Batch Loss: 0.067302,  Batch Accuracy: 98.44   [24320/54000]\n",
            "Batch Loss: 0.055503,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.040539,  Batch Accuracy: 98.44   [26880/54000]\n",
            "Batch Loss: 0.084932,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.074547,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.047884,  Batch Accuracy: 99.22   [30720/54000]\n",
            "Batch Loss: 0.043508,  Batch Accuracy: 99.22   [32000/54000]\n",
            "Batch Loss: 0.066434,  Batch Accuracy: 97.66   [33280/54000]\n",
            "Batch Loss: 0.030506,  Batch Accuracy: 98.44   [34560/54000]\n",
            "Batch Loss: 0.079850,  Batch Accuracy: 96.88   [35840/54000]\n",
            "Batch Loss: 0.066800,  Batch Accuracy: 97.66   [37120/54000]\n",
            "Batch Loss: 0.064016,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.072524,  Batch Accuracy: 99.22   [39680/54000]\n",
            "Batch Loss: 0.064711,  Batch Accuracy: 97.66   [40960/54000]\n",
            "Batch Loss: 0.056184,  Batch Accuracy: 97.66   [42240/54000]\n",
            "Batch Loss: 0.074388,  Batch Accuracy: 98.44   [43520/54000]\n",
            "Batch Loss: 0.043249,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.140787,  Batch Accuracy: 95.31   [46080/54000]\n",
            "Batch Loss: 0.042782,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.079389,  Batch Accuracy: 97.66   [48640/54000]\n",
            "Batch Loss: 0.050289,  Batch Accuracy: 98.44   [49920/54000]\n",
            "Batch Loss: 0.024142,  Batch Accuracy: 100.00   [51200/54000]\n",
            "Batch Loss: 0.044331,  Batch Accuracy: 98.44   [52480/54000]\n",
            "Batch Loss: 0.037792,  Batch Accuracy: 99.22   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.5%, Loss: 0.060182\n",
            "Validation performance: \n",
            " Accuracy: 96.7%, Loss: 0.113100\n",
            "Test performance: \n",
            " Accuracy: 96.7%, Loss: 0.107791 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Batch Loss: 0.068853,  Batch Accuracy: 97.66   [ 1280/54000]\n",
            "Batch Loss: 0.070748,  Batch Accuracy: 98.44   [ 2560/54000]\n",
            "Batch Loss: 0.017645,  Batch Accuracy: 100.00   [ 3840/54000]\n",
            "Batch Loss: 0.043041,  Batch Accuracy: 98.44   [ 5120/54000]\n",
            "Batch Loss: 0.033965,  Batch Accuracy: 100.00   [ 6400/54000]\n",
            "Batch Loss: 0.023217,  Batch Accuracy: 100.00   [ 7680/54000]\n",
            "Batch Loss: 0.104279,  Batch Accuracy: 97.66   [ 8960/54000]\n",
            "Batch Loss: 0.025189,  Batch Accuracy: 100.00   [10240/54000]\n",
            "Batch Loss: 0.075137,  Batch Accuracy: 98.44   [11520/54000]\n",
            "Batch Loss: 0.053268,  Batch Accuracy: 98.44   [12800/54000]\n",
            "Batch Loss: 0.082168,  Batch Accuracy: 97.66   [14080/54000]\n",
            "Batch Loss: 0.050998,  Batch Accuracy: 99.22   [15360/54000]\n",
            "Batch Loss: 0.051052,  Batch Accuracy: 98.44   [16640/54000]\n",
            "Batch Loss: 0.035392,  Batch Accuracy: 100.00   [17920/54000]\n",
            "Batch Loss: 0.069535,  Batch Accuracy: 97.66   [19200/54000]\n",
            "Batch Loss: 0.050547,  Batch Accuracy: 98.44   [20480/54000]\n",
            "Batch Loss: 0.025579,  Batch Accuracy: 99.22   [21760/54000]\n",
            "Batch Loss: 0.033527,  Batch Accuracy: 99.22   [23040/54000]\n",
            "Batch Loss: 0.037011,  Batch Accuracy: 99.22   [24320/54000]\n",
            "Batch Loss: 0.072863,  Batch Accuracy: 97.66   [25600/54000]\n",
            "Batch Loss: 0.032142,  Batch Accuracy: 100.00   [26880/54000]\n",
            "Batch Loss: 0.044924,  Batch Accuracy: 98.44   [28160/54000]\n",
            "Batch Loss: 0.070962,  Batch Accuracy: 97.66   [29440/54000]\n",
            "Batch Loss: 0.046490,  Batch Accuracy: 98.44   [30720/54000]\n",
            "Batch Loss: 0.049859,  Batch Accuracy: 97.66   [32000/54000]\n",
            "Batch Loss: 0.052205,  Batch Accuracy: 100.00   [33280/54000]\n",
            "Batch Loss: 0.150236,  Batch Accuracy: 96.88   [34560/54000]\n",
            "Batch Loss: 0.041103,  Batch Accuracy: 98.44   [35840/54000]\n",
            "Batch Loss: 0.052039,  Batch Accuracy: 99.22   [37120/54000]\n",
            "Batch Loss: 0.059388,  Batch Accuracy: 99.22   [38400/54000]\n",
            "Batch Loss: 0.080004,  Batch Accuracy: 98.44   [39680/54000]\n",
            "Batch Loss: 0.030266,  Batch Accuracy: 100.00   [40960/54000]\n",
            "Batch Loss: 0.093074,  Batch Accuracy: 98.44   [42240/54000]\n",
            "Batch Loss: 0.079688,  Batch Accuracy: 96.09   [43520/54000]\n",
            "Batch Loss: 0.048946,  Batch Accuracy: 99.22   [44800/54000]\n",
            "Batch Loss: 0.038707,  Batch Accuracy: 99.22   [46080/54000]\n",
            "Batch Loss: 0.089604,  Batch Accuracy: 98.44   [47360/54000]\n",
            "Batch Loss: 0.097646,  Batch Accuracy: 96.88   [48640/54000]\n",
            "Batch Loss: 0.059823,  Batch Accuracy: 97.66   [49920/54000]\n",
            "Batch Loss: 0.034106,  Batch Accuracy: 99.22   [51200/54000]\n",
            "Batch Loss: 0.053645,  Batch Accuracy: 99.22   [52480/54000]\n",
            "Batch Loss: 0.060849,  Batch Accuracy: 99.22   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 98.5%, Loss: 0.059139\n",
            "Validation performance: \n",
            " Accuracy: 96.8%, Loss: 0.110928\n",
            "Test performance: \n",
            " Accuracy: 96.8%, Loss: 0.105647 \n",
            "\n",
            "Time taken to train the model: 1.7635210474332175 minutes\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train_q2(model:nn.Module, train_loader:DataLoader, optimizer, criterion):\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        batch_correct = (predicted == labels).sum().item()\n",
        "        correct += batch_correct\n",
        "\n",
        "        if (batch + 1) % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(images)\n",
        "            print(f\"Batch Loss: {loss:>7f},  Batch Accuracy: {100*batch_correct/len(images):.2f}   [{current:>5d}/{len(train_sampler):>5d}]\")\n",
        "        batch += 1\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Training performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {train_loss:>8f}\")\n",
        "    return train_loss, accuracy\n",
        "\n",
        "\n",
        "# Validation loop\n",
        "def validate_q2(model:nn.Module, valid_loader:DataLoader, loss_fn):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(valid_loader)\n",
        "    print(f\"Validation performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {val_loss:>8f}\")\n",
        "    return val_loss, accuracy\n",
        "\n",
        "\n",
        "# Testing loop\n",
        "def test_q2(model:nn.Module, test_loader:DataLoader, loss_fn):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            test_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "# Training, Validation and Testing of the model\n",
        "num_epochs = 60\n",
        "train_losses_q2, train_accuracies_q2 = [], []\n",
        "val_losses_q2, val_accuracies_q2 = [], []\n",
        "test_losses_q2, test_accuracies_q2 = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    train_loss, train_accuracy = train_q2(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_accuracy = validate_q2(model, valid_loader, criterion)\n",
        "    test_loss, test_accuracy = test_q2(model, test_loader, criterion)\n",
        "\n",
        "    train_losses_q2.append(train_loss)\n",
        "    train_accuracies_q2.append(train_accuracy)\n",
        "    val_losses_q2.append(val_loss)\n",
        "    val_accuracies_q2.append(val_accuracy)\n",
        "    test_losses_q2.append(test_loss)\n",
        "    test_accuracies_q2.append(test_accuracy)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to train the model: {(end_time - start_time) / 60} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "JUZI7OvPWMEz",
        "outputId": "0453df4b-393c-41f4-de24-852ff5754fee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_losses_q2, label='Train')\n",
        "plt.plot(range(num_epochs), val_losses_q2, label='Validation')\n",
        "plt.plot(range(num_epochs), test_losses_q2, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_accuracies_q2, label='Train')\n",
        "plt.plot(range(num_epochs), val_accuracies_q2, label='Validation')\n",
        "plt.plot(range(num_epochs), test_accuracies_q2, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7htaXiMHWMEz"
      },
      "source": [
        "# Question-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHkKvALR7xh"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-of7MIABP56m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Bzsc_LP56m"
      },
      "source": [
        "### Classes for Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MIt8gxEK3Zo"
      },
      "outputs": [],
      "source": [
        "class SoftMax:\n",
        "    def __init__(self):\n",
        "        self.activation = None\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        self.activation = torch.exp(x) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
        "        return self.activation\n",
        "\n",
        "    def backward(self, x:torch.tensor):\n",
        "        x = self.activation\n",
        "        # x = torch.exp(x) / torch.sum(torch.exp(x))\n",
        "        return torch.diag_embed(x) - torch.bmm(x.unsqueeze(-1), x.unsqueeze(1))\n",
        "\n",
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.activation = None\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        self.activation = torch.max(torch.zeros_like(x), x)\n",
        "        return self.activation\n",
        "\n",
        "    def backward(self, x:torch.tensor):\n",
        "        return torch.where(x >= 0, torch.ones_like(x), torch.zeros_like(x))\n",
        "\n",
        "class TanH:\n",
        "    def __init__(self):\n",
        "        self.activation = None\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        self.activation = torch.tanh(x)\n",
        "        return self.activation\n",
        "\n",
        "    def backward(self, x:torch.tensor):\n",
        "        return 1 - torch.pow(self.activation, 2)\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.activation = None\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        self.activation = torch.sigmoid(x)\n",
        "        return self.activation\n",
        "\n",
        "    def backward(self, x:torch.tensor):\n",
        "        return self.activation * (1 - self.activation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akNYhqnoP56p"
      },
      "source": [
        "### Class for Linear Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIr2A04GK3Zp"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "    def __init__(self, in_features, out_features, bias=True, device:str='cpu'):\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weights = torch.randn((out_features, in_features), device=device).div_(math.sqrt(in_features + out_features))\n",
        "        self.bias = torch.randn((out_features, 1), device=device).div_(math.sqrt(in_features + out_features)) if bias else None\n",
        "        self.grad_weights = torch.zeros_like(self.weights, device=device)\n",
        "        self.grad_bias = torch.zeros_like(self.bias, device=device) if bias else None\n",
        "        self.z = torch.zeros((out_features, 1), device=device)\n",
        "        self.error_output = torch.zeros((out_features, 1), device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.z = torch.matmul(x, self.weights.t())\n",
        "        if self.bias is not None:\n",
        "            self.z += self.bias.t()\n",
        "        return self.z\n",
        "\n",
        "    def backward(self, activation_value_prevlayer:torch.tensor):\n",
        "        self.grad_weights = torch.matmul(self.error_output.t(), activation_value_prevlayer)\n",
        "        if self.bias is not None:\n",
        "            self.grad_bias = torch.sum(self.error_output, dim=0, keepdim=True).t()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3TB-7TwP56p"
      },
      "source": [
        "### Class for Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj6XXDgRK3Zr"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, in_features=28*28, out_features=10, device:str='cpu'):\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.device = device\n",
        "        self.fc1 = Linear(in_features, 512, device=device)\n",
        "        self.relu1 = ReLU()\n",
        "        self.fc2 = Linear(512, 256, device=device)\n",
        "        self.relu2 = ReLU()\n",
        "        self.fc3 = Linear(256, 128, device=device)\n",
        "        self.relu3 = ReLU()\n",
        "        self.fc4 = Linear(128, 64, device=device)\n",
        "        self.relu4 = ReLU()\n",
        "        self.fc5 = Linear(64, out_features, device=device)\n",
        "        self.softmax = SoftMax()\n",
        "        self.parameters = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5]\n",
        "        self.input_features = None\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        self.input_features = x.clone()\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu1.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        x = self.relu2.forward(x)\n",
        "        x = self.fc3.forward(x)\n",
        "        x = self.relu3.forward(x)\n",
        "        x = self.fc4.forward(x)\n",
        "        x = self.relu4.forward(x)\n",
        "        x = self.fc5.forward(x)\n",
        "        x = self.softmax.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, true_labels:torch.tensor):\n",
        "        true_labels = torch.zeros((true_labels.size(0), 10), device=self.device).scatter_(1, true_labels.view(-1, 1), 1)\n",
        "        self.fc5.error_output = torch.matmul(self.softmax.backward(self.fc5.z), (true_labels - self.softmax.activation).unsqueeze(-1)).squeeze(-1)\n",
        "        self.fc5.backward(self.relu4.activation)\n",
        "        self.fc4.error_output = self.relu4.backward(self.fc4.z) * torch.matmul(self.fc5.error_output, self.fc5.weights)\n",
        "        self.fc4.backward(self.relu3.activation)\n",
        "        self.fc3.error_output = self.relu3.backward(self.fc3.z) * torch.matmul(self.fc4.error_output, self.fc4.weights)\n",
        "        self.fc3.backward(self.relu2.activation)\n",
        "        self.fc2.error_output = self.relu2.backward(self.fc2.z) * torch.matmul(self.fc3.error_output, self.fc3.weights)\n",
        "        self.fc2.backward(self.relu1.activation)\n",
        "        self.fc1.error_output = self.relu1.backward(self.fc1.z) * torch.matmul(self.fc2.error_output, self.fc2.weights)\n",
        "        self.fc1.backward(self.input_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worO-fhEK3aI"
      },
      "source": [
        "### Class for Cross-Entropy Loss & SGD Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M9sLrz0K3aI"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss:\n",
        "    def forward(self, output:torch.tensor, labels:torch.tensor, use_softmax=False):\n",
        "        if use_softmax:\n",
        "            output = SoftMax().forward(output)\n",
        "        loss = -torch.sum(torch.log(output.gather(1, labels.unsqueeze(1)))) / labels.size(0)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, model, true_labels:torch.tensor):\n",
        "        model.backward(true_labels)\n",
        "\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self, parameters, lr=0.0003):\n",
        "        self.parameters = parameters\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        for layer in self.parameters:\n",
        "            layer.weights += self.lr * layer.grad_weights\n",
        "            if layer.bias is not None:\n",
        "                layer.bias += self.lr * layer.grad_bias\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for layer in self.parameters:\n",
        "            layer.grad_weights.zero_()\n",
        "            if layer.bias is not None:\n",
        "                layer.grad_bias.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGfFy9JE0mig"
      },
      "source": [
        "### Initialize Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyzLre72K3aL",
        "outputId": "8bb3a2be-72d5-46c0-b986-3873bea992cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 10000\n",
            "Dataset image shape: torch.Size([10000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([10000])\n",
            "\n",
            "Train Dataset Length: 54000\n",
            "Validation Dataset Length: 6000\n",
            "Test Dataset Length: 10000\n",
            "\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.float32 torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Creating training and test datasets\n",
        "root = './data/MNIST/raw/'\n",
        "train_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "test_dataset = MNISTCustomDataset(root=root, train=False, transform=None)\n",
        "\n",
        "# splitting of training and validation set\n",
        "batch_size = 128\n",
        "valid_size = 0.1\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Train Dataset Length: {}'.format(len(train_sampler)))\n",
        "print('Validation Dataset Length: {}'.format(len(valid_sampler)))\n",
        "print('Test Dataset Length: {}\\n'.format(len(test_dataset)))\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(type(images), type(labels))\n",
        "    print(images.dtype, labels.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDghauDqRVZ2"
      },
      "source": [
        "### Intialize Custom Model, Loss and Optimizer  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcCDZ71xP561",
        "outputId": "db4758bc-6623-441a-ea16-0af79ccd1c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_custom = NeuralNetwork(in_features=28*28, out_features=10, device=device)\n",
        "sgd_optimizer = SGD(model_custom.parameters, lr=0.0003)\n",
        "ce_loss = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DpJ7Zg4N1sZ"
      },
      "source": [
        "### Training of Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHH5lCzlK3aN",
        "outputId": "28f50798-a3b3-45fe-87bb-43d8c029bc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Batch loss: 22.427891,  Batch Accuracy: 13.28  [ 1280/54000]\n",
            "Batch loss: 10.905039,  Batch Accuracy: 17.19  [ 2560/54000]\n",
            "Batch loss: 4.111708,  Batch Accuracy: 46.88  [ 3840/54000]\n",
            "Batch loss: 2.140844,  Batch Accuracy: 58.59  [ 5120/54000]\n",
            "Batch loss: 1.244059,  Batch Accuracy: 70.31  [ 6400/54000]\n",
            "Batch loss: 1.004127,  Batch Accuracy: 71.09  [ 7680/54000]\n",
            "Batch loss: 0.774948,  Batch Accuracy: 81.25  [ 8960/54000]\n",
            "Batch loss: 0.699553,  Batch Accuracy: 85.16  [10240/54000]\n",
            "Batch loss: 0.585437,  Batch Accuracy: 83.59  [11520/54000]\n",
            "Batch loss: 0.261870,  Batch Accuracy: 92.97  [12800/54000]\n",
            "Batch loss: 0.626210,  Batch Accuracy: 83.59  [14080/54000]\n",
            "Batch loss: 0.687861,  Batch Accuracy: 85.16  [15360/54000]\n",
            "Batch loss: 0.557726,  Batch Accuracy: 79.69  [16640/54000]\n",
            "Batch loss: 0.572531,  Batch Accuracy: 86.72  [17920/54000]\n",
            "Batch loss: 0.378947,  Batch Accuracy: 89.84  [19200/54000]\n",
            "Batch loss: 0.308074,  Batch Accuracy: 91.41  [20480/54000]\n",
            "Batch loss: 0.325601,  Batch Accuracy: 91.41  [21760/54000]\n",
            "Batch loss: 0.475207,  Batch Accuracy: 89.06  [23040/54000]\n",
            "Batch loss: 0.373113,  Batch Accuracy: 90.62  [24320/54000]\n",
            "Batch loss: 0.468730,  Batch Accuracy: 85.16  [25600/54000]\n",
            "Batch loss: 0.163705,  Batch Accuracy: 93.75  [26880/54000]\n",
            "Batch loss: 0.339610,  Batch Accuracy: 89.06  [28160/54000]\n",
            "Batch loss: 0.388945,  Batch Accuracy: 89.84  [29440/54000]\n",
            "Batch loss: 0.328455,  Batch Accuracy: 92.19  [30720/54000]\n",
            "Batch loss: 0.301729,  Batch Accuracy: 89.84  [32000/54000]\n",
            "Batch loss: 0.296892,  Batch Accuracy: 89.84  [33280/54000]\n",
            "Batch loss: 0.200345,  Batch Accuracy: 95.31  [34560/54000]\n",
            "Batch loss: 0.528362,  Batch Accuracy: 89.84  [35840/54000]\n",
            "Batch loss: 0.250772,  Batch Accuracy: 93.75  [37120/54000]\n",
            "Batch loss: 0.403929,  Batch Accuracy: 92.19  [38400/54000]\n",
            "Batch loss: 0.222756,  Batch Accuracy: 94.53  [39680/54000]\n",
            "Batch loss: 0.193192,  Batch Accuracy: 94.53  [40960/54000]\n",
            "Batch loss: 0.208371,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.166602,  Batch Accuracy: 94.53  [43520/54000]\n",
            "Batch loss: 0.159548,  Batch Accuracy: 96.09  [44800/54000]\n",
            "Batch loss: 0.226985,  Batch Accuracy: 92.97  [46080/54000]\n",
            "Batch loss: 0.312891,  Batch Accuracy: 90.62  [47360/54000]\n",
            "Batch loss: 0.344137,  Batch Accuracy: 91.41  [48640/54000]\n",
            "Batch loss: 0.260403,  Batch Accuracy: 91.41  [49920/54000]\n",
            "Batch loss: 0.157377,  Batch Accuracy: 94.53  [51200/54000]\n",
            "Batch loss: 0.282363,  Batch Accuracy: 94.53  [52480/54000]\n",
            "Batch loss: 0.128094,  Batch Accuracy: 98.44  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 83.27%, Loss: 1.3935\n",
            "Validation performance:\n",
            " Accuracy: 92.42%, Loss: 0.2951\n",
            "Test performance: Accuracy:\n",
            " 92.83%, Loss: 0.2698\n",
            "Epoch 2\n",
            "Batch loss: 0.075900,  Batch Accuracy: 96.88  [ 1280/54000]\n",
            "Batch loss: 0.252993,  Batch Accuracy: 95.31  [ 2560/54000]\n",
            "Batch loss: 0.128095,  Batch Accuracy: 96.88  [ 3840/54000]\n",
            "Batch loss: 0.151984,  Batch Accuracy: 93.75  [ 5120/54000]\n",
            "Batch loss: 0.313767,  Batch Accuracy: 93.75  [ 6400/54000]\n",
            "Batch loss: 0.168415,  Batch Accuracy: 95.31  [ 7680/54000]\n",
            "Batch loss: 0.154115,  Batch Accuracy: 95.31  [ 8960/54000]\n",
            "Batch loss: 0.090183,  Batch Accuracy: 96.88  [10240/54000]\n",
            "Batch loss: 0.106678,  Batch Accuracy: 98.44  [11520/54000]\n",
            "Batch loss: 0.158899,  Batch Accuracy: 94.53  [12800/54000]\n",
            "Batch loss: 0.107854,  Batch Accuracy: 96.88  [14080/54000]\n",
            "Batch loss: 0.164550,  Batch Accuracy: 94.53  [15360/54000]\n",
            "Batch loss: 0.099690,  Batch Accuracy: 96.09  [16640/54000]\n",
            "Batch loss: 0.105967,  Batch Accuracy: 96.09  [17920/54000]\n",
            "Batch loss: 0.269893,  Batch Accuracy: 95.31  [19200/54000]\n",
            "Batch loss: 0.217580,  Batch Accuracy: 95.31  [20480/54000]\n",
            "Batch loss: 0.075825,  Batch Accuracy: 97.66  [21760/54000]\n",
            "Batch loss: 0.094679,  Batch Accuracy: 96.88  [23040/54000]\n",
            "Batch loss: 0.093685,  Batch Accuracy: 97.66  [24320/54000]\n",
            "Batch loss: 0.129629,  Batch Accuracy: 94.53  [25600/54000]\n",
            "Batch loss: 0.129921,  Batch Accuracy: 95.31  [26880/54000]\n",
            "Batch loss: 0.182743,  Batch Accuracy: 92.19  [28160/54000]\n",
            "Batch loss: 0.164712,  Batch Accuracy: 96.09  [29440/54000]\n",
            "Batch loss: 0.254262,  Batch Accuracy: 94.53  [30720/54000]\n",
            "Batch loss: 0.316819,  Batch Accuracy: 89.84  [32000/54000]\n",
            "Batch loss: 0.242005,  Batch Accuracy: 92.19  [33280/54000]\n",
            "Batch loss: 0.311263,  Batch Accuracy: 96.88  [34560/54000]\n",
            "Batch loss: 0.285286,  Batch Accuracy: 95.31  [35840/54000]\n",
            "Batch loss: 0.171267,  Batch Accuracy: 94.53  [37120/54000]\n",
            "Batch loss: 0.072636,  Batch Accuracy: 96.09  [38400/54000]\n",
            "Batch loss: 0.191988,  Batch Accuracy: 92.97  [39680/54000]\n",
            "Batch loss: 0.079931,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.038025,  Batch Accuracy: 98.44  [42240/54000]\n",
            "Batch loss: 0.124126,  Batch Accuracy: 96.09  [43520/54000]\n",
            "Batch loss: 0.266174,  Batch Accuracy: 92.97  [44800/54000]\n",
            "Batch loss: 0.415562,  Batch Accuracy: 90.62  [46080/54000]\n",
            "Batch loss: 0.337989,  Batch Accuracy: 93.75  [47360/54000]\n",
            "Batch loss: 0.165413,  Batch Accuracy: 95.31  [48640/54000]\n",
            "Batch loss: 0.112744,  Batch Accuracy: 97.66  [49920/54000]\n",
            "Batch loss: 0.310386,  Batch Accuracy: 93.75  [51200/54000]\n",
            "Batch loss: 0.098822,  Batch Accuracy: 97.66  [52480/54000]\n",
            "Batch loss: 0.241486,  Batch Accuracy: 94.53  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 95.04%, Loss: 0.2005\n",
            "Validation performance:\n",
            " Accuracy: 95.17%, Loss: 0.1930\n",
            "Test performance: Accuracy:\n",
            " 95.47%, Loss: 0.1765\n",
            "Epoch 3\n",
            "Batch loss: 0.072228,  Batch Accuracy: 96.88  [ 1280/54000]\n",
            "Batch loss: 0.126143,  Batch Accuracy: 96.88  [ 2560/54000]\n",
            "Batch loss: 0.059392,  Batch Accuracy: 98.44  [ 3840/54000]\n",
            "Batch loss: 0.224428,  Batch Accuracy: 95.31  [ 5120/54000]\n",
            "Batch loss: 0.346859,  Batch Accuracy: 96.09  [ 6400/54000]\n",
            "Batch loss: 0.207381,  Batch Accuracy: 96.09  [ 7680/54000]\n",
            "Batch loss: 0.309808,  Batch Accuracy: 92.97  [ 8960/54000]\n",
            "Batch loss: 0.140420,  Batch Accuracy: 95.31  [10240/54000]\n",
            "Batch loss: 0.056019,  Batch Accuracy: 98.44  [11520/54000]\n",
            "Batch loss: 0.179553,  Batch Accuracy: 96.09  [12800/54000]\n",
            "Batch loss: 0.260815,  Batch Accuracy: 94.53  [14080/54000]\n",
            "Batch loss: 0.087850,  Batch Accuracy: 98.44  [15360/54000]\n",
            "Batch loss: 0.091302,  Batch Accuracy: 97.66  [16640/54000]\n",
            "Batch loss: 0.275688,  Batch Accuracy: 95.31  [17920/54000]\n",
            "Batch loss: 0.220188,  Batch Accuracy: 94.53  [19200/54000]\n",
            "Batch loss: 0.187015,  Batch Accuracy: 94.53  [20480/54000]\n",
            "Batch loss: 0.157144,  Batch Accuracy: 95.31  [21760/54000]\n",
            "Batch loss: 0.209175,  Batch Accuracy: 93.75  [23040/54000]\n",
            "Batch loss: 0.149782,  Batch Accuracy: 97.66  [24320/54000]\n",
            "Batch loss: 0.252021,  Batch Accuracy: 95.31  [25600/54000]\n",
            "Batch loss: 0.075560,  Batch Accuracy: 97.66  [26880/54000]\n",
            "Batch loss: 0.141282,  Batch Accuracy: 96.09  [28160/54000]\n",
            "Batch loss: 0.180481,  Batch Accuracy: 95.31  [29440/54000]\n",
            "Batch loss: 0.038122,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.533270,  Batch Accuracy: 92.19  [32000/54000]\n",
            "Batch loss: 0.060820,  Batch Accuracy: 97.66  [33280/54000]\n",
            "Batch loss: 0.146444,  Batch Accuracy: 96.88  [34560/54000]\n",
            "Batch loss: 0.166573,  Batch Accuracy: 97.66  [35840/54000]\n",
            "Batch loss: 0.346947,  Batch Accuracy: 92.19  [37120/54000]\n",
            "Batch loss: 0.213697,  Batch Accuracy: 95.31  [38400/54000]\n",
            "Batch loss: 0.153146,  Batch Accuracy: 95.31  [39680/54000]\n",
            "Batch loss: 0.121821,  Batch Accuracy: 97.66  [40960/54000]\n",
            "Batch loss: 0.239499,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.110668,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.218527,  Batch Accuracy: 94.53  [44800/54000]\n",
            "Batch loss: 0.112329,  Batch Accuracy: 96.88  [46080/54000]\n",
            "Batch loss: 0.067023,  Batch Accuracy: 98.44  [47360/54000]\n",
            "Batch loss: 0.182495,  Batch Accuracy: 96.09  [48640/54000]\n",
            "Batch loss: 0.081030,  Batch Accuracy: 97.66  [49920/54000]\n",
            "Batch loss: 0.138179,  Batch Accuracy: 97.66  [51200/54000]\n",
            "Batch loss: 0.142733,  Batch Accuracy: 97.66  [52480/54000]\n",
            "Batch loss: 0.170098,  Batch Accuracy: 96.88  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 96.47%, Loss: 0.1480\n",
            "Validation performance:\n",
            " Accuracy: 95.68%, Loss: 0.1717\n",
            "Test performance: Accuracy:\n",
            " 95.93%, Loss: 0.1620\n",
            "Epoch 4\n",
            "Batch loss: 0.063565,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.076609,  Batch Accuracy: 97.66  [ 2560/54000]\n",
            "Batch loss: 0.140571,  Batch Accuracy: 96.88  [ 3840/54000]\n",
            "Batch loss: 0.171041,  Batch Accuracy: 96.09  [ 5120/54000]\n",
            "Batch loss: 0.032669,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.019810,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.157339,  Batch Accuracy: 95.31  [ 8960/54000]\n",
            "Batch loss: 0.129636,  Batch Accuracy: 97.66  [10240/54000]\n",
            "Batch loss: 0.172062,  Batch Accuracy: 96.88  [11520/54000]\n",
            "Batch loss: 0.068664,  Batch Accuracy: 98.44  [12800/54000]\n",
            "Batch loss: 0.138340,  Batch Accuracy: 96.09  [14080/54000]\n",
            "Batch loss: 0.067302,  Batch Accuracy: 97.66  [15360/54000]\n",
            "Batch loss: 0.399518,  Batch Accuracy: 94.53  [16640/54000]\n",
            "Batch loss: 0.058346,  Batch Accuracy: 97.66  [17920/54000]\n",
            "Batch loss: 0.105476,  Batch Accuracy: 97.66  [19200/54000]\n",
            "Batch loss: 0.060332,  Batch Accuracy: 96.88  [20480/54000]\n",
            "Batch loss: 0.015606,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.183638,  Batch Accuracy: 96.88  [23040/54000]\n",
            "Batch loss: 0.038533,  Batch Accuracy: 98.44  [24320/54000]\n",
            "Batch loss: 0.065525,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.076038,  Batch Accuracy: 97.66  [26880/54000]\n",
            "Batch loss: 0.136130,  Batch Accuracy: 96.88  [28160/54000]\n",
            "Batch loss: 0.192626,  Batch Accuracy: 96.09  [29440/54000]\n",
            "Batch loss: 0.110953,  Batch Accuracy: 96.88  [30720/54000]\n",
            "Batch loss: 0.069165,  Batch Accuracy: 96.88  [32000/54000]\n",
            "Batch loss: 0.095750,  Batch Accuracy: 96.88  [33280/54000]\n",
            "Batch loss: 0.099689,  Batch Accuracy: 97.66  [34560/54000]\n",
            "Batch loss: 0.125260,  Batch Accuracy: 97.66  [35840/54000]\n",
            "Batch loss: 0.038610,  Batch Accuracy: 98.44  [37120/54000]\n",
            "Batch loss: 0.043177,  Batch Accuracy: 98.44  [38400/54000]\n",
            "Batch loss: 0.119578,  Batch Accuracy: 96.09  [39680/54000]\n",
            "Batch loss: 0.067347,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.115823,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.144048,  Batch Accuracy: 96.88  [43520/54000]\n",
            "Batch loss: 0.013968,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.144120,  Batch Accuracy: 96.09  [46080/54000]\n",
            "Batch loss: 0.132477,  Batch Accuracy: 96.88  [47360/54000]\n",
            "Batch loss: 0.162891,  Batch Accuracy: 96.88  [48640/54000]\n",
            "Batch loss: 0.219848,  Batch Accuracy: 96.88  [49920/54000]\n",
            "Batch loss: 0.065084,  Batch Accuracy: 97.66  [51200/54000]\n",
            "Batch loss: 0.134413,  Batch Accuracy: 97.66  [52480/54000]\n",
            "Batch loss: 0.153055,  Batch Accuracy: 97.66  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 97.43%, Loss: 0.1141\n",
            "Validation performance:\n",
            " Accuracy: 96.25%, Loss: 0.1405\n",
            "Test performance: Accuracy:\n",
            " 96.57%, Loss: 0.1383\n",
            "Epoch 5\n",
            "Batch loss: 0.106037,  Batch Accuracy: 97.66  [ 1280/54000]\n",
            "Batch loss: 0.127601,  Batch Accuracy: 97.66  [ 2560/54000]\n",
            "Batch loss: 0.093248,  Batch Accuracy: 98.44  [ 3840/54000]\n",
            "Batch loss: 0.143353,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.152029,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.073324,  Batch Accuracy: 97.66  [ 7680/54000]\n",
            "Batch loss: 0.194679,  Batch Accuracy: 96.88  [ 8960/54000]\n",
            "Batch loss: 0.187022,  Batch Accuracy: 96.88  [10240/54000]\n",
            "Batch loss: 0.077443,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.094787,  Batch Accuracy: 97.66  [12800/54000]\n",
            "Batch loss: 0.014525,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.030900,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.061034,  Batch Accuracy: 98.44  [16640/54000]\n",
            "Batch loss: 0.029635,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.061154,  Batch Accuracy: 98.44  [19200/54000]\n",
            "Batch loss: 0.052445,  Batch Accuracy: 98.44  [20480/54000]\n",
            "Batch loss: 0.208114,  Batch Accuracy: 97.66  [21760/54000]\n",
            "Batch loss: 0.057093,  Batch Accuracy: 98.44  [23040/54000]\n",
            "Batch loss: 0.081806,  Batch Accuracy: 97.66  [24320/54000]\n",
            "Batch loss: 0.051791,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.028719,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.075106,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.103683,  Batch Accuracy: 97.66  [29440/54000]\n",
            "Batch loss: 0.146701,  Batch Accuracy: 95.31  [30720/54000]\n",
            "Batch loss: 0.125125,  Batch Accuracy: 97.66  [32000/54000]\n",
            "Batch loss: 0.045434,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.038437,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.077521,  Batch Accuracy: 98.44  [35840/54000]\n",
            "Batch loss: 0.023858,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.139973,  Batch Accuracy: 97.66  [38400/54000]\n",
            "Batch loss: 0.129725,  Batch Accuracy: 97.66  [39680/54000]\n",
            "Batch loss: 0.192329,  Batch Accuracy: 96.09  [40960/54000]\n",
            "Batch loss: 0.077281,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.185087,  Batch Accuracy: 96.88  [43520/54000]\n",
            "Batch loss: 0.060466,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.038410,  Batch Accuracy: 97.66  [46080/54000]\n",
            "Batch loss: 0.015671,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.024464,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.180804,  Batch Accuracy: 98.44  [49920/54000]\n",
            "Batch loss: 0.085829,  Batch Accuracy: 98.44  [51200/54000]\n",
            "Batch loss: 0.108538,  Batch Accuracy: 98.44  [52480/54000]\n",
            "Batch loss: 0.120378,  Batch Accuracy: 97.66  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 98.14%, Loss: 0.0915\n",
            "Validation performance:\n",
            " Accuracy: 96.32%, Loss: 0.1468\n",
            "Test performance: Accuracy:\n",
            " 96.65%, Loss: 0.1380\n",
            "Epoch 6\n",
            "Batch loss: 0.093427,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.035261,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.060174,  Batch Accuracy: 97.66  [ 3840/54000]\n",
            "Batch loss: 0.014528,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.066085,  Batch Accuracy: 98.44  [ 6400/54000]\n",
            "Batch loss: 0.165039,  Batch Accuracy: 97.66  [ 7680/54000]\n",
            "Batch loss: 0.074435,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.184833,  Batch Accuracy: 98.44  [10240/54000]\n",
            "Batch loss: 0.092713,  Batch Accuracy: 97.66  [11520/54000]\n",
            "Batch loss: 0.171377,  Batch Accuracy: 98.44  [12800/54000]\n",
            "Batch loss: 0.146083,  Batch Accuracy: 97.66  [14080/54000]\n",
            "Batch loss: 0.013302,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.066725,  Batch Accuracy: 98.44  [16640/54000]\n",
            "Batch loss: 0.087978,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.120765,  Batch Accuracy: 98.44  [19200/54000]\n",
            "Batch loss: 0.035923,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.078838,  Batch Accuracy: 97.66  [21760/54000]\n",
            "Batch loss: 0.035178,  Batch Accuracy: 98.44  [23040/54000]\n",
            "Batch loss: 0.048864,  Batch Accuracy: 98.44  [24320/54000]\n",
            "Batch loss: 0.129479,  Batch Accuracy: 97.66  [25600/54000]\n",
            "Batch loss: 0.124166,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.186982,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.035261,  Batch Accuracy: 98.44  [29440/54000]\n",
            "Batch loss: 0.036923,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.028728,  Batch Accuracy: 98.44  [32000/54000]\n",
            "Batch loss: 0.148667,  Batch Accuracy: 98.44  [33280/54000]\n",
            "Batch loss: 0.062311,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.056719,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.011686,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.055042,  Batch Accuracy: 97.66  [38400/54000]\n",
            "Batch loss: 0.045759,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.103774,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.100778,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.198021,  Batch Accuracy: 96.88  [43520/54000]\n",
            "Batch loss: 0.047706,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.041696,  Batch Accuracy: 98.44  [46080/54000]\n",
            "Batch loss: 0.013867,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.023604,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.011332,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.108978,  Batch Accuracy: 96.88  [51200/54000]\n",
            "Batch loss: 0.018791,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.015143,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 98.48%, Loss: 0.0795\n",
            "Validation performance:\n",
            " Accuracy: 96.60%, Loss: 0.1277\n",
            "Test performance: Accuracy:\n",
            " 96.94%, Loss: 0.1163\n",
            "Epoch 7\n",
            "Batch loss: 0.007939,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.077260,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.103542,  Batch Accuracy: 98.44  [ 3840/54000]\n",
            "Batch loss: 0.016437,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.074874,  Batch Accuracy: 98.44  [ 6400/54000]\n",
            "Batch loss: 0.070028,  Batch Accuracy: 97.66  [ 7680/54000]\n",
            "Batch loss: 0.179942,  Batch Accuracy: 96.88  [ 8960/54000]\n",
            "Batch loss: 0.069764,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.005524,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.104736,  Batch Accuracy: 97.66  [12800/54000]\n",
            "Batch loss: 0.004768,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.021890,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.048337,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.034316,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.096878,  Batch Accuracy: 98.44  [19200/54000]\n",
            "Batch loss: 0.048408,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.016423,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.115393,  Batch Accuracy: 97.66  [23040/54000]\n",
            "Batch loss: 0.007890,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.009292,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.071591,  Batch Accuracy: 98.44  [26880/54000]\n",
            "Batch loss: 0.092117,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.016827,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.099593,  Batch Accuracy: 98.44  [30720/54000]\n",
            "Batch loss: 0.051294,  Batch Accuracy: 98.44  [32000/54000]\n",
            "Batch loss: 0.011989,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.106543,  Batch Accuracy: 97.66  [34560/54000]\n",
            "Batch loss: 0.091089,  Batch Accuracy: 97.66  [35840/54000]\n",
            "Batch loss: 0.122960,  Batch Accuracy: 96.88  [37120/54000]\n",
            "Batch loss: 0.046527,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.012857,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.096392,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.022497,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.085191,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.119386,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.064431,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.023518,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.089200,  Batch Accuracy: 98.44  [48640/54000]\n",
            "Batch loss: 0.027782,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.010531,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.217180,  Batch Accuracy: 96.09  [52480/54000]\n",
            "Batch loss: 0.176420,  Batch Accuracy: 97.66  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 98.78%, Loss: 0.0689\n",
            "Validation performance:\n",
            " Accuracy: 96.70%, Loss: 0.1252\n",
            "Test performance: Accuracy:\n",
            " 96.94%, Loss: 0.1201\n",
            "Epoch 8\n",
            "Batch loss: 0.151870,  Batch Accuracy: 97.66  [ 1280/54000]\n",
            "Batch loss: 0.061697,  Batch Accuracy: 97.66  [ 2560/54000]\n",
            "Batch loss: 0.038708,  Batch Accuracy: 97.66  [ 3840/54000]\n",
            "Batch loss: 0.021767,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.069257,  Batch Accuracy: 97.66  [ 6400/54000]\n",
            "Batch loss: 0.037201,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.082098,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.038127,  Batch Accuracy: 98.44  [10240/54000]\n",
            "Batch loss: 0.053909,  Batch Accuracy: 97.66  [11520/54000]\n",
            "Batch loss: 0.146595,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.009963,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.103420,  Batch Accuracy: 97.66  [15360/54000]\n",
            "Batch loss: 0.121107,  Batch Accuracy: 97.66  [16640/54000]\n",
            "Batch loss: 0.008132,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.005842,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.113489,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.159420,  Batch Accuracy: 97.66  [21760/54000]\n",
            "Batch loss: 0.089758,  Batch Accuracy: 98.44  [23040/54000]\n",
            "Batch loss: 0.006564,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.023756,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.056555,  Batch Accuracy: 98.44  [26880/54000]\n",
            "Batch loss: 0.026066,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.018439,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.166465,  Batch Accuracy: 97.66  [30720/54000]\n",
            "Batch loss: 0.013119,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.069525,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.061523,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.084252,  Batch Accuracy: 97.66  [35840/54000]\n",
            "Batch loss: 0.098135,  Batch Accuracy: 98.44  [37120/54000]\n",
            "Batch loss: 0.023768,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.078118,  Batch Accuracy: 98.44  [39680/54000]\n",
            "Batch loss: 0.070420,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.098669,  Batch Accuracy: 97.66  [42240/54000]\n",
            "Batch loss: 0.086746,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.118390,  Batch Accuracy: 96.88  [44800/54000]\n",
            "Batch loss: 0.215664,  Batch Accuracy: 97.66  [46080/54000]\n",
            "Batch loss: 0.016868,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.087689,  Batch Accuracy: 98.44  [48640/54000]\n",
            "Batch loss: 0.004968,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.097320,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.113962,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.092303,  Batch Accuracy: 96.88  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 98.97%, Loss: 0.0604\n",
            "Validation performance:\n",
            " Accuracy: 96.87%, Loss: 0.1211\n",
            "Test performance: Accuracy:\n",
            " 97.01%, Loss: 0.1168\n",
            "Epoch 9\n",
            "Batch loss: 0.002842,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.075157,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.061376,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.067965,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.048711,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.013525,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.052046,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.009374,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.005835,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.209760,  Batch Accuracy: 97.66  [12800/54000]\n",
            "Batch loss: 0.008758,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.004427,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.280388,  Batch Accuracy: 96.88  [16640/54000]\n",
            "Batch loss: 0.039647,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.005498,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.007854,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.027223,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.006137,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.006907,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.013913,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.065275,  Batch Accuracy: 98.44  [26880/54000]\n",
            "Batch loss: 0.064207,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.007406,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.071688,  Batch Accuracy: 98.44  [30720/54000]\n",
            "Batch loss: 0.076436,  Batch Accuracy: 98.44  [32000/54000]\n",
            "Batch loss: 0.017732,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.082886,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.087974,  Batch Accuracy: 98.44  [35840/54000]\n",
            "Batch loss: 0.146510,  Batch Accuracy: 97.66  [37120/54000]\n",
            "Batch loss: 0.007561,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.006812,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.010625,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.007860,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.058889,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.084381,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.035408,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.013471,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.024875,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.087043,  Batch Accuracy: 97.66  [49920/54000]\n",
            "Batch loss: 0.055389,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.091305,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.027974,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.19%, Loss: 0.0525\n",
            "Validation performance:\n",
            " Accuracy: 97.03%, Loss: 0.1124\n",
            "Test performance: Accuracy:\n",
            " 96.99%, Loss: 0.1162\n",
            "Epoch 10\n",
            "Batch loss: 0.035322,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.005274,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.046145,  Batch Accuracy: 98.44  [ 3840/54000]\n",
            "Batch loss: 0.111390,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.002319,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.122225,  Batch Accuracy: 98.44  [ 7680/54000]\n",
            "Batch loss: 0.064886,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.006900,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.009231,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.041153,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.045795,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.016740,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.010514,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.063076,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.004777,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.003873,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.009444,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.003854,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.093296,  Batch Accuracy: 98.44  [24320/54000]\n",
            "Batch loss: 0.013657,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.046459,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.008720,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.036341,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.008909,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002873,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.008430,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.066831,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.003122,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.007907,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.073816,  Batch Accuracy: 98.44  [38400/54000]\n",
            "Batch loss: 0.073468,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.122730,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.048796,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.093722,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.039636,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.011592,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.008253,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.014120,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.111141,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.009072,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.066485,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.007360,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.31%, Loss: 0.0474\n",
            "Validation performance:\n",
            " Accuracy: 96.98%, Loss: 0.1177\n",
            "Test performance: Accuracy:\n",
            " 97.16%, Loss: 0.1087\n",
            "Epoch 11\n",
            "Batch loss: 0.002599,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.048913,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.013970,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.126898,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.013574,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.174939,  Batch Accuracy: 98.44  [ 7680/54000]\n",
            "Batch loss: 0.258716,  Batch Accuracy: 96.88  [ 8960/54000]\n",
            "Batch loss: 0.009263,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.094095,  Batch Accuracy: 97.66  [11520/54000]\n",
            "Batch loss: 0.069965,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.124199,  Batch Accuracy: 98.44  [14080/54000]\n",
            "Batch loss: 0.094562,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.011795,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.020942,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.088981,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.006612,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.025027,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.009491,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.004447,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.040610,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.009101,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.005095,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.008346,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.033373,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.075455,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.036901,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.006418,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.064661,  Batch Accuracy: 98.44  [35840/54000]\n",
            "Batch loss: 0.005859,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.032970,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.006016,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.040607,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.117968,  Batch Accuracy: 97.66  [42240/54000]\n",
            "Batch loss: 0.004455,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.003019,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.115655,  Batch Accuracy: 98.44  [46080/54000]\n",
            "Batch loss: 0.003167,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.007829,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.062790,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.005689,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.015450,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.056765,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.44%, Loss: 0.0433\n",
            "Validation performance:\n",
            " Accuracy: 96.92%, Loss: 0.1124\n",
            "Test performance: Accuracy:\n",
            " 97.27%, Loss: 0.1082\n",
            "Epoch 12\n",
            "Batch loss: 0.108858,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.044604,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.091246,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.005922,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.021391,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.004969,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.150986,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.012088,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.007675,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.030648,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.009138,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.005639,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.009114,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.160269,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.003331,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.004062,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.155660,  Batch Accuracy: 97.66  [21760/54000]\n",
            "Batch loss: 0.004827,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.005998,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.061243,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.008395,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.004111,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.012953,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.004630,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.124826,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.099690,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.091879,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.107138,  Batch Accuracy: 98.44  [35840/54000]\n",
            "Batch loss: 0.003545,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.003067,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.002274,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.115359,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.002612,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.002081,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.039929,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.025511,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.004440,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.089322,  Batch Accuracy: 98.44  [48640/54000]\n",
            "Batch loss: 0.004676,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.163689,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.110008,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.015738,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.47%, Loss: 0.0400\n",
            "Validation performance:\n",
            " Accuracy: 96.98%, Loss: 0.1155\n",
            "Test performance: Accuracy:\n",
            " 97.16%, Loss: 0.1115\n",
            "Epoch 13\n",
            "Batch loss: 0.002599,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.005395,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.013077,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001859,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.043208,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.100093,  Batch Accuracy: 98.44  [ 7680/54000]\n",
            "Batch loss: 0.044113,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.005873,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.050797,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.076198,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.002489,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.003318,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.003687,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.005522,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.041530,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.009176,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.008551,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.004652,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.014816,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.078155,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.014904,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.005132,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.004699,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.008925,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.045963,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.005908,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.080777,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.132344,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.006436,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.036984,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.151006,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.062771,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.064458,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.005320,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.008948,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.003699,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.013958,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.108071,  Batch Accuracy: 98.44  [48640/54000]\n",
            "Batch loss: 0.003985,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.013652,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.005871,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.004604,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.51%, Loss: 0.0384\n",
            "Validation performance:\n",
            " Accuracy: 97.00%, Loss: 0.1122\n",
            "Test performance: Accuracy:\n",
            " 97.33%, Loss: 0.1053\n",
            "Epoch 14\n",
            "Batch loss: 0.064338,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.002776,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.048670,  Batch Accuracy: 98.44  [ 3840/54000]\n",
            "Batch loss: 0.197080,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.073089,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.004235,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001553,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.003520,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.002420,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.077579,  Batch Accuracy: 98.44  [12800/54000]\n",
            "Batch loss: 0.008811,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.003384,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.003795,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.064555,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.007320,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002884,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.010730,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.005492,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.004898,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.004117,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.038261,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.003631,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.002293,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.009000,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.022220,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.040285,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.056287,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.041436,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.002273,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.069856,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.004131,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.007021,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.005151,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.002867,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.002813,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.053095,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.005316,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.083886,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.006639,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.020545,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.005582,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.005257,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.55%, Loss: 0.0366\n",
            "Validation performance:\n",
            " Accuracy: 97.03%, Loss: 0.1143\n",
            "Test performance: Accuracy:\n",
            " 97.40%, Loss: 0.1043\n",
            "Epoch 15\n",
            "Batch loss: 0.054703,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.053426,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.003195,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.003459,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.075647,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.040801,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.001134,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.003235,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.072299,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.005223,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.052829,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.002234,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.002278,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002145,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.002638,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.005458,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.056887,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.002880,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.004384,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.080051,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.004113,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.078303,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.003928,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.079358,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.044418,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.004734,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.009060,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.078441,  Batch Accuracy: 98.44  [35840/54000]\n",
            "Batch loss: 0.002833,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.004047,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.009151,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.036604,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.003175,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.002034,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.003327,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.008125,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.097208,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.004314,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.004865,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.004810,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.004470,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.004292,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.58%, Loss: 0.0351\n",
            "Validation performance:\n",
            " Accuracy: 97.15%, Loss: 0.1118\n",
            "Test performance: Accuracy:\n",
            " 97.42%, Loss: 0.1066\n",
            "Epoch 16\n",
            "Batch loss: 0.003060,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.031646,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.038709,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.002121,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001629,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.003094,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002668,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.208753,  Batch Accuracy: 98.44  [10240/54000]\n",
            "Batch loss: 0.001937,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.066913,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.003853,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.003499,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.074175,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.002373,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.048229,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.002937,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.004286,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.055412,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.001262,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.079436,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.010350,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.001438,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.004462,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.003450,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001184,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.063000,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.004255,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002310,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.131224,  Batch Accuracy: 98.44  [37120/54000]\n",
            "Batch loss: 0.003893,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.003921,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.038977,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.003427,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.005474,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.004149,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002442,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.068563,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.050153,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.082673,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.009170,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.003940,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.007761,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.61%, Loss: 0.0334\n",
            "Validation performance:\n",
            " Accuracy: 97.32%, Loss: 0.1105\n",
            "Test performance: Accuracy:\n",
            " 97.28%, Loss: 0.1050\n",
            "Epoch 17\n",
            "Batch loss: 0.003666,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.084313,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.009282,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.003110,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002019,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.004063,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002653,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.004052,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.003347,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.085509,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.036147,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001137,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.002553,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.004418,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.002642,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.061066,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.086742,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.002093,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001517,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002634,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.044817,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.119427,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.001800,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001570,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.045857,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.064119,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.062542,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.051080,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.001684,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.056443,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.004300,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.069362,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.002203,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.003028,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.123270,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.002199,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.004757,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002453,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.155956,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.002872,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.189309,  Batch Accuracy: 98.44  [52480/54000]\n",
            "Batch loss: 0.241963,  Batch Accuracy: 97.66  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.63%, Loss: 0.0323\n",
            "Validation performance:\n",
            " Accuracy: 97.18%, Loss: 0.1101\n",
            "Test performance: Accuracy:\n",
            " 97.43%, Loss: 0.1036\n",
            "Epoch 18\n",
            "Batch loss: 0.017392,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.001690,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.004573,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.005533,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002847,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002796,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002546,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.002261,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.003577,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.004541,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.003125,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001537,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.117441,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.260594,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.002383,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002276,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.003832,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.002480,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002465,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002378,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.156726,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.001707,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.003221,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.002714,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.003529,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.004087,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.004173,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001684,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.110310,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.018630,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.003908,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.003366,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.003416,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.003920,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.150157,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.001937,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.055303,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.002279,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.002369,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.183965,  Batch Accuracy: 98.44  [51200/54000]\n",
            "Batch loss: 0.002520,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.003326,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.65%, Loss: 0.0314\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1072\n",
            "Test performance: Accuracy:\n",
            " 97.39%, Loss: 0.1038\n",
            "Epoch 19\n",
            "Batch loss: 0.001833,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001771,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.018342,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.195082,  Batch Accuracy: 97.66  [ 5120/54000]\n",
            "Batch loss: 0.003913,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002334,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.003480,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.061238,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.003310,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002812,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.003317,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002738,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.002296,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002231,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.004306,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002743,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.002779,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.004543,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002323,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.006357,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.000961,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.003302,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.002349,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.010970,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.255216,  Batch Accuracy: 97.66  [32000/54000]\n",
            "Batch loss: 0.002010,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001797,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001990,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.093610,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.002348,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.003031,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.072176,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.006033,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.170785,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001188,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.004259,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001625,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002794,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001946,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.059831,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.004164,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001898,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.65%, Loss: 0.0303\n",
            "Validation performance:\n",
            " Accuracy: 97.22%, Loss: 0.1087\n",
            "Test performance: Accuracy:\n",
            " 97.43%, Loss: 0.1043\n",
            "Epoch 20\n",
            "Batch loss: 0.002646,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.002750,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.002574,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.004948,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.096996,  Batch Accuracy: 98.44  [ 6400/54000]\n",
            "Batch loss: 0.001804,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002816,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001185,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.014924,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.002170,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002484,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002091,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.146109,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.193810,  Batch Accuracy: 97.66  [17920/54000]\n",
            "Batch loss: 0.002693,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.004103,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.064097,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.002058,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002670,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.003434,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.002690,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002526,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001617,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.002670,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.003349,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.008301,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.181919,  Batch Accuracy: 98.44  [34560/54000]\n",
            "Batch loss: 0.004220,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.004713,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.050053,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.004786,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002424,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.003821,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.003755,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.004840,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.067096,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.002833,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.007170,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.052016,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.001215,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.004283,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.004335,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.67%, Loss: 0.0297\n",
            "Validation performance:\n",
            " Accuracy: 97.32%, Loss: 0.1086\n",
            "Test performance: Accuracy:\n",
            " 97.39%, Loss: 0.1047\n",
            "Epoch 21\n",
            "Batch loss: 0.064408,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.070256,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.002640,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.068395,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.004819,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.043990,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.003135,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001533,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.002154,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.003035,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.005159,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002190,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.002278,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002190,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.002707,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001692,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.094261,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.001831,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.059558,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.002738,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.003795,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002426,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.053195,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.003695,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002817,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.044149,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.003426,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.003126,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.071063,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.002466,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.052192,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.002537,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.005074,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.091699,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.002416,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.058147,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.002448,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.003106,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001508,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.063845,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.002593,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.077600,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.69%, Loss: 0.0285\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1099\n",
            "Test performance: Accuracy:\n",
            " 97.54%, Loss: 0.1029\n",
            "Epoch 22\n",
            "Batch loss: 0.064594,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.067386,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.014086,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.078437,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.002313,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.008928,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.003654,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.005166,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.003337,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002137,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002299,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.067361,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.032680,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.002235,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001355,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.081837,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.054698,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.053172,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.002737,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002295,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001834,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.042773,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.002563,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001387,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.003996,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001311,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.002980,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001997,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001861,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002601,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.002703,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002864,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.060974,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.069077,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001570,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002754,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.002603,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.048151,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.081143,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.000996,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002491,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002697,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.70%, Loss: 0.0279\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1115\n",
            "Test performance: Accuracy:\n",
            " 97.35%, Loss: 0.1068\n",
            "Epoch 23\n",
            "Batch loss: 0.001451,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001215,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001520,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.003504,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001828,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.003571,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.140691,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.056428,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.003762,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.004355,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002188,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.057576,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001148,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.017849,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.013080,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.004092,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.066157,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.002757,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.074847,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.004178,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.004527,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002524,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.004919,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.002439,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.057980,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.002236,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001625,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002371,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.000782,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.102416,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.003766,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002087,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.002293,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001592,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001928,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.102594,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.001940,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.058757,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.003138,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000527,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001461,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001959,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.71%, Loss: 0.0276\n",
            "Validation performance:\n",
            " Accuracy: 97.18%, Loss: 0.1106\n",
            "Test performance: Accuracy:\n",
            " 97.43%, Loss: 0.1053\n",
            "Epoch 24\n",
            "Batch loss: 0.001610,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.046966,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.002879,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001203,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001900,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.099535,  Batch Accuracy: 98.44  [ 7680/54000]\n",
            "Batch loss: 0.001571,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.002083,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.055846,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.001964,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001314,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.142933,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.002569,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002292,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.107995,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.001416,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.002065,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001793,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001775,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002643,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001548,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001856,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001883,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001000,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001918,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.003514,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001668,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.000751,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.102320,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.002595,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001539,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.001386,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001337,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.079381,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.023161,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.002391,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.121144,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.104923,  Batch Accuracy: 98.44  [48640/54000]\n",
            "Batch loss: 0.003017,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001950,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001615,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.039567,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.72%, Loss: 0.0270\n",
            "Validation performance:\n",
            " Accuracy: 97.18%, Loss: 0.1133\n",
            "Test performance: Accuracy:\n",
            " 97.48%, Loss: 0.1022\n",
            "Epoch 25\n",
            "Batch loss: 0.116014,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.003595,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.002062,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001634,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.000987,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.064502,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.002656,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001704,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.209567,  Batch Accuracy: 98.44  [11520/54000]\n",
            "Batch loss: 0.002322,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.085372,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001855,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.030322,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.111571,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.002453,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.004150,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.002904,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.002138,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.074692,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.001713,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.002122,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002356,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001852,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001014,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.130589,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.112108,  Batch Accuracy: 98.44  [33280/54000]\n",
            "Batch loss: 0.001721,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002271,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001819,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.071772,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.003860,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.113052,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.097382,  Batch Accuracy: 98.44  [42240/54000]\n",
            "Batch loss: 0.007115,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001740,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.003101,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.054981,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.002260,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.006139,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.112875,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.033857,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.002691,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.73%, Loss: 0.0266\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1121\n",
            "Test performance: Accuracy:\n",
            " 97.43%, Loss: 0.1035\n",
            "Epoch 26\n",
            "Batch loss: 0.001855,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.006104,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.149088,  Batch Accuracy: 97.66  [ 3840/54000]\n",
            "Batch loss: 0.061577,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.001231,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002946,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002006,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.042933,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.002334,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.003678,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001026,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002932,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.043331,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.002955,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.054992,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.001163,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001698,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001237,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002857,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002028,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.052712,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.003345,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.196153,  Batch Accuracy: 98.44  [29440/54000]\n",
            "Batch loss: 0.001745,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001519,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001040,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.004248,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001980,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.002142,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002067,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001784,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.094953,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.002628,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.003437,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001510,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.071541,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.112314,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.000908,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001082,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001605,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002417,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001288,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.74%, Loss: 0.0262\n",
            "Validation performance:\n",
            " Accuracy: 97.15%, Loss: 0.1139\n",
            "Test performance: Accuracy:\n",
            " 97.44%, Loss: 0.1045\n",
            "Epoch 27\n",
            "Batch loss: 0.001125,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.012963,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.002170,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.090428,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.059077,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.001825,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002097,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.048063,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.081208,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.051813,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.044288,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001692,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.050495,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.061361,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.003027,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.090117,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.004288,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.153447,  Batch Accuracy: 98.44  [23040/54000]\n",
            "Batch loss: 0.003481,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001482,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.002931,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001123,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.106173,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.001537,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002260,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.000767,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001447,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.067017,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.001698,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001140,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.000877,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002660,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.002575,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001862,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.146185,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.001774,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.002198,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002142,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.002803,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.002976,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001214,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.046974,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.74%, Loss: 0.0262\n",
            "Validation performance:\n",
            " Accuracy: 97.22%, Loss: 0.1124\n",
            "Test performance: Accuracy:\n",
            " 97.45%, Loss: 0.1052\n",
            "Epoch 28\n",
            "Batch loss: 0.002369,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.086277,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.001227,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000930,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002412,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002761,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002948,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.002352,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.002614,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002053,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001775,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.111435,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001721,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.003287,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.019529,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.002240,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001992,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.065836,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.060111,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.002376,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.002397,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002505,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001106,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001330,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001825,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001108,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.071062,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.001819,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.002110,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002195,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001724,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.000590,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001914,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001706,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001207,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001110,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.145518,  Batch Accuracy: 97.66  [47360/54000]\n",
            "Batch loss: 0.154680,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.001638,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.003441,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001502,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.086914,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.75%, Loss: 0.0254\n",
            "Validation performance:\n",
            " Accuracy: 97.18%, Loss: 0.1138\n",
            "Test performance: Accuracy:\n",
            " 97.33%, Loss: 0.1073\n",
            "Epoch 29\n",
            "Batch loss: 0.002895,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001880,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.050446,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.262188,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.001640,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.131202,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.002295,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.048719,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.002644,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001750,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001726,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001941,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001458,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001574,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001358,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001780,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000993,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.002198,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.000911,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.059921,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.003010,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.142020,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.004111,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.097233,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.001996,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.003979,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.002094,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.045057,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.002345,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.058995,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.001613,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.006442,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.002306,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.002704,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.002271,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002578,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001849,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001267,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000941,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.002840,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001312,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.057270,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.76%, Loss: 0.0253\n",
            "Validation performance:\n",
            " Accuracy: 97.17%, Loss: 0.1116\n",
            "Test performance: Accuracy:\n",
            " 97.36%, Loss: 0.1060\n",
            "Epoch 30\n",
            "Batch loss: 0.047844,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.000996,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.002533,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001694,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001887,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.050000,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.002627,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.188008,  Batch Accuracy: 98.44  [10240/54000]\n",
            "Batch loss: 0.002730,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002764,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001834,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002506,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001009,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.107595,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.003502,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001200,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001232,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001907,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002842,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001716,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001617,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001590,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001102,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.002814,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.157013,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.080767,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001633,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001362,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.003128,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.169109,  Batch Accuracy: 97.66  [38400/54000]\n",
            "Batch loss: 0.098552,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.154760,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.022093,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.153057,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.002079,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001327,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.179376,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.089084,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.129258,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.002825,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.111571,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.001395,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.76%, Loss: 0.0250\n",
            "Validation performance:\n",
            " Accuracy: 97.32%, Loss: 0.1119\n",
            "Test performance: Accuracy:\n",
            " 97.43%, Loss: 0.1042\n",
            "Epoch 31\n",
            "Batch loss: 0.000967,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001628,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001217,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001883,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002310,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.039413,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.002683,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.003433,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.002744,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002343,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001786,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.003034,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001614,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.179859,  Batch Accuracy: 98.44  [17920/54000]\n",
            "Batch loss: 0.000608,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001925,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.003256,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.088097,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.001199,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001811,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001939,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002978,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.002486,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001602,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002421,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001602,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.002625,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001383,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.002569,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001232,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.111547,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.002982,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.138512,  Batch Accuracy: 98.44  [42240/54000]\n",
            "Batch loss: 0.002406,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001760,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001326,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.002827,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001978,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.003905,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001845,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001124,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001769,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.76%, Loss: 0.0250\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1126\n",
            "Test performance: Accuracy:\n",
            " 97.53%, Loss: 0.1035\n",
            "Epoch 32\n",
            "Batch loss: 0.002679,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.000770,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.082913,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.111230,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.173089,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.002704,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.040207,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.001841,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.143571,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.002590,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002107,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.119014,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.000836,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002418,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001032,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000946,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001889,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001018,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002198,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001131,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.002020,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.050569,  Batch Accuracy: 99.22  [28160/54000]\n",
            "Batch loss: 0.001651,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.002638,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001713,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.002184,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.000826,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001857,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.004024,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001707,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001849,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.063937,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.002861,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.064551,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.002411,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001142,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.002298,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001415,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001570,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001780,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001591,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002099,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.76%, Loss: 0.0248\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1125\n",
            "Test performance: Accuracy:\n",
            " 97.47%, Loss: 0.1041\n",
            "Epoch 33\n",
            "Batch loss: 0.089680,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.001935,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.000615,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.086894,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.002385,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002146,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001456,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.002338,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001703,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002159,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002204,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001011,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001805,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001079,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.002027,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002237,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001109,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001683,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001524,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001976,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.053100,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.185996,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.002589,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001481,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001333,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.181850,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001839,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002037,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001496,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.055987,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.002040,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.008884,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001016,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.197392,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.002594,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.066673,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.001714,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.117508,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.245088,  Batch Accuracy: 98.44  [49920/54000]\n",
            "Batch loss: 0.001730,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.003685,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.081029,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.76%, Loss: 0.0246\n",
            "Validation performance:\n",
            " Accuracy: 97.27%, Loss: 0.1109\n",
            "Test performance: Accuracy:\n",
            " 97.51%, Loss: 0.1039\n",
            "Epoch 34\n",
            "Batch loss: 0.083372,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.002112,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001051,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001139,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001278,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001684,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001638,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.002566,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001055,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.077686,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.109420,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001845,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001517,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002830,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.068216,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.001127,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000989,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.041759,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.001396,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.002929,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001758,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.003560,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.002331,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.042038,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.001462,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.119642,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001140,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001480,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001951,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001981,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001357,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.110837,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.115637,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.048192,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001624,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.174903,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.002633,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.003183,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000737,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.050818,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.070098,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.000872,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.77%, Loss: 0.0243\n",
            "Validation performance:\n",
            " Accuracy: 97.13%, Loss: 0.1154\n",
            "Test performance: Accuracy:\n",
            " 97.49%, Loss: 0.1040\n",
            "Epoch 35\n",
            "Batch loss: 0.002277,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.173549,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.001252,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.003343,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001412,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.029429,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.001131,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001878,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001421,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.051861,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.001480,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001614,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.037862,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.001551,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001204,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001387,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.158865,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.002072,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001459,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001036,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001421,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.191919,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.001851,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.048332,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.001258,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.002947,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001222,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002073,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001724,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.130171,  Batch Accuracy: 98.44  [38400/54000]\n",
            "Batch loss: 0.000893,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.001466,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.071722,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.001546,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001914,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002155,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001856,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.052825,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.083532,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.001631,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001826,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001819,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.77%, Loss: 0.0238\n",
            "Validation performance:\n",
            " Accuracy: 97.22%, Loss: 0.1128\n",
            "Test performance: Accuracy:\n",
            " 97.38%, Loss: 0.1053\n",
            "Epoch 36\n",
            "Batch loss: 0.168989,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.001384,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.000758,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001194,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.109596,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.001172,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.003035,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001599,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.049835,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.000794,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002899,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.081039,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001496,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001882,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001385,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002604,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001071,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.136735,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.072948,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.001364,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001691,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001330,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001521,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.102981,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.001578,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001208,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.184050,  Batch Accuracy: 98.44  [34560/54000]\n",
            "Batch loss: 0.078859,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.001692,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.077445,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.001748,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.052070,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.044845,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.001712,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.002656,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001481,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.000895,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001418,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001521,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.002028,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002597,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001629,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.77%, Loss: 0.0239\n",
            "Validation performance:\n",
            " Accuracy: 97.28%, Loss: 0.1123\n",
            "Test performance: Accuracy:\n",
            " 97.57%, Loss: 0.1030\n",
            "Epoch 37\n",
            "Batch loss: 0.002165,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.171664,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.002461,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.269538,  Batch Accuracy: 98.44  [ 5120/54000]\n",
            "Batch loss: 0.000997,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002434,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.211898,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.001292,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001470,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.089511,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.001236,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.068448,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001815,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002084,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.000510,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.054974,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.000767,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001730,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002841,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001089,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001135,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001934,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001504,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.000702,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002568,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.063908,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001388,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001722,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.003148,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001603,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001887,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.003284,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.002679,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.000838,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001881,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.003304,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.002636,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001310,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.058194,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.001554,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.016764,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.002288,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.78%, Loss: 0.0234\n",
            "Validation performance:\n",
            " Accuracy: 97.07%, Loss: 0.1124\n",
            "Test performance: Accuracy:\n",
            " 97.48%, Loss: 0.1039\n",
            "Epoch 38\n",
            "Batch loss: 0.001235,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001349,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001518,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.002499,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001779,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001831,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001986,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.080398,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.000873,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.071461,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.001056,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001008,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001651,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001739,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001287,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001664,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000864,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001099,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001633,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.094015,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.001340,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.002062,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.065449,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.001774,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001342,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001880,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001567,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001410,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.003325,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.084305,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.029840,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.027372,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001713,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001365,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001618,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.052006,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.002092,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001773,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001908,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001370,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001522,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002146,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.78%, Loss: 0.0232\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1122\n",
            "Test performance: Accuracy:\n",
            " 97.56%, Loss: 0.1022\n",
            "Epoch 39\n",
            "Batch loss: 0.001363,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.093473,  Batch Accuracy: 98.44  [ 2560/54000]\n",
            "Batch loss: 0.001576,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001046,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001952,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001713,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.114268,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.001922,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001735,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.016040,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.002401,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001102,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001478,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.000914,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.089711,  Batch Accuracy: 98.44  [19200/54000]\n",
            "Batch loss: 0.001710,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.067282,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.070680,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.001951,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.000610,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001729,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001453,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001444,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.136615,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.001723,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.077824,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001125,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002045,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.176735,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.001237,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.208254,  Batch Accuracy: 98.44  [39680/54000]\n",
            "Batch loss: 0.054342,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001084,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.002024,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001726,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.148253,  Batch Accuracy: 98.44  [46080/54000]\n",
            "Batch loss: 0.002432,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.017373,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.000973,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000985,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.000951,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.023659,  Batch Accuracy: 99.22  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.79%, Loss: 0.0229\n",
            "Validation performance:\n",
            " Accuracy: 97.23%, Loss: 0.1106\n",
            "Test performance: Accuracy:\n",
            " 97.46%, Loss: 0.1044\n",
            "Epoch 40\n",
            "Batch loss: 0.002128,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001395,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001222,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001943,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.075082,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.001059,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001044,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.084221,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.001874,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.073241,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.001624,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001250,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001605,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.000514,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001269,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002477,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.069915,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.001610,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001192,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001203,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.000890,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.000753,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.092742,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.001371,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.143052,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.080557,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.005694,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001456,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001092,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002572,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.117247,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.167471,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.110483,  Batch Accuracy: 98.44  [42240/54000]\n",
            "Batch loss: 0.116674,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.109518,  Batch Accuracy: 98.44  [44800/54000]\n",
            "Batch loss: 0.000867,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001610,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002255,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001948,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.002079,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002027,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002265,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.79%, Loss: 0.0228\n",
            "Validation performance:\n",
            " Accuracy: 97.15%, Loss: 0.1125\n",
            "Test performance: Accuracy:\n",
            " 97.59%, Loss: 0.1034\n",
            "Epoch 41\n",
            "Batch loss: 0.001873,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.069007,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.002005,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000823,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002018,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001015,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.051071,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.001533,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001981,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001026,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.000572,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001473,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.002002,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.058837,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.078715,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.002116,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000926,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000927,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001331,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001514,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001158,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001313,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001153,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.003038,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001374,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001442,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001734,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.000866,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001250,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.073734,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.065085,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.002033,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.087898,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.001790,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.131668,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.002904,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001827,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001697,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.003241,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000712,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001245,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002153,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0224\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1124\n",
            "Test performance: Accuracy:\n",
            " 97.48%, Loss: 0.1045\n",
            "Epoch 42\n",
            "Batch loss: 0.001915,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001311,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.000911,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001302,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.000819,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.077984,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.067944,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.000775,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001155,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000665,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.050375,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.000813,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001945,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001036,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001803,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002305,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001358,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001393,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001041,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001667,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001607,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001516,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001293,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.113973,  Batch Accuracy: 98.44  [30720/54000]\n",
            "Batch loss: 0.181532,  Batch Accuracy: 98.44  [32000/54000]\n",
            "Batch loss: 0.107535,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001820,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001604,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.002384,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001092,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.000815,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.119675,  Batch Accuracy: 98.44  [40960/54000]\n",
            "Batch loss: 0.002301,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001334,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.000624,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.103202,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.000772,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002378,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000609,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.059614,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.002755,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002502,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0223\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1133\n",
            "Test performance: Accuracy:\n",
            " 97.45%, Loss: 0.1043\n",
            "Epoch 43\n",
            "Batch loss: 0.001006,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.002196,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001545,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.002020,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001230,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001446,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.047182,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.002045,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001006,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001849,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001154,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.069340,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.060363,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.001562,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001135,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001350,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000625,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000915,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002099,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001237,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.000995,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001442,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001579,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.222573,  Batch Accuracy: 98.44  [30720/54000]\n",
            "Batch loss: 0.000714,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001449,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.095223,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.002935,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.109592,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.001503,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001113,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.085958,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001534,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001182,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001104,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001584,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001884,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001598,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.004338,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.002134,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.056451,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.001490,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0222\n",
            "Validation performance:\n",
            " Accuracy: 97.10%, Loss: 0.1140\n",
            "Test performance: Accuracy:\n",
            " 97.50%, Loss: 0.1048\n",
            "Epoch 44\n",
            "Batch loss: 0.001537,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.089286,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.004735,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000955,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.002358,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001889,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.000833,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001923,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001840,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.002012,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001602,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.035779,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001392,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001783,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.000376,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.048110,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.001175,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001978,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001364,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.000841,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.107891,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.002162,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001875,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.139948,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.082380,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.001084,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001199,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001148,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.046907,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.068357,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.001701,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.187110,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.092763,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.112563,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001093,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.000899,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001066,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001301,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.085718,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.076313,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.000788,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001204,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0221\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1136\n",
            "Test performance: Accuracy:\n",
            " 97.58%, Loss: 0.1045\n",
            "Epoch 45\n",
            "Batch loss: 0.130468,  Batch Accuracy: 98.44  [ 1280/54000]\n",
            "Batch loss: 0.062022,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.000652,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.002246,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001614,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.080932,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.002019,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.000879,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001268,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000895,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.098070,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.066091,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001911,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001591,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.000962,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000940,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001228,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001073,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.002559,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001522,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001227,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001036,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.002012,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001247,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000825,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001188,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001404,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002378,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.000913,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001282,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.002207,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.074924,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001550,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.052415,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001053,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001708,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001450,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001111,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.002199,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.048932,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.000856,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001016,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0221\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1154\n",
            "Test performance: Accuracy:\n",
            " 97.50%, Loss: 0.1042\n",
            "Epoch 46\n",
            "Batch loss: 0.109905,  Batch Accuracy: 99.22  [ 1280/54000]\n",
            "Batch loss: 0.001453,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.040656,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.002021,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001626,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001000,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.000837,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001315,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001432,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.133805,  Batch Accuracy: 99.22  [12800/54000]\n",
            "Batch loss: 0.086192,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001424,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.084113,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.001478,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.002334,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002221,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001014,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001071,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.000654,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001240,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.074567,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.001485,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.081146,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.001207,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.054358,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.001136,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001118,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001966,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001345,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002092,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.113125,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.001987,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001348,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.000830,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001291,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001702,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001560,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001797,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.002293,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.087703,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.055348,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.001402,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0218\n",
            "Validation performance:\n",
            " Accuracy: 97.08%, Loss: 0.1145\n",
            "Test performance: Accuracy:\n",
            " 97.53%, Loss: 0.1050\n",
            "Epoch 47\n",
            "Batch loss: 0.001232,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001124,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001574,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001614,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.213353,  Batch Accuracy: 98.44  [ 6400/54000]\n",
            "Batch loss: 0.000643,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001791,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.000669,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001410,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000907,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.002647,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001545,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001504,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001259,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001573,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001112,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.002448,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001606,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001036,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.120930,  Batch Accuracy: 98.44  [25600/54000]\n",
            "Batch loss: 0.050819,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.001706,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001357,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001089,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.135101,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.002139,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001078,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.000951,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001068,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.056659,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.001047,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.000558,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001561,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001273,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001339,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.219787,  Batch Accuracy: 97.66  [46080/54000]\n",
            "Batch loss: 0.000753,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.171019,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.138596,  Batch Accuracy: 99.22  [49920/54000]\n",
            "Batch loss: 0.001738,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001696,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.000943,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.80%, Loss: 0.0219\n",
            "Validation performance:\n",
            " Accuracy: 97.28%, Loss: 0.1150\n",
            "Test performance: Accuracy:\n",
            " 97.58%, Loss: 0.1047\n",
            "Epoch 48\n",
            "Batch loss: 0.001658,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.000846,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001047,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.070541,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.001340,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001224,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.063809,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.001116,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001555,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000807,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.293680,  Batch Accuracy: 98.44  [14080/54000]\n",
            "Batch loss: 0.111236,  Batch Accuracy: 99.22  [15360/54000]\n",
            "Batch loss: 0.001099,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001542,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.080439,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.001337,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001576,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000735,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.000923,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001058,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001008,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001875,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.030839,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.063718,  Batch Accuracy: 99.22  [30720/54000]\n",
            "Batch loss: 0.147456,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.000972,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001313,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.073234,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.001488,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001448,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001742,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.001076,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.107300,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.001681,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001584,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002163,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.162956,  Batch Accuracy: 97.66  [47360/54000]\n",
            "Batch loss: 0.000883,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001539,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.104395,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.000904,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001516,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0216\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1129\n",
            "Test performance: Accuracy:\n",
            " 97.57%, Loss: 0.1043\n",
            "Epoch 49\n",
            "Batch loss: 0.001671,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001942,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001708,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.002163,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001111,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001510,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.000762,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.234882,  Batch Accuracy: 97.66  [10240/54000]\n",
            "Batch loss: 0.001273,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001229,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.014771,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001777,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000680,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002077,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001350,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000698,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001340,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.037340,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.001471,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001754,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.058495,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.002454,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.122597,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.002232,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001123,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.002781,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.002328,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001735,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001335,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.002608,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.067860,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.001488,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.056541,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.001206,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001132,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.112750,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.260692,  Batch Accuracy: 98.44  [47360/54000]\n",
            "Batch loss: 0.001967,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001660,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.066235,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.001178,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.000936,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0213\n",
            "Validation performance:\n",
            " Accuracy: 97.25%, Loss: 0.1140\n",
            "Test performance: Accuracy:\n",
            " 97.49%, Loss: 0.1060\n",
            "Epoch 50\n",
            "Batch loss: 0.001192,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001873,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001840,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001686,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001667,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.000874,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001033,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.068764,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.001237,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.162054,  Batch Accuracy: 98.44  [12800/54000]\n",
            "Batch loss: 0.180368,  Batch Accuracy: 99.22  [14080/54000]\n",
            "Batch loss: 0.001130,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001584,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001357,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.061069,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.069488,  Batch Accuracy: 99.22  [20480/54000]\n",
            "Batch loss: 0.001446,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.087709,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.108222,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.110328,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.000644,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001817,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.000903,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001416,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.002033,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001374,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.002104,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001116,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.091343,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.000969,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.000596,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.089055,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001616,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001879,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001292,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001468,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.081212,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.178056,  Batch Accuracy: 99.22  [48640/54000]\n",
            "Batch loss: 0.000931,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001459,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001279,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002084,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0213\n",
            "Validation performance:\n",
            " Accuracy: 97.33%, Loss: 0.1115\n",
            "Test performance: Accuracy:\n",
            " 97.49%, Loss: 0.1057\n",
            "Epoch 51\n",
            "Batch loss: 0.001560,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001366,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.002534,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001057,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001718,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.000788,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001553,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.096183,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.131941,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.001733,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.000836,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.002675,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001857,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.000886,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001031,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001466,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000893,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000686,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.000843,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001282,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.138045,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.000882,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.131609,  Batch Accuracy: 98.44  [29440/54000]\n",
            "Batch loss: 0.001218,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.172299,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.001043,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.000554,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.086612,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.109017,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.001180,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001774,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.059862,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001260,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.044350,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.002219,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.000758,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001394,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.000704,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000852,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000753,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002252,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001688,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0213\n",
            "Validation performance:\n",
            " Accuracy: 97.27%, Loss: 0.1132\n",
            "Test performance: Accuracy:\n",
            " 97.55%, Loss: 0.1046\n",
            "Epoch 52\n",
            "Batch loss: 0.000828,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.000551,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001303,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.144541,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.001066,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001674,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.055194,  Batch Accuracy: 99.22  [ 8960/54000]\n",
            "Batch loss: 0.087489,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.001427,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001608,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001094,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001699,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000812,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001730,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001118,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.002492,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.163863,  Batch Accuracy: 98.44  [21760/54000]\n",
            "Batch loss: 0.117856,  Batch Accuracy: 98.44  [23040/54000]\n",
            "Batch loss: 0.001873,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001551,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001297,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001084,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001986,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001097,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001591,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.000843,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.101902,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.049487,  Batch Accuracy: 99.22  [35840/54000]\n",
            "Batch loss: 0.069765,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.000927,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001090,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.086661,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.001164,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.000545,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.000644,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.098817,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.001515,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001548,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001034,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.057053,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.001109,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001372,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0212\n",
            "Validation performance:\n",
            " Accuracy: 97.17%, Loss: 0.1135\n",
            "Test performance: Accuracy:\n",
            " 97.53%, Loss: 0.1059\n",
            "Epoch 53\n",
            "Batch loss: 0.001420,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001302,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001158,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000868,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001085,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001959,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.000891,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.000671,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001477,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001107,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001182,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001890,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000505,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001024,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.025592,  Batch Accuracy: 99.22  [19200/54000]\n",
            "Batch loss: 0.001224,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000571,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000988,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.089265,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.001840,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001253,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.000921,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001181,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001792,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001425,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.132153,  Batch Accuracy: 98.44  [33280/54000]\n",
            "Batch loss: 0.002566,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.000842,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.000794,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.000568,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.000872,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002104,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001032,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.161977,  Batch Accuracy: 98.44  [43520/54000]\n",
            "Batch loss: 0.000672,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001280,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.103954,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.001021,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000345,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001416,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001951,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002023,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0211\n",
            "Validation performance:\n",
            " Accuracy: 97.28%, Loss: 0.1123\n",
            "Test performance: Accuracy:\n",
            " 97.51%, Loss: 0.1059\n",
            "Epoch 54\n",
            "Batch loss: 0.001145,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.127044,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.049584,  Batch Accuracy: 99.22  [ 3840/54000]\n",
            "Batch loss: 0.086707,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.001162,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.179647,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.000858,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001421,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.070161,  Batch Accuracy: 99.22  [11520/54000]\n",
            "Batch loss: 0.001494,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001212,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001355,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.069633,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.064493,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.000394,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.147339,  Batch Accuracy: 98.44  [20480/54000]\n",
            "Batch loss: 0.001027,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.007824,  Batch Accuracy: 99.22  [23040/54000]\n",
            "Batch loss: 0.082729,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.001609,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.000820,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001946,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001386,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001145,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.077583,  Batch Accuracy: 99.22  [32000/54000]\n",
            "Batch loss: 0.001339,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.000992,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002244,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.002025,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.048747,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.052876,  Batch Accuracy: 99.22  [39680/54000]\n",
            "Batch loss: 0.000907,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001328,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.000811,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.062305,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.088687,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.082053,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.001593,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000675,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001468,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.000855,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001964,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.81%, Loss: 0.0211\n",
            "Validation performance:\n",
            " Accuracy: 97.27%, Loss: 0.1133\n",
            "Test performance: Accuracy:\n",
            " 97.52%, Loss: 0.1065\n",
            "Epoch 55\n",
            "Batch loss: 0.001019,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001119,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.000461,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000456,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.073411,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.002686,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001626,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001505,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001134,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.010378,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001145,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001519,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001427,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001152,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001770,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000820,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000799,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001664,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001286,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.000829,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001530,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001088,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001018,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001583,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000694,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001855,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.000869,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.002535,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001620,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.082410,  Batch Accuracy: 99.22  [38400/54000]\n",
            "Batch loss: 0.001314,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002366,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.127469,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.000827,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.088412,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.001408,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001894,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001457,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000974,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001356,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.002175,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.001296,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.82%, Loss: 0.0206\n",
            "Validation performance:\n",
            " Accuracy: 97.13%, Loss: 0.1146\n",
            "Test performance: Accuracy:\n",
            " 97.51%, Loss: 0.1054\n",
            "Epoch 56\n",
            "Batch loss: 0.001361,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001253,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001077,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.114016,  Batch Accuracy: 99.22  [ 5120/54000]\n",
            "Batch loss: 0.001528,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.002415,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.000667,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001549,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001498,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000822,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001505,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001194,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000642,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.042908,  Batch Accuracy: 99.22  [17920/54000]\n",
            "Batch loss: 0.001091,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000987,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001573,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001696,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001486,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.001569,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.000986,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.000592,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001270,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001473,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.001753,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001946,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.001038,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001117,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001733,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.001535,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001356,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.000412,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.000985,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001284,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001539,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001517,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.000676,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.000838,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000468,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.143527,  Batch Accuracy: 99.22  [51200/54000]\n",
            "Batch loss: 0.000460,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.000473,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.82%, Loss: 0.0204\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1122\n",
            "Test performance: Accuracy:\n",
            " 97.45%, Loss: 0.1053\n",
            "Epoch 57\n",
            "Batch loss: 0.000632,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.088362,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.001924,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.001956,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.082426,  Batch Accuracy: 99.22  [ 6400/54000]\n",
            "Batch loss: 0.001370,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001473,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.103608,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.001024,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.001485,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001308,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.000826,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.078513,  Batch Accuracy: 99.22  [16640/54000]\n",
            "Batch loss: 0.001523,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001041,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000881,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.117687,  Batch Accuracy: 99.22  [21760/54000]\n",
            "Batch loss: 0.000917,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.001455,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.101265,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.002144,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.000744,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.079787,  Batch Accuracy: 99.22  [29440/54000]\n",
            "Batch loss: 0.000609,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000804,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.002938,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.000912,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001113,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001127,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.000936,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.002230,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.000767,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001251,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001006,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.001516,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.056617,  Batch Accuracy: 99.22  [46080/54000]\n",
            "Batch loss: 0.001084,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.000874,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.000939,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.001432,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.081419,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.001658,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.82%, Loss: 0.0204\n",
            "Validation performance:\n",
            " Accuracy: 97.17%, Loss: 0.1136\n",
            "Test performance: Accuracy:\n",
            " 97.47%, Loss: 0.1054\n",
            "Epoch 58\n",
            "Batch loss: 0.001298,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.075918,  Batch Accuracy: 99.22  [ 2560/54000]\n",
            "Batch loss: 0.001085,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000637,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001491,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.044493,  Batch Accuracy: 99.22  [ 7680/54000]\n",
            "Batch loss: 0.001144,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.106360,  Batch Accuracy: 99.22  [10240/54000]\n",
            "Batch loss: 0.000815,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000853,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.001362,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.000876,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.001330,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.001129,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001964,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.000706,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000798,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001891,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.073068,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.001130,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.003722,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.000724,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.001740,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.000642,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000915,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.134427,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.001591,  Batch Accuracy: 100.00  [34560/54000]\n",
            "Batch loss: 0.001426,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.114821,  Batch Accuracy: 99.22  [37120/54000]\n",
            "Batch loss: 0.002027,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001398,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.001873,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.000376,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.127720,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.001665,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.002003,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001762,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001580,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001894,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000905,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.001164,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.000998,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.82%, Loss: 0.0204\n",
            "Validation performance:\n",
            " Accuracy: 97.20%, Loss: 0.1118\n",
            "Test performance: Accuracy:\n",
            " 97.54%, Loss: 0.1052\n",
            "Epoch 59\n",
            "Batch loss: 0.001954,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001243,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.001599,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000469,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001175,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.000886,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.002103,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.000765,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.001390,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000825,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.000867,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.001174,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000831,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.002033,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.001147,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001626,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.000935,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.001864,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.108851,  Batch Accuracy: 99.22  [24320/54000]\n",
            "Batch loss: 0.065408,  Batch Accuracy: 99.22  [25600/54000]\n",
            "Batch loss: 0.113214,  Batch Accuracy: 99.22  [26880/54000]\n",
            "Batch loss: 0.000991,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.000920,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.001832,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000614,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.001379,  Batch Accuracy: 100.00  [33280/54000]\n",
            "Batch loss: 0.136042,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.001159,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001708,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.000392,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.000937,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.043098,  Batch Accuracy: 99.22  [40960/54000]\n",
            "Batch loss: 0.057878,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.105202,  Batch Accuracy: 99.22  [43520/54000]\n",
            "Batch loss: 0.083237,  Batch Accuracy: 99.22  [44800/54000]\n",
            "Batch loss: 0.000305,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.000851,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.002282,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001341,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000844,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.003624,  Batch Accuracy: 100.00  [52480/54000]\n",
            "Batch loss: 0.002437,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.83%, Loss: 0.0201\n",
            "Validation performance:\n",
            " Accuracy: 97.13%, Loss: 0.1142\n",
            "Test performance: Accuracy:\n",
            " 97.40%, Loss: 0.1067\n",
            "Epoch 60\n",
            "Batch loss: 0.000832,  Batch Accuracy: 100.00  [ 1280/54000]\n",
            "Batch loss: 0.001163,  Batch Accuracy: 100.00  [ 2560/54000]\n",
            "Batch loss: 0.002383,  Batch Accuracy: 100.00  [ 3840/54000]\n",
            "Batch loss: 0.000444,  Batch Accuracy: 100.00  [ 5120/54000]\n",
            "Batch loss: 0.001259,  Batch Accuracy: 100.00  [ 6400/54000]\n",
            "Batch loss: 0.001300,  Batch Accuracy: 100.00  [ 7680/54000]\n",
            "Batch loss: 0.001677,  Batch Accuracy: 100.00  [ 8960/54000]\n",
            "Batch loss: 0.001345,  Batch Accuracy: 100.00  [10240/54000]\n",
            "Batch loss: 0.000720,  Batch Accuracy: 100.00  [11520/54000]\n",
            "Batch loss: 0.000881,  Batch Accuracy: 100.00  [12800/54000]\n",
            "Batch loss: 0.000883,  Batch Accuracy: 100.00  [14080/54000]\n",
            "Batch loss: 0.000920,  Batch Accuracy: 100.00  [15360/54000]\n",
            "Batch loss: 0.000782,  Batch Accuracy: 100.00  [16640/54000]\n",
            "Batch loss: 0.000718,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.003179,  Batch Accuracy: 100.00  [19200/54000]\n",
            "Batch loss: 0.001680,  Batch Accuracy: 100.00  [20480/54000]\n",
            "Batch loss: 0.001759,  Batch Accuracy: 100.00  [21760/54000]\n",
            "Batch loss: 0.000758,  Batch Accuracy: 100.00  [23040/54000]\n",
            "Batch loss: 0.000806,  Batch Accuracy: 100.00  [24320/54000]\n",
            "Batch loss: 0.000845,  Batch Accuracy: 100.00  [25600/54000]\n",
            "Batch loss: 0.001315,  Batch Accuracy: 100.00  [26880/54000]\n",
            "Batch loss: 0.001968,  Batch Accuracy: 100.00  [28160/54000]\n",
            "Batch loss: 0.000859,  Batch Accuracy: 100.00  [29440/54000]\n",
            "Batch loss: 0.000704,  Batch Accuracy: 100.00  [30720/54000]\n",
            "Batch loss: 0.000822,  Batch Accuracy: 100.00  [32000/54000]\n",
            "Batch loss: 0.121436,  Batch Accuracy: 99.22  [33280/54000]\n",
            "Batch loss: 0.093542,  Batch Accuracy: 99.22  [34560/54000]\n",
            "Batch loss: 0.003070,  Batch Accuracy: 100.00  [35840/54000]\n",
            "Batch loss: 0.001954,  Batch Accuracy: 100.00  [37120/54000]\n",
            "Batch loss: 0.000884,  Batch Accuracy: 100.00  [38400/54000]\n",
            "Batch loss: 0.001341,  Batch Accuracy: 100.00  [39680/54000]\n",
            "Batch loss: 0.002338,  Batch Accuracy: 100.00  [40960/54000]\n",
            "Batch loss: 0.001276,  Batch Accuracy: 100.00  [42240/54000]\n",
            "Batch loss: 0.001635,  Batch Accuracy: 100.00  [43520/54000]\n",
            "Batch loss: 0.002182,  Batch Accuracy: 100.00  [44800/54000]\n",
            "Batch loss: 0.001355,  Batch Accuracy: 100.00  [46080/54000]\n",
            "Batch loss: 0.001201,  Batch Accuracy: 100.00  [47360/54000]\n",
            "Batch loss: 0.001323,  Batch Accuracy: 100.00  [48640/54000]\n",
            "Batch loss: 0.001313,  Batch Accuracy: 100.00  [49920/54000]\n",
            "Batch loss: 0.000865,  Batch Accuracy: 100.00  [51200/54000]\n",
            "Batch loss: 0.075328,  Batch Accuracy: 99.22  [52480/54000]\n",
            "Batch loss: 0.002089,  Batch Accuracy: 100.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 99.83%, Loss: 0.0198\n",
            "Validation performance:\n",
            " Accuracy: 97.08%, Loss: 0.1120\n",
            "Test performance: Accuracy:\n",
            " 97.65%, Loss: 0.1050\n",
            "Total time taken to Train: 1.824798321723938 mins\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train_Q3(model_custom:NeuralNetwork, train_loader:DataLoader, sgd_optimizer:SGD, ce_loss:CrossEntropyLoss):\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        sgd_optimizer.zero_grad()\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        ce_loss.backward(model_custom, labels)\n",
        "        sgd_optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        batch_correct = (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        correct += batch_correct\n",
        "        batch_accuracy = 100 * batch_correct / len(images)\n",
        "        if (batch + 1) % 10 == 0:\n",
        "            current = (batch + 1) * len(images)\n",
        "            print(f\"Batch loss: {loss.item():>7f},  Batch Accuracy: {batch_accuracy:>0.2f}  [{current:>5d}/{len(train_sampler):>5d}]\")\n",
        "        batch += 1\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Training performance:\\n Accuracy: {accuracy:.2f}%, Loss: {train_loss:.4f}\")\n",
        "    return train_loss, accuracy\n",
        "\n",
        "# Validation loop\n",
        "def validate_Q3(model_custom:NeuralNetwork, valid_loader:DataLoader, ce_loss:CrossEntropyLoss):\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in valid_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        val_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss /= len(valid_loader)\n",
        "    print(f\"Validation performance:\\n Accuracy: {accuracy:.2f}%, Loss: {val_loss:.4f}\")\n",
        "    return val_loss, accuracy\n",
        "\n",
        "# Testing loop\n",
        "def test_Q3(model_custom:NeuralNetwork, test_loader:DataLoader, ce_loss:CrossEntropyLoss):\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Test performance: Accuracy:\\n {accuracy:.2f}%, Loss: {test_loss:.4f}\")\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# Training, Validation, and Testing of the model_custom\n",
        "train_losses_q3, train_accuracies_q3 = [], []\n",
        "val_losses_q3, val_accuracies_q3 = [], []\n",
        "test_losses_q3, test_accuracies_q3 = [], []\n",
        "start_time = time.time()\n",
        "num_epochs = 60\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "    train_loss, train_acc = train_Q3(model_custom, train_loader, sgd_optimizer, ce_loss)\n",
        "    val_loss, val_acc = validate_Q3(model_custom, valid_loader, ce_loss)\n",
        "    test_loss, test_acc = test_Q3(model_custom, test_loader, ce_loss)\n",
        "\n",
        "    train_losses_q3.append(train_loss)\n",
        "    train_accuracies_q3.append(train_acc)\n",
        "    val_losses_q3.append(val_loss)\n",
        "    val_accuracies_q3.append(val_acc)\n",
        "    test_losses_q3.append(test_loss)\n",
        "    test_accuracies_q3.append(test_acc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'Total time taken to Train: {(end_time - start_time) / 60} mins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "1QL4cMvWK3aO",
        "outputId": "f308da6c-865a-4abc-891b-b72b918344b9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_losses_q3, label='Train')\n",
        "plt.plot(range(num_epochs), val_losses_q3, label='Validation')\n",
        "plt.plot(range(num_epochs), test_losses_q3, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_accuracies_q3, label='Train')\n",
        "plt.plot(range(num_epochs), val_accuracies_q3, label='Validation')\n",
        "plt.plot(range(num_epochs), test_accuracies_q3, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epoch')\n",
        "plt.ylim([0, 100])\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the pytorch/custom implementation of the MLP network with ReLU activation function, the model is learning the features and thus performs good.\n",
        "\n",
        "For the scratch implementation of the MLP network with ReLU activation function, the model is learning the features well and performs good in first few epochs only (as compared to Pytorch's implementation). \n",
        "\n",
        "Also, the time taken for both the scratch and pytorch implementation to train (or completing 60 epoches) are same. \n",
        "Around 1.7 and 1.8 minutes for pytorch and scratch implementation respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imwTGheZYB11"
      },
      "source": [
        "# Question-4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntNf1aR8YDMv"
      },
      "source": [
        "## Pytorch Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K80pa1rdYIzM"
      },
      "source": [
        "### Network architecture for Pytorch Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELgvi4goYLzg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MLP_Q4(nn.Module):\n",
        "    def __init__(self, in_features:int=28*28, out_features:int=10):\n",
        "        super(MLP_Q4, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=1024, bias=True)\n",
        "        self.sigmoid1 = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=512, bias=True)\n",
        "        self.sigmoid2 = nn.Sigmoid()\n",
        "        self.fc3 = nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.sigmoid3 = nn.Sigmoid()\n",
        "        self.fc4 = nn.Linear(in_features=256, out_features=128, bias=True)\n",
        "        self.sigmoid4 = nn.Sigmoid()\n",
        "        self.fc5 = nn.Linear(in_features=128, out_features=out_features, bias=True)\n",
        "        self.softmax5 = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.sigmoid1(self.fc1(x))\n",
        "        x = self.sigmoid2(self.fc2(x))\n",
        "        x = self.sigmoid3(self.fc3(x))\n",
        "        x = self.sigmoid4(self.fc4(x))\n",
        "        logits = self.fc5(x)\n",
        "        probas = self.softmax5(logits)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6hpm-HzYRgL"
      },
      "source": [
        "### Initialize Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrRGmE4kYPmJ",
        "outputId": "b13f773b-f8b3-4b81-b58a-dc19de952ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 10000\n",
            "Dataset image shape: torch.Size([10000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([10000])\n",
            "\n",
            "Train Dataset Length: 54000\n",
            "Validation Dataset Length: 6000\n",
            "Test Dataset Length: 10000\n"
          ]
        }
      ],
      "source": [
        "# Creating training and test datasets\n",
        "root = './data/MNIST/raw/'\n",
        "train_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "test_dataset = MNISTCustomDataset(root=root, train=False, transform=None)\n",
        "\n",
        "# splitting of training and validation set\n",
        "batch_size = 128\n",
        "valid_size = 0.1\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Train Dataset Length: {}'.format(len(train_sampler)))\n",
        "print('Validation Dataset Length: {}'.format(len(valid_sampler)))\n",
        "print('Test Dataset Length: {}'.format(len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMp4opl2YUJ7"
      },
      "source": [
        "### Initialization of Model and its parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_8xSPxYWDF",
        "outputId": "4447d3af-1739-4ef3-99e3-5174b9e8a1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model_q4a = MLP_Q4(in_features=28*28, out_features=10)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "optimizer_q4a = optim.SGD(model_q4a.parameters(), lr=0.0003)\n",
        "criterion_q4a = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR5kJRU-YXW8"
      },
      "source": [
        "### Training of Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci0e5FUIYZBV",
        "outputId": "528bf96a-c2e1-4c8d-949d-091e7dd43eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Batch Loss: 2.316084,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.328901,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.323633,  Batch Accuracy: 10.94   [ 3840/54000]\n",
            "Batch Loss: 2.338705,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.371053,  Batch Accuracy: 3.91   [ 6400/54000]\n",
            "Batch Loss: 2.351547,  Batch Accuracy: 7.81   [ 7680/54000]\n",
            "Batch Loss: 2.360708,  Batch Accuracy: 7.03   [ 8960/54000]\n",
            "Batch Loss: 2.333346,  Batch Accuracy: 10.16   [10240/54000]\n",
            "Batch Loss: 2.336508,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.328631,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.329980,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.318509,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.338769,  Batch Accuracy: 7.81   [16640/54000]\n",
            "Batch Loss: 2.342783,  Batch Accuracy: 6.25   [17920/54000]\n",
            "Batch Loss: 2.305357,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.343307,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.345541,  Batch Accuracy: 5.47   [21760/54000]\n",
            "Batch Loss: 2.362319,  Batch Accuracy: 5.47   [23040/54000]\n",
            "Batch Loss: 2.329907,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.331742,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.325864,  Batch Accuracy: 7.81   [26880/54000]\n",
            "Batch Loss: 2.327653,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.334445,  Batch Accuracy: 7.03   [29440/54000]\n",
            "Batch Loss: 2.310256,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.327228,  Batch Accuracy: 7.03   [32000/54000]\n",
            "Batch Loss: 2.340457,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.310139,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.314964,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.303036,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.325394,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.325318,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.332440,  Batch Accuracy: 3.12   [40960/54000]\n",
            "Batch Loss: 2.315714,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.301101,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.322240,  Batch Accuracy: 8.59   [44800/54000]\n",
            "Batch Loss: 2.327004,  Batch Accuracy: 9.38   [46080/54000]\n",
            "Batch Loss: 2.311598,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.321410,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.328908,  Batch Accuracy: 4.69   [49920/54000]\n",
            "Batch Loss: 2.325270,  Batch Accuracy: 7.81   [51200/54000]\n",
            "Batch Loss: 2.334116,  Batch Accuracy: 9.38   [52480/54000]\n",
            "Batch Loss: 2.316591,  Batch Accuracy: 9.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 9.1%, Loss: 2.329421\n",
            "Validation performance: \n",
            " Accuracy: 8.8%, Loss: 2.318650\n",
            "Test performance: \n",
            " Accuracy: 8.9%, Loss: 2.318477 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Batch Loss: 2.308783,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.327274,  Batch Accuracy: 5.47   [ 2560/54000]\n",
            "Batch Loss: 2.345750,  Batch Accuracy: 4.69   [ 3840/54000]\n",
            "Batch Loss: 2.323817,  Batch Accuracy: 6.25   [ 5120/54000]\n",
            "Batch Loss: 2.318336,  Batch Accuracy: 8.59   [ 6400/54000]\n",
            "Batch Loss: 2.300743,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.322410,  Batch Accuracy: 3.91   [ 8960/54000]\n",
            "Batch Loss: 2.322585,  Batch Accuracy: 7.81   [10240/54000]\n",
            "Batch Loss: 2.328925,  Batch Accuracy: 6.25   [11520/54000]\n",
            "Batch Loss: 2.310251,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.302642,  Batch Accuracy: 10.94   [14080/54000]\n",
            "Batch Loss: 2.316232,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.306189,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.316585,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.300817,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.318940,  Batch Accuracy: 5.47   [20480/54000]\n",
            "Batch Loss: 2.310732,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.324369,  Batch Accuracy: 4.69   [23040/54000]\n",
            "Batch Loss: 2.303977,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.311541,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.314635,  Batch Accuracy: 7.03   [26880/54000]\n",
            "Batch Loss: 2.319650,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.314963,  Batch Accuracy: 7.03   [29440/54000]\n",
            "Batch Loss: 2.304941,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.317490,  Batch Accuracy: 7.81   [32000/54000]\n",
            "Batch Loss: 2.283552,  Batch Accuracy: 13.28   [33280/54000]\n",
            "Batch Loss: 2.322286,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.286537,  Batch Accuracy: 15.62   [35840/54000]\n",
            "Batch Loss: 2.314436,  Batch Accuracy: 6.25   [37120/54000]\n",
            "Batch Loss: 2.301353,  Batch Accuracy: 14.06   [38400/54000]\n",
            "Batch Loss: 2.312193,  Batch Accuracy: 7.81   [39680/54000]\n",
            "Batch Loss: 2.300873,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.307284,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.316639,  Batch Accuracy: 7.03   [43520/54000]\n",
            "Batch Loss: 2.307568,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.306174,  Batch Accuracy: 11.72   [46080/54000]\n",
            "Batch Loss: 2.307963,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.307931,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.312200,  Batch Accuracy: 6.25   [49920/54000]\n",
            "Batch Loss: 2.308529,  Batch Accuracy: 5.47   [51200/54000]\n",
            "Batch Loss: 2.314791,  Batch Accuracy: 7.03   [52480/54000]\n",
            "Batch Loss: 2.313670,  Batch Accuracy: 8.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 9.1%, Loss: 2.311630\n",
            "Validation performance: \n",
            " Accuracy: 8.8%, Loss: 2.307913\n",
            "Test performance: \n",
            " Accuracy: 8.9%, Loss: 2.308033 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Batch Loss: 2.296566,  Batch Accuracy: 13.28   [ 1280/54000]\n",
            "Batch Loss: 2.310676,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.312613,  Batch Accuracy: 6.25   [ 3840/54000]\n",
            "Batch Loss: 2.306198,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.317934,  Batch Accuracy: 7.03   [ 6400/54000]\n",
            "Batch Loss: 2.313188,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.304424,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.313401,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.295019,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.297377,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.307701,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.307726,  Batch Accuracy: 4.69   [15360/54000]\n",
            "Batch Loss: 2.304322,  Batch Accuracy: 9.38   [16640/54000]\n",
            "Batch Loss: 2.313630,  Batch Accuracy: 9.38   [17920/54000]\n",
            "Batch Loss: 2.309873,  Batch Accuracy: 8.59   [19200/54000]\n",
            "Batch Loss: 2.310813,  Batch Accuracy: 6.25   [20480/54000]\n",
            "Batch Loss: 2.307238,  Batch Accuracy: 6.25   [21760/54000]\n",
            "Batch Loss: 2.301725,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.306744,  Batch Accuracy: 6.25   [24320/54000]\n",
            "Batch Loss: 2.292095,  Batch Accuracy: 16.41   [25600/54000]\n",
            "Batch Loss: 2.304648,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.297866,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.304408,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.305117,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.298920,  Batch Accuracy: 10.94   [32000/54000]\n",
            "Batch Loss: 2.304776,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.294868,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.311306,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.312236,  Batch Accuracy: 6.25   [37120/54000]\n",
            "Batch Loss: 2.302235,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.301110,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.297616,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.299281,  Batch Accuracy: 7.03   [42240/54000]\n",
            "Batch Loss: 2.304485,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.300138,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.300502,  Batch Accuracy: 14.84   [46080/54000]\n",
            "Batch Loss: 2.303309,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.290095,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.301863,  Batch Accuracy: 6.25   [49920/54000]\n",
            "Batch Loss: 2.305819,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.304415,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.302293,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 9.1%, Loss: 2.305285\n",
            "Validation performance: \n",
            " Accuracy: 8.8%, Loss: 2.303667\n",
            "Test performance: \n",
            " Accuracy: 8.9%, Loss: 2.303994 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Batch Loss: 2.307208,  Batch Accuracy: 9.38   [ 1280/54000]\n",
            "Batch Loss: 2.310481,  Batch Accuracy: 7.03   [ 2560/54000]\n",
            "Batch Loss: 2.299021,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.298862,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.309646,  Batch Accuracy: 3.12   [ 6400/54000]\n",
            "Batch Loss: 2.302493,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.297576,  Batch Accuracy: 5.47   [ 8960/54000]\n",
            "Batch Loss: 2.308784,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.300171,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.305033,  Batch Accuracy: 5.47   [12800/54000]\n",
            "Batch Loss: 2.303842,  Batch Accuracy: 10.94   [14080/54000]\n",
            "Batch Loss: 2.301811,  Batch Accuracy: 13.28   [15360/54000]\n",
            "Batch Loss: 2.304704,  Batch Accuracy: 6.25   [16640/54000]\n",
            "Batch Loss: 2.298901,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.301541,  Batch Accuracy: 14.06   [19200/54000]\n",
            "Batch Loss: 2.301954,  Batch Accuracy: 9.38   [20480/54000]\n",
            "Batch Loss: 2.306273,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.299126,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.306352,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.301187,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.296102,  Batch Accuracy: 14.06   [26880/54000]\n",
            "Batch Loss: 2.301526,  Batch Accuracy: 7.81   [28160/54000]\n",
            "Batch Loss: 2.301844,  Batch Accuracy: 10.94   [29440/54000]\n",
            "Batch Loss: 2.299698,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.304523,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.303559,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.303449,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.301512,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.300524,  Batch Accuracy: 5.47   [37120/54000]\n",
            "Batch Loss: 2.297706,  Batch Accuracy: 10.94   [38400/54000]\n",
            "Batch Loss: 2.297706,  Batch Accuracy: 14.06   [39680/54000]\n",
            "Batch Loss: 2.305042,  Batch Accuracy: 15.62   [40960/54000]\n",
            "Batch Loss: 2.309185,  Batch Accuracy: 6.25   [42240/54000]\n",
            "Batch Loss: 2.306227,  Batch Accuracy: 7.03   [43520/54000]\n",
            "Batch Loss: 2.306976,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.301317,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.304410,  Batch Accuracy: 6.25   [47360/54000]\n",
            "Batch Loss: 2.300567,  Batch Accuracy: 12.50   [48640/54000]\n",
            "Batch Loss: 2.298548,  Batch Accuracy: 14.06   [49920/54000]\n",
            "Batch Loss: 2.300354,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.305281,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.303306,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 10.1%, Loss: 2.302838\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.301891\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.302321 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Batch Loss: 2.296851,  Batch Accuracy: 17.19   [ 1280/54000]\n",
            "Batch Loss: 2.302929,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.302696,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.303064,  Batch Accuracy: 12.50   [ 5120/54000]\n",
            "Batch Loss: 2.300916,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.306418,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.304341,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.306948,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.298619,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.297981,  Batch Accuracy: 15.62   [12800/54000]\n",
            "Batch Loss: 2.296400,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.305203,  Batch Accuracy: 7.03   [15360/54000]\n",
            "Batch Loss: 2.299618,  Batch Accuracy: 14.06   [16640/54000]\n",
            "Batch Loss: 2.305813,  Batch Accuracy: 5.47   [17920/54000]\n",
            "Batch Loss: 2.304960,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.306759,  Batch Accuracy: 9.38   [20480/54000]\n",
            "Batch Loss: 2.297870,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.301033,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.296854,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.300513,  Batch Accuracy: 10.16   [25600/54000]\n",
            "Batch Loss: 2.306050,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.298563,  Batch Accuracy: 17.19   [28160/54000]\n",
            "Batch Loss: 2.300012,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.295955,  Batch Accuracy: 17.97   [30720/54000]\n",
            "Batch Loss: 2.306657,  Batch Accuracy: 10.16   [32000/54000]\n",
            "Batch Loss: 2.302568,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.301056,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.299483,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.296834,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.299905,  Batch Accuracy: 14.06   [38400/54000]\n",
            "Batch Loss: 2.300342,  Batch Accuracy: 15.62   [39680/54000]\n",
            "Batch Loss: 2.307685,  Batch Accuracy: 7.03   [40960/54000]\n",
            "Batch Loss: 2.305024,  Batch Accuracy: 7.03   [42240/54000]\n",
            "Batch Loss: 2.304043,  Batch Accuracy: 9.38   [43520/54000]\n",
            "Batch Loss: 2.305098,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.295749,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.299379,  Batch Accuracy: 13.28   [47360/54000]\n",
            "Batch Loss: 2.301594,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.296801,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.300412,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.298086,  Batch Accuracy: 16.41   [52480/54000]\n",
            "Batch Loss: 2.305852,  Batch Accuracy: 6.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301855\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.301084\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.301582 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Batch Loss: 2.303008,  Batch Accuracy: 13.28   [ 1280/54000]\n",
            "Batch Loss: 2.301500,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.305092,  Batch Accuracy: 9.38   [ 3840/54000]\n",
            "Batch Loss: 2.301302,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.299404,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.302068,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.296800,  Batch Accuracy: 16.41   [ 8960/54000]\n",
            "Batch Loss: 2.298343,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.301954,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.302004,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.303439,  Batch Accuracy: 10.94   [14080/54000]\n",
            "Batch Loss: 2.300923,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.303818,  Batch Accuracy: 11.72   [16640/54000]\n",
            "Batch Loss: 2.300870,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.302683,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.302693,  Batch Accuracy: 9.38   [20480/54000]\n",
            "Batch Loss: 2.302611,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.299445,  Batch Accuracy: 15.62   [23040/54000]\n",
            "Batch Loss: 2.299918,  Batch Accuracy: 13.28   [24320/54000]\n",
            "Batch Loss: 2.295080,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.299240,  Batch Accuracy: 12.50   [26880/54000]\n",
            "Batch Loss: 2.296026,  Batch Accuracy: 17.97   [28160/54000]\n",
            "Batch Loss: 2.301570,  Batch Accuracy: 8.59   [29440/54000]\n",
            "Batch Loss: 2.301940,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.303221,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.303971,  Batch Accuracy: 8.59   [33280/54000]\n",
            "Batch Loss: 2.302396,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.307235,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.301766,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.299183,  Batch Accuracy: 10.94   [38400/54000]\n",
            "Batch Loss: 2.298948,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.303579,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.301483,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.304701,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.297478,  Batch Accuracy: 14.84   [44800/54000]\n",
            "Batch Loss: 2.298386,  Batch Accuracy: 11.72   [46080/54000]\n",
            "Batch Loss: 2.301363,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.301046,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.300842,  Batch Accuracy: 13.28   [49920/54000]\n",
            "Batch Loss: 2.307490,  Batch Accuracy: 6.25   [51200/54000]\n",
            "Batch Loss: 2.301445,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.299350,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301444\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300698\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.301256 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Batch Loss: 2.295248,  Batch Accuracy: 17.19   [ 1280/54000]\n",
            "Batch Loss: 2.301394,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.306320,  Batch Accuracy: 4.69   [ 3840/54000]\n",
            "Batch Loss: 2.297639,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.300758,  Batch Accuracy: 9.38   [ 6400/54000]\n",
            "Batch Loss: 2.304683,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.295004,  Batch Accuracy: 15.62   [ 8960/54000]\n",
            "Batch Loss: 2.304321,  Batch Accuracy: 10.16   [10240/54000]\n",
            "Batch Loss: 2.300890,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.305393,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.302771,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.302600,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.299520,  Batch Accuracy: 14.06   [16640/54000]\n",
            "Batch Loss: 2.296808,  Batch Accuracy: 11.72   [17920/54000]\n",
            "Batch Loss: 2.301127,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.304053,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.294971,  Batch Accuracy: 15.62   [21760/54000]\n",
            "Batch Loss: 2.298145,  Batch Accuracy: 10.94   [23040/54000]\n",
            "Batch Loss: 2.302315,  Batch Accuracy: 7.03   [24320/54000]\n",
            "Batch Loss: 2.304769,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.308059,  Batch Accuracy: 5.47   [26880/54000]\n",
            "Batch Loss: 2.301761,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.303788,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.308090,  Batch Accuracy: 6.25   [30720/54000]\n",
            "Batch Loss: 2.304346,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.298692,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.293943,  Batch Accuracy: 14.06   [34560/54000]\n",
            "Batch Loss: 2.297906,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.299100,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.293590,  Batch Accuracy: 16.41   [38400/54000]\n",
            "Batch Loss: 2.302577,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.305414,  Batch Accuracy: 7.81   [40960/54000]\n",
            "Batch Loss: 2.302373,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.292658,  Batch Accuracy: 17.19   [43520/54000]\n",
            "Batch Loss: 2.309446,  Batch Accuracy: 7.03   [44800/54000]\n",
            "Batch Loss: 2.288915,  Batch Accuracy: 21.88   [46080/54000]\n",
            "Batch Loss: 2.305231,  Batch Accuracy: 7.03   [47360/54000]\n",
            "Batch Loss: 2.300763,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.298276,  Batch Accuracy: 13.28   [49920/54000]\n",
            "Batch Loss: 2.297634,  Batch Accuracy: 11.72   [51200/54000]\n",
            "Batch Loss: 2.309524,  Batch Accuracy: 6.25   [52480/54000]\n",
            "Batch Loss: 2.301730,  Batch Accuracy: 10.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301276\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300543\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.301109 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Batch Loss: 2.301527,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.303459,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.300555,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.303660,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.298133,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.299765,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.300516,  Batch Accuracy: 12.50   [ 8960/54000]\n",
            "Batch Loss: 2.302011,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.302380,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.300092,  Batch Accuracy: 14.06   [12800/54000]\n",
            "Batch Loss: 2.300066,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.301146,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.303371,  Batch Accuracy: 8.59   [16640/54000]\n",
            "Batch Loss: 2.304261,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.300256,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.301532,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.290954,  Batch Accuracy: 14.06   [21760/54000]\n",
            "Batch Loss: 2.296626,  Batch Accuracy: 14.84   [23040/54000]\n",
            "Batch Loss: 2.289576,  Batch Accuracy: 20.31   [24320/54000]\n",
            "Batch Loss: 2.299372,  Batch Accuracy: 14.84   [25600/54000]\n",
            "Batch Loss: 2.299096,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.307873,  Batch Accuracy: 7.03   [28160/54000]\n",
            "Batch Loss: 2.295122,  Batch Accuracy: 14.06   [29440/54000]\n",
            "Batch Loss: 2.301862,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.297621,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.302361,  Batch Accuracy: 10.94   [33280/54000]\n",
            "Batch Loss: 2.302927,  Batch Accuracy: 10.94   [34560/54000]\n",
            "Batch Loss: 2.299153,  Batch Accuracy: 14.06   [35840/54000]\n",
            "Batch Loss: 2.304436,  Batch Accuracy: 7.81   [37120/54000]\n",
            "Batch Loss: 2.309121,  Batch Accuracy: 5.47   [38400/54000]\n",
            "Batch Loss: 2.304026,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.300958,  Batch Accuracy: 7.81   [40960/54000]\n",
            "Batch Loss: 2.304029,  Batch Accuracy: 8.59   [42240/54000]\n",
            "Batch Loss: 2.294284,  Batch Accuracy: 15.62   [43520/54000]\n",
            "Batch Loss: 2.297069,  Batch Accuracy: 14.06   [44800/54000]\n",
            "Batch Loss: 2.301436,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.302443,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.304646,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.297713,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.308987,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.311508,  Batch Accuracy: 4.69   [52480/54000]\n",
            "Batch Loss: 2.308249,  Batch Accuracy: 9.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301198\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300445\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.301041 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Batch Loss: 2.298341,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.303920,  Batch Accuracy: 7.81   [ 2560/54000]\n",
            "Batch Loss: 2.304982,  Batch Accuracy: 9.38   [ 3840/54000]\n",
            "Batch Loss: 2.304444,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.293879,  Batch Accuracy: 15.62   [ 6400/54000]\n",
            "Batch Loss: 2.297782,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.298382,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.298640,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.302866,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.293189,  Batch Accuracy: 17.19   [12800/54000]\n",
            "Batch Loss: 2.303696,  Batch Accuracy: 8.59   [14080/54000]\n",
            "Batch Loss: 2.304196,  Batch Accuracy: 8.59   [15360/54000]\n",
            "Batch Loss: 2.304131,  Batch Accuracy: 7.81   [16640/54000]\n",
            "Batch Loss: 2.290457,  Batch Accuracy: 20.31   [17920/54000]\n",
            "Batch Loss: 2.302755,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.301034,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.306819,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.305501,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.302077,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.306581,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.299544,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.308038,  Batch Accuracy: 7.03   [28160/54000]\n",
            "Batch Loss: 2.292972,  Batch Accuracy: 17.19   [29440/54000]\n",
            "Batch Loss: 2.296755,  Batch Accuracy: 12.50   [30720/54000]\n",
            "Batch Loss: 2.301928,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.294736,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.295339,  Batch Accuracy: 16.41   [34560/54000]\n",
            "Batch Loss: 2.299341,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.300837,  Batch Accuracy: 8.59   [37120/54000]\n",
            "Batch Loss: 2.305234,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.300594,  Batch Accuracy: 12.50   [39680/54000]\n",
            "Batch Loss: 2.295380,  Batch Accuracy: 14.84   [40960/54000]\n",
            "Batch Loss: 2.302290,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.303612,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.299473,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.304087,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.301485,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.302060,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.297052,  Batch Accuracy: 14.84   [49920/54000]\n",
            "Batch Loss: 2.306957,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.309652,  Batch Accuracy: 6.25   [52480/54000]\n",
            "Batch Loss: 2.297191,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301167\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300380\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300989 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Batch Loss: 2.300206,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.297618,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.306084,  Batch Accuracy: 7.81   [ 3840/54000]\n",
            "Batch Loss: 2.297629,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.299498,  Batch Accuracy: 15.62   [ 6400/54000]\n",
            "Batch Loss: 2.307840,  Batch Accuracy: 5.47   [ 7680/54000]\n",
            "Batch Loss: 2.298815,  Batch Accuracy: 7.81   [ 8960/54000]\n",
            "Batch Loss: 2.299691,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.305563,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.304075,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.308128,  Batch Accuracy: 8.59   [14080/54000]\n",
            "Batch Loss: 2.299281,  Batch Accuracy: 14.84   [15360/54000]\n",
            "Batch Loss: 2.292834,  Batch Accuracy: 17.19   [16640/54000]\n",
            "Batch Loss: 2.301898,  Batch Accuracy: 9.38   [17920/54000]\n",
            "Batch Loss: 2.307032,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.306827,  Batch Accuracy: 6.25   [20480/54000]\n",
            "Batch Loss: 2.299577,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.294769,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.299284,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.301149,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.292655,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.305943,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.298309,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.295696,  Batch Accuracy: 15.62   [30720/54000]\n",
            "Batch Loss: 2.300884,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.295687,  Batch Accuracy: 17.97   [33280/54000]\n",
            "Batch Loss: 2.306671,  Batch Accuracy: 7.81   [34560/54000]\n",
            "Batch Loss: 2.304997,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.295873,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.303155,  Batch Accuracy: 11.72   [38400/54000]\n",
            "Batch Loss: 2.301914,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.291932,  Batch Accuracy: 18.75   [40960/54000]\n",
            "Batch Loss: 2.291967,  Batch Accuracy: 17.97   [42240/54000]\n",
            "Batch Loss: 2.298080,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.305633,  Batch Accuracy: 7.03   [44800/54000]\n",
            "Batch Loss: 2.301175,  Batch Accuracy: 7.81   [46080/54000]\n",
            "Batch Loss: 2.302179,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.300073,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.289008,  Batch Accuracy: 18.75   [49920/54000]\n",
            "Batch Loss: 2.307437,  Batch Accuracy: 6.25   [51200/54000]\n",
            "Batch Loss: 2.299490,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.300338,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301147\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300332\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300962 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Batch Loss: 2.300465,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.303868,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.298896,  Batch Accuracy: 7.81   [ 3840/54000]\n",
            "Batch Loss: 2.308447,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.301651,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.302747,  Batch Accuracy: 14.06   [ 7680/54000]\n",
            "Batch Loss: 2.309631,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.296206,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.297234,  Batch Accuracy: 14.06   [11520/54000]\n",
            "Batch Loss: 2.295573,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.301961,  Batch Accuracy: 11.72   [14080/54000]\n",
            "Batch Loss: 2.298652,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.299299,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.295595,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.304326,  Batch Accuracy: 7.03   [19200/54000]\n",
            "Batch Loss: 2.299555,  Batch Accuracy: 14.06   [20480/54000]\n",
            "Batch Loss: 2.296685,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.294951,  Batch Accuracy: 14.84   [23040/54000]\n",
            "Batch Loss: 2.303985,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.307617,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.300081,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.295609,  Batch Accuracy: 14.84   [28160/54000]\n",
            "Batch Loss: 2.290890,  Batch Accuracy: 18.75   [29440/54000]\n",
            "Batch Loss: 2.307316,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.304506,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.302033,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.290048,  Batch Accuracy: 20.31   [34560/54000]\n",
            "Batch Loss: 2.297714,  Batch Accuracy: 11.72   [35840/54000]\n",
            "Batch Loss: 2.298725,  Batch Accuracy: 10.16   [37120/54000]\n",
            "Batch Loss: 2.294078,  Batch Accuracy: 15.62   [38400/54000]\n",
            "Batch Loss: 2.301251,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.300226,  Batch Accuracy: 10.94   [40960/54000]\n",
            "Batch Loss: 2.300839,  Batch Accuracy: 14.06   [42240/54000]\n",
            "Batch Loss: 2.301522,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.300313,  Batch Accuracy: 14.84   [44800/54000]\n",
            "Batch Loss: 2.306153,  Batch Accuracy: 7.03   [46080/54000]\n",
            "Batch Loss: 2.295284,  Batch Accuracy: 14.06   [47360/54000]\n",
            "Batch Loss: 2.309139,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.294153,  Batch Accuracy: 13.28   [49920/54000]\n",
            "Batch Loss: 2.306080,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.298195,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.300504,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301135\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300323\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300949 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Batch Loss: 2.309573,  Batch Accuracy: 6.25   [ 1280/54000]\n",
            "Batch Loss: 2.301880,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.307081,  Batch Accuracy: 9.38   [ 3840/54000]\n",
            "Batch Loss: 2.297268,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.298412,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.301360,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.304528,  Batch Accuracy: 10.16   [ 8960/54000]\n",
            "Batch Loss: 2.305449,  Batch Accuracy: 10.94   [10240/54000]\n",
            "Batch Loss: 2.293579,  Batch Accuracy: 16.41   [11520/54000]\n",
            "Batch Loss: 2.295856,  Batch Accuracy: 14.06   [12800/54000]\n",
            "Batch Loss: 2.307774,  Batch Accuracy: 7.03   [14080/54000]\n",
            "Batch Loss: 2.297684,  Batch Accuracy: 17.19   [15360/54000]\n",
            "Batch Loss: 2.295843,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.303499,  Batch Accuracy: 7.03   [17920/54000]\n",
            "Batch Loss: 2.304038,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.303882,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.301033,  Batch Accuracy: 10.94   [21760/54000]\n",
            "Batch Loss: 2.303011,  Batch Accuracy: 5.47   [23040/54000]\n",
            "Batch Loss: 2.300777,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.298642,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.304217,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.298097,  Batch Accuracy: 13.28   [28160/54000]\n",
            "Batch Loss: 2.301775,  Batch Accuracy: 10.16   [29440/54000]\n",
            "Batch Loss: 2.307833,  Batch Accuracy: 7.81   [30720/54000]\n",
            "Batch Loss: 2.302464,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.299767,  Batch Accuracy: 10.94   [33280/54000]\n",
            "Batch Loss: 2.302962,  Batch Accuracy: 13.28   [34560/54000]\n",
            "Batch Loss: 2.294577,  Batch Accuracy: 14.84   [35840/54000]\n",
            "Batch Loss: 2.308335,  Batch Accuracy: 9.38   [37120/54000]\n",
            "Batch Loss: 2.301033,  Batch Accuracy: 10.16   [38400/54000]\n",
            "Batch Loss: 2.299919,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.300047,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.297961,  Batch Accuracy: 13.28   [42240/54000]\n",
            "Batch Loss: 2.306069,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.293540,  Batch Accuracy: 14.06   [44800/54000]\n",
            "Batch Loss: 2.302546,  Batch Accuracy: 8.59   [46080/54000]\n",
            "Batch Loss: 2.301941,  Batch Accuracy: 8.59   [47360/54000]\n",
            "Batch Loss: 2.303292,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.308368,  Batch Accuracy: 7.81   [49920/54000]\n",
            "Batch Loss: 2.305632,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.305616,  Batch Accuracy: 7.81   [52480/54000]\n",
            "Batch Loss: 2.304508,  Batch Accuracy: 7.03   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301127\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300344\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300935 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Batch Loss: 2.298270,  Batch Accuracy: 15.62   [ 1280/54000]\n",
            "Batch Loss: 2.303076,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.300550,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.301878,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.298016,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.303475,  Batch Accuracy: 10.16   [ 7680/54000]\n",
            "Batch Loss: 2.302819,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.303482,  Batch Accuracy: 11.72   [10240/54000]\n",
            "Batch Loss: 2.295439,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.297682,  Batch Accuracy: 12.50   [12800/54000]\n",
            "Batch Loss: 2.299305,  Batch Accuracy: 7.81   [14080/54000]\n",
            "Batch Loss: 2.307121,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.309380,  Batch Accuracy: 11.72   [16640/54000]\n",
            "Batch Loss: 2.295048,  Batch Accuracy: 14.84   [17920/54000]\n",
            "Batch Loss: 2.304169,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.296247,  Batch Accuracy: 17.19   [20480/54000]\n",
            "Batch Loss: 2.296606,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.305033,  Batch Accuracy: 7.03   [23040/54000]\n",
            "Batch Loss: 2.298328,  Batch Accuracy: 11.72   [24320/54000]\n",
            "Batch Loss: 2.308929,  Batch Accuracy: 7.03   [25600/54000]\n",
            "Batch Loss: 2.298496,  Batch Accuracy: 12.50   [26880/54000]\n",
            "Batch Loss: 2.296633,  Batch Accuracy: 10.94   [28160/54000]\n",
            "Batch Loss: 2.297031,  Batch Accuracy: 14.84   [29440/54000]\n",
            "Batch Loss: 2.296507,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.299376,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.311278,  Batch Accuracy: 10.94   [33280/54000]\n",
            "Batch Loss: 2.300585,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.299070,  Batch Accuracy: 7.81   [35840/54000]\n",
            "Batch Loss: 2.297946,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.301617,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.301378,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.300424,  Batch Accuracy: 14.06   [40960/54000]\n",
            "Batch Loss: 2.307518,  Batch Accuracy: 8.59   [42240/54000]\n",
            "Batch Loss: 2.294924,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.309736,  Batch Accuracy: 7.03   [44800/54000]\n",
            "Batch Loss: 2.301161,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.298226,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.306663,  Batch Accuracy: 10.94   [48640/54000]\n",
            "Batch Loss: 2.300080,  Batch Accuracy: 14.84   [49920/54000]\n",
            "Batch Loss: 2.305962,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.307568,  Batch Accuracy: 7.03   [52480/54000]\n",
            "Batch Loss: 2.303498,  Batch Accuracy: 10.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301120\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300302\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300917 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Batch Loss: 2.303088,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.288405,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.301721,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.306510,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.302529,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.299493,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.304320,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.302085,  Batch Accuracy: 8.59   [10240/54000]\n",
            "Batch Loss: 2.301132,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.305887,  Batch Accuracy: 8.59   [12800/54000]\n",
            "Batch Loss: 2.308316,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.301724,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.294537,  Batch Accuracy: 12.50   [16640/54000]\n",
            "Batch Loss: 2.306331,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.306941,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.302429,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.304849,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.295284,  Batch Accuracy: 16.41   [23040/54000]\n",
            "Batch Loss: 2.295295,  Batch Accuracy: 16.41   [24320/54000]\n",
            "Batch Loss: 2.298482,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.307876,  Batch Accuracy: 4.69   [26880/54000]\n",
            "Batch Loss: 2.302604,  Batch Accuracy: 5.47   [28160/54000]\n",
            "Batch Loss: 2.304933,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.302865,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.298062,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.304079,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.304920,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.299694,  Batch Accuracy: 11.72   [35840/54000]\n",
            "Batch Loss: 2.300629,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.300681,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.300986,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.305554,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.308267,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.301276,  Batch Accuracy: 14.06   [43520/54000]\n",
            "Batch Loss: 2.297030,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.299895,  Batch Accuracy: 10.94   [46080/54000]\n",
            "Batch Loss: 2.294352,  Batch Accuracy: 14.84   [47360/54000]\n",
            "Batch Loss: 2.305641,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.301926,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.295844,  Batch Accuracy: 14.06   [51200/54000]\n",
            "Batch Loss: 2.293778,  Batch Accuracy: 16.41   [52480/54000]\n",
            "Batch Loss: 2.305653,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301107\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300292\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300904 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Batch Loss: 2.304158,  Batch Accuracy: 13.28   [ 1280/54000]\n",
            "Batch Loss: 2.304749,  Batch Accuracy: 7.81   [ 2560/54000]\n",
            "Batch Loss: 2.297186,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.310946,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.292389,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.294380,  Batch Accuracy: 14.84   [ 7680/54000]\n",
            "Batch Loss: 2.297143,  Batch Accuracy: 14.06   [ 8960/54000]\n",
            "Batch Loss: 2.302590,  Batch Accuracy: 10.16   [10240/54000]\n",
            "Batch Loss: 2.304635,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.291392,  Batch Accuracy: 16.41   [12800/54000]\n",
            "Batch Loss: 2.296019,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.300411,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.299786,  Batch Accuracy: 14.06   [16640/54000]\n",
            "Batch Loss: 2.307909,  Batch Accuracy: 7.03   [17920/54000]\n",
            "Batch Loss: 2.299365,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.296296,  Batch Accuracy: 12.50   [20480/54000]\n",
            "Batch Loss: 2.302296,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.300367,  Batch Accuracy: 14.06   [23040/54000]\n",
            "Batch Loss: 2.296037,  Batch Accuracy: 11.72   [24320/54000]\n",
            "Batch Loss: 2.305845,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.289527,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.299729,  Batch Accuracy: 10.94   [28160/54000]\n",
            "Batch Loss: 2.297137,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.289078,  Batch Accuracy: 19.53   [30720/54000]\n",
            "Batch Loss: 2.299449,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.300237,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.300618,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.309275,  Batch Accuracy: 4.69   [35840/54000]\n",
            "Batch Loss: 2.296376,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.300100,  Batch Accuracy: 10.16   [38400/54000]\n",
            "Batch Loss: 2.303602,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.297497,  Batch Accuracy: 10.94   [40960/54000]\n",
            "Batch Loss: 2.305630,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.304613,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.305154,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.298146,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.303299,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.294632,  Batch Accuracy: 14.06   [48640/54000]\n",
            "Batch Loss: 2.297489,  Batch Accuracy: 14.06   [49920/54000]\n",
            "Batch Loss: 2.300627,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.301253,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.302828,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301104\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300301\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300896 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Batch Loss: 2.304273,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.301430,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.304212,  Batch Accuracy: 14.06   [ 3840/54000]\n",
            "Batch Loss: 2.298038,  Batch Accuracy: 12.50   [ 5120/54000]\n",
            "Batch Loss: 2.300158,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.299225,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.301523,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.300237,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.290303,  Batch Accuracy: 16.41   [11520/54000]\n",
            "Batch Loss: 2.308536,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.301928,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.301184,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.308298,  Batch Accuracy: 7.03   [16640/54000]\n",
            "Batch Loss: 2.303116,  Batch Accuracy: 7.03   [17920/54000]\n",
            "Batch Loss: 2.303193,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.294923,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.299725,  Batch Accuracy: 14.06   [21760/54000]\n",
            "Batch Loss: 2.292613,  Batch Accuracy: 17.19   [23040/54000]\n",
            "Batch Loss: 2.306781,  Batch Accuracy: 6.25   [24320/54000]\n",
            "Batch Loss: 2.303747,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.296310,  Batch Accuracy: 14.06   [26880/54000]\n",
            "Batch Loss: 2.302947,  Batch Accuracy: 11.72   [28160/54000]\n",
            "Batch Loss: 2.305048,  Batch Accuracy: 10.16   [29440/54000]\n",
            "Batch Loss: 2.302188,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.304073,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.299591,  Batch Accuracy: 13.28   [33280/54000]\n",
            "Batch Loss: 2.297716,  Batch Accuracy: 14.06   [34560/54000]\n",
            "Batch Loss: 2.309540,  Batch Accuracy: 7.03   [35840/54000]\n",
            "Batch Loss: 2.296715,  Batch Accuracy: 12.50   [37120/54000]\n",
            "Batch Loss: 2.302241,  Batch Accuracy: 10.16   [38400/54000]\n",
            "Batch Loss: 2.300544,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.300792,  Batch Accuracy: 15.62   [40960/54000]\n",
            "Batch Loss: 2.305321,  Batch Accuracy: 5.47   [42240/54000]\n",
            "Batch Loss: 2.295140,  Batch Accuracy: 14.84   [43520/54000]\n",
            "Batch Loss: 2.310352,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.300168,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.303820,  Batch Accuracy: 7.81   [47360/54000]\n",
            "Batch Loss: 2.308102,  Batch Accuracy: 7.03   [48640/54000]\n",
            "Batch Loss: 2.295102,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.292291,  Batch Accuracy: 17.97   [51200/54000]\n",
            "Batch Loss: 2.298451,  Batch Accuracy: 9.38   [52480/54000]\n",
            "Batch Loss: 2.302867,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301097\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300287\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300888 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Batch Loss: 2.301482,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.297847,  Batch Accuracy: 16.41   [ 2560/54000]\n",
            "Batch Loss: 2.300802,  Batch Accuracy: 12.50   [ 3840/54000]\n",
            "Batch Loss: 2.303653,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.298456,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.301890,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.300404,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.301582,  Batch Accuracy: 10.94   [10240/54000]\n",
            "Batch Loss: 2.301477,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.291486,  Batch Accuracy: 17.97   [12800/54000]\n",
            "Batch Loss: 2.304342,  Batch Accuracy: 10.94   [14080/54000]\n",
            "Batch Loss: 2.303718,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.302935,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.303825,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.298228,  Batch Accuracy: 14.84   [19200/54000]\n",
            "Batch Loss: 2.301830,  Batch Accuracy: 12.50   [20480/54000]\n",
            "Batch Loss: 2.296640,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.304914,  Batch Accuracy: 7.03   [23040/54000]\n",
            "Batch Loss: 2.299622,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.298885,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.301862,  Batch Accuracy: 11.72   [26880/54000]\n",
            "Batch Loss: 2.304999,  Batch Accuracy: 7.81   [28160/54000]\n",
            "Batch Loss: 2.301570,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.300819,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.307968,  Batch Accuracy: 7.81   [32000/54000]\n",
            "Batch Loss: 2.298234,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.301192,  Batch Accuracy: 10.94   [34560/54000]\n",
            "Batch Loss: 2.297590,  Batch Accuracy: 16.41   [35840/54000]\n",
            "Batch Loss: 2.304818,  Batch Accuracy: 10.16   [37120/54000]\n",
            "Batch Loss: 2.307472,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.291489,  Batch Accuracy: 17.19   [39680/54000]\n",
            "Batch Loss: 2.312663,  Batch Accuracy: 7.81   [40960/54000]\n",
            "Batch Loss: 2.301845,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.301549,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.301147,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.303368,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.294011,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.298833,  Batch Accuracy: 14.84   [48640/54000]\n",
            "Batch Loss: 2.288203,  Batch Accuracy: 19.53   [49920/54000]\n",
            "Batch Loss: 2.305370,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.298684,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.291192,  Batch Accuracy: 14.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301088\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300275\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300874 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Batch Loss: 2.300213,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.304067,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.303210,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.306308,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.302338,  Batch Accuracy: 14.06   [ 6400/54000]\n",
            "Batch Loss: 2.313574,  Batch Accuracy: 6.25   [ 7680/54000]\n",
            "Batch Loss: 2.298764,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.302736,  Batch Accuracy: 10.94   [10240/54000]\n",
            "Batch Loss: 2.311842,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.296829,  Batch Accuracy: 14.06   [12800/54000]\n",
            "Batch Loss: 2.301597,  Batch Accuracy: 7.81   [14080/54000]\n",
            "Batch Loss: 2.299123,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.309383,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.307722,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.296847,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.298606,  Batch Accuracy: 12.50   [20480/54000]\n",
            "Batch Loss: 2.307895,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.295503,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.298506,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.301564,  Batch Accuracy: 10.16   [25600/54000]\n",
            "Batch Loss: 2.296448,  Batch Accuracy: 15.62   [26880/54000]\n",
            "Batch Loss: 2.308087,  Batch Accuracy: 5.47   [28160/54000]\n",
            "Batch Loss: 2.301007,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.305015,  Batch Accuracy: 8.59   [30720/54000]\n",
            "Batch Loss: 2.292893,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.297413,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.302750,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.304493,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.306555,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.298281,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.292321,  Batch Accuracy: 16.41   [39680/54000]\n",
            "Batch Loss: 2.296391,  Batch Accuracy: 15.62   [40960/54000]\n",
            "Batch Loss: 2.294972,  Batch Accuracy: 14.84   [42240/54000]\n",
            "Batch Loss: 2.300395,  Batch Accuracy: 14.84   [43520/54000]\n",
            "Batch Loss: 2.302495,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.305471,  Batch Accuracy: 9.38   [46080/54000]\n",
            "Batch Loss: 2.296120,  Batch Accuracy: 15.62   [47360/54000]\n",
            "Batch Loss: 2.297561,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.299183,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.302414,  Batch Accuracy: 7.81   [51200/54000]\n",
            "Batch Loss: 2.305960,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.298547,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301083\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300262\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300871 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Batch Loss: 2.294344,  Batch Accuracy: 17.97   [ 1280/54000]\n",
            "Batch Loss: 2.301737,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.304071,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.302351,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.298454,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.298508,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.300186,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.293520,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.300763,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.299250,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.293823,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.303667,  Batch Accuracy: 7.81   [15360/54000]\n",
            "Batch Loss: 2.293645,  Batch Accuracy: 14.06   [16640/54000]\n",
            "Batch Loss: 2.303823,  Batch Accuracy: 11.72   [17920/54000]\n",
            "Batch Loss: 2.298840,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.301560,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.304461,  Batch Accuracy: 7.81   [21760/54000]\n",
            "Batch Loss: 2.310441,  Batch Accuracy: 5.47   [23040/54000]\n",
            "Batch Loss: 2.302566,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.302846,  Batch Accuracy: 12.50   [25600/54000]\n",
            "Batch Loss: 2.302487,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.299410,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.298917,  Batch Accuracy: 14.06   [29440/54000]\n",
            "Batch Loss: 2.301546,  Batch Accuracy: 12.50   [30720/54000]\n",
            "Batch Loss: 2.306113,  Batch Accuracy: 10.16   [32000/54000]\n",
            "Batch Loss: 2.297519,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.294714,  Batch Accuracy: 16.41   [34560/54000]\n",
            "Batch Loss: 2.292592,  Batch Accuracy: 14.06   [35840/54000]\n",
            "Batch Loss: 2.300678,  Batch Accuracy: 7.81   [37120/54000]\n",
            "Batch Loss: 2.302278,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.298207,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.305400,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.292829,  Batch Accuracy: 15.62   [42240/54000]\n",
            "Batch Loss: 2.305939,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.301890,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.296299,  Batch Accuracy: 14.84   [46080/54000]\n",
            "Batch Loss: 2.301729,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.299541,  Batch Accuracy: 14.06   [48640/54000]\n",
            "Batch Loss: 2.306412,  Batch Accuracy: 5.47   [49920/54000]\n",
            "Batch Loss: 2.299729,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.302693,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.304533,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301078\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300230\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300857 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Batch Loss: 2.306976,  Batch Accuracy: 9.38   [ 1280/54000]\n",
            "Batch Loss: 2.294369,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.310081,  Batch Accuracy: 8.59   [ 3840/54000]\n",
            "Batch Loss: 2.308112,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.297562,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.307938,  Batch Accuracy: 6.25   [ 7680/54000]\n",
            "Batch Loss: 2.306644,  Batch Accuracy: 7.81   [ 8960/54000]\n",
            "Batch Loss: 2.310846,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.300802,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.308155,  Batch Accuracy: 6.25   [12800/54000]\n",
            "Batch Loss: 2.300416,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.300543,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.303511,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.296882,  Batch Accuracy: 12.50   [17920/54000]\n",
            "Batch Loss: 2.306502,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.300137,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.303974,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.297110,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.304507,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.293814,  Batch Accuracy: 15.62   [25600/54000]\n",
            "Batch Loss: 2.290106,  Batch Accuracy: 17.19   [26880/54000]\n",
            "Batch Loss: 2.301954,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.294190,  Batch Accuracy: 18.75   [29440/54000]\n",
            "Batch Loss: 2.295575,  Batch Accuracy: 14.06   [30720/54000]\n",
            "Batch Loss: 2.301395,  Batch Accuracy: 12.50   [32000/54000]\n",
            "Batch Loss: 2.302408,  Batch Accuracy: 7.03   [33280/54000]\n",
            "Batch Loss: 2.306231,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.301099,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.293944,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.303867,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.306901,  Batch Accuracy: 7.03   [39680/54000]\n",
            "Batch Loss: 2.301265,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.293821,  Batch Accuracy: 13.28   [42240/54000]\n",
            "Batch Loss: 2.296192,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.304253,  Batch Accuracy: 9.38   [44800/54000]\n",
            "Batch Loss: 2.308133,  Batch Accuracy: 7.03   [46080/54000]\n",
            "Batch Loss: 2.299695,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.301797,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.299515,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.300060,  Batch Accuracy: 11.72   [51200/54000]\n",
            "Batch Loss: 2.302289,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.299330,  Batch Accuracy: 14.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301071\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300236\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300858 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Batch Loss: 2.299843,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.303755,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.309283,  Batch Accuracy: 6.25   [ 3840/54000]\n",
            "Batch Loss: 2.295145,  Batch Accuracy: 14.84   [ 5120/54000]\n",
            "Batch Loss: 2.297939,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.296522,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.304285,  Batch Accuracy: 7.81   [ 8960/54000]\n",
            "Batch Loss: 2.301875,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.302689,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.304093,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.307829,  Batch Accuracy: 7.81   [14080/54000]\n",
            "Batch Loss: 2.304056,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.292465,  Batch Accuracy: 19.53   [16640/54000]\n",
            "Batch Loss: 2.308006,  Batch Accuracy: 6.25   [17920/54000]\n",
            "Batch Loss: 2.309262,  Batch Accuracy: 4.69   [19200/54000]\n",
            "Batch Loss: 2.299575,  Batch Accuracy: 14.06   [20480/54000]\n",
            "Batch Loss: 2.300767,  Batch Accuracy: 14.84   [21760/54000]\n",
            "Batch Loss: 2.300553,  Batch Accuracy: 10.94   [23040/54000]\n",
            "Batch Loss: 2.301350,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.296641,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.304879,  Batch Accuracy: 8.59   [26880/54000]\n",
            "Batch Loss: 2.302045,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.300495,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.302777,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.306755,  Batch Accuracy: 10.16   [32000/54000]\n",
            "Batch Loss: 2.310077,  Batch Accuracy: 7.03   [33280/54000]\n",
            "Batch Loss: 2.301311,  Batch Accuracy: 7.81   [34560/54000]\n",
            "Batch Loss: 2.295917,  Batch Accuracy: 14.06   [35840/54000]\n",
            "Batch Loss: 2.307207,  Batch Accuracy: 7.03   [37120/54000]\n",
            "Batch Loss: 2.299036,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.298613,  Batch Accuracy: 12.50   [39680/54000]\n",
            "Batch Loss: 2.302836,  Batch Accuracy: 8.59   [40960/54000]\n",
            "Batch Loss: 2.297186,  Batch Accuracy: 13.28   [42240/54000]\n",
            "Batch Loss: 2.292515,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.305468,  Batch Accuracy: 7.81   [44800/54000]\n",
            "Batch Loss: 2.301946,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.303200,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.300513,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.299165,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.303683,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.299924,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.301080,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301062\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300247\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300848 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Batch Loss: 2.307341,  Batch Accuracy: 6.25   [ 1280/54000]\n",
            "Batch Loss: 2.302622,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.300315,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.304822,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.298302,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.302901,  Batch Accuracy: 10.16   [ 7680/54000]\n",
            "Batch Loss: 2.303126,  Batch Accuracy: 9.38   [ 8960/54000]\n",
            "Batch Loss: 2.304742,  Batch Accuracy: 8.59   [10240/54000]\n",
            "Batch Loss: 2.299750,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.298516,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.305562,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.303869,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.293601,  Batch Accuracy: 14.84   [16640/54000]\n",
            "Batch Loss: 2.295358,  Batch Accuracy: 14.84   [17920/54000]\n",
            "Batch Loss: 2.292932,  Batch Accuracy: 14.06   [19200/54000]\n",
            "Batch Loss: 2.310713,  Batch Accuracy: 7.03   [20480/54000]\n",
            "Batch Loss: 2.302552,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.301932,  Batch Accuracy: 9.38   [23040/54000]\n",
            "Batch Loss: 2.300358,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.309565,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.295258,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.295959,  Batch Accuracy: 13.28   [28160/54000]\n",
            "Batch Loss: 2.296445,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.294399,  Batch Accuracy: 14.06   [30720/54000]\n",
            "Batch Loss: 2.297126,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.305869,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.305463,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.295516,  Batch Accuracy: 14.84   [35840/54000]\n",
            "Batch Loss: 2.301417,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.300028,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.296357,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.303403,  Batch Accuracy: 8.59   [40960/54000]\n",
            "Batch Loss: 2.306297,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.306154,  Batch Accuracy: 9.38   [43520/54000]\n",
            "Batch Loss: 2.304972,  Batch Accuracy: 7.81   [44800/54000]\n",
            "Batch Loss: 2.295649,  Batch Accuracy: 14.84   [46080/54000]\n",
            "Batch Loss: 2.301239,  Batch Accuracy: 7.81   [47360/54000]\n",
            "Batch Loss: 2.300474,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.297858,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.299695,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.298824,  Batch Accuracy: 14.06   [52480/54000]\n",
            "Batch Loss: 2.306071,  Batch Accuracy: 5.47   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301054\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300233\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300845 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Batch Loss: 2.299705,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.300611,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.302535,  Batch Accuracy: 12.50   [ 3840/54000]\n",
            "Batch Loss: 2.299161,  Batch Accuracy: 11.72   [ 5120/54000]\n",
            "Batch Loss: 2.299929,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.302623,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.297525,  Batch Accuracy: 12.50   [ 8960/54000]\n",
            "Batch Loss: 2.294935,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.302717,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.303922,  Batch Accuracy: 10.94   [12800/54000]\n",
            "Batch Loss: 2.296945,  Batch Accuracy: 14.06   [14080/54000]\n",
            "Batch Loss: 2.300248,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.298861,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.303696,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.300531,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.297325,  Batch Accuracy: 14.84   [20480/54000]\n",
            "Batch Loss: 2.308015,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.297428,  Batch Accuracy: 13.28   [23040/54000]\n",
            "Batch Loss: 2.298083,  Batch Accuracy: 12.50   [24320/54000]\n",
            "Batch Loss: 2.301146,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.301082,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.301441,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.306159,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.291671,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.290679,  Batch Accuracy: 17.19   [32000/54000]\n",
            "Batch Loss: 2.295554,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.304039,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.299076,  Batch Accuracy: 13.28   [35840/54000]\n",
            "Batch Loss: 2.303744,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.306403,  Batch Accuracy: 7.03   [38400/54000]\n",
            "Batch Loss: 2.304247,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.298069,  Batch Accuracy: 7.81   [40960/54000]\n",
            "Batch Loss: 2.306937,  Batch Accuracy: 8.59   [42240/54000]\n",
            "Batch Loss: 2.306836,  Batch Accuracy: 7.03   [43520/54000]\n",
            "Batch Loss: 2.304913,  Batch Accuracy: 9.38   [44800/54000]\n",
            "Batch Loss: 2.300131,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.293305,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.300037,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.300689,  Batch Accuracy: 14.06   [49920/54000]\n",
            "Batch Loss: 2.300227,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.303754,  Batch Accuracy: 9.38   [52480/54000]\n",
            "Batch Loss: 2.304417,  Batch Accuracy: 8.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301047\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300196\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300840 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Batch Loss: 2.305571,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.299474,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.302992,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.302566,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.296590,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.297732,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.297531,  Batch Accuracy: 12.50   [ 8960/54000]\n",
            "Batch Loss: 2.301904,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.300332,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.303211,  Batch Accuracy: 8.59   [12800/54000]\n",
            "Batch Loss: 2.299064,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.296718,  Batch Accuracy: 13.28   [15360/54000]\n",
            "Batch Loss: 2.306107,  Batch Accuracy: 7.81   [16640/54000]\n",
            "Batch Loss: 2.301504,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.303811,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.302577,  Batch Accuracy: 7.81   [20480/54000]\n",
            "Batch Loss: 2.298849,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.303498,  Batch Accuracy: 13.28   [23040/54000]\n",
            "Batch Loss: 2.296592,  Batch Accuracy: 13.28   [24320/54000]\n",
            "Batch Loss: 2.307368,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.298328,  Batch Accuracy: 11.72   [26880/54000]\n",
            "Batch Loss: 2.305811,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.304863,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.302730,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.299384,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.303102,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.296492,  Batch Accuracy: 13.28   [34560/54000]\n",
            "Batch Loss: 2.297262,  Batch Accuracy: 14.06   [35840/54000]\n",
            "Batch Loss: 2.304924,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.304533,  Batch Accuracy: 10.16   [38400/54000]\n",
            "Batch Loss: 2.295228,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.305261,  Batch Accuracy: 6.25   [40960/54000]\n",
            "Batch Loss: 2.302161,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.304689,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.293622,  Batch Accuracy: 19.53   [44800/54000]\n",
            "Batch Loss: 2.298551,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.299813,  Batch Accuracy: 13.28   [47360/54000]\n",
            "Batch Loss: 2.299403,  Batch Accuracy: 10.94   [48640/54000]\n",
            "Batch Loss: 2.291809,  Batch Accuracy: 13.28   [49920/54000]\n",
            "Batch Loss: 2.300030,  Batch Accuracy: 11.72   [51200/54000]\n",
            "Batch Loss: 2.302421,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.302622,  Batch Accuracy: 8.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301045\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300204\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300833 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Batch Loss: 2.304441,  Batch Accuracy: 9.38   [ 1280/54000]\n",
            "Batch Loss: 2.304704,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.302035,  Batch Accuracy: 7.81   [ 3840/54000]\n",
            "Batch Loss: 2.299093,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.304593,  Batch Accuracy: 9.38   [ 6400/54000]\n",
            "Batch Loss: 2.299688,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.304691,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.304673,  Batch Accuracy: 7.81   [10240/54000]\n",
            "Batch Loss: 2.295249,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.293936,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.306201,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.303583,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.301987,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.306535,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.293447,  Batch Accuracy: 16.41   [19200/54000]\n",
            "Batch Loss: 2.300623,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.302087,  Batch Accuracy: 7.81   [21760/54000]\n",
            "Batch Loss: 2.300264,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.300268,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.288939,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.303274,  Batch Accuracy: 11.72   [26880/54000]\n",
            "Batch Loss: 2.299669,  Batch Accuracy: 13.28   [28160/54000]\n",
            "Batch Loss: 2.301721,  Batch Accuracy: 10.94   [29440/54000]\n",
            "Batch Loss: 2.299806,  Batch Accuracy: 16.41   [30720/54000]\n",
            "Batch Loss: 2.296582,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.295133,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.303704,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.303393,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.296207,  Batch Accuracy: 17.19   [37120/54000]\n",
            "Batch Loss: 2.296321,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.292686,  Batch Accuracy: 14.84   [39680/54000]\n",
            "Batch Loss: 2.303666,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.304402,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.304403,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.296965,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.300516,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.298654,  Batch Accuracy: 13.28   [47360/54000]\n",
            "Batch Loss: 2.301206,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.302184,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.302044,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.300866,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.300997,  Batch Accuracy: 10.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301031\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300183\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300819 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Batch Loss: 2.299992,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.300237,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.302790,  Batch Accuracy: 12.50   [ 3840/54000]\n",
            "Batch Loss: 2.304811,  Batch Accuracy: 7.81   [ 5120/54000]\n",
            "Batch Loss: 2.304902,  Batch Accuracy: 10.16   [ 6400/54000]\n",
            "Batch Loss: 2.307235,  Batch Accuracy: 7.03   [ 7680/54000]\n",
            "Batch Loss: 2.293614,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.298290,  Batch Accuracy: 11.72   [10240/54000]\n",
            "Batch Loss: 2.301096,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.303758,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.297084,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.302115,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.301992,  Batch Accuracy: 8.59   [16640/54000]\n",
            "Batch Loss: 2.305954,  Batch Accuracy: 12.50   [17920/54000]\n",
            "Batch Loss: 2.311538,  Batch Accuracy: 3.12   [19200/54000]\n",
            "Batch Loss: 2.294760,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.309274,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.291175,  Batch Accuracy: 17.19   [23040/54000]\n",
            "Batch Loss: 2.297909,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.302829,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.299940,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.291375,  Batch Accuracy: 18.75   [28160/54000]\n",
            "Batch Loss: 2.308835,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.305116,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.296615,  Batch Accuracy: 10.16   [32000/54000]\n",
            "Batch Loss: 2.300851,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.302716,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.299704,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.296342,  Batch Accuracy: 12.50   [37120/54000]\n",
            "Batch Loss: 2.300359,  Batch Accuracy: 16.41   [38400/54000]\n",
            "Batch Loss: 2.299823,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.301260,  Batch Accuracy: 13.28   [40960/54000]\n",
            "Batch Loss: 2.301904,  Batch Accuracy: 11.72   [42240/54000]\n",
            "Batch Loss: 2.301987,  Batch Accuracy: 9.38   [43520/54000]\n",
            "Batch Loss: 2.311026,  Batch Accuracy: 5.47   [44800/54000]\n",
            "Batch Loss: 2.298159,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.303506,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.300345,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.303494,  Batch Accuracy: 13.28   [49920/54000]\n",
            "Batch Loss: 2.289241,  Batch Accuracy: 17.19   [51200/54000]\n",
            "Batch Loss: 2.298866,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.298021,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301027\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300170\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300812 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Batch Loss: 2.298379,  Batch Accuracy: 14.84   [ 1280/54000]\n",
            "Batch Loss: 2.293984,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.303020,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.301136,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.302283,  Batch Accuracy: 10.16   [ 6400/54000]\n",
            "Batch Loss: 2.302563,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.297497,  Batch Accuracy: 14.06   [ 8960/54000]\n",
            "Batch Loss: 2.297720,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.295722,  Batch Accuracy: 14.84   [11520/54000]\n",
            "Batch Loss: 2.299227,  Batch Accuracy: 12.50   [12800/54000]\n",
            "Batch Loss: 2.296035,  Batch Accuracy: 15.62   [14080/54000]\n",
            "Batch Loss: 2.303171,  Batch Accuracy: 8.59   [15360/54000]\n",
            "Batch Loss: 2.299367,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.299620,  Batch Accuracy: 11.72   [17920/54000]\n",
            "Batch Loss: 2.297075,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.300162,  Batch Accuracy: 12.50   [20480/54000]\n",
            "Batch Loss: 2.293306,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.306849,  Batch Accuracy: 9.38   [23040/54000]\n",
            "Batch Loss: 2.301920,  Batch Accuracy: 7.81   [24320/54000]\n",
            "Batch Loss: 2.302414,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.298837,  Batch Accuracy: 15.62   [26880/54000]\n",
            "Batch Loss: 2.301630,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.301559,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.298646,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.309611,  Batch Accuracy: 7.03   [32000/54000]\n",
            "Batch Loss: 2.302834,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.298819,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.303705,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.295057,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.295228,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.301730,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.300663,  Batch Accuracy: 8.59   [40960/54000]\n",
            "Batch Loss: 2.293567,  Batch Accuracy: 13.28   [42240/54000]\n",
            "Batch Loss: 2.294841,  Batch Accuracy: 16.41   [43520/54000]\n",
            "Batch Loss: 2.293457,  Batch Accuracy: 17.97   [44800/54000]\n",
            "Batch Loss: 2.303349,  Batch Accuracy: 8.59   [46080/54000]\n",
            "Batch Loss: 2.297935,  Batch Accuracy: 10.16   [47360/54000]\n",
            "Batch Loss: 2.299811,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.298004,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.301122,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.291053,  Batch Accuracy: 17.19   [52480/54000]\n",
            "Batch Loss: 2.288451,  Batch Accuracy: 17.19   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301023\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300164\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300809 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Batch Loss: 2.301754,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.298539,  Batch Accuracy: 13.28   [ 2560/54000]\n",
            "Batch Loss: 2.305062,  Batch Accuracy: 7.03   [ 3840/54000]\n",
            "Batch Loss: 2.302068,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.298762,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.302724,  Batch Accuracy: 10.16   [ 7680/54000]\n",
            "Batch Loss: 2.299835,  Batch Accuracy: 14.06   [ 8960/54000]\n",
            "Batch Loss: 2.303025,  Batch Accuracy: 5.47   [10240/54000]\n",
            "Batch Loss: 2.305356,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.302042,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.295181,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.291392,  Batch Accuracy: 13.28   [15360/54000]\n",
            "Batch Loss: 2.302820,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.314794,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.307452,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.302898,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.301968,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.301036,  Batch Accuracy: 9.38   [23040/54000]\n",
            "Batch Loss: 2.300646,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.306582,  Batch Accuracy: 6.25   [25600/54000]\n",
            "Batch Loss: 2.309155,  Batch Accuracy: 7.81   [26880/54000]\n",
            "Batch Loss: 2.290457,  Batch Accuracy: 17.19   [28160/54000]\n",
            "Batch Loss: 2.307379,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.295046,  Batch Accuracy: 14.84   [30720/54000]\n",
            "Batch Loss: 2.299892,  Batch Accuracy: 12.50   [32000/54000]\n",
            "Batch Loss: 2.309280,  Batch Accuracy: 10.94   [33280/54000]\n",
            "Batch Loss: 2.302043,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.306208,  Batch Accuracy: 7.81   [35840/54000]\n",
            "Batch Loss: 2.300242,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.299764,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.301889,  Batch Accuracy: 7.81   [39680/54000]\n",
            "Batch Loss: 2.291759,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.304694,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.306903,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.294893,  Batch Accuracy: 14.06   [44800/54000]\n",
            "Batch Loss: 2.294950,  Batch Accuracy: 11.72   [46080/54000]\n",
            "Batch Loss: 2.299660,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.308717,  Batch Accuracy: 6.25   [48640/54000]\n",
            "Batch Loss: 2.303803,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.292914,  Batch Accuracy: 15.62   [51200/54000]\n",
            "Batch Loss: 2.298928,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.293210,  Batch Accuracy: 14.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301013\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300195\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300800 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Batch Loss: 2.303576,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.308146,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.294228,  Batch Accuracy: 15.62   [ 3840/54000]\n",
            "Batch Loss: 2.304959,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.310175,  Batch Accuracy: 9.38   [ 6400/54000]\n",
            "Batch Loss: 2.297652,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.300903,  Batch Accuracy: 13.28   [ 8960/54000]\n",
            "Batch Loss: 2.298398,  Batch Accuracy: 13.28   [10240/54000]\n",
            "Batch Loss: 2.293696,  Batch Accuracy: 18.75   [11520/54000]\n",
            "Batch Loss: 2.301685,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.300607,  Batch Accuracy: 8.59   [14080/54000]\n",
            "Batch Loss: 2.306597,  Batch Accuracy: 8.59   [15360/54000]\n",
            "Batch Loss: 2.306196,  Batch Accuracy: 7.81   [16640/54000]\n",
            "Batch Loss: 2.303361,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.293717,  Batch Accuracy: 15.62   [19200/54000]\n",
            "Batch Loss: 2.296829,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.300112,  Batch Accuracy: 11.72   [21760/54000]\n",
            "Batch Loss: 2.298868,  Batch Accuracy: 10.94   [23040/54000]\n",
            "Batch Loss: 2.301188,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.300866,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.302893,  Batch Accuracy: 11.72   [26880/54000]\n",
            "Batch Loss: 2.299361,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.306410,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.300939,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.295880,  Batch Accuracy: 15.62   [32000/54000]\n",
            "Batch Loss: 2.303806,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.302405,  Batch Accuracy: 10.94   [34560/54000]\n",
            "Batch Loss: 2.308651,  Batch Accuracy: 7.81   [35840/54000]\n",
            "Batch Loss: 2.298496,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.306185,  Batch Accuracy: 5.47   [38400/54000]\n",
            "Batch Loss: 2.293262,  Batch Accuracy: 14.84   [39680/54000]\n",
            "Batch Loss: 2.301697,  Batch Accuracy: 14.84   [40960/54000]\n",
            "Batch Loss: 2.301644,  Batch Accuracy: 7.03   [42240/54000]\n",
            "Batch Loss: 2.300552,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.299570,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.297305,  Batch Accuracy: 14.06   [46080/54000]\n",
            "Batch Loss: 2.305127,  Batch Accuracy: 6.25   [47360/54000]\n",
            "Batch Loss: 2.301237,  Batch Accuracy: 14.84   [48640/54000]\n",
            "Batch Loss: 2.294866,  Batch Accuracy: 14.84   [49920/54000]\n",
            "Batch Loss: 2.297707,  Batch Accuracy: 13.28   [51200/54000]\n",
            "Batch Loss: 2.302715,  Batch Accuracy: 7.81   [52480/54000]\n",
            "Batch Loss: 2.288342,  Batch Accuracy: 18.75   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301007\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300179\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300789 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Batch Loss: 2.302480,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.300448,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.301072,  Batch Accuracy: 12.50   [ 3840/54000]\n",
            "Batch Loss: 2.294885,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.294965,  Batch Accuracy: 14.06   [ 6400/54000]\n",
            "Batch Loss: 2.307374,  Batch Accuracy: 10.16   [ 7680/54000]\n",
            "Batch Loss: 2.300957,  Batch Accuracy: 13.28   [ 8960/54000]\n",
            "Batch Loss: 2.296131,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.301834,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.299080,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.302441,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.291807,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.305811,  Batch Accuracy: 8.59   [16640/54000]\n",
            "Batch Loss: 2.288812,  Batch Accuracy: 15.62   [17920/54000]\n",
            "Batch Loss: 2.293967,  Batch Accuracy: 14.84   [19200/54000]\n",
            "Batch Loss: 2.300691,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.299295,  Batch Accuracy: 13.28   [21760/54000]\n",
            "Batch Loss: 2.294138,  Batch Accuracy: 18.75   [23040/54000]\n",
            "Batch Loss: 2.305853,  Batch Accuracy: 10.16   [24320/54000]\n",
            "Batch Loss: 2.303129,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.297704,  Batch Accuracy: 12.50   [26880/54000]\n",
            "Batch Loss: 2.296887,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.302321,  Batch Accuracy: 8.59   [29440/54000]\n",
            "Batch Loss: 2.297065,  Batch Accuracy: 16.41   [30720/54000]\n",
            "Batch Loss: 2.300134,  Batch Accuracy: 12.50   [32000/54000]\n",
            "Batch Loss: 2.302383,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.300708,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.300291,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.299736,  Batch Accuracy: 8.59   [37120/54000]\n",
            "Batch Loss: 2.306868,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.297132,  Batch Accuracy: 14.84   [39680/54000]\n",
            "Batch Loss: 2.295263,  Batch Accuracy: 14.06   [40960/54000]\n",
            "Batch Loss: 2.302640,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.304564,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.306087,  Batch Accuracy: 4.69   [44800/54000]\n",
            "Batch Loss: 2.294924,  Batch Accuracy: 14.06   [46080/54000]\n",
            "Batch Loss: 2.302793,  Batch Accuracy: 8.59   [47360/54000]\n",
            "Batch Loss: 2.303561,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.303462,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.305116,  Batch Accuracy: 11.72   [51200/54000]\n",
            "Batch Loss: 2.295508,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.297105,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.301001\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300169\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300785 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Batch Loss: 2.304285,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.298480,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.302468,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.294486,  Batch Accuracy: 12.50   [ 5120/54000]\n",
            "Batch Loss: 2.301517,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.295672,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.307735,  Batch Accuracy: 9.38   [ 8960/54000]\n",
            "Batch Loss: 2.290693,  Batch Accuracy: 14.84   [10240/54000]\n",
            "Batch Loss: 2.295527,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.309042,  Batch Accuracy: 10.94   [12800/54000]\n",
            "Batch Loss: 2.303406,  Batch Accuracy: 5.47   [14080/54000]\n",
            "Batch Loss: 2.303629,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.307277,  Batch Accuracy: 4.69   [16640/54000]\n",
            "Batch Loss: 2.295958,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.295371,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.298413,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.300406,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.304969,  Batch Accuracy: 6.25   [23040/54000]\n",
            "Batch Loss: 2.300278,  Batch Accuracy: 12.50   [24320/54000]\n",
            "Batch Loss: 2.302326,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.294190,  Batch Accuracy: 16.41   [26880/54000]\n",
            "Batch Loss: 2.302376,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.302439,  Batch Accuracy: 7.03   [29440/54000]\n",
            "Batch Loss: 2.306490,  Batch Accuracy: 8.59   [30720/54000]\n",
            "Batch Loss: 2.301666,  Batch Accuracy: 12.50   [32000/54000]\n",
            "Batch Loss: 2.296014,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.305124,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.300119,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.306481,  Batch Accuracy: 8.59   [37120/54000]\n",
            "Batch Loss: 2.304443,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.304206,  Batch Accuracy: 7.03   [39680/54000]\n",
            "Batch Loss: 2.302420,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.302721,  Batch Accuracy: 7.81   [42240/54000]\n",
            "Batch Loss: 2.298912,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.307253,  Batch Accuracy: 5.47   [44800/54000]\n",
            "Batch Loss: 2.307390,  Batch Accuracy: 9.38   [46080/54000]\n",
            "Batch Loss: 2.301917,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.300714,  Batch Accuracy: 10.94   [48640/54000]\n",
            "Batch Loss: 2.299809,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.307498,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.307389,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.309094,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300994\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300183\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300784 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Batch Loss: 2.308232,  Batch Accuracy: 7.03   [ 1280/54000]\n",
            "Batch Loss: 2.298751,  Batch Accuracy: 13.28   [ 2560/54000]\n",
            "Batch Loss: 2.302947,  Batch Accuracy: 8.59   [ 3840/54000]\n",
            "Batch Loss: 2.306754,  Batch Accuracy: 7.81   [ 5120/54000]\n",
            "Batch Loss: 2.305375,  Batch Accuracy: 7.03   [ 6400/54000]\n",
            "Batch Loss: 2.299346,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.300231,  Batch Accuracy: 10.16   [ 8960/54000]\n",
            "Batch Loss: 2.310799,  Batch Accuracy: 6.25   [10240/54000]\n",
            "Batch Loss: 2.291180,  Batch Accuracy: 14.84   [11520/54000]\n",
            "Batch Loss: 2.291328,  Batch Accuracy: 14.84   [12800/54000]\n",
            "Batch Loss: 2.302154,  Batch Accuracy: 14.06   [14080/54000]\n",
            "Batch Loss: 2.299810,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.292250,  Batch Accuracy: 14.84   [16640/54000]\n",
            "Batch Loss: 2.306220,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.304370,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.298493,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.300794,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.301296,  Batch Accuracy: 11.72   [23040/54000]\n",
            "Batch Loss: 2.299704,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.304482,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.294821,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.300940,  Batch Accuracy: 10.94   [28160/54000]\n",
            "Batch Loss: 2.302876,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.296658,  Batch Accuracy: 13.28   [30720/54000]\n",
            "Batch Loss: 2.302801,  Batch Accuracy: 10.16   [32000/54000]\n",
            "Batch Loss: 2.307277,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.301849,  Batch Accuracy: 9.38   [34560/54000]\n",
            "Batch Loss: 2.307725,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.305380,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.304999,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.309679,  Batch Accuracy: 7.81   [39680/54000]\n",
            "Batch Loss: 2.309471,  Batch Accuracy: 10.16   [40960/54000]\n",
            "Batch Loss: 2.299213,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.303826,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.303171,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.304104,  Batch Accuracy: 7.03   [46080/54000]\n",
            "Batch Loss: 2.301961,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.304238,  Batch Accuracy: 7.03   [48640/54000]\n",
            "Batch Loss: 2.308410,  Batch Accuracy: 9.38   [49920/54000]\n",
            "Batch Loss: 2.306289,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.302040,  Batch Accuracy: 12.50   [52480/54000]\n",
            "Batch Loss: 2.295195,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300985\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300162\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300778 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Batch Loss: 2.303952,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.290382,  Batch Accuracy: 19.53   [ 2560/54000]\n",
            "Batch Loss: 2.299848,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.307710,  Batch Accuracy: 6.25   [ 5120/54000]\n",
            "Batch Loss: 2.301371,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.304414,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.309938,  Batch Accuracy: 6.25   [ 8960/54000]\n",
            "Batch Loss: 2.293709,  Batch Accuracy: 13.28   [10240/54000]\n",
            "Batch Loss: 2.302861,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.297042,  Batch Accuracy: 14.84   [12800/54000]\n",
            "Batch Loss: 2.298926,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.296637,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.298674,  Batch Accuracy: 15.62   [16640/54000]\n",
            "Batch Loss: 2.310291,  Batch Accuracy: 5.47   [17920/54000]\n",
            "Batch Loss: 2.298166,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.296946,  Batch Accuracy: 14.84   [20480/54000]\n",
            "Batch Loss: 2.304023,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.298453,  Batch Accuracy: 14.06   [23040/54000]\n",
            "Batch Loss: 2.300291,  Batch Accuracy: 13.28   [24320/54000]\n",
            "Batch Loss: 2.304188,  Batch Accuracy: 10.16   [25600/54000]\n",
            "Batch Loss: 2.298578,  Batch Accuracy: 15.62   [26880/54000]\n",
            "Batch Loss: 2.305568,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.311907,  Batch Accuracy: 6.25   [29440/54000]\n",
            "Batch Loss: 2.297927,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.297623,  Batch Accuracy: 17.97   [32000/54000]\n",
            "Batch Loss: 2.301713,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.296962,  Batch Accuracy: 14.84   [34560/54000]\n",
            "Batch Loss: 2.299226,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.295335,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.309319,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.298170,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.312577,  Batch Accuracy: 5.47   [40960/54000]\n",
            "Batch Loss: 2.300670,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.307411,  Batch Accuracy: 6.25   [43520/54000]\n",
            "Batch Loss: 2.309292,  Batch Accuracy: 8.59   [44800/54000]\n",
            "Batch Loss: 2.301314,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.292800,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.301801,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.305179,  Batch Accuracy: 9.38   [49920/54000]\n",
            "Batch Loss: 2.305553,  Batch Accuracy: 7.81   [51200/54000]\n",
            "Batch Loss: 2.304842,  Batch Accuracy: 9.38   [52480/54000]\n",
            "Batch Loss: 2.302276,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300979\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300119\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300770 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Batch Loss: 2.304021,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.306897,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.300294,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.307744,  Batch Accuracy: 9.38   [ 5120/54000]\n",
            "Batch Loss: 2.302891,  Batch Accuracy: 14.84   [ 6400/54000]\n",
            "Batch Loss: 2.300442,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.308123,  Batch Accuracy: 7.81   [ 8960/54000]\n",
            "Batch Loss: 2.294320,  Batch Accuracy: 15.62   [10240/54000]\n",
            "Batch Loss: 2.298923,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.305947,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.297497,  Batch Accuracy: 14.84   [14080/54000]\n",
            "Batch Loss: 2.293699,  Batch Accuracy: 14.06   [15360/54000]\n",
            "Batch Loss: 2.302770,  Batch Accuracy: 9.38   [16640/54000]\n",
            "Batch Loss: 2.304660,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.299773,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.299922,  Batch Accuracy: 7.03   [20480/54000]\n",
            "Batch Loss: 2.305305,  Batch Accuracy: 11.72   [21760/54000]\n",
            "Batch Loss: 2.294465,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.304983,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.301301,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.302209,  Batch Accuracy: 14.06   [26880/54000]\n",
            "Batch Loss: 2.296858,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.294566,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.302445,  Batch Accuracy: 7.81   [30720/54000]\n",
            "Batch Loss: 2.296653,  Batch Accuracy: 14.06   [32000/54000]\n",
            "Batch Loss: 2.299122,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.302356,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.302166,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.301340,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.302481,  Batch Accuracy: 11.72   [38400/54000]\n",
            "Batch Loss: 2.300966,  Batch Accuracy: 9.38   [39680/54000]\n",
            "Batch Loss: 2.293752,  Batch Accuracy: 14.06   [40960/54000]\n",
            "Batch Loss: 2.301539,  Batch Accuracy: 11.72   [42240/54000]\n",
            "Batch Loss: 2.308546,  Batch Accuracy: 7.81   [43520/54000]\n",
            "Batch Loss: 2.309160,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.293103,  Batch Accuracy: 17.19   [46080/54000]\n",
            "Batch Loss: 2.298404,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.294947,  Batch Accuracy: 16.41   [48640/54000]\n",
            "Batch Loss: 2.304492,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.306067,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.299505,  Batch Accuracy: 12.50   [52480/54000]\n",
            "Batch Loss: 2.304565,  Batch Accuracy: 6.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300976\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300122\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300763 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Batch Loss: 2.300275,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.310497,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.302178,  Batch Accuracy: 10.94   [ 3840/54000]\n",
            "Batch Loss: 2.307029,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.301152,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.306221,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.297329,  Batch Accuracy: 15.62   [ 8960/54000]\n",
            "Batch Loss: 2.299655,  Batch Accuracy: 13.28   [10240/54000]\n",
            "Batch Loss: 2.300346,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.296768,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.307043,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.305054,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.296061,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.304003,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.300816,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.298644,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.293226,  Batch Accuracy: 15.62   [21760/54000]\n",
            "Batch Loss: 2.304195,  Batch Accuracy: 7.81   [23040/54000]\n",
            "Batch Loss: 2.307824,  Batch Accuracy: 7.03   [24320/54000]\n",
            "Batch Loss: 2.299071,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.305876,  Batch Accuracy: 10.94   [26880/54000]\n",
            "Batch Loss: 2.296875,  Batch Accuracy: 14.84   [28160/54000]\n",
            "Batch Loss: 2.302408,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.304131,  Batch Accuracy: 7.03   [30720/54000]\n",
            "Batch Loss: 2.299354,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.302650,  Batch Accuracy: 8.59   [33280/54000]\n",
            "Batch Loss: 2.297022,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.301459,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.303700,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.297857,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.306025,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.301692,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.299056,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.298098,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.295418,  Batch Accuracy: 13.28   [44800/54000]\n",
            "Batch Loss: 2.294027,  Batch Accuracy: 17.19   [46080/54000]\n",
            "Batch Loss: 2.303407,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.301874,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.305504,  Batch Accuracy: 6.25   [49920/54000]\n",
            "Batch Loss: 2.298871,  Batch Accuracy: 13.28   [51200/54000]\n",
            "Batch Loss: 2.304065,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.294880,  Batch Accuracy: 14.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300968\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300143\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300760 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Batch Loss: 2.306136,  Batch Accuracy: 7.03   [ 1280/54000]\n",
            "Batch Loss: 2.300818,  Batch Accuracy: 14.84   [ 2560/54000]\n",
            "Batch Loss: 2.292127,  Batch Accuracy: 16.41   [ 3840/54000]\n",
            "Batch Loss: 2.306667,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.296704,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.293396,  Batch Accuracy: 14.06   [ 7680/54000]\n",
            "Batch Loss: 2.298560,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.306628,  Batch Accuracy: 5.47   [10240/54000]\n",
            "Batch Loss: 2.300344,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.296248,  Batch Accuracy: 12.50   [12800/54000]\n",
            "Batch Loss: 2.304363,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.304026,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.300674,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.295355,  Batch Accuracy: 14.84   [17920/54000]\n",
            "Batch Loss: 2.303479,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.307313,  Batch Accuracy: 9.38   [20480/54000]\n",
            "Batch Loss: 2.303052,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.301610,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.305382,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.295464,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.304600,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.309831,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.295659,  Batch Accuracy: 17.19   [29440/54000]\n",
            "Batch Loss: 2.308706,  Batch Accuracy: 7.81   [30720/54000]\n",
            "Batch Loss: 2.300794,  Batch Accuracy: 10.94   [32000/54000]\n",
            "Batch Loss: 2.303426,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.302565,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.306655,  Batch Accuracy: 7.03   [35840/54000]\n",
            "Batch Loss: 2.297213,  Batch Accuracy: 12.50   [37120/54000]\n",
            "Batch Loss: 2.306733,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.294379,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.298635,  Batch Accuracy: 10.16   [40960/54000]\n",
            "Batch Loss: 2.301339,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.303931,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.302691,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.302248,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.309957,  Batch Accuracy: 5.47   [47360/54000]\n",
            "Batch Loss: 2.309756,  Batch Accuracy: 5.47   [48640/54000]\n",
            "Batch Loss: 2.300714,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.307240,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.305506,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.302308,  Batch Accuracy: 9.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300960\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300160\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300752 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Batch Loss: 2.303851,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.302615,  Batch Accuracy: 7.81   [ 2560/54000]\n",
            "Batch Loss: 2.306644,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.305537,  Batch Accuracy: 8.59   [ 5120/54000]\n",
            "Batch Loss: 2.307617,  Batch Accuracy: 7.03   [ 6400/54000]\n",
            "Batch Loss: 2.301883,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.300042,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.303949,  Batch Accuracy: 7.03   [10240/54000]\n",
            "Batch Loss: 2.297700,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.305352,  Batch Accuracy: 8.59   [12800/54000]\n",
            "Batch Loss: 2.302705,  Batch Accuracy: 6.25   [14080/54000]\n",
            "Batch Loss: 2.297309,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.296454,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.302654,  Batch Accuracy: 10.94   [17920/54000]\n",
            "Batch Loss: 2.300070,  Batch Accuracy: 14.06   [19200/54000]\n",
            "Batch Loss: 2.301610,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.295893,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.301847,  Batch Accuracy: 10.94   [23040/54000]\n",
            "Batch Loss: 2.302882,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.307574,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.299759,  Batch Accuracy: 10.94   [26880/54000]\n",
            "Batch Loss: 2.310534,  Batch Accuracy: 8.59   [28160/54000]\n",
            "Batch Loss: 2.300143,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.304747,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.300394,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.299398,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.295949,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.302035,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.311951,  Batch Accuracy: 6.25   [37120/54000]\n",
            "Batch Loss: 2.299110,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.291360,  Batch Accuracy: 14.06   [39680/54000]\n",
            "Batch Loss: 2.308378,  Batch Accuracy: 7.03   [40960/54000]\n",
            "Batch Loss: 2.294092,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.305280,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.301802,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.308784,  Batch Accuracy: 3.91   [46080/54000]\n",
            "Batch Loss: 2.296179,  Batch Accuracy: 15.62   [47360/54000]\n",
            "Batch Loss: 2.302951,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.304274,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.298072,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.300606,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.297910,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300953\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300121\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300746 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Batch Loss: 2.296551,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.306550,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.295135,  Batch Accuracy: 14.06   [ 3840/54000]\n",
            "Batch Loss: 2.299500,  Batch Accuracy: 11.72   [ 5120/54000]\n",
            "Batch Loss: 2.305387,  Batch Accuracy: 6.25   [ 6400/54000]\n",
            "Batch Loss: 2.301065,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.299806,  Batch Accuracy: 9.38   [ 8960/54000]\n",
            "Batch Loss: 2.305538,  Batch Accuracy: 6.25   [10240/54000]\n",
            "Batch Loss: 2.308511,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.303624,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.298545,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.301661,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.302276,  Batch Accuracy: 7.03   [16640/54000]\n",
            "Batch Loss: 2.301321,  Batch Accuracy: 10.94   [17920/54000]\n",
            "Batch Loss: 2.295625,  Batch Accuracy: 14.06   [19200/54000]\n",
            "Batch Loss: 2.300318,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.296685,  Batch Accuracy: 11.72   [21760/54000]\n",
            "Batch Loss: 2.307617,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.301342,  Batch Accuracy: 13.28   [24320/54000]\n",
            "Batch Loss: 2.301862,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.305855,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.308208,  Batch Accuracy: 7.03   [28160/54000]\n",
            "Batch Loss: 2.299839,  Batch Accuracy: 11.72   [29440/54000]\n",
            "Batch Loss: 2.306405,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.301310,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.298838,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.302585,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.296159,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.301995,  Batch Accuracy: 12.50   [37120/54000]\n",
            "Batch Loss: 2.297144,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.295576,  Batch Accuracy: 14.84   [39680/54000]\n",
            "Batch Loss: 2.302104,  Batch Accuracy: 7.81   [40960/54000]\n",
            "Batch Loss: 2.306248,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.300329,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.300158,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.297867,  Batch Accuracy: 8.59   [46080/54000]\n",
            "Batch Loss: 2.296950,  Batch Accuracy: 13.28   [47360/54000]\n",
            "Batch Loss: 2.300120,  Batch Accuracy: 12.50   [48640/54000]\n",
            "Batch Loss: 2.306992,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.299869,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.306121,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.295937,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300944\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300124\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300738 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Batch Loss: 2.297465,  Batch Accuracy: 14.84   [ 1280/54000]\n",
            "Batch Loss: 2.304802,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.301550,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.296811,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.299241,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.311074,  Batch Accuracy: 4.69   [ 7680/54000]\n",
            "Batch Loss: 2.305618,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.303038,  Batch Accuracy: 7.03   [10240/54000]\n",
            "Batch Loss: 2.305793,  Batch Accuracy: 9.38   [11520/54000]\n",
            "Batch Loss: 2.301542,  Batch Accuracy: 7.03   [12800/54000]\n",
            "Batch Loss: 2.298048,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.295819,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.311630,  Batch Accuracy: 3.12   [16640/54000]\n",
            "Batch Loss: 2.293257,  Batch Accuracy: 16.41   [17920/54000]\n",
            "Batch Loss: 2.293324,  Batch Accuracy: 13.28   [19200/54000]\n",
            "Batch Loss: 2.300286,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.302042,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.305121,  Batch Accuracy: 11.72   [23040/54000]\n",
            "Batch Loss: 2.299861,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.299651,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.296348,  Batch Accuracy: 14.06   [26880/54000]\n",
            "Batch Loss: 2.292477,  Batch Accuracy: 16.41   [28160/54000]\n",
            "Batch Loss: 2.299773,  Batch Accuracy: 10.16   [29440/54000]\n",
            "Batch Loss: 2.288569,  Batch Accuracy: 20.31   [30720/54000]\n",
            "Batch Loss: 2.293709,  Batch Accuracy: 14.84   [32000/54000]\n",
            "Batch Loss: 2.307041,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.306436,  Batch Accuracy: 7.81   [34560/54000]\n",
            "Batch Loss: 2.301454,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.295665,  Batch Accuracy: 17.97   [37120/54000]\n",
            "Batch Loss: 2.306948,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.299037,  Batch Accuracy: 12.50   [39680/54000]\n",
            "Batch Loss: 2.299925,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.297286,  Batch Accuracy: 15.62   [42240/54000]\n",
            "Batch Loss: 2.296872,  Batch Accuracy: 16.41   [43520/54000]\n",
            "Batch Loss: 2.299617,  Batch Accuracy: 14.06   [44800/54000]\n",
            "Batch Loss: 2.291030,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.303448,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.302328,  Batch Accuracy: 12.50   [48640/54000]\n",
            "Batch Loss: 2.302547,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.303899,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.306444,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.301523,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300938\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300121\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300730 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Batch Loss: 2.300067,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.297361,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.297331,  Batch Accuracy: 15.62   [ 3840/54000]\n",
            "Batch Loss: 2.297333,  Batch Accuracy: 12.50   [ 5120/54000]\n",
            "Batch Loss: 2.303156,  Batch Accuracy: 10.94   [ 6400/54000]\n",
            "Batch Loss: 2.309914,  Batch Accuracy: 7.81   [ 7680/54000]\n",
            "Batch Loss: 2.299240,  Batch Accuracy: 12.50   [ 8960/54000]\n",
            "Batch Loss: 2.305779,  Batch Accuracy: 7.03   [10240/54000]\n",
            "Batch Loss: 2.306283,  Batch Accuracy: 7.81   [11520/54000]\n",
            "Batch Loss: 2.300716,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.295661,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.300598,  Batch Accuracy: 7.03   [15360/54000]\n",
            "Batch Loss: 2.301113,  Batch Accuracy: 12.50   [16640/54000]\n",
            "Batch Loss: 2.304046,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.292059,  Batch Accuracy: 17.97   [19200/54000]\n",
            "Batch Loss: 2.296668,  Batch Accuracy: 18.75   [20480/54000]\n",
            "Batch Loss: 2.295847,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.303028,  Batch Accuracy: 7.81   [23040/54000]\n",
            "Batch Loss: 2.297025,  Batch Accuracy: 13.28   [24320/54000]\n",
            "Batch Loss: 2.304103,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.295647,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.290945,  Batch Accuracy: 17.97   [28160/54000]\n",
            "Batch Loss: 2.299663,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.304145,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.303542,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.295178,  Batch Accuracy: 11.72   [33280/54000]\n",
            "Batch Loss: 2.300462,  Batch Accuracy: 14.06   [34560/54000]\n",
            "Batch Loss: 2.306145,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.303786,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.300165,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.302037,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.300992,  Batch Accuracy: 10.94   [40960/54000]\n",
            "Batch Loss: 2.299072,  Batch Accuracy: 11.72   [42240/54000]\n",
            "Batch Loss: 2.298601,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.288953,  Batch Accuracy: 17.19   [44800/54000]\n",
            "Batch Loss: 2.294255,  Batch Accuracy: 14.84   [46080/54000]\n",
            "Batch Loss: 2.301989,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.295200,  Batch Accuracy: 15.62   [48640/54000]\n",
            "Batch Loss: 2.296905,  Batch Accuracy: 14.84   [49920/54000]\n",
            "Batch Loss: 2.302143,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.292579,  Batch Accuracy: 15.62   [52480/54000]\n",
            "Batch Loss: 2.292030,  Batch Accuracy: 15.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300931\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300088\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300723 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Batch Loss: 2.294614,  Batch Accuracy: 13.28   [ 1280/54000]\n",
            "Batch Loss: 2.304690,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.299197,  Batch Accuracy: 14.84   [ 3840/54000]\n",
            "Batch Loss: 2.310347,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.303008,  Batch Accuracy: 7.03   [ 6400/54000]\n",
            "Batch Loss: 2.290486,  Batch Accuracy: 17.97   [ 7680/54000]\n",
            "Batch Loss: 2.302156,  Batch Accuracy: 13.28   [ 8960/54000]\n",
            "Batch Loss: 2.298422,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.301968,  Batch Accuracy: 10.16   [11520/54000]\n",
            "Batch Loss: 2.308398,  Batch Accuracy: 7.81   [12800/54000]\n",
            "Batch Loss: 2.298152,  Batch Accuracy: 16.41   [14080/54000]\n",
            "Batch Loss: 2.297708,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.297298,  Batch Accuracy: 11.72   [16640/54000]\n",
            "Batch Loss: 2.307615,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.303811,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.291899,  Batch Accuracy: 15.62   [20480/54000]\n",
            "Batch Loss: 2.306961,  Batch Accuracy: 10.16   [21760/54000]\n",
            "Batch Loss: 2.298599,  Batch Accuracy: 9.38   [23040/54000]\n",
            "Batch Loss: 2.307076,  Batch Accuracy: 7.81   [24320/54000]\n",
            "Batch Loss: 2.295289,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.296345,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.297467,  Batch Accuracy: 16.41   [28160/54000]\n",
            "Batch Loss: 2.309644,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.300779,  Batch Accuracy: 14.06   [30720/54000]\n",
            "Batch Loss: 2.300069,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.298705,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.301396,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.301757,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.301235,  Batch Accuracy: 10.16   [37120/54000]\n",
            "Batch Loss: 2.305146,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.301666,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.298961,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.296350,  Batch Accuracy: 14.84   [42240/54000]\n",
            "Batch Loss: 2.301932,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.301260,  Batch Accuracy: 13.28   [44800/54000]\n",
            "Batch Loss: 2.305026,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.288770,  Batch Accuracy: 17.97   [47360/54000]\n",
            "Batch Loss: 2.296101,  Batch Accuracy: 12.50   [48640/54000]\n",
            "Batch Loss: 2.298310,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.302230,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.297858,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.299138,  Batch Accuracy: 10.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300926\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300091\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300717 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Batch Loss: 2.302371,  Batch Accuracy: 7.03   [ 1280/54000]\n",
            "Batch Loss: 2.298757,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.304303,  Batch Accuracy: 14.06   [ 3840/54000]\n",
            "Batch Loss: 2.299163,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.302158,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.284365,  Batch Accuracy: 21.88   [ 7680/54000]\n",
            "Batch Loss: 2.296465,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.307166,  Batch Accuracy: 7.81   [10240/54000]\n",
            "Batch Loss: 2.300133,  Batch Accuracy: 7.81   [11520/54000]\n",
            "Batch Loss: 2.308635,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.301099,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.301139,  Batch Accuracy: 8.59   [15360/54000]\n",
            "Batch Loss: 2.297771,  Batch Accuracy: 14.06   [16640/54000]\n",
            "Batch Loss: 2.290968,  Batch Accuracy: 15.62   [17920/54000]\n",
            "Batch Loss: 2.300273,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.301261,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.295692,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.298022,  Batch Accuracy: 10.94   [23040/54000]\n",
            "Batch Loss: 2.302325,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.306082,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.291720,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.303800,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.295968,  Batch Accuracy: 15.62   [29440/54000]\n",
            "Batch Loss: 2.298033,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.294879,  Batch Accuracy: 10.94   [32000/54000]\n",
            "Batch Loss: 2.301045,  Batch Accuracy: 10.94   [33280/54000]\n",
            "Batch Loss: 2.295408,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.302591,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.303654,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.297527,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.307682,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.305345,  Batch Accuracy: 10.94   [40960/54000]\n",
            "Batch Loss: 2.293947,  Batch Accuracy: 14.06   [42240/54000]\n",
            "Batch Loss: 2.303785,  Batch Accuracy: 7.81   [43520/54000]\n",
            "Batch Loss: 2.307561,  Batch Accuracy: 9.38   [44800/54000]\n",
            "Batch Loss: 2.294615,  Batch Accuracy: 14.06   [46080/54000]\n",
            "Batch Loss: 2.293897,  Batch Accuracy: 16.41   [47360/54000]\n",
            "Batch Loss: 2.296527,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.301671,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.299653,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.301921,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.309273,  Batch Accuracy: 7.03   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300918\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300085\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300710 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Batch Loss: 2.308839,  Batch Accuracy: 6.25   [ 1280/54000]\n",
            "Batch Loss: 2.300790,  Batch Accuracy: 12.50   [ 2560/54000]\n",
            "Batch Loss: 2.302786,  Batch Accuracy: 9.38   [ 3840/54000]\n",
            "Batch Loss: 2.290606,  Batch Accuracy: 15.62   [ 5120/54000]\n",
            "Batch Loss: 2.302595,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.296977,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.297069,  Batch Accuracy: 14.84   [ 8960/54000]\n",
            "Batch Loss: 2.300185,  Batch Accuracy: 11.72   [10240/54000]\n",
            "Batch Loss: 2.310574,  Batch Accuracy: 6.25   [11520/54000]\n",
            "Batch Loss: 2.294841,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.290992,  Batch Accuracy: 14.06   [14080/54000]\n",
            "Batch Loss: 2.303231,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.304205,  Batch Accuracy: 8.59   [16640/54000]\n",
            "Batch Loss: 2.292432,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.306610,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.304671,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.299694,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.288289,  Batch Accuracy: 19.53   [23040/54000]\n",
            "Batch Loss: 2.297794,  Batch Accuracy: 10.16   [24320/54000]\n",
            "Batch Loss: 2.298021,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.302468,  Batch Accuracy: 6.25   [26880/54000]\n",
            "Batch Loss: 2.296141,  Batch Accuracy: 14.84   [28160/54000]\n",
            "Batch Loss: 2.305585,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.299355,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.309517,  Batch Accuracy: 6.25   [32000/54000]\n",
            "Batch Loss: 2.310241,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.300279,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.308676,  Batch Accuracy: 7.81   [35840/54000]\n",
            "Batch Loss: 2.303920,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.300986,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.301894,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.298541,  Batch Accuracy: 10.94   [40960/54000]\n",
            "Batch Loss: 2.301550,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.291122,  Batch Accuracy: 16.41   [43520/54000]\n",
            "Batch Loss: 2.301731,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.306930,  Batch Accuracy: 10.94   [46080/54000]\n",
            "Batch Loss: 2.303758,  Batch Accuracy: 10.16   [47360/54000]\n",
            "Batch Loss: 2.303213,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.301486,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.306627,  Batch Accuracy: 8.59   [51200/54000]\n",
            "Batch Loss: 2.304280,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.305976,  Batch Accuracy: 6.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300913\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300063\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300695 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Batch Loss: 2.296036,  Batch Accuracy: 14.06   [ 1280/54000]\n",
            "Batch Loss: 2.301461,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.305375,  Batch Accuracy: 10.94   [ 3840/54000]\n",
            "Batch Loss: 2.307414,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.303617,  Batch Accuracy: 10.16   [ 6400/54000]\n",
            "Batch Loss: 2.303839,  Batch Accuracy: 7.81   [ 7680/54000]\n",
            "Batch Loss: 2.297906,  Batch Accuracy: 14.84   [ 8960/54000]\n",
            "Batch Loss: 2.297754,  Batch Accuracy: 10.94   [10240/54000]\n",
            "Batch Loss: 2.297930,  Batch Accuracy: 12.50   [11520/54000]\n",
            "Batch Loss: 2.300188,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.302200,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.303389,  Batch Accuracy: 7.03   [15360/54000]\n",
            "Batch Loss: 2.302021,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.308595,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.303092,  Batch Accuracy: 8.59   [19200/54000]\n",
            "Batch Loss: 2.291398,  Batch Accuracy: 17.19   [20480/54000]\n",
            "Batch Loss: 2.299963,  Batch Accuracy: 10.94   [21760/54000]\n",
            "Batch Loss: 2.298136,  Batch Accuracy: 14.84   [23040/54000]\n",
            "Batch Loss: 2.306493,  Batch Accuracy: 7.03   [24320/54000]\n",
            "Batch Loss: 2.298587,  Batch Accuracy: 12.50   [25600/54000]\n",
            "Batch Loss: 2.299435,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.305236,  Batch Accuracy: 7.81   [28160/54000]\n",
            "Batch Loss: 2.300046,  Batch Accuracy: 8.59   [29440/54000]\n",
            "Batch Loss: 2.298910,  Batch Accuracy: 15.62   [30720/54000]\n",
            "Batch Loss: 2.311211,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.297387,  Batch Accuracy: 15.62   [33280/54000]\n",
            "Batch Loss: 2.295667,  Batch Accuracy: 15.62   [34560/54000]\n",
            "Batch Loss: 2.300103,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.301587,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.312611,  Batch Accuracy: 7.03   [38400/54000]\n",
            "Batch Loss: 2.297960,  Batch Accuracy: 12.50   [39680/54000]\n",
            "Batch Loss: 2.298524,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.302434,  Batch Accuracy: 8.59   [42240/54000]\n",
            "Batch Loss: 2.298604,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.297611,  Batch Accuracy: 14.06   [44800/54000]\n",
            "Batch Loss: 2.304011,  Batch Accuracy: 9.38   [46080/54000]\n",
            "Batch Loss: 2.298186,  Batch Accuracy: 14.06   [47360/54000]\n",
            "Batch Loss: 2.303508,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.299673,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.302473,  Batch Accuracy: 12.50   [51200/54000]\n",
            "Batch Loss: 2.297916,  Batch Accuracy: 14.84   [52480/54000]\n",
            "Batch Loss: 2.297829,  Batch Accuracy: 13.28   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300906\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300082\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300687 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Batch Loss: 2.301050,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.305434,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.304413,  Batch Accuracy: 7.81   [ 3840/54000]\n",
            "Batch Loss: 2.306310,  Batch Accuracy: 5.47   [ 5120/54000]\n",
            "Batch Loss: 2.306105,  Batch Accuracy: 7.81   [ 6400/54000]\n",
            "Batch Loss: 2.301758,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.299901,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.291033,  Batch Accuracy: 14.84   [10240/54000]\n",
            "Batch Loss: 2.300666,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.295597,  Batch Accuracy: 14.06   [12800/54000]\n",
            "Batch Loss: 2.296579,  Batch Accuracy: 11.72   [14080/54000]\n",
            "Batch Loss: 2.296450,  Batch Accuracy: 14.84   [15360/54000]\n",
            "Batch Loss: 2.299752,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.307729,  Batch Accuracy: 7.81   [17920/54000]\n",
            "Batch Loss: 2.296244,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.300836,  Batch Accuracy: 10.94   [20480/54000]\n",
            "Batch Loss: 2.297725,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.299466,  Batch Accuracy: 14.06   [23040/54000]\n",
            "Batch Loss: 2.296698,  Batch Accuracy: 12.50   [24320/54000]\n",
            "Batch Loss: 2.298637,  Batch Accuracy: 12.50   [25600/54000]\n",
            "Batch Loss: 2.296100,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.301906,  Batch Accuracy: 14.06   [28160/54000]\n",
            "Batch Loss: 2.298313,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.301692,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.303013,  Batch Accuracy: 10.94   [32000/54000]\n",
            "Batch Loss: 2.307128,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.295786,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.297767,  Batch Accuracy: 9.38   [35840/54000]\n",
            "Batch Loss: 2.301986,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.297573,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.301291,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.300847,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.297026,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.297277,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.300017,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.293253,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.299958,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.307022,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.304165,  Batch Accuracy: 9.38   [49920/54000]\n",
            "Batch Loss: 2.300174,  Batch Accuracy: 12.50   [51200/54000]\n",
            "Batch Loss: 2.305295,  Batch Accuracy: 7.03   [52480/54000]\n",
            "Batch Loss: 2.301367,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300897\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300089\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300688 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Batch Loss: 2.295362,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.302024,  Batch Accuracy: 8.59   [ 2560/54000]\n",
            "Batch Loss: 2.303941,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.299374,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.304958,  Batch Accuracy: 7.81   [ 6400/54000]\n",
            "Batch Loss: 2.307696,  Batch Accuracy: 8.59   [ 7680/54000]\n",
            "Batch Loss: 2.305780,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.297784,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.301569,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.297173,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.302701,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.302256,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.302727,  Batch Accuracy: 9.38   [16640/54000]\n",
            "Batch Loss: 2.297697,  Batch Accuracy: 10.94   [17920/54000]\n",
            "Batch Loss: 2.310489,  Batch Accuracy: 6.25   [19200/54000]\n",
            "Batch Loss: 2.298812,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.299734,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.296869,  Batch Accuracy: 13.28   [23040/54000]\n",
            "Batch Loss: 2.310860,  Batch Accuracy: 5.47   [24320/54000]\n",
            "Batch Loss: 2.301439,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.296884,  Batch Accuracy: 16.41   [26880/54000]\n",
            "Batch Loss: 2.303730,  Batch Accuracy: 11.72   [28160/54000]\n",
            "Batch Loss: 2.302050,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.306982,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.300927,  Batch Accuracy: 11.72   [32000/54000]\n",
            "Batch Loss: 2.300068,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.294995,  Batch Accuracy: 15.62   [34560/54000]\n",
            "Batch Loss: 2.300237,  Batch Accuracy: 14.06   [35840/54000]\n",
            "Batch Loss: 2.300664,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.300407,  Batch Accuracy: 11.72   [38400/54000]\n",
            "Batch Loss: 2.303092,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.297816,  Batch Accuracy: 14.06   [40960/54000]\n",
            "Batch Loss: 2.294414,  Batch Accuracy: 14.84   [42240/54000]\n",
            "Batch Loss: 2.305220,  Batch Accuracy: 6.25   [43520/54000]\n",
            "Batch Loss: 2.304418,  Batch Accuracy: 8.59   [44800/54000]\n",
            "Batch Loss: 2.290183,  Batch Accuracy: 15.62   [46080/54000]\n",
            "Batch Loss: 2.308689,  Batch Accuracy: 7.81   [47360/54000]\n",
            "Batch Loss: 2.295218,  Batch Accuracy: 16.41   [48640/54000]\n",
            "Batch Loss: 2.304473,  Batch Accuracy: 7.03   [49920/54000]\n",
            "Batch Loss: 2.300108,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.302696,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.310846,  Batch Accuracy: 7.03   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300889\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300087\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300682 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Batch Loss: 2.295418,  Batch Accuracy: 12.50   [ 1280/54000]\n",
            "Batch Loss: 2.301280,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.303395,  Batch Accuracy: 8.59   [ 3840/54000]\n",
            "Batch Loss: 2.298220,  Batch Accuracy: 14.06   [ 5120/54000]\n",
            "Batch Loss: 2.295830,  Batch Accuracy: 14.84   [ 6400/54000]\n",
            "Batch Loss: 2.303870,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.300748,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.297934,  Batch Accuracy: 10.94   [10240/54000]\n",
            "Batch Loss: 2.301126,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.301009,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.295110,  Batch Accuracy: 14.84   [14080/54000]\n",
            "Batch Loss: 2.306653,  Batch Accuracy: 7.03   [15360/54000]\n",
            "Batch Loss: 2.300375,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.296912,  Batch Accuracy: 12.50   [17920/54000]\n",
            "Batch Loss: 2.298815,  Batch Accuracy: 13.28   [19200/54000]\n",
            "Batch Loss: 2.299477,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.293928,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.303238,  Batch Accuracy: 15.62   [23040/54000]\n",
            "Batch Loss: 2.287321,  Batch Accuracy: 16.41   [24320/54000]\n",
            "Batch Loss: 2.292631,  Batch Accuracy: 17.19   [25600/54000]\n",
            "Batch Loss: 2.298508,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.303083,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.292405,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.305425,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.302845,  Batch Accuracy: 7.03   [32000/54000]\n",
            "Batch Loss: 2.297356,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.305643,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.306404,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.300335,  Batch Accuracy: 9.38   [37120/54000]\n",
            "Batch Loss: 2.298798,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.305949,  Batch Accuracy: 7.81   [39680/54000]\n",
            "Batch Loss: 2.296584,  Batch Accuracy: 14.84   [40960/54000]\n",
            "Batch Loss: 2.300035,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.302512,  Batch Accuracy: 9.38   [43520/54000]\n",
            "Batch Loss: 2.300644,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.296968,  Batch Accuracy: 9.38   [46080/54000]\n",
            "Batch Loss: 2.297455,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.300484,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.307038,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.298104,  Batch Accuracy: 14.06   [51200/54000]\n",
            "Batch Loss: 2.298849,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.300154,  Batch Accuracy: 8.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300883\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300071\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300672 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Batch Loss: 2.299998,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.297751,  Batch Accuracy: 13.28   [ 2560/54000]\n",
            "Batch Loss: 2.317558,  Batch Accuracy: 5.47   [ 3840/54000]\n",
            "Batch Loss: 2.311798,  Batch Accuracy: 6.25   [ 5120/54000]\n",
            "Batch Loss: 2.303345,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.295605,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.296136,  Batch Accuracy: 10.94   [ 8960/54000]\n",
            "Batch Loss: 2.297215,  Batch Accuracy: 17.19   [10240/54000]\n",
            "Batch Loss: 2.304254,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.296065,  Batch Accuracy: 14.06   [12800/54000]\n",
            "Batch Loss: 2.296912,  Batch Accuracy: 14.84   [14080/54000]\n",
            "Batch Loss: 2.301749,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.295204,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.300340,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.298459,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.306391,  Batch Accuracy: 7.03   [20480/54000]\n",
            "Batch Loss: 2.298552,  Batch Accuracy: 11.72   [21760/54000]\n",
            "Batch Loss: 2.304232,  Batch Accuracy: 8.59   [23040/54000]\n",
            "Batch Loss: 2.306899,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.309319,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.301794,  Batch Accuracy: 8.59   [26880/54000]\n",
            "Batch Loss: 2.302819,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.299537,  Batch Accuracy: 9.38   [29440/54000]\n",
            "Batch Loss: 2.302445,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.305607,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.304847,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.306077,  Batch Accuracy: 7.03   [34560/54000]\n",
            "Batch Loss: 2.311425,  Batch Accuracy: 6.25   [35840/54000]\n",
            "Batch Loss: 2.299363,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.302719,  Batch Accuracy: 10.94   [38400/54000]\n",
            "Batch Loss: 2.299893,  Batch Accuracy: 12.50   [39680/54000]\n",
            "Batch Loss: 2.305392,  Batch Accuracy: 7.03   [40960/54000]\n",
            "Batch Loss: 2.296834,  Batch Accuracy: 16.41   [42240/54000]\n",
            "Batch Loss: 2.308546,  Batch Accuracy: 7.81   [43520/54000]\n",
            "Batch Loss: 2.302448,  Batch Accuracy: 12.50   [44800/54000]\n",
            "Batch Loss: 2.292976,  Batch Accuracy: 15.62   [46080/54000]\n",
            "Batch Loss: 2.297629,  Batch Accuracy: 11.72   [47360/54000]\n",
            "Batch Loss: 2.304478,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.297209,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.300678,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.304101,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.290906,  Batch Accuracy: 16.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300874\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300060\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300661 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Batch Loss: 2.301391,  Batch Accuracy: 7.81   [ 1280/54000]\n",
            "Batch Loss: 2.292274,  Batch Accuracy: 18.75   [ 2560/54000]\n",
            "Batch Loss: 2.302656,  Batch Accuracy: 10.94   [ 3840/54000]\n",
            "Batch Loss: 2.301644,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.297758,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.296677,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.301075,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.294746,  Batch Accuracy: 15.62   [10240/54000]\n",
            "Batch Loss: 2.298201,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.296665,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.305696,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.301698,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.300796,  Batch Accuracy: 9.38   [16640/54000]\n",
            "Batch Loss: 2.308548,  Batch Accuracy: 4.69   [17920/54000]\n",
            "Batch Loss: 2.301983,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.301605,  Batch Accuracy: 12.50   [20480/54000]\n",
            "Batch Loss: 2.305059,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.306083,  Batch Accuracy: 8.59   [23040/54000]\n",
            "Batch Loss: 2.302027,  Batch Accuracy: 10.16   [24320/54000]\n",
            "Batch Loss: 2.293600,  Batch Accuracy: 17.97   [25600/54000]\n",
            "Batch Loss: 2.303875,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.303135,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.298028,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.303612,  Batch Accuracy: 10.16   [30720/54000]\n",
            "Batch Loss: 2.303142,  Batch Accuracy: 8.59   [32000/54000]\n",
            "Batch Loss: 2.301579,  Batch Accuracy: 13.28   [33280/54000]\n",
            "Batch Loss: 2.304806,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.300951,  Batch Accuracy: 11.72   [35840/54000]\n",
            "Batch Loss: 2.302231,  Batch Accuracy: 8.59   [37120/54000]\n",
            "Batch Loss: 2.298323,  Batch Accuracy: 14.84   [38400/54000]\n",
            "Batch Loss: 2.303446,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.298569,  Batch Accuracy: 14.84   [40960/54000]\n",
            "Batch Loss: 2.305275,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.296716,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.299718,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.304342,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.295701,  Batch Accuracy: 14.06   [47360/54000]\n",
            "Batch Loss: 2.304065,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.297562,  Batch Accuracy: 15.62   [49920/54000]\n",
            "Batch Loss: 2.298315,  Batch Accuracy: 12.50   [51200/54000]\n",
            "Batch Loss: 2.298645,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.299057,  Batch Accuracy: 14.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300872\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300064\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300659 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Batch Loss: 2.302396,  Batch Accuracy: 7.81   [ 1280/54000]\n",
            "Batch Loss: 2.303976,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.301033,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.298316,  Batch Accuracy: 12.50   [ 5120/54000]\n",
            "Batch Loss: 2.301297,  Batch Accuracy: 8.59   [ 6400/54000]\n",
            "Batch Loss: 2.302175,  Batch Accuracy: 10.94   [ 7680/54000]\n",
            "Batch Loss: 2.305351,  Batch Accuracy: 10.16   [ 8960/54000]\n",
            "Batch Loss: 2.303336,  Batch Accuracy: 6.25   [10240/54000]\n",
            "Batch Loss: 2.302055,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.299295,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.299457,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.305613,  Batch Accuracy: 8.59   [15360/54000]\n",
            "Batch Loss: 2.302710,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.298758,  Batch Accuracy: 11.72   [17920/54000]\n",
            "Batch Loss: 2.304329,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.295641,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.304996,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.298013,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.302745,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.297207,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.302879,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.297975,  Batch Accuracy: 17.19   [28160/54000]\n",
            "Batch Loss: 2.294898,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.296450,  Batch Accuracy: 13.28   [30720/54000]\n",
            "Batch Loss: 2.293433,  Batch Accuracy: 15.62   [32000/54000]\n",
            "Batch Loss: 2.298248,  Batch Accuracy: 12.50   [33280/54000]\n",
            "Batch Loss: 2.308263,  Batch Accuracy: 4.69   [34560/54000]\n",
            "Batch Loss: 2.294176,  Batch Accuracy: 15.62   [35840/54000]\n",
            "Batch Loss: 2.305557,  Batch Accuracy: 8.59   [37120/54000]\n",
            "Batch Loss: 2.296333,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.301218,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.301063,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.302396,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.305115,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.304409,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.300035,  Batch Accuracy: 10.94   [46080/54000]\n",
            "Batch Loss: 2.300720,  Batch Accuracy: 7.81   [47360/54000]\n",
            "Batch Loss: 2.295287,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.300983,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.296916,  Batch Accuracy: 14.06   [51200/54000]\n",
            "Batch Loss: 2.304362,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.304211,  Batch Accuracy: 14.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300862\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300008\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300649 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Batch Loss: 2.313853,  Batch Accuracy: 7.03   [ 1280/54000]\n",
            "Batch Loss: 2.301837,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.308336,  Batch Accuracy: 7.03   [ 3840/54000]\n",
            "Batch Loss: 2.298465,  Batch Accuracy: 15.62   [ 5120/54000]\n",
            "Batch Loss: 2.300340,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.293683,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.300260,  Batch Accuracy: 12.50   [ 8960/54000]\n",
            "Batch Loss: 2.304733,  Batch Accuracy: 7.81   [10240/54000]\n",
            "Batch Loss: 2.296137,  Batch Accuracy: 13.28   [11520/54000]\n",
            "Batch Loss: 2.304501,  Batch Accuracy: 10.16   [12800/54000]\n",
            "Batch Loss: 2.298485,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.303463,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.309876,  Batch Accuracy: 5.47   [16640/54000]\n",
            "Batch Loss: 2.303602,  Batch Accuracy: 10.16   [17920/54000]\n",
            "Batch Loss: 2.301193,  Batch Accuracy: 9.38   [19200/54000]\n",
            "Batch Loss: 2.296361,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.304564,  Batch Accuracy: 11.72   [21760/54000]\n",
            "Batch Loss: 2.301726,  Batch Accuracy: 10.16   [23040/54000]\n",
            "Batch Loss: 2.298960,  Batch Accuracy: 12.50   [24320/54000]\n",
            "Batch Loss: 2.295187,  Batch Accuracy: 12.50   [25600/54000]\n",
            "Batch Loss: 2.303778,  Batch Accuracy: 9.38   [26880/54000]\n",
            "Batch Loss: 2.297801,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.300635,  Batch Accuracy: 8.59   [29440/54000]\n",
            "Batch Loss: 2.303777,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.296718,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.303767,  Batch Accuracy: 13.28   [33280/54000]\n",
            "Batch Loss: 2.292169,  Batch Accuracy: 14.84   [34560/54000]\n",
            "Batch Loss: 2.304954,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.298762,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.298239,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.303048,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.303495,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.300166,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.295562,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.290461,  Batch Accuracy: 17.97   [44800/54000]\n",
            "Batch Loss: 2.300763,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.300020,  Batch Accuracy: 6.25   [47360/54000]\n",
            "Batch Loss: 2.304120,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.303907,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.296389,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.292841,  Batch Accuracy: 17.19   [52480/54000]\n",
            "Batch Loss: 2.305123,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300854\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300038\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300642 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Batch Loss: 2.305923,  Batch Accuracy: 7.03   [ 1280/54000]\n",
            "Batch Loss: 2.305073,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.297836,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.308715,  Batch Accuracy: 7.03   [ 5120/54000]\n",
            "Batch Loss: 2.303526,  Batch Accuracy: 13.28   [ 6400/54000]\n",
            "Batch Loss: 2.296813,  Batch Accuracy: 13.28   [ 7680/54000]\n",
            "Batch Loss: 2.291045,  Batch Accuracy: 17.97   [ 8960/54000]\n",
            "Batch Loss: 2.300609,  Batch Accuracy: 11.72   [10240/54000]\n",
            "Batch Loss: 2.310666,  Batch Accuracy: 6.25   [11520/54000]\n",
            "Batch Loss: 2.303393,  Batch Accuracy: 7.81   [12800/54000]\n",
            "Batch Loss: 2.296659,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.300729,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.304816,  Batch Accuracy: 7.81   [16640/54000]\n",
            "Batch Loss: 2.299906,  Batch Accuracy: 8.59   [17920/54000]\n",
            "Batch Loss: 2.307350,  Batch Accuracy: 6.25   [19200/54000]\n",
            "Batch Loss: 2.301895,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.306068,  Batch Accuracy: 8.59   [21760/54000]\n",
            "Batch Loss: 2.297442,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.307009,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.296624,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.300097,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.292200,  Batch Accuracy: 16.41   [28160/54000]\n",
            "Batch Loss: 2.302271,  Batch Accuracy: 6.25   [29440/54000]\n",
            "Batch Loss: 2.300758,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.298719,  Batch Accuracy: 14.06   [32000/54000]\n",
            "Batch Loss: 2.300317,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.307248,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.290247,  Batch Accuracy: 20.31   [35840/54000]\n",
            "Batch Loss: 2.291536,  Batch Accuracy: 18.75   [37120/54000]\n",
            "Batch Loss: 2.288923,  Batch Accuracy: 16.41   [38400/54000]\n",
            "Batch Loss: 2.296709,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.299119,  Batch Accuracy: 15.62   [40960/54000]\n",
            "Batch Loss: 2.298265,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.295851,  Batch Accuracy: 14.84   [43520/54000]\n",
            "Batch Loss: 2.294932,  Batch Accuracy: 17.19   [44800/54000]\n",
            "Batch Loss: 2.303180,  Batch Accuracy: 7.03   [46080/54000]\n",
            "Batch Loss: 2.301346,  Batch Accuracy: 7.03   [47360/54000]\n",
            "Batch Loss: 2.298222,  Batch Accuracy: 14.06   [48640/54000]\n",
            "Batch Loss: 2.290163,  Batch Accuracy: 17.19   [49920/54000]\n",
            "Batch Loss: 2.308808,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.295164,  Batch Accuracy: 18.75   [52480/54000]\n",
            "Batch Loss: 2.298742,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300850\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300028\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300638 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Batch Loss: 2.300185,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.302950,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.301288,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.300766,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.299420,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.299548,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.294775,  Batch Accuracy: 15.62   [ 8960/54000]\n",
            "Batch Loss: 2.303852,  Batch Accuracy: 10.16   [10240/54000]\n",
            "Batch Loss: 2.294551,  Batch Accuracy: 15.62   [11520/54000]\n",
            "Batch Loss: 2.299705,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.301096,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.300729,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.296492,  Batch Accuracy: 10.94   [16640/54000]\n",
            "Batch Loss: 2.299510,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.300537,  Batch Accuracy: 14.06   [19200/54000]\n",
            "Batch Loss: 2.303451,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.307593,  Batch Accuracy: 7.03   [21760/54000]\n",
            "Batch Loss: 2.293643,  Batch Accuracy: 17.19   [23040/54000]\n",
            "Batch Loss: 2.301505,  Batch Accuracy: 11.72   [24320/54000]\n",
            "Batch Loss: 2.300339,  Batch Accuracy: 10.16   [25600/54000]\n",
            "Batch Loss: 2.307510,  Batch Accuracy: 7.81   [26880/54000]\n",
            "Batch Loss: 2.297891,  Batch Accuracy: 11.72   [28160/54000]\n",
            "Batch Loss: 2.306889,  Batch Accuracy: 8.59   [29440/54000]\n",
            "Batch Loss: 2.297385,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.298877,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.300659,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.293175,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.309856,  Batch Accuracy: 7.03   [35840/54000]\n",
            "Batch Loss: 2.301793,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.296675,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.299182,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.306626,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.300776,  Batch Accuracy: 9.38   [42240/54000]\n",
            "Batch Loss: 2.298681,  Batch Accuracy: 14.06   [43520/54000]\n",
            "Batch Loss: 2.304721,  Batch Accuracy: 8.59   [44800/54000]\n",
            "Batch Loss: 2.305319,  Batch Accuracy: 6.25   [46080/54000]\n",
            "Batch Loss: 2.307216,  Batch Accuracy: 10.16   [47360/54000]\n",
            "Batch Loss: 2.300626,  Batch Accuracy: 10.94   [48640/54000]\n",
            "Batch Loss: 2.303343,  Batch Accuracy: 10.16   [49920/54000]\n",
            "Batch Loss: 2.306889,  Batch Accuracy: 7.81   [51200/54000]\n",
            "Batch Loss: 2.300968,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.296918,  Batch Accuracy: 14.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300843\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.300007\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300629 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Batch Loss: 2.295745,  Batch Accuracy: 14.06   [ 1280/54000]\n",
            "Batch Loss: 2.294451,  Batch Accuracy: 14.06   [ 2560/54000]\n",
            "Batch Loss: 2.304906,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.304320,  Batch Accuracy: 10.16   [ 5120/54000]\n",
            "Batch Loss: 2.303849,  Batch Accuracy: 8.59   [ 6400/54000]\n",
            "Batch Loss: 2.308354,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.301110,  Batch Accuracy: 10.16   [ 8960/54000]\n",
            "Batch Loss: 2.305637,  Batch Accuracy: 8.59   [10240/54000]\n",
            "Batch Loss: 2.308320,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.297634,  Batch Accuracy: 12.50   [12800/54000]\n",
            "Batch Loss: 2.306295,  Batch Accuracy: 4.69   [14080/54000]\n",
            "Batch Loss: 2.296784,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.297351,  Batch Accuracy: 12.50   [16640/54000]\n",
            "Batch Loss: 2.308123,  Batch Accuracy: 4.69   [17920/54000]\n",
            "Batch Loss: 2.293521,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.298276,  Batch Accuracy: 14.06   [20480/54000]\n",
            "Batch Loss: 2.306914,  Batch Accuracy: 7.81   [21760/54000]\n",
            "Batch Loss: 2.304203,  Batch Accuracy: 11.72   [23040/54000]\n",
            "Batch Loss: 2.291984,  Batch Accuracy: 15.62   [24320/54000]\n",
            "Batch Loss: 2.305333,  Batch Accuracy: 9.38   [25600/54000]\n",
            "Batch Loss: 2.303114,  Batch Accuracy: 7.03   [26880/54000]\n",
            "Batch Loss: 2.303031,  Batch Accuracy: 7.81   [28160/54000]\n",
            "Batch Loss: 2.302706,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.297493,  Batch Accuracy: 14.06   [30720/54000]\n",
            "Batch Loss: 2.296432,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.302150,  Batch Accuracy: 7.03   [33280/54000]\n",
            "Batch Loss: 2.304749,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.294877,  Batch Accuracy: 15.62   [35840/54000]\n",
            "Batch Loss: 2.297674,  Batch Accuracy: 12.50   [37120/54000]\n",
            "Batch Loss: 2.311106,  Batch Accuracy: 7.81   [38400/54000]\n",
            "Batch Loss: 2.306256,  Batch Accuracy: 7.03   [39680/54000]\n",
            "Batch Loss: 2.305101,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.307282,  Batch Accuracy: 7.03   [42240/54000]\n",
            "Batch Loss: 2.308125,  Batch Accuracy: 6.25   [43520/54000]\n",
            "Batch Loss: 2.291501,  Batch Accuracy: 17.19   [44800/54000]\n",
            "Batch Loss: 2.304186,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.301469,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.303153,  Batch Accuracy: 8.59   [48640/54000]\n",
            "Batch Loss: 2.303364,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.308023,  Batch Accuracy: 7.81   [51200/54000]\n",
            "Batch Loss: 2.308979,  Batch Accuracy: 7.03   [52480/54000]\n",
            "Batch Loss: 2.295459,  Batch Accuracy: 14.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300835\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299999\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300618 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Batch Loss: 2.297969,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.308801,  Batch Accuracy: 7.03   [ 2560/54000]\n",
            "Batch Loss: 2.303655,  Batch Accuracy: 7.81   [ 3840/54000]\n",
            "Batch Loss: 2.292733,  Batch Accuracy: 14.06   [ 5120/54000]\n",
            "Batch Loss: 2.293239,  Batch Accuracy: 15.62   [ 6400/54000]\n",
            "Batch Loss: 2.301553,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.304286,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.300328,  Batch Accuracy: 8.59   [10240/54000]\n",
            "Batch Loss: 2.302866,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.300618,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.306273,  Batch Accuracy: 10.16   [14080/54000]\n",
            "Batch Loss: 2.305079,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.303013,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.301887,  Batch Accuracy: 9.38   [17920/54000]\n",
            "Batch Loss: 2.299804,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.303056,  Batch Accuracy: 9.38   [20480/54000]\n",
            "Batch Loss: 2.297019,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.289101,  Batch Accuracy: 18.75   [23040/54000]\n",
            "Batch Loss: 2.297290,  Batch Accuracy: 15.62   [24320/54000]\n",
            "Batch Loss: 2.308501,  Batch Accuracy: 7.03   [25600/54000]\n",
            "Batch Loss: 2.304476,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.309748,  Batch Accuracy: 5.47   [28160/54000]\n",
            "Batch Loss: 2.294865,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.302823,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.300266,  Batch Accuracy: 9.38   [32000/54000]\n",
            "Batch Loss: 2.293512,  Batch Accuracy: 14.06   [33280/54000]\n",
            "Batch Loss: 2.301671,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.313246,  Batch Accuracy: 7.81   [35840/54000]\n",
            "Batch Loss: 2.308908,  Batch Accuracy: 7.03   [37120/54000]\n",
            "Batch Loss: 2.299037,  Batch Accuracy: 10.94   [38400/54000]\n",
            "Batch Loss: 2.292096,  Batch Accuracy: 19.53   [39680/54000]\n",
            "Batch Loss: 2.303197,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.298397,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.300543,  Batch Accuracy: 9.38   [43520/54000]\n",
            "Batch Loss: 2.300807,  Batch Accuracy: 9.38   [44800/54000]\n",
            "Batch Loss: 2.297442,  Batch Accuracy: 11.72   [46080/54000]\n",
            "Batch Loss: 2.302659,  Batch Accuracy: 8.59   [47360/54000]\n",
            "Batch Loss: 2.304465,  Batch Accuracy: 9.38   [48640/54000]\n",
            "Batch Loss: 2.302761,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.300468,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.301162,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.302335,  Batch Accuracy: 10.94   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300828\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299989\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300614 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Batch Loss: 2.301491,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.301992,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.302491,  Batch Accuracy: 11.72   [ 3840/54000]\n",
            "Batch Loss: 2.288480,  Batch Accuracy: 17.97   [ 5120/54000]\n",
            "Batch Loss: 2.304109,  Batch Accuracy: 5.47   [ 6400/54000]\n",
            "Batch Loss: 2.302170,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.305440,  Batch Accuracy: 9.38   [ 8960/54000]\n",
            "Batch Loss: 2.298205,  Batch Accuracy: 11.72   [10240/54000]\n",
            "Batch Loss: 2.297428,  Batch Accuracy: 14.06   [11520/54000]\n",
            "Batch Loss: 2.302395,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.306108,  Batch Accuracy: 6.25   [14080/54000]\n",
            "Batch Loss: 2.296612,  Batch Accuracy: 11.72   [15360/54000]\n",
            "Batch Loss: 2.302933,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.294529,  Batch Accuracy: 14.06   [17920/54000]\n",
            "Batch Loss: 2.302619,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.300288,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.299263,  Batch Accuracy: 10.94   [21760/54000]\n",
            "Batch Loss: 2.301186,  Batch Accuracy: 9.38   [23040/54000]\n",
            "Batch Loss: 2.304054,  Batch Accuracy: 11.72   [24320/54000]\n",
            "Batch Loss: 2.294306,  Batch Accuracy: 13.28   [25600/54000]\n",
            "Batch Loss: 2.301590,  Batch Accuracy: 10.16   [26880/54000]\n",
            "Batch Loss: 2.296274,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.297756,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.296239,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.291331,  Batch Accuracy: 14.84   [32000/54000]\n",
            "Batch Loss: 2.302170,  Batch Accuracy: 7.81   [33280/54000]\n",
            "Batch Loss: 2.305016,  Batch Accuracy: 10.94   [34560/54000]\n",
            "Batch Loss: 2.305980,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.307348,  Batch Accuracy: 3.91   [37120/54000]\n",
            "Batch Loss: 2.297141,  Batch Accuracy: 15.62   [38400/54000]\n",
            "Batch Loss: 2.299129,  Batch Accuracy: 13.28   [39680/54000]\n",
            "Batch Loss: 2.301224,  Batch Accuracy: 13.28   [40960/54000]\n",
            "Batch Loss: 2.293488,  Batch Accuracy: 14.06   [42240/54000]\n",
            "Batch Loss: 2.301687,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.303402,  Batch Accuracy: 10.16   [44800/54000]\n",
            "Batch Loss: 2.304296,  Batch Accuracy: 12.50   [46080/54000]\n",
            "Batch Loss: 2.293727,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.299348,  Batch Accuracy: 14.06   [48640/54000]\n",
            "Batch Loss: 2.295394,  Batch Accuracy: 11.72   [49920/54000]\n",
            "Batch Loss: 2.294581,  Batch Accuracy: 13.28   [51200/54000]\n",
            "Batch Loss: 2.304265,  Batch Accuracy: 10.16   [52480/54000]\n",
            "Batch Loss: 2.290205,  Batch Accuracy: 14.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300820\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299988\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300610 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Batch Loss: 2.300908,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.302640,  Batch Accuracy: 10.16   [ 2560/54000]\n",
            "Batch Loss: 2.306398,  Batch Accuracy: 9.38   [ 3840/54000]\n",
            "Batch Loss: 2.302351,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.293864,  Batch Accuracy: 12.50   [ 6400/54000]\n",
            "Batch Loss: 2.304619,  Batch Accuracy: 7.81   [ 7680/54000]\n",
            "Batch Loss: 2.295325,  Batch Accuracy: 11.72   [ 8960/54000]\n",
            "Batch Loss: 2.314042,  Batch Accuracy: 9.38   [10240/54000]\n",
            "Batch Loss: 2.307372,  Batch Accuracy: 11.72   [11520/54000]\n",
            "Batch Loss: 2.296812,  Batch Accuracy: 16.41   [12800/54000]\n",
            "Batch Loss: 2.305382,  Batch Accuracy: 10.94   [14080/54000]\n",
            "Batch Loss: 2.305355,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.306064,  Batch Accuracy: 8.59   [16640/54000]\n",
            "Batch Loss: 2.294793,  Batch Accuracy: 17.97   [17920/54000]\n",
            "Batch Loss: 2.301709,  Batch Accuracy: 7.81   [19200/54000]\n",
            "Batch Loss: 2.306185,  Batch Accuracy: 8.59   [20480/54000]\n",
            "Batch Loss: 2.295468,  Batch Accuracy: 16.41   [21760/54000]\n",
            "Batch Loss: 2.299206,  Batch Accuracy: 14.06   [23040/54000]\n",
            "Batch Loss: 2.306168,  Batch Accuracy: 8.59   [24320/54000]\n",
            "Batch Loss: 2.302169,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.296633,  Batch Accuracy: 13.28   [26880/54000]\n",
            "Batch Loss: 2.297471,  Batch Accuracy: 14.84   [28160/54000]\n",
            "Batch Loss: 2.304276,  Batch Accuracy: 10.94   [29440/54000]\n",
            "Batch Loss: 2.300776,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.298952,  Batch Accuracy: 10.94   [32000/54000]\n",
            "Batch Loss: 2.294014,  Batch Accuracy: 15.62   [33280/54000]\n",
            "Batch Loss: 2.287562,  Batch Accuracy: 15.62   [34560/54000]\n",
            "Batch Loss: 2.297887,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.307567,  Batch Accuracy: 10.16   [37120/54000]\n",
            "Batch Loss: 2.305907,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.306540,  Batch Accuracy: 7.81   [39680/54000]\n",
            "Batch Loss: 2.306942,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.300880,  Batch Accuracy: 10.94   [42240/54000]\n",
            "Batch Loss: 2.306521,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.309223,  Batch Accuracy: 8.59   [44800/54000]\n",
            "Batch Loss: 2.305469,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.300279,  Batch Accuracy: 14.84   [47360/54000]\n",
            "Batch Loss: 2.304221,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.298337,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.300453,  Batch Accuracy: 15.62   [51200/54000]\n",
            "Batch Loss: 2.303130,  Batch Accuracy: 8.59   [52480/54000]\n",
            "Batch Loss: 2.288720,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300817\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299996\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300601 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Batch Loss: 2.305137,  Batch Accuracy: 7.81   [ 1280/54000]\n",
            "Batch Loss: 2.308845,  Batch Accuracy: 6.25   [ 2560/54000]\n",
            "Batch Loss: 2.299878,  Batch Accuracy: 14.84   [ 3840/54000]\n",
            "Batch Loss: 2.291905,  Batch Accuracy: 15.62   [ 5120/54000]\n",
            "Batch Loss: 2.300322,  Batch Accuracy: 10.16   [ 6400/54000]\n",
            "Batch Loss: 2.298939,  Batch Accuracy: 11.72   [ 7680/54000]\n",
            "Batch Loss: 2.298373,  Batch Accuracy: 13.28   [ 8960/54000]\n",
            "Batch Loss: 2.309370,  Batch Accuracy: 7.03   [10240/54000]\n",
            "Batch Loss: 2.300817,  Batch Accuracy: 8.59   [11520/54000]\n",
            "Batch Loss: 2.307401,  Batch Accuracy: 6.25   [12800/54000]\n",
            "Batch Loss: 2.294010,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.300547,  Batch Accuracy: 10.94   [15360/54000]\n",
            "Batch Loss: 2.299954,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.298545,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.299322,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.298806,  Batch Accuracy: 11.72   [20480/54000]\n",
            "Batch Loss: 2.299522,  Batch Accuracy: 10.94   [21760/54000]\n",
            "Batch Loss: 2.301341,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.299108,  Batch Accuracy: 14.84   [24320/54000]\n",
            "Batch Loss: 2.305715,  Batch Accuracy: 10.94   [25600/54000]\n",
            "Batch Loss: 2.304438,  Batch Accuracy: 11.72   [26880/54000]\n",
            "Batch Loss: 2.299381,  Batch Accuracy: 14.84   [28160/54000]\n",
            "Batch Loss: 2.300777,  Batch Accuracy: 10.16   [29440/54000]\n",
            "Batch Loss: 2.297426,  Batch Accuracy: 14.84   [30720/54000]\n",
            "Batch Loss: 2.309642,  Batch Accuracy: 6.25   [32000/54000]\n",
            "Batch Loss: 2.302088,  Batch Accuracy: 9.38   [33280/54000]\n",
            "Batch Loss: 2.304585,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.299079,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.296504,  Batch Accuracy: 13.28   [37120/54000]\n",
            "Batch Loss: 2.304152,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.303001,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.306597,  Batch Accuracy: 9.38   [40960/54000]\n",
            "Batch Loss: 2.300826,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.303540,  Batch Accuracy: 10.16   [43520/54000]\n",
            "Batch Loss: 2.301814,  Batch Accuracy: 12.50   [44800/54000]\n",
            "Batch Loss: 2.298480,  Batch Accuracy: 17.19   [46080/54000]\n",
            "Batch Loss: 2.297935,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.302417,  Batch Accuracy: 10.94   [48640/54000]\n",
            "Batch Loss: 2.304579,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.299887,  Batch Accuracy: 9.38   [51200/54000]\n",
            "Batch Loss: 2.291300,  Batch Accuracy: 13.28   [52480/54000]\n",
            "Batch Loss: 2.294330,  Batch Accuracy: 16.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300809\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299999\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300593 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Batch Loss: 2.308786,  Batch Accuracy: 6.25   [ 1280/54000]\n",
            "Batch Loss: 2.291349,  Batch Accuracy: 19.53   [ 2560/54000]\n",
            "Batch Loss: 2.299627,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.296383,  Batch Accuracy: 13.28   [ 5120/54000]\n",
            "Batch Loss: 2.304428,  Batch Accuracy: 11.72   [ 6400/54000]\n",
            "Batch Loss: 2.299733,  Batch Accuracy: 12.50   [ 7680/54000]\n",
            "Batch Loss: 2.299267,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.297480,  Batch Accuracy: 13.28   [10240/54000]\n",
            "Batch Loss: 2.294415,  Batch Accuracy: 17.19   [11520/54000]\n",
            "Batch Loss: 2.309872,  Batch Accuracy: 9.38   [12800/54000]\n",
            "Batch Loss: 2.296713,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.304605,  Batch Accuracy: 7.03   [15360/54000]\n",
            "Batch Loss: 2.294390,  Batch Accuracy: 13.28   [16640/54000]\n",
            "Batch Loss: 2.296167,  Batch Accuracy: 11.72   [17920/54000]\n",
            "Batch Loss: 2.312048,  Batch Accuracy: 5.47   [19200/54000]\n",
            "Batch Loss: 2.299777,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.304546,  Batch Accuracy: 7.81   [21760/54000]\n",
            "Batch Loss: 2.296852,  Batch Accuracy: 17.19   [23040/54000]\n",
            "Batch Loss: 2.304572,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.294544,  Batch Accuracy: 17.19   [25600/54000]\n",
            "Batch Loss: 2.297268,  Batch Accuracy: 16.41   [26880/54000]\n",
            "Batch Loss: 2.303428,  Batch Accuracy: 9.38   [28160/54000]\n",
            "Batch Loss: 2.307493,  Batch Accuracy: 7.81   [29440/54000]\n",
            "Batch Loss: 2.306780,  Batch Accuracy: 9.38   [30720/54000]\n",
            "Batch Loss: 2.305497,  Batch Accuracy: 7.03   [32000/54000]\n",
            "Batch Loss: 2.299576,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.306666,  Batch Accuracy: 7.81   [34560/54000]\n",
            "Batch Loss: 2.300774,  Batch Accuracy: 10.94   [35840/54000]\n",
            "Batch Loss: 2.295822,  Batch Accuracy: 10.94   [37120/54000]\n",
            "Batch Loss: 2.296108,  Batch Accuracy: 14.84   [38400/54000]\n",
            "Batch Loss: 2.302991,  Batch Accuracy: 11.72   [39680/54000]\n",
            "Batch Loss: 2.303291,  Batch Accuracy: 10.16   [40960/54000]\n",
            "Batch Loss: 2.302788,  Batch Accuracy: 10.16   [42240/54000]\n",
            "Batch Loss: 2.309682,  Batch Accuracy: 8.59   [43520/54000]\n",
            "Batch Loss: 2.296367,  Batch Accuracy: 13.28   [44800/54000]\n",
            "Batch Loss: 2.298666,  Batch Accuracy: 11.72   [46080/54000]\n",
            "Batch Loss: 2.298524,  Batch Accuracy: 10.94   [47360/54000]\n",
            "Batch Loss: 2.308630,  Batch Accuracy: 7.81   [48640/54000]\n",
            "Batch Loss: 2.304011,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.302491,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.297145,  Batch Accuracy: 15.62   [52480/54000]\n",
            "Batch Loss: 2.299655,  Batch Accuracy: 11.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300798\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299982\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300586 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Batch Loss: 2.301857,  Batch Accuracy: 8.59   [ 1280/54000]\n",
            "Batch Loss: 2.306539,  Batch Accuracy: 7.03   [ 2560/54000]\n",
            "Batch Loss: 2.297748,  Batch Accuracy: 13.28   [ 3840/54000]\n",
            "Batch Loss: 2.301229,  Batch Accuracy: 11.72   [ 5120/54000]\n",
            "Batch Loss: 2.296009,  Batch Accuracy: 9.38   [ 6400/54000]\n",
            "Batch Loss: 2.309770,  Batch Accuracy: 6.25   [ 7680/54000]\n",
            "Batch Loss: 2.291328,  Batch Accuracy: 17.97   [ 8960/54000]\n",
            "Batch Loss: 2.298394,  Batch Accuracy: 14.06   [10240/54000]\n",
            "Batch Loss: 2.303943,  Batch Accuracy: 9.38   [11520/54000]\n",
            "Batch Loss: 2.296511,  Batch Accuracy: 11.72   [12800/54000]\n",
            "Batch Loss: 2.294866,  Batch Accuracy: 13.28   [14080/54000]\n",
            "Batch Loss: 2.301197,  Batch Accuracy: 10.16   [15360/54000]\n",
            "Batch Loss: 2.309540,  Batch Accuracy: 7.03   [16640/54000]\n",
            "Batch Loss: 2.305605,  Batch Accuracy: 7.03   [17920/54000]\n",
            "Batch Loss: 2.298264,  Batch Accuracy: 12.50   [19200/54000]\n",
            "Batch Loss: 2.302771,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.298709,  Batch Accuracy: 10.94   [21760/54000]\n",
            "Batch Loss: 2.298904,  Batch Accuracy: 13.28   [23040/54000]\n",
            "Batch Loss: 2.298906,  Batch Accuracy: 12.50   [24320/54000]\n",
            "Batch Loss: 2.299772,  Batch Accuracy: 11.72   [25600/54000]\n",
            "Batch Loss: 2.295720,  Batch Accuracy: 12.50   [26880/54000]\n",
            "Batch Loss: 2.302805,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.295487,  Batch Accuracy: 15.62   [29440/54000]\n",
            "Batch Loss: 2.304220,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.298698,  Batch Accuracy: 13.28   [32000/54000]\n",
            "Batch Loss: 2.292749,  Batch Accuracy: 14.06   [33280/54000]\n",
            "Batch Loss: 2.302011,  Batch Accuracy: 7.81   [34560/54000]\n",
            "Batch Loss: 2.310405,  Batch Accuracy: 8.59   [35840/54000]\n",
            "Batch Loss: 2.295372,  Batch Accuracy: 15.62   [37120/54000]\n",
            "Batch Loss: 2.302083,  Batch Accuracy: 8.59   [38400/54000]\n",
            "Batch Loss: 2.300786,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.305890,  Batch Accuracy: 8.59   [40960/54000]\n",
            "Batch Loss: 2.299048,  Batch Accuracy: 13.28   [42240/54000]\n",
            "Batch Loss: 2.298354,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.293517,  Batch Accuracy: 17.97   [44800/54000]\n",
            "Batch Loss: 2.292348,  Batch Accuracy: 16.41   [46080/54000]\n",
            "Batch Loss: 2.302439,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.307692,  Batch Accuracy: 12.50   [48640/54000]\n",
            "Batch Loss: 2.304808,  Batch Accuracy: 8.59   [49920/54000]\n",
            "Batch Loss: 2.302244,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.295555,  Batch Accuracy: 11.72   [52480/54000]\n",
            "Batch Loss: 2.300734,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.2%, Loss: 2.300795\n",
            "Validation performance: \n",
            " Accuracy: 11.5%, Loss: 2.299965\n",
            "Test performance: \n",
            " Accuracy: 11.3%, Loss: 2.300571 \n",
            "\n",
            "Time taken to train the model: 1.8604769508043926 minutes\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train_q4a(model_q4a:nn.Module, train_loader:DataLoader, optimizer, criterion):\n",
        "    model_q4a.train()\n",
        "    model_q4a = model_q4a.to(device)\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_q4a(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        batch_correct = (predicted == labels).sum().item()\n",
        "        correct += batch_correct\n",
        "\n",
        "        if (batch + 1) % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(images)\n",
        "            print(f\"Batch Loss: {loss:>7f},  Batch Accuracy: {100*batch_correct/len(images):.2f}   [{current:>5d}/{len(train_sampler):>5d}]\")\n",
        "        batch += 1\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Training performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {train_loss:>8f}\")\n",
        "    return train_loss, accuracy\n",
        "\n",
        "\n",
        "# Validation loop\n",
        "def validate_q4a(model_q4a:nn.Module, valid_loader:DataLoader, loss_fn):\n",
        "    model_q4a.eval()\n",
        "    model_q4a = model_q4a.to(device)\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_q4a(images)\n",
        "            val_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(valid_loader)\n",
        "    print(f\"Validation performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {val_loss:>8f}\")\n",
        "    return val_loss, accuracy\n",
        "\n",
        "\n",
        "# Testing loop\n",
        "def test_q4a(model_q4a:nn.Module, test_loader:DataLoader, loss_fn):\n",
        "    model_q4a.eval()\n",
        "    model_q4a = model_q4a.to(device)\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_q4a(images)\n",
        "            test_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "# Training, Validation and Testing of the model\n",
        "num_epochs = 60\n",
        "train_losses_q4a, train_accuracies_q4a = [], []\n",
        "val_losses_q4a, val_accuracies_q4a = [], []\n",
        "test_losses_q4a, test_accuracies_q4a = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    train_loss, train_accuracy = train_q4a(model_q4a, train_loader, optimizer_q4a, criterion_q4a)\n",
        "    val_loss, val_accuracy = validate_q4a(model_q4a, valid_loader, criterion_q4a)\n",
        "    test_loss, test_accuracy = test_q4a(model_q4a, test_loader, criterion_q4a)\n",
        "\n",
        "    train_losses_q4a.append(train_loss)\n",
        "    train_accuracies_q4a.append(train_accuracy)\n",
        "    val_losses_q4a.append(val_loss)\n",
        "    val_accuracies_q4a.append(val_accuracy)\n",
        "    test_losses_q4a.append(test_loss)\n",
        "    test_accuracies_q4a.append(test_accuracy)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to train the model: {(end_time - start_time) / 60} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "V6GUOy-2YdYx",
        "outputId": "709c98ef-4eb1-45d0-fd12-67327d025baf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_losses_q4a, label='Train')\n",
        "plt.plot(range(num_epochs), val_losses_q4a, label='Validation')\n",
        "plt.plot(range(num_epochs), test_losses_q4a, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_accuracies_q4a, label='Train')\n",
        "plt.plot(range(num_epochs), val_accuracies_q4a, label='Validation')\n",
        "plt.plot(range(num_epochs), test_accuracies_q4a, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEqEH14u5p_H"
      },
      "source": [
        "## Scratch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muJ0s5sW5tJX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQrM9APF8IoZ"
      },
      "source": [
        "### Model architecture for scratch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ3xNKIF6xx9"
      },
      "outputs": [],
      "source": [
        "class MyNet:\n",
        "    def __init__(self, in_features=28*28, out_features=10, device:str='cpu'):\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.device = device\n",
        "        self.fc1 = Linear(in_features, 1024, device=device)\n",
        "        self.sigmoid1 = Sigmoid()\n",
        "        self.fc2 = Linear(1024, 512, device=device)\n",
        "        self.sigmoid2 = Sigmoid()\n",
        "        self.fc3 = Linear(512, 256, device=device)\n",
        "        self.sigmoid3 = Sigmoid()\n",
        "        self.fc4 = Linear(256, 128, device=device)\n",
        "        self.sigmoid4 = Sigmoid()\n",
        "        self.fc5 = Linear(128, out_features, device=device)\n",
        "        self.softmax = SoftMax()\n",
        "        self.parameters = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5]\n",
        "        self.input_features = None\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        self.input_features = x.clone()\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.sigmoid1.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        x = self.sigmoid2.forward(x)\n",
        "        x = self.fc3.forward(x)\n",
        "        x = self.sigmoid3.forward(x)\n",
        "        x = self.fc4.forward(x)\n",
        "        x = self.sigmoid4.forward(x)\n",
        "        x = self.fc5.forward(x)\n",
        "        x = self.softmax.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, true_labels:torch.tensor):\n",
        "        true_labels = torch.zeros((true_labels.size(0), 10), device=self.device).scatter_(1, true_labels.view(-1, 1), 1)\n",
        "        self.fc5.error_output = torch.matmul(self.softmax.backward(self.fc5.z), (true_labels - self.softmax.activation).unsqueeze(-1)).squeeze(-1)\n",
        "        self.fc5.backward(self.sigmoid4.activation)\n",
        "        self.fc4.error_output = self.sigmoid4.backward(self.fc4.z) * torch.matmul(self.fc5.error_output, self.fc5.weights)\n",
        "        self.fc4.backward(self.sigmoid3.activation)\n",
        "        self.fc3.error_output = self.sigmoid3.backward(self.fc3.z) * torch.matmul(self.fc4.error_output, self.fc4.weights)\n",
        "        self.fc3.backward(self.sigmoid2.activation)\n",
        "        self.fc2.error_output = self.sigmoid2.backward(self.fc2.z) * torch.matmul(self.fc3.error_output, self.fc3.weights)\n",
        "        self.fc2.backward(self.sigmoid1.activation)\n",
        "        self.fc1.error_output = self.sigmoid1.backward(self.fc1.z) * torch.matmul(self.fc2.error_output, self.fc2.weights)\n",
        "        self.fc1.backward(self.input_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSHQc5qp-eAL"
      },
      "source": [
        "### Initialize Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaikeGiQ8GQ0",
        "outputId": "a50fa124-b97a-48dc-d74f-92f429621719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 10000\n",
            "Dataset image shape: torch.Size([10000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([10000])\n",
            "\n",
            "Train Dataset Length: 54000\n",
            "Validation Dataset Length: 6000\n",
            "Test Dataset Length: 10000\n",
            "\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.float32 torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Creating training and test datasets\n",
        "root = './data/MNIST/raw/'\n",
        "train_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "test_dataset = MNISTCustomDataset(root=root, train=False, transform=None)\n",
        "\n",
        "# splitting of training and validation set\n",
        "batch_size = 128\n",
        "valid_size = 0.1\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Train Dataset Length: {}'.format(len(train_sampler)))\n",
        "print('Validation Dataset Length: {}'.format(len(valid_sampler)))\n",
        "print('Test Dataset Length: {}\\n'.format(len(test_dataset)))\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(type(images), type(labels))\n",
        "    print(images.dtype, labels.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fymcjcFs-qXj"
      },
      "source": [
        "### Intialize Custom Model, Loss and Optimizer  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJkp5axg-b_n",
        "outputId": "44b4b69d-d88e-4c1c-ee2f-07921ddf0795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_q4b = MyNet(in_features=28*28, out_features=10, device=device)\n",
        "sgd_optimizer_q4b = SGD(model_q4b.parameters, lr=0.0003)\n",
        "ce_loss_q4b = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhQOwvZn_CON"
      },
      "source": [
        "### Training of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CetC58kw_FH0",
        "outputId": "a9b65348-69c1-4163-edd2-f83c31b51af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Batch loss: 2.355545,  Batch Accuracy: 9.38  [ 1280/54000]\n",
            "Batch loss: 2.344710,  Batch Accuracy: 10.16  [ 2560/54000]\n",
            "Batch loss: 2.382210,  Batch Accuracy: 5.47  [ 3840/54000]\n",
            "Batch loss: 2.348142,  Batch Accuracy: 10.16  [ 5120/54000]\n",
            "Batch loss: 2.290088,  Batch Accuracy: 15.62  [ 6400/54000]\n",
            "Batch loss: 2.321336,  Batch Accuracy: 9.38  [ 7680/54000]\n",
            "Batch loss: 2.320848,  Batch Accuracy: 10.16  [ 8960/54000]\n",
            "Batch loss: 2.326009,  Batch Accuracy: 10.16  [10240/54000]\n",
            "Batch loss: 2.286733,  Batch Accuracy: 14.06  [11520/54000]\n",
            "Batch loss: 2.317568,  Batch Accuracy: 12.50  [12800/54000]\n",
            "Batch loss: 2.314056,  Batch Accuracy: 10.16  [14080/54000]\n",
            "Batch loss: 2.297371,  Batch Accuracy: 9.38  [15360/54000]\n",
            "Batch loss: 2.294428,  Batch Accuracy: 12.50  [16640/54000]\n",
            "Batch loss: 2.313814,  Batch Accuracy: 6.25  [17920/54000]\n",
            "Batch loss: 2.304512,  Batch Accuracy: 8.59  [19200/54000]\n",
            "Batch loss: 2.291830,  Batch Accuracy: 15.62  [20480/54000]\n",
            "Batch loss: 2.305219,  Batch Accuracy: 9.38  [21760/54000]\n",
            "Batch loss: 2.305759,  Batch Accuracy: 9.38  [23040/54000]\n",
            "Batch loss: 2.297436,  Batch Accuracy: 14.84  [24320/54000]\n",
            "Batch loss: 2.301224,  Batch Accuracy: 10.94  [25600/54000]\n",
            "Batch loss: 2.315886,  Batch Accuracy: 7.03  [26880/54000]\n",
            "Batch loss: 2.295605,  Batch Accuracy: 12.50  [28160/54000]\n",
            "Batch loss: 2.297390,  Batch Accuracy: 14.06  [29440/54000]\n",
            "Batch loss: 2.301181,  Batch Accuracy: 11.72  [30720/54000]\n",
            "Batch loss: 2.300989,  Batch Accuracy: 10.94  [32000/54000]\n",
            "Batch loss: 2.295955,  Batch Accuracy: 15.62  [33280/54000]\n",
            "Batch loss: 2.299324,  Batch Accuracy: 12.50  [34560/54000]\n",
            "Batch loss: 2.298732,  Batch Accuracy: 10.94  [35840/54000]\n",
            "Batch loss: 2.297783,  Batch Accuracy: 14.06  [37120/54000]\n",
            "Batch loss: 2.299444,  Batch Accuracy: 10.16  [38400/54000]\n",
            "Batch loss: 2.306682,  Batch Accuracy: 10.16  [39680/54000]\n",
            "Batch loss: 2.291982,  Batch Accuracy: 16.41  [40960/54000]\n",
            "Batch loss: 2.304426,  Batch Accuracy: 8.59  [42240/54000]\n",
            "Batch loss: 2.296806,  Batch Accuracy: 12.50  [43520/54000]\n",
            "Batch loss: 2.302109,  Batch Accuracy: 10.94  [44800/54000]\n",
            "Batch loss: 2.300913,  Batch Accuracy: 14.84  [46080/54000]\n",
            "Batch loss: 2.300337,  Batch Accuracy: 9.38  [47360/54000]\n",
            "Batch loss: 2.299580,  Batch Accuracy: 10.94  [48640/54000]\n",
            "Batch loss: 2.296383,  Batch Accuracy: 11.72  [49920/54000]\n",
            "Batch loss: 2.307978,  Batch Accuracy: 7.03  [51200/54000]\n",
            "Batch loss: 2.296392,  Batch Accuracy: 14.06  [52480/54000]\n",
            "Batch loss: 2.293394,  Batch Accuracy: 12.50  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.07%, Loss: 2.3102\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2996\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2999\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Batch loss: 2.299847,  Batch Accuracy: 11.72  [ 1280/54000]\n",
            "Batch loss: 2.297593,  Batch Accuracy: 13.28  [ 2560/54000]\n",
            "Batch loss: 2.309242,  Batch Accuracy: 9.38  [ 3840/54000]\n",
            "Batch loss: 2.310342,  Batch Accuracy: 10.16  [ 5120/54000]\n",
            "Batch loss: 2.299690,  Batch Accuracy: 13.28  [ 6400/54000]\n",
            "Batch loss: 2.300460,  Batch Accuracy: 11.72  [ 7680/54000]\n",
            "Batch loss: 2.304959,  Batch Accuracy: 7.81  [ 8960/54000]\n",
            "Batch loss: 2.290164,  Batch Accuracy: 11.72  [10240/54000]\n",
            "Batch loss: 2.287948,  Batch Accuracy: 14.06  [11520/54000]\n",
            "Batch loss: 2.296841,  Batch Accuracy: 10.16  [12800/54000]\n",
            "Batch loss: 2.304310,  Batch Accuracy: 7.81  [14080/54000]\n",
            "Batch loss: 2.293491,  Batch Accuracy: 15.62  [15360/54000]\n",
            "Batch loss: 2.302470,  Batch Accuracy: 9.38  [16640/54000]\n",
            "Batch loss: 2.295486,  Batch Accuracy: 11.72  [17920/54000]\n",
            "Batch loss: 2.300952,  Batch Accuracy: 10.94  [19200/54000]\n",
            "Batch loss: 2.301159,  Batch Accuracy: 10.94  [20480/54000]\n",
            "Batch loss: 2.303174,  Batch Accuracy: 9.38  [21760/54000]\n",
            "Batch loss: 2.302486,  Batch Accuracy: 12.50  [23040/54000]\n",
            "Batch loss: 2.297046,  Batch Accuracy: 7.03  [24320/54000]\n",
            "Batch loss: 2.293466,  Batch Accuracy: 11.72  [25600/54000]\n",
            "Batch loss: 2.300595,  Batch Accuracy: 11.72  [26880/54000]\n",
            "Batch loss: 2.305616,  Batch Accuracy: 10.16  [28160/54000]\n",
            "Batch loss: 2.298006,  Batch Accuracy: 13.28  [29440/54000]\n",
            "Batch loss: 2.295449,  Batch Accuracy: 20.31  [30720/54000]\n",
            "Batch loss: 2.307604,  Batch Accuracy: 10.94  [32000/54000]\n",
            "Batch loss: 2.304022,  Batch Accuracy: 10.94  [33280/54000]\n",
            "Batch loss: 2.291103,  Batch Accuracy: 13.28  [34560/54000]\n",
            "Batch loss: 2.299245,  Batch Accuracy: 9.38  [35840/54000]\n",
            "Batch loss: 2.290683,  Batch Accuracy: 18.75  [37120/54000]\n",
            "Batch loss: 2.301551,  Batch Accuracy: 13.28  [38400/54000]\n",
            "Batch loss: 2.301379,  Batch Accuracy: 10.16  [39680/54000]\n",
            "Batch loss: 2.299675,  Batch Accuracy: 10.94  [40960/54000]\n",
            "Batch loss: 2.297362,  Batch Accuracy: 10.94  [42240/54000]\n",
            "Batch loss: 2.298001,  Batch Accuracy: 7.81  [43520/54000]\n",
            "Batch loss: 2.303203,  Batch Accuracy: 7.81  [44800/54000]\n",
            "Batch loss: 2.303561,  Batch Accuracy: 12.50  [46080/54000]\n",
            "Batch loss: 2.295117,  Batch Accuracy: 11.72  [47360/54000]\n",
            "Batch loss: 2.304786,  Batch Accuracy: 3.91  [48640/54000]\n",
            "Batch loss: 2.305954,  Batch Accuracy: 9.38  [49920/54000]\n",
            "Batch loss: 2.305675,  Batch Accuracy: 7.81  [51200/54000]\n",
            "Batch loss: 2.299496,  Batch Accuracy: 12.50  [52480/54000]\n",
            "Batch loss: 2.304935,  Batch Accuracy: 9.38  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.22%, Loss: 2.2996\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2986\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2985\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Batch loss: 2.297919,  Batch Accuracy: 15.62  [ 1280/54000]\n",
            "Batch loss: 2.298072,  Batch Accuracy: 11.72  [ 2560/54000]\n",
            "Batch loss: 2.299483,  Batch Accuracy: 13.28  [ 3840/54000]\n",
            "Batch loss: 2.298220,  Batch Accuracy: 9.38  [ 5120/54000]\n",
            "Batch loss: 2.297397,  Batch Accuracy: 14.84  [ 6400/54000]\n",
            "Batch loss: 2.303754,  Batch Accuracy: 7.81  [ 7680/54000]\n",
            "Batch loss: 2.294868,  Batch Accuracy: 14.84  [ 8960/54000]\n",
            "Batch loss: 2.295388,  Batch Accuracy: 13.28  [10240/54000]\n",
            "Batch loss: 2.301887,  Batch Accuracy: 8.59  [11520/54000]\n",
            "Batch loss: 2.301691,  Batch Accuracy: 12.50  [12800/54000]\n",
            "Batch loss: 2.304541,  Batch Accuracy: 9.38  [14080/54000]\n",
            "Batch loss: 2.293081,  Batch Accuracy: 15.62  [15360/54000]\n",
            "Batch loss: 2.304335,  Batch Accuracy: 7.81  [16640/54000]\n",
            "Batch loss: 2.306221,  Batch Accuracy: 7.81  [17920/54000]\n",
            "Batch loss: 2.294492,  Batch Accuracy: 9.38  [19200/54000]\n",
            "Batch loss: 2.296316,  Batch Accuracy: 10.94  [20480/54000]\n",
            "Batch loss: 2.305856,  Batch Accuracy: 9.38  [21760/54000]\n",
            "Batch loss: 2.289277,  Batch Accuracy: 17.97  [23040/54000]\n",
            "Batch loss: 2.296668,  Batch Accuracy: 10.94  [24320/54000]\n",
            "Batch loss: 2.293509,  Batch Accuracy: 13.28  [25600/54000]\n",
            "Batch loss: 2.293931,  Batch Accuracy: 13.28  [26880/54000]\n",
            "Batch loss: 2.292594,  Batch Accuracy: 13.28  [28160/54000]\n",
            "Batch loss: 2.284349,  Batch Accuracy: 16.41  [29440/54000]\n",
            "Batch loss: 2.302775,  Batch Accuracy: 7.81  [30720/54000]\n",
            "Batch loss: 2.309889,  Batch Accuracy: 5.47  [32000/54000]\n",
            "Batch loss: 2.306810,  Batch Accuracy: 9.38  [33280/54000]\n",
            "Batch loss: 2.300573,  Batch Accuracy: 12.50  [34560/54000]\n",
            "Batch loss: 2.283181,  Batch Accuracy: 16.41  [35840/54000]\n",
            "Batch loss: 2.302843,  Batch Accuracy: 9.38  [37120/54000]\n",
            "Batch loss: 2.297074,  Batch Accuracy: 14.06  [38400/54000]\n",
            "Batch loss: 2.304426,  Batch Accuracy: 9.38  [39680/54000]\n",
            "Batch loss: 2.299907,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.296709,  Batch Accuracy: 10.94  [42240/54000]\n",
            "Batch loss: 2.298201,  Batch Accuracy: 10.16  [43520/54000]\n",
            "Batch loss: 2.292121,  Batch Accuracy: 15.62  [44800/54000]\n",
            "Batch loss: 2.302138,  Batch Accuracy: 7.03  [46080/54000]\n",
            "Batch loss: 2.288353,  Batch Accuracy: 12.50  [47360/54000]\n",
            "Batch loss: 2.296904,  Batch Accuracy: 14.06  [48640/54000]\n",
            "Batch loss: 2.296927,  Batch Accuracy: 12.50  [49920/54000]\n",
            "Batch loss: 2.295079,  Batch Accuracy: 16.41  [51200/54000]\n",
            "Batch loss: 2.299370,  Batch Accuracy: 11.72  [52480/54000]\n",
            "Batch loss: 2.293696,  Batch Accuracy: 12.50  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.19%, Loss: 2.2984\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2972\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2975\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Batch loss: 2.292538,  Batch Accuracy: 12.50  [ 1280/54000]\n",
            "Batch loss: 2.296261,  Batch Accuracy: 13.28  [ 2560/54000]\n",
            "Batch loss: 2.292295,  Batch Accuracy: 14.06  [ 3840/54000]\n",
            "Batch loss: 2.296681,  Batch Accuracy: 10.16  [ 5120/54000]\n",
            "Batch loss: 2.297544,  Batch Accuracy: 6.25  [ 6400/54000]\n",
            "Batch loss: 2.293452,  Batch Accuracy: 16.41  [ 7680/54000]\n",
            "Batch loss: 2.296832,  Batch Accuracy: 12.50  [ 8960/54000]\n",
            "Batch loss: 2.294406,  Batch Accuracy: 9.38  [10240/54000]\n",
            "Batch loss: 2.286549,  Batch Accuracy: 17.19  [11520/54000]\n",
            "Batch loss: 2.298785,  Batch Accuracy: 10.94  [12800/54000]\n",
            "Batch loss: 2.300333,  Batch Accuracy: 7.81  [14080/54000]\n",
            "Batch loss: 2.296321,  Batch Accuracy: 10.16  [15360/54000]\n",
            "Batch loss: 2.291866,  Batch Accuracy: 13.28  [16640/54000]\n",
            "Batch loss: 2.310421,  Batch Accuracy: 5.47  [17920/54000]\n",
            "Batch loss: 2.300402,  Batch Accuracy: 9.38  [19200/54000]\n",
            "Batch loss: 2.301209,  Batch Accuracy: 13.28  [20480/54000]\n",
            "Batch loss: 2.287267,  Batch Accuracy: 14.84  [21760/54000]\n",
            "Batch loss: 2.294346,  Batch Accuracy: 15.62  [23040/54000]\n",
            "Batch loss: 2.296926,  Batch Accuracy: 10.16  [24320/54000]\n",
            "Batch loss: 2.298787,  Batch Accuracy: 5.47  [25600/54000]\n",
            "Batch loss: 2.297420,  Batch Accuracy: 12.50  [26880/54000]\n",
            "Batch loss: 2.302902,  Batch Accuracy: 8.59  [28160/54000]\n",
            "Batch loss: 2.278408,  Batch Accuracy: 20.31  [29440/54000]\n",
            "Batch loss: 2.298763,  Batch Accuracy: 13.28  [30720/54000]\n",
            "Batch loss: 2.288528,  Batch Accuracy: 15.62  [32000/54000]\n",
            "Batch loss: 2.285835,  Batch Accuracy: 17.97  [33280/54000]\n",
            "Batch loss: 2.304777,  Batch Accuracy: 6.25  [34560/54000]\n",
            "Batch loss: 2.294009,  Batch Accuracy: 15.62  [35840/54000]\n",
            "Batch loss: 2.300921,  Batch Accuracy: 7.81  [37120/54000]\n",
            "Batch loss: 2.294049,  Batch Accuracy: 12.50  [38400/54000]\n",
            "Batch loss: 2.301628,  Batch Accuracy: 9.38  [39680/54000]\n",
            "Batch loss: 2.296148,  Batch Accuracy: 15.62  [40960/54000]\n",
            "Batch loss: 2.308546,  Batch Accuracy: 7.81  [42240/54000]\n",
            "Batch loss: 2.292575,  Batch Accuracy: 12.50  [43520/54000]\n",
            "Batch loss: 2.298330,  Batch Accuracy: 11.72  [44800/54000]\n",
            "Batch loss: 2.294205,  Batch Accuracy: 14.06  [46080/54000]\n",
            "Batch loss: 2.297443,  Batch Accuracy: 12.50  [47360/54000]\n",
            "Batch loss: 2.298168,  Batch Accuracy: 6.25  [48640/54000]\n",
            "Batch loss: 2.289776,  Batch Accuracy: 10.94  [49920/54000]\n",
            "Batch loss: 2.303626,  Batch Accuracy: 8.59  [51200/54000]\n",
            "Batch loss: 2.292930,  Batch Accuracy: 13.28  [52480/54000]\n",
            "Batch loss: 2.298814,  Batch Accuracy: 8.59  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.20%, Loss: 2.2973\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2962\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2961\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Batch loss: 2.295614,  Batch Accuracy: 12.50  [ 1280/54000]\n",
            "Batch loss: 2.298268,  Batch Accuracy: 9.38  [ 2560/54000]\n",
            "Batch loss: 2.298244,  Batch Accuracy: 7.03  [ 3840/54000]\n",
            "Batch loss: 2.290126,  Batch Accuracy: 14.84  [ 5120/54000]\n",
            "Batch loss: 2.298994,  Batch Accuracy: 9.38  [ 6400/54000]\n",
            "Batch loss: 2.308517,  Batch Accuracy: 10.16  [ 7680/54000]\n",
            "Batch loss: 2.292284,  Batch Accuracy: 16.41  [ 8960/54000]\n",
            "Batch loss: 2.294132,  Batch Accuracy: 10.16  [10240/54000]\n",
            "Batch loss: 2.296614,  Batch Accuracy: 8.59  [11520/54000]\n",
            "Batch loss: 2.287891,  Batch Accuracy: 14.84  [12800/54000]\n",
            "Batch loss: 2.300234,  Batch Accuracy: 10.16  [14080/54000]\n",
            "Batch loss: 2.302541,  Batch Accuracy: 8.59  [15360/54000]\n",
            "Batch loss: 2.300025,  Batch Accuracy: 7.81  [16640/54000]\n",
            "Batch loss: 2.301769,  Batch Accuracy: 8.59  [17920/54000]\n",
            "Batch loss: 2.283044,  Batch Accuracy: 16.41  [19200/54000]\n",
            "Batch loss: 2.298792,  Batch Accuracy: 10.94  [20480/54000]\n",
            "Batch loss: 2.284149,  Batch Accuracy: 14.06  [21760/54000]\n",
            "Batch loss: 2.295107,  Batch Accuracy: 14.06  [23040/54000]\n",
            "Batch loss: 2.295103,  Batch Accuracy: 10.94  [24320/54000]\n",
            "Batch loss: 2.302541,  Batch Accuracy: 10.16  [25600/54000]\n",
            "Batch loss: 2.286775,  Batch Accuracy: 14.84  [26880/54000]\n",
            "Batch loss: 2.295977,  Batch Accuracy: 13.28  [28160/54000]\n",
            "Batch loss: 2.297522,  Batch Accuracy: 11.72  [29440/54000]\n",
            "Batch loss: 2.298937,  Batch Accuracy: 9.38  [30720/54000]\n",
            "Batch loss: 2.300025,  Batch Accuracy: 10.16  [32000/54000]\n",
            "Batch loss: 2.301194,  Batch Accuracy: 10.16  [33280/54000]\n",
            "Batch loss: 2.293384,  Batch Accuracy: 11.72  [34560/54000]\n",
            "Batch loss: 2.288450,  Batch Accuracy: 13.28  [35840/54000]\n",
            "Batch loss: 2.305419,  Batch Accuracy: 7.03  [37120/54000]\n",
            "Batch loss: 2.305878,  Batch Accuracy: 10.16  [38400/54000]\n",
            "Batch loss: 2.298387,  Batch Accuracy: 12.50  [39680/54000]\n",
            "Batch loss: 2.295387,  Batch Accuracy: 14.84  [40960/54000]\n",
            "Batch loss: 2.297098,  Batch Accuracy: 12.50  [42240/54000]\n",
            "Batch loss: 2.290478,  Batch Accuracy: 13.28  [43520/54000]\n",
            "Batch loss: 2.294150,  Batch Accuracy: 7.81  [44800/54000]\n",
            "Batch loss: 2.293067,  Batch Accuracy: 10.16  [46080/54000]\n",
            "Batch loss: 2.284194,  Batch Accuracy: 18.75  [47360/54000]\n",
            "Batch loss: 2.303230,  Batch Accuracy: 7.81  [48640/54000]\n",
            "Batch loss: 2.297009,  Batch Accuracy: 10.94  [49920/54000]\n",
            "Batch loss: 2.297615,  Batch Accuracy: 9.38  [51200/54000]\n",
            "Batch loss: 2.298543,  Batch Accuracy: 5.47  [52480/54000]\n",
            "Batch loss: 2.300591,  Batch Accuracy: 8.59  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.22%, Loss: 2.2960\n",
            "Validation performance:\n",
            " Accuracy: 18.85%, Loss: 2.2950\n",
            "Test performance: Accuracy:\n",
            " 18.28%, Loss: 2.2950\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Batch loss: 2.293639,  Batch Accuracy: 21.88  [ 1280/54000]\n",
            "Batch loss: 2.294822,  Batch Accuracy: 14.06  [ 2560/54000]\n",
            "Batch loss: 2.300664,  Batch Accuracy: 9.38  [ 3840/54000]\n",
            "Batch loss: 2.293231,  Batch Accuracy: 10.94  [ 5120/54000]\n",
            "Batch loss: 2.293838,  Batch Accuracy: 13.28  [ 6400/54000]\n",
            "Batch loss: 2.285539,  Batch Accuracy: 14.84  [ 7680/54000]\n",
            "Batch loss: 2.293128,  Batch Accuracy: 10.16  [ 8960/54000]\n",
            "Batch loss: 2.294314,  Batch Accuracy: 14.06  [10240/54000]\n",
            "Batch loss: 2.304370,  Batch Accuracy: 12.50  [11520/54000]\n",
            "Batch loss: 2.291418,  Batch Accuracy: 10.16  [12800/54000]\n",
            "Batch loss: 2.290401,  Batch Accuracy: 16.41  [14080/54000]\n",
            "Batch loss: 2.294732,  Batch Accuracy: 14.06  [15360/54000]\n",
            "Batch loss: 2.304610,  Batch Accuracy: 4.69  [16640/54000]\n",
            "Batch loss: 2.290865,  Batch Accuracy: 11.72  [17920/54000]\n",
            "Batch loss: 2.305309,  Batch Accuracy: 7.81  [19200/54000]\n",
            "Batch loss: 2.308696,  Batch Accuracy: 8.59  [20480/54000]\n",
            "Batch loss: 2.294890,  Batch Accuracy: 12.50  [21760/54000]\n",
            "Batch loss: 2.306013,  Batch Accuracy: 6.25  [23040/54000]\n",
            "Batch loss: 2.297286,  Batch Accuracy: 7.03  [24320/54000]\n",
            "Batch loss: 2.296786,  Batch Accuracy: 9.38  [25600/54000]\n",
            "Batch loss: 2.299790,  Batch Accuracy: 10.94  [26880/54000]\n",
            "Batch loss: 2.286300,  Batch Accuracy: 14.84  [28160/54000]\n",
            "Batch loss: 2.294728,  Batch Accuracy: 7.81  [29440/54000]\n",
            "Batch loss: 2.292035,  Batch Accuracy: 14.06  [30720/54000]\n",
            "Batch loss: 2.300379,  Batch Accuracy: 11.72  [32000/54000]\n",
            "Batch loss: 2.289726,  Batch Accuracy: 12.50  [33280/54000]\n",
            "Batch loss: 2.291071,  Batch Accuracy: 12.50  [34560/54000]\n",
            "Batch loss: 2.286768,  Batch Accuracy: 13.28  [35840/54000]\n",
            "Batch loss: 2.297883,  Batch Accuracy: 9.38  [37120/54000]\n",
            "Batch loss: 2.288660,  Batch Accuracy: 14.06  [38400/54000]\n",
            "Batch loss: 2.302387,  Batch Accuracy: 7.81  [39680/54000]\n",
            "Batch loss: 2.302206,  Batch Accuracy: 9.38  [40960/54000]\n",
            "Batch loss: 2.292831,  Batch Accuracy: 10.94  [42240/54000]\n",
            "Batch loss: 2.298726,  Batch Accuracy: 7.03  [43520/54000]\n",
            "Batch loss: 2.287826,  Batch Accuracy: 12.50  [44800/54000]\n",
            "Batch loss: 2.290613,  Batch Accuracy: 11.72  [46080/54000]\n",
            "Batch loss: 2.291809,  Batch Accuracy: 11.72  [47360/54000]\n",
            "Batch loss: 2.286364,  Batch Accuracy: 14.84  [48640/54000]\n",
            "Batch loss: 2.284028,  Batch Accuracy: 12.50  [49920/54000]\n",
            "Batch loss: 2.289666,  Batch Accuracy: 13.28  [51200/54000]\n",
            "Batch loss: 2.302446,  Batch Accuracy: 8.59  [52480/54000]\n",
            "Batch loss: 2.292696,  Batch Accuracy: 10.94  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 12.09%, Loss: 2.2947\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2940\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2937\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Batch loss: 2.282743,  Batch Accuracy: 18.75  [ 1280/54000]\n",
            "Batch loss: 2.290785,  Batch Accuracy: 12.50  [ 2560/54000]\n",
            "Batch loss: 2.291918,  Batch Accuracy: 11.72  [ 3840/54000]\n",
            "Batch loss: 2.289992,  Batch Accuracy: 11.72  [ 5120/54000]\n",
            "Batch loss: 2.290202,  Batch Accuracy: 13.28  [ 6400/54000]\n",
            "Batch loss: 2.282798,  Batch Accuracy: 14.84  [ 7680/54000]\n",
            "Batch loss: 2.297311,  Batch Accuracy: 10.94  [ 8960/54000]\n",
            "Batch loss: 2.289979,  Batch Accuracy: 14.84  [10240/54000]\n",
            "Batch loss: 2.288127,  Batch Accuracy: 14.84  [11520/54000]\n",
            "Batch loss: 2.303662,  Batch Accuracy: 7.81  [12800/54000]\n",
            "Batch loss: 2.297936,  Batch Accuracy: 7.81  [14080/54000]\n",
            "Batch loss: 2.295726,  Batch Accuracy: 8.59  [15360/54000]\n",
            "Batch loss: 2.293863,  Batch Accuracy: 9.38  [16640/54000]\n",
            "Batch loss: 2.279422,  Batch Accuracy: 15.62  [17920/54000]\n",
            "Batch loss: 2.289665,  Batch Accuracy: 12.50  [19200/54000]\n",
            "Batch loss: 2.297151,  Batch Accuracy: 13.28  [20480/54000]\n",
            "Batch loss: 2.301894,  Batch Accuracy: 9.38  [21760/54000]\n",
            "Batch loss: 2.294665,  Batch Accuracy: 9.38  [23040/54000]\n",
            "Batch loss: 2.304047,  Batch Accuracy: 7.81  [24320/54000]\n",
            "Batch loss: 2.292567,  Batch Accuracy: 13.28  [25600/54000]\n",
            "Batch loss: 2.296773,  Batch Accuracy: 10.16  [26880/54000]\n",
            "Batch loss: 2.289987,  Batch Accuracy: 10.94  [28160/54000]\n",
            "Batch loss: 2.287607,  Batch Accuracy: 12.50  [29440/54000]\n",
            "Batch loss: 2.286616,  Batch Accuracy: 12.50  [30720/54000]\n",
            "Batch loss: 2.291837,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.301045,  Batch Accuracy: 5.47  [33280/54000]\n",
            "Batch loss: 2.293886,  Batch Accuracy: 10.16  [34560/54000]\n",
            "Batch loss: 2.294085,  Batch Accuracy: 7.03  [35840/54000]\n",
            "Batch loss: 2.293237,  Batch Accuracy: 10.16  [37120/54000]\n",
            "Batch loss: 2.293432,  Batch Accuracy: 13.28  [38400/54000]\n",
            "Batch loss: 2.305514,  Batch Accuracy: 10.94  [39680/54000]\n",
            "Batch loss: 2.288122,  Batch Accuracy: 17.97  [40960/54000]\n",
            "Batch loss: 2.290906,  Batch Accuracy: 10.16  [42240/54000]\n",
            "Batch loss: 2.292282,  Batch Accuracy: 10.16  [43520/54000]\n",
            "Batch loss: 2.298631,  Batch Accuracy: 7.03  [44800/54000]\n",
            "Batch loss: 2.296495,  Batch Accuracy: 9.38  [46080/54000]\n",
            "Batch loss: 2.295569,  Batch Accuracy: 5.47  [47360/54000]\n",
            "Batch loss: 2.292832,  Batch Accuracy: 22.66  [48640/54000]\n",
            "Batch loss: 2.295341,  Batch Accuracy: 10.16  [49920/54000]\n",
            "Batch loss: 2.283940,  Batch Accuracy: 14.06  [51200/54000]\n",
            "Batch loss: 2.296467,  Batch Accuracy: 12.50  [52480/54000]\n",
            "Batch loss: 2.293276,  Batch Accuracy: 7.81  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.73%, Loss: 2.2933\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2922\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2922\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Batch loss: 2.277279,  Batch Accuracy: 16.41  [ 1280/54000]\n",
            "Batch loss: 2.292656,  Batch Accuracy: 7.03  [ 2560/54000]\n",
            "Batch loss: 2.295732,  Batch Accuracy: 8.59  [ 3840/54000]\n",
            "Batch loss: 2.297006,  Batch Accuracy: 3.91  [ 5120/54000]\n",
            "Batch loss: 2.304588,  Batch Accuracy: 7.81  [ 6400/54000]\n",
            "Batch loss: 2.288871,  Batch Accuracy: 12.50  [ 7680/54000]\n",
            "Batch loss: 2.298534,  Batch Accuracy: 8.59  [ 8960/54000]\n",
            "Batch loss: 2.296940,  Batch Accuracy: 10.16  [10240/54000]\n",
            "Batch loss: 2.299152,  Batch Accuracy: 7.81  [11520/54000]\n",
            "Batch loss: 2.288679,  Batch Accuracy: 13.28  [12800/54000]\n",
            "Batch loss: 2.293257,  Batch Accuracy: 12.50  [14080/54000]\n",
            "Batch loss: 2.285778,  Batch Accuracy: 15.62  [15360/54000]\n",
            "Batch loss: 2.291684,  Batch Accuracy: 13.28  [16640/54000]\n",
            "Batch loss: 2.303934,  Batch Accuracy: 8.59  [17920/54000]\n",
            "Batch loss: 2.294376,  Batch Accuracy: 13.28  [19200/54000]\n",
            "Batch loss: 2.299925,  Batch Accuracy: 7.81  [20480/54000]\n",
            "Batch loss: 2.289815,  Batch Accuracy: 12.50  [21760/54000]\n",
            "Batch loss: 2.286373,  Batch Accuracy: 11.72  [23040/54000]\n",
            "Batch loss: 2.294998,  Batch Accuracy: 12.50  [24320/54000]\n",
            "Batch loss: 2.296069,  Batch Accuracy: 9.38  [25600/54000]\n",
            "Batch loss: 2.291991,  Batch Accuracy: 10.16  [26880/54000]\n",
            "Batch loss: 2.302376,  Batch Accuracy: 7.81  [28160/54000]\n",
            "Batch loss: 2.283626,  Batch Accuracy: 14.06  [29440/54000]\n",
            "Batch loss: 2.300397,  Batch Accuracy: 7.81  [30720/54000]\n",
            "Batch loss: 2.282526,  Batch Accuracy: 15.62  [32000/54000]\n",
            "Batch loss: 2.285949,  Batch Accuracy: 15.62  [33280/54000]\n",
            "Batch loss: 2.290507,  Batch Accuracy: 10.16  [34560/54000]\n",
            "Batch loss: 2.293279,  Batch Accuracy: 10.94  [35840/54000]\n",
            "Batch loss: 2.289701,  Batch Accuracy: 11.72  [37120/54000]\n",
            "Batch loss: 2.295132,  Batch Accuracy: 8.59  [38400/54000]\n",
            "Batch loss: 2.290704,  Batch Accuracy: 12.50  [39680/54000]\n",
            "Batch loss: 2.290203,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.294847,  Batch Accuracy: 8.59  [42240/54000]\n",
            "Batch loss: 2.297059,  Batch Accuracy: 10.16  [43520/54000]\n",
            "Batch loss: 2.292296,  Batch Accuracy: 9.38  [44800/54000]\n",
            "Batch loss: 2.297641,  Batch Accuracy: 8.59  [46080/54000]\n",
            "Batch loss: 2.294957,  Batch Accuracy: 9.38  [47360/54000]\n",
            "Batch loss: 2.285623,  Batch Accuracy: 11.72  [48640/54000]\n",
            "Batch loss: 2.288092,  Batch Accuracy: 12.50  [49920/54000]\n",
            "Batch loss: 2.295749,  Batch Accuracy: 13.28  [51200/54000]\n",
            "Batch loss: 2.300785,  Batch Accuracy: 4.69  [52480/54000]\n",
            "Batch loss: 2.289535,  Batch Accuracy: 14.84  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.35%, Loss: 2.2919\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2906\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2907\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Batch loss: 2.286122,  Batch Accuracy: 12.50  [ 1280/54000]\n",
            "Batch loss: 2.285890,  Batch Accuracy: 14.84  [ 2560/54000]\n",
            "Batch loss: 2.297105,  Batch Accuracy: 7.03  [ 3840/54000]\n",
            "Batch loss: 2.295233,  Batch Accuracy: 10.16  [ 5120/54000]\n",
            "Batch loss: 2.296070,  Batch Accuracy: 7.81  [ 6400/54000]\n",
            "Batch loss: 2.292849,  Batch Accuracy: 7.03  [ 7680/54000]\n",
            "Batch loss: 2.292649,  Batch Accuracy: 10.16  [ 8960/54000]\n",
            "Batch loss: 2.301585,  Batch Accuracy: 9.38  [10240/54000]\n",
            "Batch loss: 2.293677,  Batch Accuracy: 9.38  [11520/54000]\n",
            "Batch loss: 2.293535,  Batch Accuracy: 19.53  [12800/54000]\n",
            "Batch loss: 2.280618,  Batch Accuracy: 13.28  [14080/54000]\n",
            "Batch loss: 2.290664,  Batch Accuracy: 9.38  [15360/54000]\n",
            "Batch loss: 2.277129,  Batch Accuracy: 16.41  [16640/54000]\n",
            "Batch loss: 2.290026,  Batch Accuracy: 10.16  [17920/54000]\n",
            "Batch loss: 2.278438,  Batch Accuracy: 14.84  [19200/54000]\n",
            "Batch loss: 2.283193,  Batch Accuracy: 12.50  [20480/54000]\n",
            "Batch loss: 2.282485,  Batch Accuracy: 14.06  [21760/54000]\n",
            "Batch loss: 2.303130,  Batch Accuracy: 7.81  [23040/54000]\n",
            "Batch loss: 2.294889,  Batch Accuracy: 10.16  [24320/54000]\n",
            "Batch loss: 2.289972,  Batch Accuracy: 8.59  [25600/54000]\n",
            "Batch loss: 2.292354,  Batch Accuracy: 14.06  [26880/54000]\n",
            "Batch loss: 2.289394,  Batch Accuracy: 11.72  [28160/54000]\n",
            "Batch loss: 2.291732,  Batch Accuracy: 9.38  [29440/54000]\n",
            "Batch loss: 2.286002,  Batch Accuracy: 11.72  [30720/54000]\n",
            "Batch loss: 2.290616,  Batch Accuracy: 10.94  [32000/54000]\n",
            "Batch loss: 2.298573,  Batch Accuracy: 7.03  [33280/54000]\n",
            "Batch loss: 2.290058,  Batch Accuracy: 14.06  [34560/54000]\n",
            "Batch loss: 2.294506,  Batch Accuracy: 9.38  [35840/54000]\n",
            "Batch loss: 2.290175,  Batch Accuracy: 9.38  [37120/54000]\n",
            "Batch loss: 2.292349,  Batch Accuracy: 10.16  [38400/54000]\n",
            "Batch loss: 2.296124,  Batch Accuracy: 7.03  [39680/54000]\n",
            "Batch loss: 2.286068,  Batch Accuracy: 10.94  [40960/54000]\n",
            "Batch loss: 2.278184,  Batch Accuracy: 16.41  [42240/54000]\n",
            "Batch loss: 2.297181,  Batch Accuracy: 11.72  [43520/54000]\n",
            "Batch loss: 2.287044,  Batch Accuracy: 13.28  [44800/54000]\n",
            "Batch loss: 2.289636,  Batch Accuracy: 13.28  [46080/54000]\n",
            "Batch loss: 2.279300,  Batch Accuracy: 14.06  [47360/54000]\n",
            "Batch loss: 2.302723,  Batch Accuracy: 6.25  [48640/54000]\n",
            "Batch loss: 2.298524,  Batch Accuracy: 9.38  [49920/54000]\n",
            "Batch loss: 2.296281,  Batch Accuracy: 8.59  [51200/54000]\n",
            "Batch loss: 2.298940,  Batch Accuracy: 7.81  [52480/54000]\n",
            "Batch loss: 2.291016,  Batch Accuracy: 16.41  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.49%, Loss: 2.2902\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2886\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2889\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Batch loss: 2.281741,  Batch Accuracy: 14.84  [ 1280/54000]\n",
            "Batch loss: 2.297834,  Batch Accuracy: 10.16  [ 2560/54000]\n",
            "Batch loss: 2.289552,  Batch Accuracy: 12.50  [ 3840/54000]\n",
            "Batch loss: 2.277181,  Batch Accuracy: 16.41  [ 5120/54000]\n",
            "Batch loss: 2.289214,  Batch Accuracy: 9.38  [ 6400/54000]\n",
            "Batch loss: 2.284635,  Batch Accuracy: 8.59  [ 7680/54000]\n",
            "Batch loss: 2.298063,  Batch Accuracy: 5.47  [ 8960/54000]\n",
            "Batch loss: 2.286093,  Batch Accuracy: 11.72  [10240/54000]\n",
            "Batch loss: 2.282814,  Batch Accuracy: 13.28  [11520/54000]\n",
            "Batch loss: 2.289300,  Batch Accuracy: 11.72  [12800/54000]\n",
            "Batch loss: 2.284276,  Batch Accuracy: 14.06  [14080/54000]\n",
            "Batch loss: 2.292459,  Batch Accuracy: 9.38  [15360/54000]\n",
            "Batch loss: 2.280937,  Batch Accuracy: 14.06  [16640/54000]\n",
            "Batch loss: 2.292632,  Batch Accuracy: 7.81  [17920/54000]\n",
            "Batch loss: 2.285579,  Batch Accuracy: 12.50  [19200/54000]\n",
            "Batch loss: 2.291312,  Batch Accuracy: 8.59  [20480/54000]\n",
            "Batch loss: 2.289456,  Batch Accuracy: 10.16  [21760/54000]\n",
            "Batch loss: 2.287361,  Batch Accuracy: 10.16  [23040/54000]\n",
            "Batch loss: 2.295853,  Batch Accuracy: 5.47  [24320/54000]\n",
            "Batch loss: 2.270183,  Batch Accuracy: 15.62  [25600/54000]\n",
            "Batch loss: 2.275477,  Batch Accuracy: 14.84  [26880/54000]\n",
            "Batch loss: 2.288426,  Batch Accuracy: 8.59  [28160/54000]\n",
            "Batch loss: 2.296110,  Batch Accuracy: 8.59  [29440/54000]\n",
            "Batch loss: 2.281868,  Batch Accuracy: 14.06  [30720/54000]\n",
            "Batch loss: 2.289289,  Batch Accuracy: 8.59  [32000/54000]\n",
            "Batch loss: 2.282910,  Batch Accuracy: 13.28  [33280/54000]\n",
            "Batch loss: 2.303583,  Batch Accuracy: 8.59  [34560/54000]\n",
            "Batch loss: 2.290863,  Batch Accuracy: 8.59  [35840/54000]\n",
            "Batch loss: 2.288673,  Batch Accuracy: 7.81  [37120/54000]\n",
            "Batch loss: 2.288992,  Batch Accuracy: 10.94  [38400/54000]\n",
            "Batch loss: 2.295606,  Batch Accuracy: 8.59  [39680/54000]\n",
            "Batch loss: 2.287063,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.279965,  Batch Accuracy: 14.84  [42240/54000]\n",
            "Batch loss: 2.295532,  Batch Accuracy: 7.03  [43520/54000]\n",
            "Batch loss: 2.288960,  Batch Accuracy: 14.06  [44800/54000]\n",
            "Batch loss: 2.293127,  Batch Accuracy: 7.03  [46080/54000]\n",
            "Batch loss: 2.276867,  Batch Accuracy: 15.62  [47360/54000]\n",
            "Batch loss: 2.276520,  Batch Accuracy: 17.19  [48640/54000]\n",
            "Batch loss: 2.293389,  Batch Accuracy: 8.59  [49920/54000]\n",
            "Batch loss: 2.292147,  Batch Accuracy: 9.38  [51200/54000]\n",
            "Batch loss: 2.287776,  Batch Accuracy: 9.38  [52480/54000]\n",
            "Batch loss: 2.284469,  Batch Accuracy: 12.50  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.19%, Loss: 2.2886\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2865\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2868\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Batch loss: 2.286237,  Batch Accuracy: 9.38  [ 1280/54000]\n",
            "Batch loss: 2.283492,  Batch Accuracy: 13.28  [ 2560/54000]\n",
            "Batch loss: 2.293427,  Batch Accuracy: 12.50  [ 3840/54000]\n",
            "Batch loss: 2.285800,  Batch Accuracy: 14.06  [ 5120/54000]\n",
            "Batch loss: 2.290471,  Batch Accuracy: 10.16  [ 6400/54000]\n",
            "Batch loss: 2.281625,  Batch Accuracy: 13.28  [ 7680/54000]\n",
            "Batch loss: 2.285471,  Batch Accuracy: 11.72  [ 8960/54000]\n",
            "Batch loss: 2.291975,  Batch Accuracy: 5.47  [10240/54000]\n",
            "Batch loss: 2.286599,  Batch Accuracy: 12.50  [11520/54000]\n",
            "Batch loss: 2.278874,  Batch Accuracy: 14.84  [12800/54000]\n",
            "Batch loss: 2.283378,  Batch Accuracy: 12.50  [14080/54000]\n",
            "Batch loss: 2.289615,  Batch Accuracy: 8.59  [15360/54000]\n",
            "Batch loss: 2.300153,  Batch Accuracy: 8.59  [16640/54000]\n",
            "Batch loss: 2.291384,  Batch Accuracy: 8.59  [17920/54000]\n",
            "Batch loss: 2.286334,  Batch Accuracy: 10.94  [19200/54000]\n",
            "Batch loss: 2.290338,  Batch Accuracy: 11.72  [20480/54000]\n",
            "Batch loss: 2.284814,  Batch Accuracy: 13.28  [21760/54000]\n",
            "Batch loss: 2.295276,  Batch Accuracy: 7.81  [23040/54000]\n",
            "Batch loss: 2.287553,  Batch Accuracy: 10.94  [24320/54000]\n",
            "Batch loss: 2.286380,  Batch Accuracy: 11.72  [25600/54000]\n",
            "Batch loss: 2.282311,  Batch Accuracy: 10.94  [26880/54000]\n",
            "Batch loss: 2.286024,  Batch Accuracy: 10.16  [28160/54000]\n",
            "Batch loss: 2.275083,  Batch Accuracy: 16.41  [29440/54000]\n",
            "Batch loss: 2.281940,  Batch Accuracy: 14.84  [30720/54000]\n",
            "Batch loss: 2.283796,  Batch Accuracy: 11.72  [32000/54000]\n",
            "Batch loss: 2.276463,  Batch Accuracy: 14.06  [33280/54000]\n",
            "Batch loss: 2.287789,  Batch Accuracy: 10.16  [34560/54000]\n",
            "Batch loss: 2.287950,  Batch Accuracy: 13.28  [35840/54000]\n",
            "Batch loss: 2.297182,  Batch Accuracy: 6.25  [37120/54000]\n",
            "Batch loss: 2.283293,  Batch Accuracy: 13.28  [38400/54000]\n",
            "Batch loss: 2.290638,  Batch Accuracy: 11.72  [39680/54000]\n",
            "Batch loss: 2.276992,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.284669,  Batch Accuracy: 13.28  [42240/54000]\n",
            "Batch loss: 2.290761,  Batch Accuracy: 9.38  [43520/54000]\n",
            "Batch loss: 2.289418,  Batch Accuracy: 8.59  [44800/54000]\n",
            "Batch loss: 2.287282,  Batch Accuracy: 10.94  [46080/54000]\n",
            "Batch loss: 2.285234,  Batch Accuracy: 10.16  [47360/54000]\n",
            "Batch loss: 2.285123,  Batch Accuracy: 7.03  [48640/54000]\n",
            "Batch loss: 2.281207,  Batch Accuracy: 10.94  [49920/54000]\n",
            "Batch loss: 2.296589,  Batch Accuracy: 7.81  [51200/54000]\n",
            "Batch loss: 2.285015,  Batch Accuracy: 10.94  [52480/54000]\n",
            "Batch loss: 2.295468,  Batch Accuracy: 5.47  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.20%, Loss: 2.2866\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2852\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2849\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Batch loss: 2.291537,  Batch Accuracy: 10.16  [ 1280/54000]\n",
            "Batch loss: 2.284108,  Batch Accuracy: 12.50  [ 2560/54000]\n",
            "Batch loss: 2.286098,  Batch Accuracy: 9.38  [ 3840/54000]\n",
            "Batch loss: 2.292845,  Batch Accuracy: 9.38  [ 5120/54000]\n",
            "Batch loss: 2.277190,  Batch Accuracy: 12.50  [ 6400/54000]\n",
            "Batch loss: 2.288861,  Batch Accuracy: 10.16  [ 7680/54000]\n",
            "Batch loss: 2.292815,  Batch Accuracy: 7.03  [ 8960/54000]\n",
            "Batch loss: 2.291577,  Batch Accuracy: 17.19  [10240/54000]\n",
            "Batch loss: 2.286879,  Batch Accuracy: 14.84  [11520/54000]\n",
            "Batch loss: 2.280827,  Batch Accuracy: 11.72  [12800/54000]\n",
            "Batch loss: 2.289485,  Batch Accuracy: 10.16  [14080/54000]\n",
            "Batch loss: 2.288461,  Batch Accuracy: 12.50  [15360/54000]\n",
            "Batch loss: 2.289577,  Batch Accuracy: 10.16  [16640/54000]\n",
            "Batch loss: 2.284945,  Batch Accuracy: 14.06  [17920/54000]\n",
            "Batch loss: 2.278225,  Batch Accuracy: 13.28  [19200/54000]\n",
            "Batch loss: 2.291807,  Batch Accuracy: 10.16  [20480/54000]\n",
            "Batch loss: 2.283596,  Batch Accuracy: 14.84  [21760/54000]\n",
            "Batch loss: 2.280932,  Batch Accuracy: 12.50  [23040/54000]\n",
            "Batch loss: 2.284166,  Batch Accuracy: 12.50  [24320/54000]\n",
            "Batch loss: 2.275684,  Batch Accuracy: 12.50  [25600/54000]\n",
            "Batch loss: 2.287935,  Batch Accuracy: 10.94  [26880/54000]\n",
            "Batch loss: 2.287549,  Batch Accuracy: 10.94  [28160/54000]\n",
            "Batch loss: 2.269443,  Batch Accuracy: 17.19  [29440/54000]\n",
            "Batch loss: 2.290099,  Batch Accuracy: 9.38  [30720/54000]\n",
            "Batch loss: 2.284416,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.283562,  Batch Accuracy: 14.06  [33280/54000]\n",
            "Batch loss: 2.283782,  Batch Accuracy: 12.50  [34560/54000]\n",
            "Batch loss: 2.292034,  Batch Accuracy: 8.59  [35840/54000]\n",
            "Batch loss: 2.282695,  Batch Accuracy: 13.28  [37120/54000]\n",
            "Batch loss: 2.278287,  Batch Accuracy: 14.84  [38400/54000]\n",
            "Batch loss: 2.272512,  Batch Accuracy: 15.62  [39680/54000]\n",
            "Batch loss: 2.281837,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.287644,  Batch Accuracy: 10.16  [42240/54000]\n",
            "Batch loss: 2.275030,  Batch Accuracy: 13.28  [43520/54000]\n",
            "Batch loss: 2.273157,  Batch Accuracy: 12.50  [44800/54000]\n",
            "Batch loss: 2.284085,  Batch Accuracy: 11.72  [46080/54000]\n",
            "Batch loss: 2.282156,  Batch Accuracy: 10.94  [47360/54000]\n",
            "Batch loss: 2.288540,  Batch Accuracy: 7.81  [48640/54000]\n",
            "Batch loss: 2.281522,  Batch Accuracy: 10.94  [49920/54000]\n",
            "Batch loss: 2.279735,  Batch Accuracy: 10.16  [51200/54000]\n",
            "Batch loss: 2.273350,  Batch Accuracy: 16.41  [52480/54000]\n",
            "Batch loss: 2.293558,  Batch Accuracy: 11.72  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.29%, Loss: 2.2844\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2832\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2829\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Batch loss: 2.286250,  Batch Accuracy: 10.16  [ 1280/54000]\n",
            "Batch loss: 2.293611,  Batch Accuracy: 9.38  [ 2560/54000]\n",
            "Batch loss: 2.286322,  Batch Accuracy: 11.72  [ 3840/54000]\n",
            "Batch loss: 2.278184,  Batch Accuracy: 12.50  [ 5120/54000]\n",
            "Batch loss: 2.286816,  Batch Accuracy: 10.16  [ 6400/54000]\n",
            "Batch loss: 2.278631,  Batch Accuracy: 13.28  [ 7680/54000]\n",
            "Batch loss: 2.286535,  Batch Accuracy: 13.28  [ 8960/54000]\n",
            "Batch loss: 2.296858,  Batch Accuracy: 7.81  [10240/54000]\n",
            "Batch loss: 2.294008,  Batch Accuracy: 4.69  [11520/54000]\n",
            "Batch loss: 2.284473,  Batch Accuracy: 10.16  [12800/54000]\n",
            "Batch loss: 2.289655,  Batch Accuracy: 8.59  [14080/54000]\n",
            "Batch loss: 2.289591,  Batch Accuracy: 10.16  [15360/54000]\n",
            "Batch loss: 2.282557,  Batch Accuracy: 9.38  [16640/54000]\n",
            "Batch loss: 2.266422,  Batch Accuracy: 14.84  [17920/54000]\n",
            "Batch loss: 2.281216,  Batch Accuracy: 11.72  [19200/54000]\n",
            "Batch loss: 2.290036,  Batch Accuracy: 7.81  [20480/54000]\n",
            "Batch loss: 2.278648,  Batch Accuracy: 11.72  [21760/54000]\n",
            "Batch loss: 2.282719,  Batch Accuracy: 12.50  [23040/54000]\n",
            "Batch loss: 2.280782,  Batch Accuracy: 10.94  [24320/54000]\n",
            "Batch loss: 2.269401,  Batch Accuracy: 14.06  [25600/54000]\n",
            "Batch loss: 2.292338,  Batch Accuracy: 7.81  [26880/54000]\n",
            "Batch loss: 2.271478,  Batch Accuracy: 11.72  [28160/54000]\n",
            "Batch loss: 2.277072,  Batch Accuracy: 12.50  [29440/54000]\n",
            "Batch loss: 2.292129,  Batch Accuracy: 8.59  [30720/54000]\n",
            "Batch loss: 2.279939,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.275822,  Batch Accuracy: 10.94  [33280/54000]\n",
            "Batch loss: 2.289945,  Batch Accuracy: 10.94  [34560/54000]\n",
            "Batch loss: 2.287694,  Batch Accuracy: 9.38  [35840/54000]\n",
            "Batch loss: 2.283165,  Batch Accuracy: 10.94  [37120/54000]\n",
            "Batch loss: 2.276366,  Batch Accuracy: 11.72  [38400/54000]\n",
            "Batch loss: 2.287078,  Batch Accuracy: 10.16  [39680/54000]\n",
            "Batch loss: 2.274426,  Batch Accuracy: 12.50  [40960/54000]\n",
            "Batch loss: 2.271781,  Batch Accuracy: 15.62  [42240/54000]\n",
            "Batch loss: 2.262701,  Batch Accuracy: 13.28  [43520/54000]\n",
            "Batch loss: 2.267649,  Batch Accuracy: 17.19  [44800/54000]\n",
            "Batch loss: 2.290164,  Batch Accuracy: 6.25  [46080/54000]\n",
            "Batch loss: 2.290690,  Batch Accuracy: 10.16  [47360/54000]\n",
            "Batch loss: 2.282220,  Batch Accuracy: 11.72  [48640/54000]\n",
            "Batch loss: 2.274909,  Batch Accuracy: 12.50  [49920/54000]\n",
            "Batch loss: 2.267752,  Batch Accuracy: 12.50  [51200/54000]\n",
            "Batch loss: 2.279945,  Batch Accuracy: 8.59  [52480/54000]\n",
            "Batch loss: 2.277515,  Batch Accuracy: 14.84  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.19%, Loss: 2.2820\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2801\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2797\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Batch loss: 2.272340,  Batch Accuracy: 14.84  [ 1280/54000]\n",
            "Batch loss: 2.294887,  Batch Accuracy: 6.25  [ 2560/54000]\n",
            "Batch loss: 2.278352,  Batch Accuracy: 12.50  [ 3840/54000]\n",
            "Batch loss: 2.284201,  Batch Accuracy: 7.81  [ 5120/54000]\n",
            "Batch loss: 2.266023,  Batch Accuracy: 14.06  [ 6400/54000]\n",
            "Batch loss: 2.276034,  Batch Accuracy: 10.16  [ 7680/54000]\n",
            "Batch loss: 2.284942,  Batch Accuracy: 10.94  [ 8960/54000]\n",
            "Batch loss: 2.290298,  Batch Accuracy: 8.59  [10240/54000]\n",
            "Batch loss: 2.269094,  Batch Accuracy: 14.06  [11520/54000]\n",
            "Batch loss: 2.287223,  Batch Accuracy: 7.03  [12800/54000]\n",
            "Batch loss: 2.265423,  Batch Accuracy: 13.28  [14080/54000]\n",
            "Batch loss: 2.293290,  Batch Accuracy: 9.38  [15360/54000]\n",
            "Batch loss: 2.276444,  Batch Accuracy: 11.72  [16640/54000]\n",
            "Batch loss: 2.293029,  Batch Accuracy: 8.59  [17920/54000]\n",
            "Batch loss: 2.273406,  Batch Accuracy: 11.72  [19200/54000]\n",
            "Batch loss: 2.271009,  Batch Accuracy: 11.72  [20480/54000]\n",
            "Batch loss: 2.269212,  Batch Accuracy: 14.06  [21760/54000]\n",
            "Batch loss: 2.276780,  Batch Accuracy: 10.94  [23040/54000]\n",
            "Batch loss: 2.272123,  Batch Accuracy: 12.50  [24320/54000]\n",
            "Batch loss: 2.287132,  Batch Accuracy: 7.81  [25600/54000]\n",
            "Batch loss: 2.288661,  Batch Accuracy: 8.59  [26880/54000]\n",
            "Batch loss: 2.283710,  Batch Accuracy: 8.59  [28160/54000]\n",
            "Batch loss: 2.288707,  Batch Accuracy: 8.59  [29440/54000]\n",
            "Batch loss: 2.272053,  Batch Accuracy: 12.50  [30720/54000]\n",
            "Batch loss: 2.266211,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.282914,  Batch Accuracy: 9.38  [33280/54000]\n",
            "Batch loss: 2.279275,  Batch Accuracy: 8.59  [34560/54000]\n",
            "Batch loss: 2.289890,  Batch Accuracy: 11.72  [35840/54000]\n",
            "Batch loss: 2.279969,  Batch Accuracy: 11.72  [37120/54000]\n",
            "Batch loss: 2.260159,  Batch Accuracy: 17.97  [38400/54000]\n",
            "Batch loss: 2.275968,  Batch Accuracy: 10.94  [39680/54000]\n",
            "Batch loss: 2.271515,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.283151,  Batch Accuracy: 11.72  [42240/54000]\n",
            "Batch loss: 2.282984,  Batch Accuracy: 7.81  [43520/54000]\n",
            "Batch loss: 2.271992,  Batch Accuracy: 11.72  [44800/54000]\n",
            "Batch loss: 2.273518,  Batch Accuracy: 11.72  [46080/54000]\n",
            "Batch loss: 2.273093,  Batch Accuracy: 12.50  [47360/54000]\n",
            "Batch loss: 2.274075,  Batch Accuracy: 7.81  [48640/54000]\n",
            "Batch loss: 2.266842,  Batch Accuracy: 13.28  [49920/54000]\n",
            "Batch loss: 2.257709,  Batch Accuracy: 16.41  [51200/54000]\n",
            "Batch loss: 2.287638,  Batch Accuracy: 9.38  [52480/54000]\n",
            "Batch loss: 2.275225,  Batch Accuracy: 10.16  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.20%, Loss: 2.2791\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2769\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2766\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Batch loss: 2.276350,  Batch Accuracy: 10.94  [ 1280/54000]\n",
            "Batch loss: 2.284075,  Batch Accuracy: 10.16  [ 2560/54000]\n",
            "Batch loss: 2.274939,  Batch Accuracy: 13.28  [ 3840/54000]\n",
            "Batch loss: 2.277386,  Batch Accuracy: 10.16  [ 5120/54000]\n",
            "Batch loss: 2.278353,  Batch Accuracy: 13.28  [ 6400/54000]\n",
            "Batch loss: 2.270147,  Batch Accuracy: 14.06  [ 7680/54000]\n",
            "Batch loss: 2.285990,  Batch Accuracy: 9.38  [ 8960/54000]\n",
            "Batch loss: 2.262766,  Batch Accuracy: 14.06  [10240/54000]\n",
            "Batch loss: 2.291368,  Batch Accuracy: 7.03  [11520/54000]\n",
            "Batch loss: 2.260963,  Batch Accuracy: 12.50  [12800/54000]\n",
            "Batch loss: 2.288649,  Batch Accuracy: 9.38  [14080/54000]\n",
            "Batch loss: 2.279484,  Batch Accuracy: 8.59  [15360/54000]\n",
            "Batch loss: 2.268063,  Batch Accuracy: 15.62  [16640/54000]\n",
            "Batch loss: 2.277329,  Batch Accuracy: 10.16  [17920/54000]\n",
            "Batch loss: 2.266925,  Batch Accuracy: 13.28  [19200/54000]\n",
            "Batch loss: 2.282838,  Batch Accuracy: 7.81  [20480/54000]\n",
            "Batch loss: 2.286092,  Batch Accuracy: 9.38  [21760/54000]\n",
            "Batch loss: 2.273669,  Batch Accuracy: 12.50  [23040/54000]\n",
            "Batch loss: 2.284995,  Batch Accuracy: 9.38  [24320/54000]\n",
            "Batch loss: 2.269088,  Batch Accuracy: 14.06  [25600/54000]\n",
            "Batch loss: 2.296934,  Batch Accuracy: 5.47  [26880/54000]\n",
            "Batch loss: 2.279239,  Batch Accuracy: 14.06  [28160/54000]\n",
            "Batch loss: 2.272740,  Batch Accuracy: 11.72  [29440/54000]\n",
            "Batch loss: 2.268774,  Batch Accuracy: 14.84  [30720/54000]\n",
            "Batch loss: 2.269844,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.279148,  Batch Accuracy: 10.94  [33280/54000]\n",
            "Batch loss: 2.287545,  Batch Accuracy: 7.81  [34560/54000]\n",
            "Batch loss: 2.273130,  Batch Accuracy: 10.16  [35840/54000]\n",
            "Batch loss: 2.281850,  Batch Accuracy: 9.38  [37120/54000]\n",
            "Batch loss: 2.268683,  Batch Accuracy: 13.28  [38400/54000]\n",
            "Batch loss: 2.265125,  Batch Accuracy: 14.06  [39680/54000]\n",
            "Batch loss: 2.273432,  Batch Accuracy: 12.50  [40960/54000]\n",
            "Batch loss: 2.272943,  Batch Accuracy: 13.28  [42240/54000]\n",
            "Batch loss: 2.264452,  Batch Accuracy: 14.06  [43520/54000]\n",
            "Batch loss: 2.270505,  Batch Accuracy: 10.94  [44800/54000]\n",
            "Batch loss: 2.276030,  Batch Accuracy: 8.59  [46080/54000]\n",
            "Batch loss: 2.268418,  Batch Accuracy: 12.50  [47360/54000]\n",
            "Batch loss: 2.273002,  Batch Accuracy: 12.50  [48640/54000]\n",
            "Batch loss: 2.266795,  Batch Accuracy: 12.50  [49920/54000]\n",
            "Batch loss: 2.282390,  Batch Accuracy: 7.81  [51200/54000]\n",
            "Batch loss: 2.265029,  Batch Accuracy: 11.72  [52480/54000]\n",
            "Batch loss: 2.271722,  Batch Accuracy: 14.06  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.24%, Loss: 2.2757\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2727\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2727\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Batch loss: 2.278339,  Batch Accuracy: 10.94  [ 1280/54000]\n",
            "Batch loss: 2.273734,  Batch Accuracy: 10.94  [ 2560/54000]\n",
            "Batch loss: 2.255851,  Batch Accuracy: 15.62  [ 3840/54000]\n",
            "Batch loss: 2.256130,  Batch Accuracy: 17.97  [ 5120/54000]\n",
            "Batch loss: 2.289389,  Batch Accuracy: 7.03  [ 6400/54000]\n",
            "Batch loss: 2.277568,  Batch Accuracy: 9.38  [ 7680/54000]\n",
            "Batch loss: 2.266825,  Batch Accuracy: 13.28  [ 8960/54000]\n",
            "Batch loss: 2.258682,  Batch Accuracy: 17.19  [10240/54000]\n",
            "Batch loss: 2.268066,  Batch Accuracy: 10.16  [11520/54000]\n",
            "Batch loss: 2.276223,  Batch Accuracy: 10.94  [12800/54000]\n",
            "Batch loss: 2.267158,  Batch Accuracy: 13.28  [14080/54000]\n",
            "Batch loss: 2.264773,  Batch Accuracy: 12.50  [15360/54000]\n",
            "Batch loss: 2.256150,  Batch Accuracy: 14.06  [16640/54000]\n",
            "Batch loss: 2.283655,  Batch Accuracy: 8.59  [17920/54000]\n",
            "Batch loss: 2.274486,  Batch Accuracy: 10.94  [19200/54000]\n",
            "Batch loss: 2.271176,  Batch Accuracy: 10.94  [20480/54000]\n",
            "Batch loss: 2.273426,  Batch Accuracy: 10.94  [21760/54000]\n",
            "Batch loss: 2.270042,  Batch Accuracy: 10.16  [23040/54000]\n",
            "Batch loss: 2.271111,  Batch Accuracy: 8.59  [24320/54000]\n",
            "Batch loss: 2.274163,  Batch Accuracy: 8.59  [25600/54000]\n",
            "Batch loss: 2.274333,  Batch Accuracy: 7.03  [26880/54000]\n",
            "Batch loss: 2.273200,  Batch Accuracy: 10.16  [28160/54000]\n",
            "Batch loss: 2.253969,  Batch Accuracy: 15.62  [29440/54000]\n",
            "Batch loss: 2.246611,  Batch Accuracy: 15.62  [30720/54000]\n",
            "Batch loss: 2.263228,  Batch Accuracy: 12.50  [32000/54000]\n",
            "Batch loss: 2.259945,  Batch Accuracy: 14.84  [33280/54000]\n",
            "Batch loss: 2.267522,  Batch Accuracy: 14.84  [34560/54000]\n",
            "Batch loss: 2.263141,  Batch Accuracy: 13.28  [35840/54000]\n",
            "Batch loss: 2.273564,  Batch Accuracy: 11.72  [37120/54000]\n",
            "Batch loss: 2.283319,  Batch Accuracy: 7.81  [38400/54000]\n",
            "Batch loss: 2.267215,  Batch Accuracy: 11.72  [39680/54000]\n",
            "Batch loss: 2.255934,  Batch Accuracy: 15.62  [40960/54000]\n",
            "Batch loss: 2.259720,  Batch Accuracy: 14.84  [42240/54000]\n",
            "Batch loss: 2.273128,  Batch Accuracy: 10.16  [43520/54000]\n",
            "Batch loss: 2.264340,  Batch Accuracy: 10.16  [44800/54000]\n",
            "Batch loss: 2.267723,  Batch Accuracy: 10.16  [46080/54000]\n",
            "Batch loss: 2.271153,  Batch Accuracy: 11.72  [47360/54000]\n",
            "Batch loss: 2.264226,  Batch Accuracy: 13.28  [48640/54000]\n",
            "Batch loss: 2.261017,  Batch Accuracy: 13.28  [49920/54000]\n",
            "Batch loss: 2.264284,  Batch Accuracy: 14.84  [51200/54000]\n",
            "Batch loss: 2.271933,  Batch Accuracy: 9.38  [52480/54000]\n",
            "Batch loss: 2.294271,  Batch Accuracy: 6.25  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.23%, Loss: 2.2716\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2686\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2681\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Batch loss: 2.279874,  Batch Accuracy: 10.94  [ 1280/54000]\n",
            "Batch loss: 2.258303,  Batch Accuracy: 14.84  [ 2560/54000]\n",
            "Batch loss: 2.271725,  Batch Accuracy: 11.72  [ 3840/54000]\n",
            "Batch loss: 2.262388,  Batch Accuracy: 13.28  [ 5120/54000]\n",
            "Batch loss: 2.269951,  Batch Accuracy: 10.16  [ 6400/54000]\n",
            "Batch loss: 2.251061,  Batch Accuracy: 15.62  [ 7680/54000]\n",
            "Batch loss: 2.268365,  Batch Accuracy: 13.28  [ 8960/54000]\n",
            "Batch loss: 2.265560,  Batch Accuracy: 10.16  [10240/54000]\n",
            "Batch loss: 2.277846,  Batch Accuracy: 9.38  [11520/54000]\n",
            "Batch loss: 2.261322,  Batch Accuracy: 12.50  [12800/54000]\n",
            "Batch loss: 2.272468,  Batch Accuracy: 10.94  [14080/54000]\n",
            "Batch loss: 2.271946,  Batch Accuracy: 10.94  [15360/54000]\n",
            "Batch loss: 2.253309,  Batch Accuracy: 14.06  [16640/54000]\n",
            "Batch loss: 2.263080,  Batch Accuracy: 11.72  [17920/54000]\n",
            "Batch loss: 2.244565,  Batch Accuracy: 18.75  [19200/54000]\n",
            "Batch loss: 2.261461,  Batch Accuracy: 11.72  [20480/54000]\n",
            "Batch loss: 2.256123,  Batch Accuracy: 14.06  [21760/54000]\n",
            "Batch loss: 2.265260,  Batch Accuracy: 11.72  [23040/54000]\n",
            "Batch loss: 2.264749,  Batch Accuracy: 9.38  [24320/54000]\n",
            "Batch loss: 2.273329,  Batch Accuracy: 10.16  [25600/54000]\n",
            "Batch loss: 2.265789,  Batch Accuracy: 9.38  [26880/54000]\n",
            "Batch loss: 2.263368,  Batch Accuracy: 13.28  [28160/54000]\n",
            "Batch loss: 2.254081,  Batch Accuracy: 12.50  [29440/54000]\n",
            "Batch loss: 2.253793,  Batch Accuracy: 12.50  [30720/54000]\n",
            "Batch loss: 2.280015,  Batch Accuracy: 7.81  [32000/54000]\n",
            "Batch loss: 2.241401,  Batch Accuracy: 15.62  [33280/54000]\n",
            "Batch loss: 2.255801,  Batch Accuracy: 14.84  [34560/54000]\n",
            "Batch loss: 2.263777,  Batch Accuracy: 11.72  [35840/54000]\n",
            "Batch loss: 2.264011,  Batch Accuracy: 10.94  [37120/54000]\n",
            "Batch loss: 2.255840,  Batch Accuracy: 11.72  [38400/54000]\n",
            "Batch loss: 2.244498,  Batch Accuracy: 16.41  [39680/54000]\n",
            "Batch loss: 2.259557,  Batch Accuracy: 12.50  [40960/54000]\n",
            "Batch loss: 2.263186,  Batch Accuracy: 10.94  [42240/54000]\n",
            "Batch loss: 2.254838,  Batch Accuracy: 14.06  [43520/54000]\n",
            "Batch loss: 2.284143,  Batch Accuracy: 7.03  [44800/54000]\n",
            "Batch loss: 2.267155,  Batch Accuracy: 10.16  [46080/54000]\n",
            "Batch loss: 2.250724,  Batch Accuracy: 15.62  [47360/54000]\n",
            "Batch loss: 2.265707,  Batch Accuracy: 8.59  [48640/54000]\n",
            "Batch loss: 2.264098,  Batch Accuracy: 10.16  [49920/54000]\n",
            "Batch loss: 2.286031,  Batch Accuracy: 7.03  [51200/54000]\n",
            "Batch loss: 2.258595,  Batch Accuracy: 12.50  [52480/54000]\n",
            "Batch loss: 2.258350,  Batch Accuracy: 12.50  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.20%, Loss: 2.2667\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2616\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2614\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Batch loss: 2.255341,  Batch Accuracy: 13.28  [ 1280/54000]\n",
            "Batch loss: 2.260933,  Batch Accuracy: 11.72  [ 2560/54000]\n",
            "Batch loss: 2.259708,  Batch Accuracy: 11.72  [ 3840/54000]\n",
            "Batch loss: 2.261935,  Batch Accuracy: 12.50  [ 5120/54000]\n",
            "Batch loss: 2.290157,  Batch Accuracy: 7.03  [ 6400/54000]\n",
            "Batch loss: 2.276591,  Batch Accuracy: 7.03  [ 7680/54000]\n",
            "Batch loss: 2.244430,  Batch Accuracy: 14.84  [ 8960/54000]\n",
            "Batch loss: 2.256402,  Batch Accuracy: 13.28  [10240/54000]\n",
            "Batch loss: 2.253985,  Batch Accuracy: 13.28  [11520/54000]\n",
            "Batch loss: 2.255038,  Batch Accuracy: 12.50  [12800/54000]\n",
            "Batch loss: 2.244239,  Batch Accuracy: 14.06  [14080/54000]\n",
            "Batch loss: 2.245266,  Batch Accuracy: 16.41  [15360/54000]\n",
            "Batch loss: 2.239632,  Batch Accuracy: 16.41  [16640/54000]\n",
            "Batch loss: 2.264108,  Batch Accuracy: 10.16  [17920/54000]\n",
            "Batch loss: 2.245902,  Batch Accuracy: 14.06  [19200/54000]\n",
            "Batch loss: 2.257251,  Batch Accuracy: 13.28  [20480/54000]\n",
            "Batch loss: 2.268459,  Batch Accuracy: 7.81  [21760/54000]\n",
            "Batch loss: 2.269908,  Batch Accuracy: 10.94  [23040/54000]\n",
            "Batch loss: 2.269145,  Batch Accuracy: 9.38  [24320/54000]\n",
            "Batch loss: 2.271624,  Batch Accuracy: 9.38  [25600/54000]\n",
            "Batch loss: 2.278471,  Batch Accuracy: 6.25  [26880/54000]\n",
            "Batch loss: 2.265355,  Batch Accuracy: 9.38  [28160/54000]\n",
            "Batch loss: 2.257828,  Batch Accuracy: 12.50  [29440/54000]\n",
            "Batch loss: 2.254530,  Batch Accuracy: 10.94  [30720/54000]\n",
            "Batch loss: 2.262450,  Batch Accuracy: 10.16  [32000/54000]\n",
            "Batch loss: 2.236614,  Batch Accuracy: 17.19  [33280/54000]\n",
            "Batch loss: 2.266999,  Batch Accuracy: 9.38  [34560/54000]\n",
            "Batch loss: 2.260056,  Batch Accuracy: 10.16  [35840/54000]\n",
            "Batch loss: 2.259948,  Batch Accuracy: 10.94  [37120/54000]\n",
            "Batch loss: 2.277478,  Batch Accuracy: 8.59  [38400/54000]\n",
            "Batch loss: 2.255424,  Batch Accuracy: 13.28  [39680/54000]\n",
            "Batch loss: 2.254343,  Batch Accuracy: 11.72  [40960/54000]\n",
            "Batch loss: 2.258183,  Batch Accuracy: 10.16  [42240/54000]\n",
            "Batch loss: 2.241955,  Batch Accuracy: 14.84  [43520/54000]\n",
            "Batch loss: 2.266392,  Batch Accuracy: 10.16  [44800/54000]\n",
            "Batch loss: 2.259335,  Batch Accuracy: 11.72  [46080/54000]\n",
            "Batch loss: 2.256820,  Batch Accuracy: 8.59  [47360/54000]\n",
            "Batch loss: 2.262947,  Batch Accuracy: 11.72  [48640/54000]\n",
            "Batch loss: 2.242768,  Batch Accuracy: 14.06  [49920/54000]\n",
            "Batch loss: 2.219867,  Batch Accuracy: 17.19  [51200/54000]\n",
            "Batch loss: 2.262122,  Batch Accuracy: 9.38  [52480/54000]\n",
            "Batch loss: 2.276565,  Batch Accuracy: 5.47  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.26%, Loss: 2.2600\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2546\n",
            "Test performance: Accuracy:\n",
            " 11.37%, Loss: 2.2550\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Batch loss: 2.259562,  Batch Accuracy: 10.16  [ 1280/54000]\n",
            "Batch loss: 2.263841,  Batch Accuracy: 9.38  [ 2560/54000]\n",
            "Batch loss: 2.259524,  Batch Accuracy: 10.16  [ 3840/54000]\n",
            "Batch loss: 2.233242,  Batch Accuracy: 16.41  [ 5120/54000]\n",
            "Batch loss: 2.260941,  Batch Accuracy: 10.16  [ 6400/54000]\n",
            "Batch loss: 2.259485,  Batch Accuracy: 10.94  [ 7680/54000]\n",
            "Batch loss: 2.251587,  Batch Accuracy: 12.50  [ 8960/54000]\n",
            "Batch loss: 2.244362,  Batch Accuracy: 14.84  [10240/54000]\n",
            "Batch loss: 2.269025,  Batch Accuracy: 8.59  [11520/54000]\n",
            "Batch loss: 2.244671,  Batch Accuracy: 13.28  [12800/54000]\n",
            "Batch loss: 2.260734,  Batch Accuracy: 8.59  [14080/54000]\n",
            "Batch loss: 2.261994,  Batch Accuracy: 7.81  [15360/54000]\n",
            "Batch loss: 2.262053,  Batch Accuracy: 7.81  [16640/54000]\n",
            "Batch loss: 2.270877,  Batch Accuracy: 10.16  [17920/54000]\n",
            "Batch loss: 2.240672,  Batch Accuracy: 10.94  [19200/54000]\n",
            "Batch loss: 2.254389,  Batch Accuracy: 12.50  [20480/54000]\n",
            "Batch loss: 2.230874,  Batch Accuracy: 14.84  [21760/54000]\n",
            "Batch loss: 2.254263,  Batch Accuracy: 12.50  [23040/54000]\n",
            "Batch loss: 2.246300,  Batch Accuracy: 11.72  [24320/54000]\n",
            "Batch loss: 2.262761,  Batch Accuracy: 8.59  [25600/54000]\n",
            "Batch loss: 2.257662,  Batch Accuracy: 10.16  [26880/54000]\n",
            "Batch loss: 2.205984,  Batch Accuracy: 20.31  [28160/54000]\n",
            "Batch loss: 2.255278,  Batch Accuracy: 10.94  [29440/54000]\n",
            "Batch loss: 2.263771,  Batch Accuracy: 10.16  [30720/54000]\n",
            "Batch loss: 2.244442,  Batch Accuracy: 11.72  [32000/54000]\n",
            "Batch loss: 2.258894,  Batch Accuracy: 10.94  [33280/54000]\n",
            "Batch loss: 2.281432,  Batch Accuracy: 7.81  [34560/54000]\n",
            "Batch loss: 2.258618,  Batch Accuracy: 10.16  [35840/54000]\n",
            "Batch loss: 2.235679,  Batch Accuracy: 13.28  [37120/54000]\n",
            "Batch loss: 2.255245,  Batch Accuracy: 8.59  [38400/54000]\n",
            "Batch loss: 2.247222,  Batch Accuracy: 11.72  [39680/54000]\n",
            "Batch loss: 2.264438,  Batch Accuracy: 10.94  [40960/54000]\n",
            "Batch loss: 2.236493,  Batch Accuracy: 14.06  [42240/54000]\n",
            "Batch loss: 2.260962,  Batch Accuracy: 8.59  [43520/54000]\n",
            "Batch loss: 2.251437,  Batch Accuracy: 14.84  [44800/54000]\n",
            "Batch loss: 2.242191,  Batch Accuracy: 14.84  [46080/54000]\n",
            "Batch loss: 2.241723,  Batch Accuracy: 13.28  [47360/54000]\n",
            "Batch loss: 2.242333,  Batch Accuracy: 11.72  [48640/54000]\n",
            "Batch loss: 2.254895,  Batch Accuracy: 8.59  [49920/54000]\n",
            "Batch loss: 2.239715,  Batch Accuracy: 10.94  [51200/54000]\n",
            "Batch loss: 2.250938,  Batch Accuracy: 11.72  [52480/54000]\n",
            "Batch loss: 2.249551,  Batch Accuracy: 11.72  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.49%, Loss: 2.2514\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2437\n",
            "Test performance: Accuracy:\n",
            " 11.35%, Loss: 2.2444\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Batch loss: 2.232514,  Batch Accuracy: 17.19  [ 1280/54000]\n",
            "Batch loss: 2.257054,  Batch Accuracy: 10.16  [ 2560/54000]\n",
            "Batch loss: 2.241932,  Batch Accuracy: 10.16  [ 3840/54000]\n",
            "Batch loss: 2.262176,  Batch Accuracy: 7.03  [ 5120/54000]\n",
            "Batch loss: 2.269263,  Batch Accuracy: 6.25  [ 6400/54000]\n",
            "Batch loss: 2.254613,  Batch Accuracy: 10.16  [ 7680/54000]\n",
            "Batch loss: 2.246834,  Batch Accuracy: 11.72  [ 8960/54000]\n",
            "Batch loss: 2.224606,  Batch Accuracy: 15.62  [10240/54000]\n",
            "Batch loss: 2.222606,  Batch Accuracy: 14.06  [11520/54000]\n",
            "Batch loss: 2.211755,  Batch Accuracy: 14.84  [12800/54000]\n",
            "Batch loss: 2.269956,  Batch Accuracy: 6.25  [14080/54000]\n",
            "Batch loss: 2.216390,  Batch Accuracy: 15.62  [15360/54000]\n",
            "Batch loss: 2.240630,  Batch Accuracy: 13.28  [16640/54000]\n",
            "Batch loss: 2.245677,  Batch Accuracy: 10.16  [17920/54000]\n",
            "Batch loss: 2.268398,  Batch Accuracy: 8.59  [19200/54000]\n",
            "Batch loss: 2.243290,  Batch Accuracy: 9.38  [20480/54000]\n",
            "Batch loss: 2.234553,  Batch Accuracy: 12.50  [21760/54000]\n",
            "Batch loss: 2.232738,  Batch Accuracy: 11.72  [23040/54000]\n",
            "Batch loss: 2.220999,  Batch Accuracy: 14.06  [24320/54000]\n",
            "Batch loss: 2.206789,  Batch Accuracy: 16.41  [25600/54000]\n",
            "Batch loss: 2.253631,  Batch Accuracy: 8.59  [26880/54000]\n",
            "Batch loss: 2.226171,  Batch Accuracy: 13.28  [28160/54000]\n",
            "Batch loss: 2.216786,  Batch Accuracy: 14.06  [29440/54000]\n",
            "Batch loss: 2.244024,  Batch Accuracy: 10.16  [30720/54000]\n",
            "Batch loss: 2.273442,  Batch Accuracy: 7.03  [32000/54000]\n",
            "Batch loss: 2.265202,  Batch Accuracy: 7.03  [33280/54000]\n",
            "Batch loss: 2.244025,  Batch Accuracy: 12.50  [34560/54000]\n",
            "Batch loss: 2.233986,  Batch Accuracy: 12.50  [35840/54000]\n",
            "Batch loss: 2.246481,  Batch Accuracy: 9.38  [37120/54000]\n",
            "Batch loss: 2.195717,  Batch Accuracy: 17.19  [38400/54000]\n",
            "Batch loss: 2.235140,  Batch Accuracy: 10.16  [39680/54000]\n",
            "Batch loss: 2.223796,  Batch Accuracy: 14.06  [40960/54000]\n",
            "Batch loss: 2.245051,  Batch Accuracy: 10.94  [42240/54000]\n",
            "Batch loss: 2.223596,  Batch Accuracy: 14.06  [43520/54000]\n",
            "Batch loss: 2.195418,  Batch Accuracy: 19.53  [44800/54000]\n",
            "Batch loss: 2.235927,  Batch Accuracy: 12.50  [46080/54000]\n",
            "Batch loss: 2.242699,  Batch Accuracy: 8.59  [47360/54000]\n",
            "Batch loss: 2.231333,  Batch Accuracy: 10.94  [48640/54000]\n",
            "Batch loss: 2.216816,  Batch Accuracy: 14.06  [49920/54000]\n",
            "Batch loss: 2.197642,  Batch Accuracy: 15.62  [51200/54000]\n",
            "Batch loss: 2.228761,  Batch Accuracy: 10.94  [52480/54000]\n",
            "Batch loss: 2.195543,  Batch Accuracy: 15.62  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 11.50%, Loss: 2.2390\n",
            "Validation performance:\n",
            " Accuracy: 11.63%, Loss: 2.2288\n",
            "Test performance: Accuracy:\n",
            " 11.37%, Loss: 2.2297\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Batch loss: 2.250500,  Batch Accuracy: 9.38  [ 1280/54000]\n",
            "Batch loss: 2.213441,  Batch Accuracy: 13.28  [ 2560/54000]\n",
            "Batch loss: 2.265698,  Batch Accuracy: 6.25  [ 3840/54000]\n",
            "Batch loss: 2.221082,  Batch Accuracy: 12.50  [ 5120/54000]\n",
            "Batch loss: 2.201160,  Batch Accuracy: 16.41  [ 6400/54000]\n",
            "Batch loss: 2.238613,  Batch Accuracy: 10.94  [ 7680/54000]\n",
            "Batch loss: 2.223977,  Batch Accuracy: 11.72  [ 8960/54000]\n",
            "Batch loss: 2.254006,  Batch Accuracy: 7.03  [10240/54000]\n",
            "Batch loss: 2.215549,  Batch Accuracy: 14.06  [11520/54000]\n",
            "Batch loss: 2.256573,  Batch Accuracy: 14.06  [12800/54000]\n",
            "Batch loss: 2.193123,  Batch Accuracy: 18.75  [14080/54000]\n",
            "Batch loss: 2.245637,  Batch Accuracy: 10.16  [15360/54000]\n",
            "Batch loss: 2.224117,  Batch Accuracy: 14.84  [16640/54000]\n",
            "Batch loss: 2.237823,  Batch Accuracy: 12.50  [17920/54000]\n",
            "Batch loss: 2.223853,  Batch Accuracy: 10.94  [19200/54000]\n",
            "Batch loss: 2.266335,  Batch Accuracy: 9.38  [20480/54000]\n",
            "Batch loss: 2.234930,  Batch Accuracy: 11.72  [21760/54000]\n",
            "Batch loss: 2.228777,  Batch Accuracy: 11.72  [23040/54000]\n",
            "Batch loss: 2.244638,  Batch Accuracy: 9.38  [24320/54000]\n",
            "Batch loss: 2.178958,  Batch Accuracy: 16.41  [25600/54000]\n",
            "Batch loss: 2.244652,  Batch Accuracy: 8.59  [26880/54000]\n",
            "Batch loss: 2.211028,  Batch Accuracy: 11.72  [28160/54000]\n",
            "Batch loss: 2.255491,  Batch Accuracy: 10.94  [29440/54000]\n",
            "Batch loss: 2.241631,  Batch Accuracy: 13.28  [30720/54000]\n",
            "Batch loss: 2.193839,  Batch Accuracy: 17.19  [32000/54000]\n",
            "Batch loss: 2.253641,  Batch Accuracy: 10.16  [33280/54000]\n",
            "Batch loss: 2.254552,  Batch Accuracy: 13.28  [34560/54000]\n",
            "Batch loss: 2.249292,  Batch Accuracy: 14.84  [35840/54000]\n",
            "Batch loss: 2.279035,  Batch Accuracy: 7.81  [37120/54000]\n",
            "Batch loss: 2.192834,  Batch Accuracy: 13.28  [38400/54000]\n",
            "Batch loss: 2.188096,  Batch Accuracy: 13.28  [39680/54000]\n",
            "Batch loss: 2.231706,  Batch Accuracy: 9.38  [40960/54000]\n",
            "Batch loss: 2.215049,  Batch Accuracy: 12.50  [42240/54000]\n",
            "Batch loss: 2.241318,  Batch Accuracy: 8.59  [43520/54000]\n",
            "Batch loss: 2.193477,  Batch Accuracy: 17.19  [44800/54000]\n",
            "Batch loss: 2.214617,  Batch Accuracy: 13.28  [46080/54000]\n",
            "Batch loss: 2.204957,  Batch Accuracy: 14.84  [47360/54000]\n",
            "Batch loss: 2.205707,  Batch Accuracy: 10.16  [48640/54000]\n",
            "Batch loss: 2.210230,  Batch Accuracy: 9.38  [49920/54000]\n",
            "Batch loss: 2.229307,  Batch Accuracy: 9.38  [51200/54000]\n",
            "Batch loss: 2.226408,  Batch Accuracy: 10.94  [52480/54000]\n",
            "Batch loss: 2.132103,  Batch Accuracy: 21.09  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 12.68%, Loss: 2.2197\n",
            "Validation performance:\n",
            " Accuracy: 13.00%, Loss: 2.2005\n",
            "Test performance: Accuracy:\n",
            " 13.17%, Loss: 2.2020\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Batch loss: 2.217947,  Batch Accuracy: 12.50  [ 1280/54000]\n",
            "Batch loss: 2.232981,  Batch Accuracy: 10.94  [ 2560/54000]\n",
            "Batch loss: 2.161313,  Batch Accuracy: 19.53  [ 3840/54000]\n",
            "Batch loss: 2.148734,  Batch Accuracy: 18.75  [ 5120/54000]\n",
            "Batch loss: 2.208035,  Batch Accuracy: 10.94  [ 6400/54000]\n",
            "Batch loss: 2.218989,  Batch Accuracy: 10.16  [ 7680/54000]\n",
            "Batch loss: 2.186202,  Batch Accuracy: 14.84  [ 8960/54000]\n",
            "Batch loss: 2.181127,  Batch Accuracy: 17.97  [10240/54000]\n",
            "Batch loss: 2.214906,  Batch Accuracy: 12.50  [11520/54000]\n",
            "Batch loss: 2.189301,  Batch Accuracy: 16.41  [12800/54000]\n",
            "Batch loss: 2.232798,  Batch Accuracy: 10.16  [14080/54000]\n",
            "Batch loss: 2.168594,  Batch Accuracy: 21.88  [15360/54000]\n",
            "Batch loss: 2.176292,  Batch Accuracy: 16.41  [16640/54000]\n",
            "Batch loss: 2.134890,  Batch Accuracy: 19.53  [17920/54000]\n",
            "Batch loss: 2.184071,  Batch Accuracy: 14.84  [19200/54000]\n",
            "Batch loss: 2.189202,  Batch Accuracy: 14.06  [20480/54000]\n",
            "Batch loss: 2.202564,  Batch Accuracy: 14.84  [21760/54000]\n",
            "Batch loss: 2.115731,  Batch Accuracy: 20.31  [23040/54000]\n",
            "Batch loss: 2.106215,  Batch Accuracy: 17.19  [24320/54000]\n",
            "Batch loss: 2.162305,  Batch Accuracy: 14.84  [25600/54000]\n",
            "Batch loss: 2.149044,  Batch Accuracy: 18.75  [26880/54000]\n",
            "Batch loss: 2.199390,  Batch Accuracy: 14.06  [28160/54000]\n",
            "Batch loss: 2.205019,  Batch Accuracy: 13.28  [29440/54000]\n",
            "Batch loss: 2.145628,  Batch Accuracy: 19.53  [30720/54000]\n",
            "Batch loss: 2.183057,  Batch Accuracy: 14.84  [32000/54000]\n",
            "Batch loss: 2.221731,  Batch Accuracy: 15.62  [33280/54000]\n",
            "Batch loss: 2.248857,  Batch Accuracy: 13.28  [34560/54000]\n",
            "Batch loss: 2.123839,  Batch Accuracy: 24.22  [35840/54000]\n",
            "Batch loss: 2.175181,  Batch Accuracy: 16.41  [37120/54000]\n",
            "Batch loss: 2.201277,  Batch Accuracy: 17.19  [38400/54000]\n",
            "Batch loss: 2.126967,  Batch Accuracy: 21.09  [39680/54000]\n",
            "Batch loss: 2.104423,  Batch Accuracy: 28.12  [40960/54000]\n",
            "Batch loss: 2.187263,  Batch Accuracy: 16.41  [42240/54000]\n",
            "Batch loss: 2.121632,  Batch Accuracy: 24.22  [43520/54000]\n",
            "Batch loss: 2.193758,  Batch Accuracy: 12.50  [44800/54000]\n",
            "Batch loss: 2.180569,  Batch Accuracy: 19.53  [46080/54000]\n",
            "Batch loss: 2.190541,  Batch Accuracy: 20.31  [47360/54000]\n",
            "Batch loss: 2.163242,  Batch Accuracy: 21.09  [48640/54000]\n",
            "Batch loss: 2.204676,  Batch Accuracy: 13.28  [49920/54000]\n",
            "Batch loss: 2.118170,  Batch Accuracy: 19.53  [51200/54000]\n",
            "Batch loss: 2.149137,  Batch Accuracy: 18.75  [52480/54000]\n",
            "Batch loss: 2.156484,  Batch Accuracy: 25.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 16.56%, Loss: 2.1850\n",
            "Validation performance:\n",
            " Accuracy: 22.18%, Loss: 2.1500\n",
            "Test performance: Accuracy:\n",
            " 21.93%, Loss: 2.1521\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Batch loss: 2.192700,  Batch Accuracy: 21.09  [ 1280/54000]\n",
            "Batch loss: 2.169334,  Batch Accuracy: 21.09  [ 2560/54000]\n",
            "Batch loss: 2.106602,  Batch Accuracy: 23.44  [ 3840/54000]\n",
            "Batch loss: 2.065781,  Batch Accuracy: 29.69  [ 5120/54000]\n",
            "Batch loss: 2.159842,  Batch Accuracy: 19.53  [ 6400/54000]\n",
            "Batch loss: 2.139482,  Batch Accuracy: 21.88  [ 7680/54000]\n",
            "Batch loss: 2.147445,  Batch Accuracy: 25.78  [ 8960/54000]\n",
            "Batch loss: 2.139708,  Batch Accuracy: 25.00  [10240/54000]\n",
            "Batch loss: 2.051002,  Batch Accuracy: 27.34  [11520/54000]\n",
            "Batch loss: 2.135032,  Batch Accuracy: 22.66  [12800/54000]\n",
            "Batch loss: 2.059572,  Batch Accuracy: 28.91  [14080/54000]\n",
            "Batch loss: 2.081649,  Batch Accuracy: 24.22  [15360/54000]\n",
            "Batch loss: 2.142511,  Batch Accuracy: 22.66  [16640/54000]\n",
            "Batch loss: 2.123138,  Batch Accuracy: 21.09  [17920/54000]\n",
            "Batch loss: 2.144339,  Batch Accuracy: 23.44  [19200/54000]\n",
            "Batch loss: 2.102772,  Batch Accuracy: 19.53  [20480/54000]\n",
            "Batch loss: 2.167973,  Batch Accuracy: 21.09  [21760/54000]\n",
            "Batch loss: 2.149384,  Batch Accuracy: 21.88  [23040/54000]\n",
            "Batch loss: 2.138687,  Batch Accuracy: 21.09  [24320/54000]\n",
            "Batch loss: 2.243367,  Batch Accuracy: 12.50  [25600/54000]\n",
            "Batch loss: 2.114275,  Batch Accuracy: 23.44  [26880/54000]\n",
            "Batch loss: 2.123441,  Batch Accuracy: 21.88  [28160/54000]\n",
            "Batch loss: 2.082043,  Batch Accuracy: 23.44  [29440/54000]\n",
            "Batch loss: 2.198742,  Batch Accuracy: 17.97  [30720/54000]\n",
            "Batch loss: 2.014473,  Batch Accuracy: 24.22  [32000/54000]\n",
            "Batch loss: 2.104871,  Batch Accuracy: 23.44  [33280/54000]\n",
            "Batch loss: 2.065385,  Batch Accuracy: 22.66  [34560/54000]\n",
            "Batch loss: 2.150245,  Batch Accuracy: 20.31  [35840/54000]\n",
            "Batch loss: 2.110625,  Batch Accuracy: 23.44  [37120/54000]\n",
            "Batch loss: 2.096883,  Batch Accuracy: 24.22  [38400/54000]\n",
            "Batch loss: 2.055380,  Batch Accuracy: 34.38  [39680/54000]\n",
            "Batch loss: 2.116207,  Batch Accuracy: 26.56  [40960/54000]\n",
            "Batch loss: 2.077965,  Batch Accuracy: 24.22  [42240/54000]\n",
            "Batch loss: 2.081600,  Batch Accuracy: 25.78  [43520/54000]\n",
            "Batch loss: 2.148289,  Batch Accuracy: 25.78  [44800/54000]\n",
            "Batch loss: 2.084489,  Batch Accuracy: 25.78  [46080/54000]\n",
            "Batch loss: 2.075241,  Batch Accuracy: 32.81  [47360/54000]\n",
            "Batch loss: 2.089234,  Batch Accuracy: 28.91  [48640/54000]\n",
            "Batch loss: 1.966228,  Batch Accuracy: 31.25  [49920/54000]\n",
            "Batch loss: 2.098302,  Batch Accuracy: 29.69  [51200/54000]\n",
            "Batch loss: 2.079420,  Batch Accuracy: 19.53  [52480/54000]\n",
            "Batch loss: 2.046709,  Batch Accuracy: 27.34  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 22.92%, Loss: 2.1241\n",
            "Validation performance:\n",
            " Accuracy: 25.58%, Loss: 2.0808\n",
            "Test performance: Accuracy:\n",
            " 25.08%, Loss: 2.0830\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Batch loss: 2.073059,  Batch Accuracy: 22.66  [ 1280/54000]\n",
            "Batch loss: 2.151631,  Batch Accuracy: 28.91  [ 2560/54000]\n",
            "Batch loss: 2.052134,  Batch Accuracy: 23.44  [ 3840/54000]\n",
            "Batch loss: 2.103682,  Batch Accuracy: 21.09  [ 5120/54000]\n",
            "Batch loss: 2.119718,  Batch Accuracy: 21.09  [ 6400/54000]\n",
            "Batch loss: 1.994437,  Batch Accuracy: 25.78  [ 7680/54000]\n",
            "Batch loss: 2.104436,  Batch Accuracy: 21.88  [ 8960/54000]\n",
            "Batch loss: 2.118178,  Batch Accuracy: 17.97  [10240/54000]\n",
            "Batch loss: 2.036204,  Batch Accuracy: 23.44  [11520/54000]\n",
            "Batch loss: 2.042584,  Batch Accuracy: 27.34  [12800/54000]\n",
            "Batch loss: 2.029470,  Batch Accuracy: 28.91  [14080/54000]\n",
            "Batch loss: 2.030107,  Batch Accuracy: 32.03  [15360/54000]\n",
            "Batch loss: 2.052635,  Batch Accuracy: 25.00  [16640/54000]\n",
            "Batch loss: 2.144656,  Batch Accuracy: 20.31  [17920/54000]\n",
            "Batch loss: 2.069169,  Batch Accuracy: 27.34  [19200/54000]\n",
            "Batch loss: 2.110065,  Batch Accuracy: 28.12  [20480/54000]\n",
            "Batch loss: 2.085459,  Batch Accuracy: 21.88  [21760/54000]\n",
            "Batch loss: 2.146577,  Batch Accuracy: 19.53  [23040/54000]\n",
            "Batch loss: 2.120095,  Batch Accuracy: 23.44  [24320/54000]\n",
            "Batch loss: 1.973381,  Batch Accuracy: 32.03  [25600/54000]\n",
            "Batch loss: 2.054149,  Batch Accuracy: 25.00  [26880/54000]\n",
            "Batch loss: 2.071271,  Batch Accuracy: 28.12  [28160/54000]\n",
            "Batch loss: 2.136491,  Batch Accuracy: 19.53  [29440/54000]\n",
            "Batch loss: 2.097506,  Batch Accuracy: 26.56  [30720/54000]\n",
            "Batch loss: 2.023896,  Batch Accuracy: 29.69  [32000/54000]\n",
            "Batch loss: 2.097343,  Batch Accuracy: 29.69  [33280/54000]\n",
            "Batch loss: 2.079833,  Batch Accuracy: 29.69  [34560/54000]\n",
            "Batch loss: 2.102170,  Batch Accuracy: 18.75  [35840/54000]\n",
            "Batch loss: 2.154932,  Batch Accuracy: 25.00  [37120/54000]\n",
            "Batch loss: 2.075402,  Batch Accuracy: 28.91  [38400/54000]\n",
            "Batch loss: 2.169372,  Batch Accuracy: 16.41  [39680/54000]\n",
            "Batch loss: 2.054106,  Batch Accuracy: 30.47  [40960/54000]\n",
            "Batch loss: 2.021472,  Batch Accuracy: 30.47  [42240/54000]\n",
            "Batch loss: 2.113120,  Batch Accuracy: 24.22  [43520/54000]\n",
            "Batch loss: 1.921811,  Batch Accuracy: 32.81  [44800/54000]\n",
            "Batch loss: 2.033845,  Batch Accuracy: 28.91  [46080/54000]\n",
            "Batch loss: 1.955732,  Batch Accuracy: 38.28  [47360/54000]\n",
            "Batch loss: 2.069144,  Batch Accuracy: 28.91  [48640/54000]\n",
            "Batch loss: 1.999088,  Batch Accuracy: 30.47  [49920/54000]\n",
            "Batch loss: 2.108894,  Batch Accuracy: 22.66  [51200/54000]\n",
            "Batch loss: 2.023951,  Batch Accuracy: 36.72  [52480/54000]\n",
            "Batch loss: 2.041531,  Batch Accuracy: 32.81  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 26.47%, Loss: 2.0577\n",
            "Validation performance:\n",
            " Accuracy: 31.70%, Loss: 2.0210\n",
            "Test performance: Accuracy:\n",
            " 31.31%, Loss: 2.0223\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Batch loss: 2.025035,  Batch Accuracy: 32.81  [ 1280/54000]\n",
            "Batch loss: 2.098055,  Batch Accuracy: 30.47  [ 2560/54000]\n",
            "Batch loss: 2.064180,  Batch Accuracy: 27.34  [ 3840/54000]\n",
            "Batch loss: 2.078046,  Batch Accuracy: 28.12  [ 5120/54000]\n",
            "Batch loss: 2.125740,  Batch Accuracy: 30.47  [ 6400/54000]\n",
            "Batch loss: 2.011109,  Batch Accuracy: 44.53  [ 7680/54000]\n",
            "Batch loss: 2.025938,  Batch Accuracy: 33.59  [ 8960/54000]\n",
            "Batch loss: 2.063563,  Batch Accuracy: 30.47  [10240/54000]\n",
            "Batch loss: 2.050788,  Batch Accuracy: 25.00  [11520/54000]\n",
            "Batch loss: 2.062190,  Batch Accuracy: 29.69  [12800/54000]\n",
            "Batch loss: 2.050654,  Batch Accuracy: 30.47  [14080/54000]\n",
            "Batch loss: 2.072030,  Batch Accuracy: 30.47  [15360/54000]\n",
            "Batch loss: 1.980447,  Batch Accuracy: 33.59  [16640/54000]\n",
            "Batch loss: 2.055498,  Batch Accuracy: 23.44  [17920/54000]\n",
            "Batch loss: 1.904837,  Batch Accuracy: 38.28  [19200/54000]\n",
            "Batch loss: 2.029798,  Batch Accuracy: 25.78  [20480/54000]\n",
            "Batch loss: 1.962828,  Batch Accuracy: 33.59  [21760/54000]\n",
            "Batch loss: 2.017964,  Batch Accuracy: 31.25  [23040/54000]\n",
            "Batch loss: 2.009849,  Batch Accuracy: 25.78  [24320/54000]\n",
            "Batch loss: 1.996862,  Batch Accuracy: 26.56  [25600/54000]\n",
            "Batch loss: 2.028850,  Batch Accuracy: 28.12  [26880/54000]\n",
            "Batch loss: 2.070506,  Batch Accuracy: 32.03  [28160/54000]\n",
            "Batch loss: 1.964387,  Batch Accuracy: 33.59  [29440/54000]\n",
            "Batch loss: 1.940376,  Batch Accuracy: 32.03  [30720/54000]\n",
            "Batch loss: 1.977453,  Batch Accuracy: 28.12  [32000/54000]\n",
            "Batch loss: 1.951993,  Batch Accuracy: 39.84  [33280/54000]\n",
            "Batch loss: 1.949448,  Batch Accuracy: 40.62  [34560/54000]\n",
            "Batch loss: 2.034022,  Batch Accuracy: 25.00  [35840/54000]\n",
            "Batch loss: 2.012125,  Batch Accuracy: 40.62  [37120/54000]\n",
            "Batch loss: 2.105957,  Batch Accuracy: 29.69  [38400/54000]\n",
            "Batch loss: 2.043293,  Batch Accuracy: 32.03  [39680/54000]\n",
            "Batch loss: 1.973930,  Batch Accuracy: 45.31  [40960/54000]\n",
            "Batch loss: 1.934074,  Batch Accuracy: 31.25  [42240/54000]\n",
            "Batch loss: 2.003839,  Batch Accuracy: 37.50  [43520/54000]\n",
            "Batch loss: 2.000427,  Batch Accuracy: 35.94  [44800/54000]\n",
            "Batch loss: 1.923971,  Batch Accuracy: 35.94  [46080/54000]\n",
            "Batch loss: 2.039257,  Batch Accuracy: 39.06  [47360/54000]\n",
            "Batch loss: 2.034038,  Batch Accuracy: 33.59  [48640/54000]\n",
            "Batch loss: 2.026791,  Batch Accuracy: 35.94  [49920/54000]\n",
            "Batch loss: 1.994338,  Batch Accuracy: 32.03  [51200/54000]\n",
            "Batch loss: 2.031600,  Batch Accuracy: 27.34  [52480/54000]\n",
            "Batch loss: 2.001376,  Batch Accuracy: 31.25  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 32.22%, Loss: 2.0122\n",
            "Validation performance:\n",
            " Accuracy: 32.25%, Loss: 1.9866\n",
            "Test performance: Accuracy:\n",
            " 32.04%, Loss: 1.9876\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Batch loss: 2.005076,  Batch Accuracy: 24.22  [ 1280/54000]\n",
            "Batch loss: 2.059519,  Batch Accuracy: 34.38  [ 2560/54000]\n",
            "Batch loss: 1.978225,  Batch Accuracy: 32.81  [ 3840/54000]\n",
            "Batch loss: 1.879101,  Batch Accuracy: 43.75  [ 5120/54000]\n",
            "Batch loss: 2.032907,  Batch Accuracy: 28.12  [ 6400/54000]\n",
            "Batch loss: 2.053573,  Batch Accuracy: 28.12  [ 7680/54000]\n",
            "Batch loss: 2.018103,  Batch Accuracy: 36.72  [ 8960/54000]\n",
            "Batch loss: 2.057619,  Batch Accuracy: 29.69  [10240/54000]\n",
            "Batch loss: 1.961501,  Batch Accuracy: 29.69  [11520/54000]\n",
            "Batch loss: 1.956161,  Batch Accuracy: 32.03  [12800/54000]\n",
            "Batch loss: 1.966691,  Batch Accuracy: 30.47  [14080/54000]\n",
            "Batch loss: 2.021070,  Batch Accuracy: 28.91  [15360/54000]\n",
            "Batch loss: 1.932288,  Batch Accuracy: 38.28  [16640/54000]\n",
            "Batch loss: 1.912639,  Batch Accuracy: 41.41  [17920/54000]\n",
            "Batch loss: 1.895608,  Batch Accuracy: 43.75  [19200/54000]\n",
            "Batch loss: 2.008460,  Batch Accuracy: 35.16  [20480/54000]\n",
            "Batch loss: 1.935317,  Batch Accuracy: 34.38  [21760/54000]\n",
            "Batch loss: 2.102481,  Batch Accuracy: 33.59  [23040/54000]\n",
            "Batch loss: 2.067137,  Batch Accuracy: 28.12  [24320/54000]\n",
            "Batch loss: 2.057426,  Batch Accuracy: 25.00  [25600/54000]\n",
            "Batch loss: 1.907201,  Batch Accuracy: 42.19  [26880/54000]\n",
            "Batch loss: 1.957872,  Batch Accuracy: 33.59  [28160/54000]\n",
            "Batch loss: 2.002344,  Batch Accuracy: 42.19  [29440/54000]\n",
            "Batch loss: 2.047187,  Batch Accuracy: 26.56  [30720/54000]\n",
            "Batch loss: 1.965566,  Batch Accuracy: 36.72  [32000/54000]\n",
            "Batch loss: 1.973751,  Batch Accuracy: 39.06  [33280/54000]\n",
            "Batch loss: 1.967586,  Batch Accuracy: 37.50  [34560/54000]\n",
            "Batch loss: 1.938200,  Batch Accuracy: 41.41  [35840/54000]\n",
            "Batch loss: 2.057992,  Batch Accuracy: 32.81  [37120/54000]\n",
            "Batch loss: 1.955222,  Batch Accuracy: 34.38  [38400/54000]\n",
            "Batch loss: 1.962263,  Batch Accuracy: 36.72  [39680/54000]\n",
            "Batch loss: 2.051738,  Batch Accuracy: 35.16  [40960/54000]\n",
            "Batch loss: 2.000811,  Batch Accuracy: 32.03  [42240/54000]\n",
            "Batch loss: 2.034314,  Batch Accuracy: 30.47  [43520/54000]\n",
            "Batch loss: 1.945012,  Batch Accuracy: 34.38  [44800/54000]\n",
            "Batch loss: 1.961718,  Batch Accuracy: 32.81  [46080/54000]\n",
            "Batch loss: 1.886822,  Batch Accuracy: 39.84  [47360/54000]\n",
            "Batch loss: 1.923087,  Batch Accuracy: 32.81  [48640/54000]\n",
            "Batch loss: 1.920758,  Batch Accuracy: 28.12  [49920/54000]\n",
            "Batch loss: 1.939219,  Batch Accuracy: 32.81  [51200/54000]\n",
            "Batch loss: 2.015606,  Batch Accuracy: 21.88  [52480/54000]\n",
            "Batch loss: 2.024759,  Batch Accuracy: 28.12  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 34.37%, Loss: 1.9824\n",
            "Validation performance:\n",
            " Accuracy: 31.07%, Loss: 1.9610\n",
            "Test performance: Accuracy:\n",
            " 30.54%, Loss: 1.9620\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Batch loss: 1.978695,  Batch Accuracy: 29.69  [ 1280/54000]\n",
            "Batch loss: 1.910122,  Batch Accuracy: 36.72  [ 2560/54000]\n",
            "Batch loss: 1.951607,  Batch Accuracy: 32.03  [ 3840/54000]\n",
            "Batch loss: 2.015039,  Batch Accuracy: 29.69  [ 5120/54000]\n",
            "Batch loss: 1.999397,  Batch Accuracy: 33.59  [ 6400/54000]\n",
            "Batch loss: 1.990815,  Batch Accuracy: 35.16  [ 7680/54000]\n",
            "Batch loss: 1.939628,  Batch Accuracy: 28.12  [ 8960/54000]\n",
            "Batch loss: 1.930144,  Batch Accuracy: 33.59  [10240/54000]\n",
            "Batch loss: 2.035806,  Batch Accuracy: 28.12  [11520/54000]\n",
            "Batch loss: 2.035463,  Batch Accuracy: 37.50  [12800/54000]\n",
            "Batch loss: 1.991147,  Batch Accuracy: 40.62  [14080/54000]\n",
            "Batch loss: 1.959621,  Batch Accuracy: 39.84  [15360/54000]\n",
            "Batch loss: 2.012220,  Batch Accuracy: 33.59  [16640/54000]\n",
            "Batch loss: 1.985640,  Batch Accuracy: 39.84  [17920/54000]\n",
            "Batch loss: 2.010143,  Batch Accuracy: 37.50  [19200/54000]\n",
            "Batch loss: 1.995534,  Batch Accuracy: 36.72  [20480/54000]\n",
            "Batch loss: 1.956944,  Batch Accuracy: 34.38  [21760/54000]\n",
            "Batch loss: 2.010009,  Batch Accuracy: 28.91  [23040/54000]\n",
            "Batch loss: 1.987140,  Batch Accuracy: 33.59  [24320/54000]\n",
            "Batch loss: 1.950368,  Batch Accuracy: 39.84  [25600/54000]\n",
            "Batch loss: 1.967304,  Batch Accuracy: 29.69  [26880/54000]\n",
            "Batch loss: 1.894849,  Batch Accuracy: 35.94  [28160/54000]\n",
            "Batch loss: 1.928740,  Batch Accuracy: 32.03  [29440/54000]\n",
            "Batch loss: 1.958398,  Batch Accuracy: 32.81  [30720/54000]\n",
            "Batch loss: 1.893268,  Batch Accuracy: 35.16  [32000/54000]\n",
            "Batch loss: 1.945366,  Batch Accuracy: 35.94  [33280/54000]\n",
            "Batch loss: 2.012443,  Batch Accuracy: 29.69  [34560/54000]\n",
            "Batch loss: 1.933046,  Batch Accuracy: 40.62  [35840/54000]\n",
            "Batch loss: 2.007885,  Batch Accuracy: 34.38  [37120/54000]\n",
            "Batch loss: 1.958204,  Batch Accuracy: 31.25  [38400/54000]\n",
            "Batch loss: 1.901610,  Batch Accuracy: 32.81  [39680/54000]\n",
            "Batch loss: 1.990531,  Batch Accuracy: 30.47  [40960/54000]\n",
            "Batch loss: 1.950932,  Batch Accuracy: 32.81  [42240/54000]\n",
            "Batch loss: 2.107339,  Batch Accuracy: 28.91  [43520/54000]\n",
            "Batch loss: 2.034951,  Batch Accuracy: 29.69  [44800/54000]\n",
            "Batch loss: 2.060769,  Batch Accuracy: 32.81  [46080/54000]\n",
            "Batch loss: 1.895976,  Batch Accuracy: 35.16  [47360/54000]\n",
            "Batch loss: 1.873029,  Batch Accuracy: 40.62  [48640/54000]\n",
            "Batch loss: 1.927675,  Batch Accuracy: 41.41  [49920/54000]\n",
            "Batch loss: 1.955823,  Batch Accuracy: 32.81  [51200/54000]\n",
            "Batch loss: 1.875157,  Batch Accuracy: 32.03  [52480/54000]\n",
            "Batch loss: 2.099426,  Batch Accuracy: 25.78  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 35.09%, Loss: 1.9585\n",
            "Validation performance:\n",
            " Accuracy: 35.63%, Loss: 1.9392\n",
            "Test performance: Accuracy:\n",
            " 35.77%, Loss: 1.9384\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Batch loss: 1.965230,  Batch Accuracy: 42.97  [ 1280/54000]\n",
            "Batch loss: 1.969488,  Batch Accuracy: 39.06  [ 2560/54000]\n",
            "Batch loss: 1.896201,  Batch Accuracy: 35.94  [ 3840/54000]\n",
            "Batch loss: 2.016954,  Batch Accuracy: 29.69  [ 5120/54000]\n",
            "Batch loss: 1.826458,  Batch Accuracy: 41.41  [ 6400/54000]\n",
            "Batch loss: 1.937707,  Batch Accuracy: 37.50  [ 7680/54000]\n",
            "Batch loss: 1.872513,  Batch Accuracy: 36.72  [ 8960/54000]\n",
            "Batch loss: 1.945416,  Batch Accuracy: 32.81  [10240/54000]\n",
            "Batch loss: 1.897441,  Batch Accuracy: 35.94  [11520/54000]\n",
            "Batch loss: 2.043651,  Batch Accuracy: 26.56  [12800/54000]\n",
            "Batch loss: 1.902212,  Batch Accuracy: 31.25  [14080/54000]\n",
            "Batch loss: 1.961947,  Batch Accuracy: 28.12  [15360/54000]\n",
            "Batch loss: 1.964179,  Batch Accuracy: 31.25  [16640/54000]\n",
            "Batch loss: 1.986052,  Batch Accuracy: 38.28  [17920/54000]\n",
            "Batch loss: 1.872650,  Batch Accuracy: 41.41  [19200/54000]\n",
            "Batch loss: 2.025131,  Batch Accuracy: 34.38  [20480/54000]\n",
            "Batch loss: 1.991207,  Batch Accuracy: 35.16  [21760/54000]\n",
            "Batch loss: 1.991213,  Batch Accuracy: 41.41  [23040/54000]\n",
            "Batch loss: 2.018003,  Batch Accuracy: 37.50  [24320/54000]\n",
            "Batch loss: 1.869301,  Batch Accuracy: 35.16  [25600/54000]\n",
            "Batch loss: 1.814063,  Batch Accuracy: 38.28  [26880/54000]\n",
            "Batch loss: 1.890141,  Batch Accuracy: 42.19  [28160/54000]\n",
            "Batch loss: 2.013099,  Batch Accuracy: 30.47  [29440/54000]\n",
            "Batch loss: 1.960028,  Batch Accuracy: 35.16  [30720/54000]\n",
            "Batch loss: 1.988379,  Batch Accuracy: 35.16  [32000/54000]\n",
            "Batch loss: 1.958766,  Batch Accuracy: 32.03  [33280/54000]\n",
            "Batch loss: 1.917647,  Batch Accuracy: 32.03  [34560/54000]\n",
            "Batch loss: 1.870142,  Batch Accuracy: 39.06  [35840/54000]\n",
            "Batch loss: 1.898506,  Batch Accuracy: 33.59  [37120/54000]\n",
            "Batch loss: 1.867863,  Batch Accuracy: 37.50  [38400/54000]\n",
            "Batch loss: 1.993337,  Batch Accuracy: 34.38  [39680/54000]\n",
            "Batch loss: 1.968076,  Batch Accuracy: 32.81  [40960/54000]\n",
            "Batch loss: 1.838496,  Batch Accuracy: 39.06  [42240/54000]\n",
            "Batch loss: 1.861055,  Batch Accuracy: 39.84  [43520/54000]\n",
            "Batch loss: 1.823856,  Batch Accuracy: 39.06  [44800/54000]\n",
            "Batch loss: 1.983130,  Batch Accuracy: 35.16  [46080/54000]\n",
            "Batch loss: 1.912260,  Batch Accuracy: 36.72  [47360/54000]\n",
            "Batch loss: 1.927339,  Batch Accuracy: 27.34  [48640/54000]\n",
            "Batch loss: 1.921116,  Batch Accuracy: 35.94  [49920/54000]\n",
            "Batch loss: 1.969841,  Batch Accuracy: 32.03  [51200/54000]\n",
            "Batch loss: 1.811063,  Batch Accuracy: 37.50  [52480/54000]\n",
            "Batch loss: 1.887721,  Batch Accuracy: 36.72  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 35.71%, Loss: 1.9343\n",
            "Validation performance:\n",
            " Accuracy: 35.12%, Loss: 1.9128\n",
            "Test performance: Accuracy:\n",
            " 35.18%, Loss: 1.9112\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Batch loss: 1.932009,  Batch Accuracy: 33.59  [ 1280/54000]\n",
            "Batch loss: 1.916605,  Batch Accuracy: 35.16  [ 2560/54000]\n",
            "Batch loss: 1.984886,  Batch Accuracy: 26.56  [ 3840/54000]\n",
            "Batch loss: 1.853578,  Batch Accuracy: 35.94  [ 5120/54000]\n",
            "Batch loss: 1.897303,  Batch Accuracy: 36.72  [ 6400/54000]\n",
            "Batch loss: 1.900806,  Batch Accuracy: 36.72  [ 7680/54000]\n",
            "Batch loss: 1.898864,  Batch Accuracy: 39.06  [ 8960/54000]\n",
            "Batch loss: 1.996202,  Batch Accuracy: 30.47  [10240/54000]\n",
            "Batch loss: 1.984539,  Batch Accuracy: 32.81  [11520/54000]\n",
            "Batch loss: 1.902737,  Batch Accuracy: 32.81  [12800/54000]\n",
            "Batch loss: 1.868086,  Batch Accuracy: 38.28  [14080/54000]\n",
            "Batch loss: 1.841456,  Batch Accuracy: 38.28  [15360/54000]\n",
            "Batch loss: 1.942341,  Batch Accuracy: 33.59  [16640/54000]\n",
            "Batch loss: 1.967956,  Batch Accuracy: 35.16  [17920/54000]\n",
            "Batch loss: 1.891994,  Batch Accuracy: 39.06  [19200/54000]\n",
            "Batch loss: 1.907283,  Batch Accuracy: 37.50  [20480/54000]\n",
            "Batch loss: 1.906997,  Batch Accuracy: 40.62  [21760/54000]\n",
            "Batch loss: 1.936709,  Batch Accuracy: 33.59  [23040/54000]\n",
            "Batch loss: 1.856372,  Batch Accuracy: 43.75  [24320/54000]\n",
            "Batch loss: 2.005846,  Batch Accuracy: 32.03  [25600/54000]\n",
            "Batch loss: 1.925155,  Batch Accuracy: 35.94  [26880/54000]\n",
            "Batch loss: 1.830614,  Batch Accuracy: 39.84  [28160/54000]\n",
            "Batch loss: 1.937489,  Batch Accuracy: 33.59  [29440/54000]\n",
            "Batch loss: 1.839149,  Batch Accuracy: 33.59  [30720/54000]\n",
            "Batch loss: 1.965506,  Batch Accuracy: 29.69  [32000/54000]\n",
            "Batch loss: 1.912556,  Batch Accuracy: 37.50  [33280/54000]\n",
            "Batch loss: 1.929277,  Batch Accuracy: 35.16  [34560/54000]\n",
            "Batch loss: 1.903827,  Batch Accuracy: 38.28  [35840/54000]\n",
            "Batch loss: 1.914108,  Batch Accuracy: 30.47  [37120/54000]\n",
            "Batch loss: 1.904204,  Batch Accuracy: 36.72  [38400/54000]\n",
            "Batch loss: 1.939340,  Batch Accuracy: 33.59  [39680/54000]\n",
            "Batch loss: 1.927804,  Batch Accuracy: 43.75  [40960/54000]\n",
            "Batch loss: 1.859319,  Batch Accuracy: 37.50  [42240/54000]\n",
            "Batch loss: 1.984931,  Batch Accuracy: 34.38  [43520/54000]\n",
            "Batch loss: 1.816912,  Batch Accuracy: 33.59  [44800/54000]\n",
            "Batch loss: 1.854426,  Batch Accuracy: 41.41  [46080/54000]\n",
            "Batch loss: 1.870274,  Batch Accuracy: 35.94  [47360/54000]\n",
            "Batch loss: 1.765185,  Batch Accuracy: 42.19  [48640/54000]\n",
            "Batch loss: 1.905505,  Batch Accuracy: 31.25  [49920/54000]\n",
            "Batch loss: 1.945191,  Batch Accuracy: 29.69  [51200/54000]\n",
            "Batch loss: 1.916526,  Batch Accuracy: 37.50  [52480/54000]\n",
            "Batch loss: 1.924354,  Batch Accuracy: 31.25  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 35.86%, Loss: 1.9056\n",
            "Validation performance:\n",
            " Accuracy: 34.97%, Loss: 1.8843\n",
            "Test performance: Accuracy:\n",
            " 35.05%, Loss: 1.8811\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Batch loss: 1.944368,  Batch Accuracy: 34.38  [ 1280/54000]\n",
            "Batch loss: 2.019156,  Batch Accuracy: 30.47  [ 2560/54000]\n",
            "Batch loss: 1.907541,  Batch Accuracy: 31.25  [ 3840/54000]\n",
            "Batch loss: 2.011938,  Batch Accuracy: 31.25  [ 5120/54000]\n",
            "Batch loss: 1.782256,  Batch Accuracy: 36.72  [ 6400/54000]\n",
            "Batch loss: 1.918888,  Batch Accuracy: 33.59  [ 7680/54000]\n",
            "Batch loss: 1.756730,  Batch Accuracy: 48.44  [ 8960/54000]\n",
            "Batch loss: 1.832911,  Batch Accuracy: 33.59  [10240/54000]\n",
            "Batch loss: 1.845205,  Batch Accuracy: 40.62  [11520/54000]\n",
            "Batch loss: 1.868687,  Batch Accuracy: 35.94  [12800/54000]\n",
            "Batch loss: 1.868176,  Batch Accuracy: 39.06  [14080/54000]\n",
            "Batch loss: 1.850905,  Batch Accuracy: 35.94  [15360/54000]\n",
            "Batch loss: 1.949748,  Batch Accuracy: 38.28  [16640/54000]\n",
            "Batch loss: 1.901537,  Batch Accuracy: 34.38  [17920/54000]\n",
            "Batch loss: 1.842499,  Batch Accuracy: 33.59  [19200/54000]\n",
            "Batch loss: 1.867188,  Batch Accuracy: 38.28  [20480/54000]\n",
            "Batch loss: 1.958218,  Batch Accuracy: 26.56  [21760/54000]\n",
            "Batch loss: 1.883077,  Batch Accuracy: 30.47  [23040/54000]\n",
            "Batch loss: 1.873693,  Batch Accuracy: 25.78  [24320/54000]\n",
            "Batch loss: 1.757742,  Batch Accuracy: 41.41  [25600/54000]\n",
            "Batch loss: 1.821258,  Batch Accuracy: 32.81  [26880/54000]\n",
            "Batch loss: 1.867272,  Batch Accuracy: 33.59  [28160/54000]\n",
            "Batch loss: 1.871965,  Batch Accuracy: 35.94  [29440/54000]\n",
            "Batch loss: 1.851820,  Batch Accuracy: 35.16  [30720/54000]\n",
            "Batch loss: 1.832063,  Batch Accuracy: 42.19  [32000/54000]\n",
            "Batch loss: 1.882074,  Batch Accuracy: 39.06  [33280/54000]\n",
            "Batch loss: 1.897041,  Batch Accuracy: 41.41  [34560/54000]\n",
            "Batch loss: 1.833406,  Batch Accuracy: 38.28  [35840/54000]\n",
            "Batch loss: 1.872913,  Batch Accuracy: 38.28  [37120/54000]\n",
            "Batch loss: 1.832894,  Batch Accuracy: 42.19  [38400/54000]\n",
            "Batch loss: 1.935569,  Batch Accuracy: 28.91  [39680/54000]\n",
            "Batch loss: 1.715339,  Batch Accuracy: 44.53  [40960/54000]\n",
            "Batch loss: 1.867912,  Batch Accuracy: 33.59  [42240/54000]\n",
            "Batch loss: 1.850250,  Batch Accuracy: 31.25  [43520/54000]\n",
            "Batch loss: 1.868451,  Batch Accuracy: 34.38  [44800/54000]\n",
            "Batch loss: 1.773084,  Batch Accuracy: 41.41  [46080/54000]\n",
            "Batch loss: 1.777167,  Batch Accuracy: 40.62  [47360/54000]\n",
            "Batch loss: 1.828698,  Batch Accuracy: 35.94  [48640/54000]\n",
            "Batch loss: 1.908721,  Batch Accuracy: 32.03  [49920/54000]\n",
            "Batch loss: 1.840118,  Batch Accuracy: 35.94  [51200/54000]\n",
            "Batch loss: 1.843042,  Batch Accuracy: 39.06  [52480/54000]\n",
            "Batch loss: 1.879889,  Batch Accuracy: 39.06  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 35.93%, Loss: 1.8702\n",
            "Validation performance:\n",
            " Accuracy: 36.22%, Loss: 1.8436\n",
            "Test performance: Accuracy:\n",
            " 36.61%, Loss: 1.8388\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Batch loss: 1.871829,  Batch Accuracy: 33.59  [ 1280/54000]\n",
            "Batch loss: 1.847682,  Batch Accuracy: 39.84  [ 2560/54000]\n",
            "Batch loss: 1.867847,  Batch Accuracy: 37.50  [ 3840/54000]\n",
            "Batch loss: 1.906985,  Batch Accuracy: 28.12  [ 5120/54000]\n",
            "Batch loss: 1.829871,  Batch Accuracy: 36.72  [ 6400/54000]\n",
            "Batch loss: 1.816578,  Batch Accuracy: 36.72  [ 7680/54000]\n",
            "Batch loss: 1.847238,  Batch Accuracy: 35.94  [ 8960/54000]\n",
            "Batch loss: 1.853134,  Batch Accuracy: 34.38  [10240/54000]\n",
            "Batch loss: 1.784723,  Batch Accuracy: 35.94  [11520/54000]\n",
            "Batch loss: 1.907287,  Batch Accuracy: 33.59  [12800/54000]\n",
            "Batch loss: 1.813121,  Batch Accuracy: 39.06  [14080/54000]\n",
            "Batch loss: 1.819310,  Batch Accuracy: 35.94  [15360/54000]\n",
            "Batch loss: 1.798943,  Batch Accuracy: 36.72  [16640/54000]\n",
            "Batch loss: 1.860396,  Batch Accuracy: 39.84  [17920/54000]\n",
            "Batch loss: 1.907670,  Batch Accuracy: 32.03  [19200/54000]\n",
            "Batch loss: 1.882768,  Batch Accuracy: 36.72  [20480/54000]\n",
            "Batch loss: 1.795307,  Batch Accuracy: 40.62  [21760/54000]\n",
            "Batch loss: 1.743636,  Batch Accuracy: 39.06  [23040/54000]\n",
            "Batch loss: 1.844902,  Batch Accuracy: 35.94  [24320/54000]\n",
            "Batch loss: 1.729840,  Batch Accuracy: 43.75  [25600/54000]\n",
            "Batch loss: 1.848649,  Batch Accuracy: 34.38  [26880/54000]\n",
            "Batch loss: 1.888198,  Batch Accuracy: 33.59  [28160/54000]\n",
            "Batch loss: 1.830923,  Batch Accuracy: 33.59  [29440/54000]\n",
            "Batch loss: 1.943277,  Batch Accuracy: 29.69  [30720/54000]\n",
            "Batch loss: 1.740681,  Batch Accuracy: 37.50  [32000/54000]\n",
            "Batch loss: 1.746641,  Batch Accuracy: 38.28  [33280/54000]\n",
            "Batch loss: 1.715724,  Batch Accuracy: 44.53  [34560/54000]\n",
            "Batch loss: 1.815434,  Batch Accuracy: 42.19  [35840/54000]\n",
            "Batch loss: 1.823389,  Batch Accuracy: 31.25  [37120/54000]\n",
            "Batch loss: 1.783675,  Batch Accuracy: 39.06  [38400/54000]\n",
            "Batch loss: 1.891961,  Batch Accuracy: 35.16  [39680/54000]\n",
            "Batch loss: 1.827955,  Batch Accuracy: 37.50  [40960/54000]\n",
            "Batch loss: 1.763210,  Batch Accuracy: 40.62  [42240/54000]\n",
            "Batch loss: 1.797097,  Batch Accuracy: 37.50  [43520/54000]\n",
            "Batch loss: 1.719493,  Batch Accuracy: 39.84  [44800/54000]\n",
            "Batch loss: 1.757492,  Batch Accuracy: 36.72  [46080/54000]\n",
            "Batch loss: 1.803299,  Batch Accuracy: 37.50  [47360/54000]\n",
            "Batch loss: 1.790198,  Batch Accuracy: 35.94  [48640/54000]\n",
            "Batch loss: 1.830565,  Batch Accuracy: 36.72  [49920/54000]\n",
            "Batch loss: 1.787180,  Batch Accuracy: 41.41  [51200/54000]\n",
            "Batch loss: 1.853920,  Batch Accuracy: 35.16  [52480/54000]\n",
            "Batch loss: 1.766096,  Batch Accuracy: 39.84  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 36.79%, Loss: 1.8251\n",
            "Validation performance:\n",
            " Accuracy: 37.97%, Loss: 1.7960\n",
            "Test performance: Accuracy:\n",
            " 38.22%, Loss: 1.7900\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Batch loss: 1.809058,  Batch Accuracy: 35.16  [ 1280/54000]\n",
            "Batch loss: 1.859067,  Batch Accuracy: 35.94  [ 2560/54000]\n",
            "Batch loss: 1.796777,  Batch Accuracy: 38.28  [ 3840/54000]\n",
            "Batch loss: 1.770101,  Batch Accuracy: 36.72  [ 5120/54000]\n",
            "Batch loss: 1.802190,  Batch Accuracy: 39.06  [ 6400/54000]\n",
            "Batch loss: 1.677802,  Batch Accuracy: 51.56  [ 7680/54000]\n",
            "Batch loss: 1.809314,  Batch Accuracy: 33.59  [ 8960/54000]\n",
            "Batch loss: 1.827286,  Batch Accuracy: 39.06  [10240/54000]\n",
            "Batch loss: 1.749563,  Batch Accuracy: 40.62  [11520/54000]\n",
            "Batch loss: 1.762476,  Batch Accuracy: 37.50  [12800/54000]\n",
            "Batch loss: 1.677153,  Batch Accuracy: 39.84  [14080/54000]\n",
            "Batch loss: 1.762089,  Batch Accuracy: 38.28  [15360/54000]\n",
            "Batch loss: 1.865420,  Batch Accuracy: 37.50  [16640/54000]\n",
            "Batch loss: 1.774888,  Batch Accuracy: 41.41  [17920/54000]\n",
            "Batch loss: 1.855237,  Batch Accuracy: 35.16  [19200/54000]\n",
            "Batch loss: 1.781424,  Batch Accuracy: 38.28  [20480/54000]\n",
            "Batch loss: 1.799362,  Batch Accuracy: 30.47  [21760/54000]\n",
            "Batch loss: 1.804262,  Batch Accuracy: 41.41  [23040/54000]\n",
            "Batch loss: 1.845735,  Batch Accuracy: 34.38  [24320/54000]\n",
            "Batch loss: 1.726565,  Batch Accuracy: 44.53  [25600/54000]\n",
            "Batch loss: 1.826998,  Batch Accuracy: 33.59  [26880/54000]\n",
            "Batch loss: 1.818099,  Batch Accuracy: 33.59  [28160/54000]\n",
            "Batch loss: 1.733430,  Batch Accuracy: 39.06  [29440/54000]\n",
            "Batch loss: 1.707933,  Batch Accuracy: 39.84  [30720/54000]\n",
            "Batch loss: 1.881608,  Batch Accuracy: 27.34  [32000/54000]\n",
            "Batch loss: 1.764542,  Batch Accuracy: 39.06  [33280/54000]\n",
            "Batch loss: 1.793928,  Batch Accuracy: 37.50  [34560/54000]\n",
            "Batch loss: 1.824677,  Batch Accuracy: 34.38  [35840/54000]\n",
            "Batch loss: 1.825937,  Batch Accuracy: 30.47  [37120/54000]\n",
            "Batch loss: 1.708658,  Batch Accuracy: 36.72  [38400/54000]\n",
            "Batch loss: 1.722322,  Batch Accuracy: 35.94  [39680/54000]\n",
            "Batch loss: 1.708067,  Batch Accuracy: 42.97  [40960/54000]\n",
            "Batch loss: 1.697354,  Batch Accuracy: 40.62  [42240/54000]\n",
            "Batch loss: 1.701020,  Batch Accuracy: 45.31  [43520/54000]\n",
            "Batch loss: 1.751620,  Batch Accuracy: 38.28  [44800/54000]\n",
            "Batch loss: 1.727759,  Batch Accuracy: 36.72  [46080/54000]\n",
            "Batch loss: 1.742998,  Batch Accuracy: 40.62  [47360/54000]\n",
            "Batch loss: 1.740928,  Batch Accuracy: 39.84  [48640/54000]\n",
            "Batch loss: 1.773019,  Batch Accuracy: 35.94  [49920/54000]\n",
            "Batch loss: 1.778883,  Batch Accuracy: 38.28  [51200/54000]\n",
            "Batch loss: 1.661487,  Batch Accuracy: 42.97  [52480/54000]\n",
            "Batch loss: 1.764610,  Batch Accuracy: 39.84  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 38.14%, Loss: 1.7714\n",
            "Validation performance:\n",
            " Accuracy: 38.97%, Loss: 1.7390\n",
            "Test performance: Accuracy:\n",
            " 38.93%, Loss: 1.7320\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Batch loss: 1.704506,  Batch Accuracy: 33.59  [ 1280/54000]\n",
            "Batch loss: 1.657266,  Batch Accuracy: 38.28  [ 2560/54000]\n",
            "Batch loss: 1.728993,  Batch Accuracy: 39.84  [ 3840/54000]\n",
            "Batch loss: 1.746908,  Batch Accuracy: 39.06  [ 5120/54000]\n",
            "Batch loss: 1.804017,  Batch Accuracy: 36.72  [ 6400/54000]\n",
            "Batch loss: 1.759125,  Batch Accuracy: 39.84  [ 7680/54000]\n",
            "Batch loss: 1.764681,  Batch Accuracy: 35.16  [ 8960/54000]\n",
            "Batch loss: 1.752711,  Batch Accuracy: 37.50  [10240/54000]\n",
            "Batch loss: 1.741600,  Batch Accuracy: 41.41  [11520/54000]\n",
            "Batch loss: 1.740777,  Batch Accuracy: 39.84  [12800/54000]\n",
            "Batch loss: 1.708722,  Batch Accuracy: 42.19  [14080/54000]\n",
            "Batch loss: 1.633481,  Batch Accuracy: 52.34  [15360/54000]\n",
            "Batch loss: 1.756875,  Batch Accuracy: 35.16  [16640/54000]\n",
            "Batch loss: 1.700475,  Batch Accuracy: 39.06  [17920/54000]\n",
            "Batch loss: 1.660044,  Batch Accuracy: 42.97  [19200/54000]\n",
            "Batch loss: 1.821922,  Batch Accuracy: 31.25  [20480/54000]\n",
            "Batch loss: 1.651788,  Batch Accuracy: 43.75  [21760/54000]\n",
            "Batch loss: 1.762105,  Batch Accuracy: 38.28  [23040/54000]\n",
            "Batch loss: 1.661669,  Batch Accuracy: 42.19  [24320/54000]\n",
            "Batch loss: 1.807310,  Batch Accuracy: 34.38  [25600/54000]\n",
            "Batch loss: 1.787408,  Batch Accuracy: 32.03  [26880/54000]\n",
            "Batch loss: 1.685752,  Batch Accuracy: 39.84  [28160/54000]\n",
            "Batch loss: 1.681581,  Batch Accuracy: 41.41  [29440/54000]\n",
            "Batch loss: 1.755793,  Batch Accuracy: 41.41  [30720/54000]\n",
            "Batch loss: 1.792978,  Batch Accuracy: 35.94  [32000/54000]\n",
            "Batch loss: 1.759974,  Batch Accuracy: 34.38  [33280/54000]\n",
            "Batch loss: 1.696050,  Batch Accuracy: 39.06  [34560/54000]\n",
            "Batch loss: 1.771512,  Batch Accuracy: 34.38  [35840/54000]\n",
            "Batch loss: 1.564935,  Batch Accuracy: 48.44  [37120/54000]\n",
            "Batch loss: 1.690342,  Batch Accuracy: 40.62  [38400/54000]\n",
            "Batch loss: 1.765600,  Batch Accuracy: 36.72  [39680/54000]\n",
            "Batch loss: 1.681138,  Batch Accuracy: 43.75  [40960/54000]\n",
            "Batch loss: 1.698595,  Batch Accuracy: 42.19  [42240/54000]\n",
            "Batch loss: 1.647850,  Batch Accuracy: 39.06  [43520/54000]\n",
            "Batch loss: 1.608986,  Batch Accuracy: 43.75  [44800/54000]\n",
            "Batch loss: 1.688053,  Batch Accuracy: 42.97  [46080/54000]\n",
            "Batch loss: 1.653300,  Batch Accuracy: 39.84  [47360/54000]\n",
            "Batch loss: 1.651922,  Batch Accuracy: 39.06  [48640/54000]\n",
            "Batch loss: 1.695406,  Batch Accuracy: 46.88  [49920/54000]\n",
            "Batch loss: 1.733876,  Batch Accuracy: 38.28  [51200/54000]\n",
            "Batch loss: 1.677225,  Batch Accuracy: 36.72  [52480/54000]\n",
            "Batch loss: 1.672653,  Batch Accuracy: 40.62  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 39.58%, Loss: 1.7091\n",
            "Validation performance:\n",
            " Accuracy: 40.78%, Loss: 1.6675\n",
            "Test performance: Accuracy:\n",
            " 40.62%, Loss: 1.6603\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Batch loss: 1.690108,  Batch Accuracy: 41.41  [ 1280/54000]\n",
            "Batch loss: 1.612779,  Batch Accuracy: 48.44  [ 2560/54000]\n",
            "Batch loss: 1.596387,  Batch Accuracy: 42.19  [ 3840/54000]\n",
            "Batch loss: 1.789188,  Batch Accuracy: 35.94  [ 5120/54000]\n",
            "Batch loss: 1.604439,  Batch Accuracy: 42.19  [ 6400/54000]\n",
            "Batch loss: 1.627741,  Batch Accuracy: 42.19  [ 7680/54000]\n",
            "Batch loss: 1.549301,  Batch Accuracy: 46.09  [ 8960/54000]\n",
            "Batch loss: 1.582709,  Batch Accuracy: 48.44  [10240/54000]\n",
            "Batch loss: 1.686834,  Batch Accuracy: 39.06  [11520/54000]\n",
            "Batch loss: 1.792737,  Batch Accuracy: 32.81  [12800/54000]\n",
            "Batch loss: 1.636795,  Batch Accuracy: 42.19  [14080/54000]\n",
            "Batch loss: 1.594322,  Batch Accuracy: 43.75  [15360/54000]\n",
            "Batch loss: 1.626216,  Batch Accuracy: 42.97  [16640/54000]\n",
            "Batch loss: 1.671255,  Batch Accuracy: 39.84  [17920/54000]\n",
            "Batch loss: 1.730330,  Batch Accuracy: 39.84  [19200/54000]\n",
            "Batch loss: 1.641533,  Batch Accuracy: 44.53  [20480/54000]\n",
            "Batch loss: 1.624636,  Batch Accuracy: 42.97  [21760/54000]\n",
            "Batch loss: 1.631764,  Batch Accuracy: 39.06  [23040/54000]\n",
            "Batch loss: 1.663523,  Batch Accuracy: 36.72  [24320/54000]\n",
            "Batch loss: 1.611927,  Batch Accuracy: 41.41  [25600/54000]\n",
            "Batch loss: 1.590637,  Batch Accuracy: 43.75  [26880/54000]\n",
            "Batch loss: 1.663549,  Batch Accuracy: 42.19  [28160/54000]\n",
            "Batch loss: 1.657462,  Batch Accuracy: 41.41  [29440/54000]\n",
            "Batch loss: 1.633498,  Batch Accuracy: 42.19  [30720/54000]\n",
            "Batch loss: 1.668968,  Batch Accuracy: 38.28  [32000/54000]\n",
            "Batch loss: 1.600148,  Batch Accuracy: 43.75  [33280/54000]\n",
            "Batch loss: 1.672394,  Batch Accuracy: 36.72  [34560/54000]\n",
            "Batch loss: 1.659680,  Batch Accuracy: 40.62  [35840/54000]\n",
            "Batch loss: 1.544257,  Batch Accuracy: 48.44  [37120/54000]\n",
            "Batch loss: 1.597385,  Batch Accuracy: 45.31  [38400/54000]\n",
            "Batch loss: 1.640707,  Batch Accuracy: 35.16  [39680/54000]\n",
            "Batch loss: 1.662586,  Batch Accuracy: 35.16  [40960/54000]\n",
            "Batch loss: 1.647089,  Batch Accuracy: 37.50  [42240/54000]\n",
            "Batch loss: 1.571535,  Batch Accuracy: 45.31  [43520/54000]\n",
            "Batch loss: 1.681768,  Batch Accuracy: 35.16  [44800/54000]\n",
            "Batch loss: 1.620760,  Batch Accuracy: 44.53  [46080/54000]\n",
            "Batch loss: 1.606343,  Batch Accuracy: 37.50  [47360/54000]\n",
            "Batch loss: 1.710466,  Batch Accuracy: 32.81  [48640/54000]\n",
            "Batch loss: 1.576317,  Batch Accuracy: 48.44  [49920/54000]\n",
            "Batch loss: 1.517725,  Batch Accuracy: 49.22  [51200/54000]\n",
            "Batch loss: 1.510382,  Batch Accuracy: 46.88  [52480/54000]\n",
            "Batch loss: 1.543373,  Batch Accuracy: 46.88  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 41.20%, Loss: 1.6360\n",
            "Validation performance:\n",
            " Accuracy: 42.35%, Loss: 1.5960\n",
            "Test performance: Accuracy:\n",
            " 42.16%, Loss: 1.5904\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Batch loss: 1.529935,  Batch Accuracy: 48.44  [ 1280/54000]\n",
            "Batch loss: 1.489621,  Batch Accuracy: 49.22  [ 2560/54000]\n",
            "Batch loss: 1.624929,  Batch Accuracy: 42.97  [ 3840/54000]\n",
            "Batch loss: 1.637965,  Batch Accuracy: 42.19  [ 5120/54000]\n",
            "Batch loss: 1.508278,  Batch Accuracy: 45.31  [ 6400/54000]\n",
            "Batch loss: 1.556415,  Batch Accuracy: 39.84  [ 7680/54000]\n",
            "Batch loss: 1.551167,  Batch Accuracy: 46.88  [ 8960/54000]\n",
            "Batch loss: 1.642802,  Batch Accuracy: 42.97  [10240/54000]\n",
            "Batch loss: 1.624415,  Batch Accuracy: 36.72  [11520/54000]\n",
            "Batch loss: 1.549421,  Batch Accuracy: 44.53  [12800/54000]\n",
            "Batch loss: 1.501293,  Batch Accuracy: 50.00  [14080/54000]\n",
            "Batch loss: 1.534709,  Batch Accuracy: 44.53  [15360/54000]\n",
            "Batch loss: 1.476407,  Batch Accuracy: 54.69  [16640/54000]\n",
            "Batch loss: 1.621940,  Batch Accuracy: 44.53  [17920/54000]\n",
            "Batch loss: 1.499384,  Batch Accuracy: 48.44  [19200/54000]\n",
            "Batch loss: 1.445714,  Batch Accuracy: 52.34  [20480/54000]\n",
            "Batch loss: 1.472383,  Batch Accuracy: 47.66  [21760/54000]\n",
            "Batch loss: 1.575513,  Batch Accuracy: 42.19  [23040/54000]\n",
            "Batch loss: 1.669637,  Batch Accuracy: 34.38  [24320/54000]\n",
            "Batch loss: 1.609777,  Batch Accuracy: 40.62  [25600/54000]\n",
            "Batch loss: 1.547096,  Batch Accuracy: 39.06  [26880/54000]\n",
            "Batch loss: 1.441570,  Batch Accuracy: 49.22  [28160/54000]\n",
            "Batch loss: 1.607523,  Batch Accuracy: 42.19  [29440/54000]\n",
            "Batch loss: 1.549093,  Batch Accuracy: 41.41  [30720/54000]\n",
            "Batch loss: 1.507463,  Batch Accuracy: 46.88  [32000/54000]\n",
            "Batch loss: 1.573317,  Batch Accuracy: 43.75  [33280/54000]\n",
            "Batch loss: 1.662030,  Batch Accuracy: 42.97  [34560/54000]\n",
            "Batch loss: 1.575882,  Batch Accuracy: 40.62  [35840/54000]\n",
            "Batch loss: 1.602941,  Batch Accuracy: 46.09  [37120/54000]\n",
            "Batch loss: 1.528852,  Batch Accuracy: 42.19  [38400/54000]\n",
            "Batch loss: 1.503935,  Batch Accuracy: 46.09  [39680/54000]\n",
            "Batch loss: 1.570536,  Batch Accuracy: 39.06  [40960/54000]\n",
            "Batch loss: 1.557044,  Batch Accuracy: 41.41  [42240/54000]\n",
            "Batch loss: 1.562090,  Batch Accuracy: 43.75  [43520/54000]\n",
            "Batch loss: 1.327126,  Batch Accuracy: 58.59  [44800/54000]\n",
            "Batch loss: 1.555399,  Batch Accuracy: 40.62  [46080/54000]\n",
            "Batch loss: 1.427431,  Batch Accuracy: 48.44  [47360/54000]\n",
            "Batch loss: 1.487369,  Batch Accuracy: 46.88  [48640/54000]\n",
            "Batch loss: 1.524664,  Batch Accuracy: 40.62  [49920/54000]\n",
            "Batch loss: 1.412310,  Batch Accuracy: 50.00  [51200/54000]\n",
            "Batch loss: 1.540069,  Batch Accuracy: 46.88  [52480/54000]\n",
            "Batch loss: 1.534635,  Batch Accuracy: 43.75  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 44.23%, Loss: 1.5544\n",
            "Validation performance:\n",
            " Accuracy: 45.87%, Loss: 1.5089\n",
            "Test performance: Accuracy:\n",
            " 45.47%, Loss: 1.5051\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Batch loss: 1.411436,  Batch Accuracy: 55.47  [ 1280/54000]\n",
            "Batch loss: 1.539680,  Batch Accuracy: 44.53  [ 2560/54000]\n",
            "Batch loss: 1.439312,  Batch Accuracy: 51.56  [ 3840/54000]\n",
            "Batch loss: 1.562006,  Batch Accuracy: 40.62  [ 5120/54000]\n",
            "Batch loss: 1.478340,  Batch Accuracy: 50.00  [ 6400/54000]\n",
            "Batch loss: 1.590128,  Batch Accuracy: 40.62  [ 7680/54000]\n",
            "Batch loss: 1.498939,  Batch Accuracy: 42.97  [ 8960/54000]\n",
            "Batch loss: 1.472526,  Batch Accuracy: 48.44  [10240/54000]\n",
            "Batch loss: 1.410762,  Batch Accuracy: 50.78  [11520/54000]\n",
            "Batch loss: 1.471380,  Batch Accuracy: 45.31  [12800/54000]\n",
            "Batch loss: 1.550313,  Batch Accuracy: 44.53  [14080/54000]\n",
            "Batch loss: 1.396415,  Batch Accuracy: 54.69  [15360/54000]\n",
            "Batch loss: 1.542926,  Batch Accuracy: 41.41  [16640/54000]\n",
            "Batch loss: 1.604835,  Batch Accuracy: 42.97  [17920/54000]\n",
            "Batch loss: 1.391437,  Batch Accuracy: 49.22  [19200/54000]\n",
            "Batch loss: 1.552256,  Batch Accuracy: 40.62  [20480/54000]\n",
            "Batch loss: 1.480204,  Batch Accuracy: 46.88  [21760/54000]\n",
            "Batch loss: 1.473527,  Batch Accuracy: 46.09  [23040/54000]\n",
            "Batch loss: 1.535460,  Batch Accuracy: 42.97  [24320/54000]\n",
            "Batch loss: 1.524231,  Batch Accuracy: 46.09  [25600/54000]\n",
            "Batch loss: 1.379081,  Batch Accuracy: 55.47  [26880/54000]\n",
            "Batch loss: 1.485388,  Batch Accuracy: 46.09  [28160/54000]\n",
            "Batch loss: 1.405493,  Batch Accuracy: 55.47  [29440/54000]\n",
            "Batch loss: 1.417037,  Batch Accuracy: 54.69  [30720/54000]\n",
            "Batch loss: 1.409947,  Batch Accuracy: 53.12  [32000/54000]\n",
            "Batch loss: 1.395879,  Batch Accuracy: 56.25  [33280/54000]\n",
            "Batch loss: 1.376369,  Batch Accuracy: 50.78  [34560/54000]\n",
            "Batch loss: 1.495865,  Batch Accuracy: 42.19  [35840/54000]\n",
            "Batch loss: 1.504451,  Batch Accuracy: 44.53  [37120/54000]\n",
            "Batch loss: 1.481325,  Batch Accuracy: 50.00  [38400/54000]\n",
            "Batch loss: 1.374343,  Batch Accuracy: 54.69  [39680/54000]\n",
            "Batch loss: 1.435427,  Batch Accuracy: 50.78  [40960/54000]\n",
            "Batch loss: 1.404651,  Batch Accuracy: 52.34  [42240/54000]\n",
            "Batch loss: 1.451730,  Batch Accuracy: 50.00  [43520/54000]\n",
            "Batch loss: 1.360873,  Batch Accuracy: 52.34  [44800/54000]\n",
            "Batch loss: 1.513210,  Batch Accuracy: 46.88  [46080/54000]\n",
            "Batch loss: 1.424752,  Batch Accuracy: 50.78  [47360/54000]\n",
            "Batch loss: 1.496464,  Batch Accuracy: 48.44  [48640/54000]\n",
            "Batch loss: 1.389007,  Batch Accuracy: 56.25  [49920/54000]\n",
            "Batch loss: 1.374495,  Batch Accuracy: 48.44  [51200/54000]\n",
            "Batch loss: 1.515006,  Batch Accuracy: 47.66  [52480/54000]\n",
            "Batch loss: 1.379687,  Batch Accuracy: 58.59  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 48.90%, Loss: 1.4639\n",
            "Validation performance:\n",
            " Accuracy: 51.73%, Loss: 1.4107\n",
            "Test performance: Accuracy:\n",
            " 51.05%, Loss: 1.4096\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Batch loss: 1.306857,  Batch Accuracy: 55.47  [ 1280/54000]\n",
            "Batch loss: 1.351559,  Batch Accuracy: 55.47  [ 2560/54000]\n",
            "Batch loss: 1.409147,  Batch Accuracy: 56.25  [ 3840/54000]\n",
            "Batch loss: 1.410774,  Batch Accuracy: 50.00  [ 5120/54000]\n",
            "Batch loss: 1.342926,  Batch Accuracy: 53.91  [ 6400/54000]\n",
            "Batch loss: 1.444508,  Batch Accuracy: 51.56  [ 7680/54000]\n",
            "Batch loss: 1.439170,  Batch Accuracy: 43.75  [ 8960/54000]\n",
            "Batch loss: 1.456319,  Batch Accuracy: 50.00  [10240/54000]\n",
            "Batch loss: 1.409971,  Batch Accuracy: 53.12  [11520/54000]\n",
            "Batch loss: 1.496664,  Batch Accuracy: 47.66  [12800/54000]\n",
            "Batch loss: 1.338961,  Batch Accuracy: 56.25  [14080/54000]\n",
            "Batch loss: 1.467888,  Batch Accuracy: 53.91  [15360/54000]\n",
            "Batch loss: 1.392618,  Batch Accuracy: 52.34  [16640/54000]\n",
            "Batch loss: 1.426785,  Batch Accuracy: 53.12  [17920/54000]\n",
            "Batch loss: 1.377191,  Batch Accuracy: 52.34  [19200/54000]\n",
            "Batch loss: 1.370923,  Batch Accuracy: 54.69  [20480/54000]\n",
            "Batch loss: 1.396971,  Batch Accuracy: 52.34  [21760/54000]\n",
            "Batch loss: 1.437444,  Batch Accuracy: 53.12  [23040/54000]\n",
            "Batch loss: 1.268980,  Batch Accuracy: 61.72  [24320/54000]\n",
            "Batch loss: 1.408970,  Batch Accuracy: 53.12  [25600/54000]\n",
            "Batch loss: 1.451749,  Batch Accuracy: 51.56  [26880/54000]\n",
            "Batch loss: 1.310495,  Batch Accuracy: 55.47  [28160/54000]\n",
            "Batch loss: 1.272063,  Batch Accuracy: 57.03  [29440/54000]\n",
            "Batch loss: 1.382372,  Batch Accuracy: 59.38  [30720/54000]\n",
            "Batch loss: 1.414752,  Batch Accuracy: 50.78  [32000/54000]\n",
            "Batch loss: 1.379008,  Batch Accuracy: 59.38  [33280/54000]\n",
            "Batch loss: 1.315343,  Batch Accuracy: 60.16  [34560/54000]\n",
            "Batch loss: 1.337746,  Batch Accuracy: 55.47  [35840/54000]\n",
            "Batch loss: 1.239966,  Batch Accuracy: 59.38  [37120/54000]\n",
            "Batch loss: 1.427315,  Batch Accuracy: 57.03  [38400/54000]\n",
            "Batch loss: 1.367936,  Batch Accuracy: 57.81  [39680/54000]\n",
            "Batch loss: 1.282274,  Batch Accuracy: 57.03  [40960/54000]\n",
            "Batch loss: 1.244430,  Batch Accuracy: 61.72  [42240/54000]\n",
            "Batch loss: 1.449904,  Batch Accuracy: 46.88  [43520/54000]\n",
            "Batch loss: 1.428223,  Batch Accuracy: 51.56  [44800/54000]\n",
            "Batch loss: 1.362327,  Batch Accuracy: 57.81  [46080/54000]\n",
            "Batch loss: 1.203768,  Batch Accuracy: 63.28  [47360/54000]\n",
            "Batch loss: 1.355336,  Batch Accuracy: 55.47  [48640/54000]\n",
            "Batch loss: 1.297236,  Batch Accuracy: 56.25  [49920/54000]\n",
            "Batch loss: 1.312980,  Batch Accuracy: 53.12  [51200/54000]\n",
            "Batch loss: 1.337386,  Batch Accuracy: 56.25  [52480/54000]\n",
            "Batch loss: 1.306316,  Batch Accuracy: 60.16  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 54.76%, Loss: 1.3657\n",
            "Validation performance:\n",
            " Accuracy: 57.80%, Loss: 1.3087\n",
            "Test performance: Accuracy:\n",
            " 57.47%, Loss: 1.3099\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Batch loss: 1.225931,  Batch Accuracy: 64.84  [ 1280/54000]\n",
            "Batch loss: 1.415202,  Batch Accuracy: 56.25  [ 2560/54000]\n",
            "Batch loss: 1.204021,  Batch Accuracy: 66.41  [ 3840/54000]\n",
            "Batch loss: 1.242936,  Batch Accuracy: 63.28  [ 5120/54000]\n",
            "Batch loss: 1.312698,  Batch Accuracy: 60.94  [ 6400/54000]\n",
            "Batch loss: 1.349401,  Batch Accuracy: 60.16  [ 7680/54000]\n",
            "Batch loss: 1.346770,  Batch Accuracy: 57.03  [ 8960/54000]\n",
            "Batch loss: 1.295138,  Batch Accuracy: 60.94  [10240/54000]\n",
            "Batch loss: 1.377118,  Batch Accuracy: 56.25  [11520/54000]\n",
            "Batch loss: 1.241619,  Batch Accuracy: 59.38  [12800/54000]\n",
            "Batch loss: 1.402176,  Batch Accuracy: 53.12  [14080/54000]\n",
            "Batch loss: 1.271525,  Batch Accuracy: 62.50  [15360/54000]\n",
            "Batch loss: 1.302235,  Batch Accuracy: 62.50  [16640/54000]\n",
            "Batch loss: 1.264756,  Batch Accuracy: 60.16  [17920/54000]\n",
            "Batch loss: 1.240085,  Batch Accuracy: 61.72  [19200/54000]\n",
            "Batch loss: 1.331378,  Batch Accuracy: 57.03  [20480/54000]\n",
            "Batch loss: 1.277720,  Batch Accuracy: 56.25  [21760/54000]\n",
            "Batch loss: 1.223779,  Batch Accuracy: 60.16  [23040/54000]\n",
            "Batch loss: 1.204142,  Batch Accuracy: 63.28  [24320/54000]\n",
            "Batch loss: 1.130346,  Batch Accuracy: 61.72  [25600/54000]\n",
            "Batch loss: 1.304535,  Batch Accuracy: 56.25  [26880/54000]\n",
            "Batch loss: 1.114061,  Batch Accuracy: 68.75  [28160/54000]\n",
            "Batch loss: 1.278774,  Batch Accuracy: 53.12  [29440/54000]\n",
            "Batch loss: 1.162800,  Batch Accuracy: 69.53  [30720/54000]\n",
            "Batch loss: 1.453432,  Batch Accuracy: 55.47  [32000/54000]\n",
            "Batch loss: 1.260671,  Batch Accuracy: 61.72  [33280/54000]\n",
            "Batch loss: 1.196054,  Batch Accuracy: 66.41  [34560/54000]\n",
            "Batch loss: 1.146173,  Batch Accuracy: 63.28  [35840/54000]\n",
            "Batch loss: 1.369861,  Batch Accuracy: 53.12  [37120/54000]\n",
            "Batch loss: 1.234898,  Batch Accuracy: 57.03  [38400/54000]\n",
            "Batch loss: 1.312448,  Batch Accuracy: 55.47  [39680/54000]\n",
            "Batch loss: 1.202452,  Batch Accuracy: 60.16  [40960/54000]\n",
            "Batch loss: 1.189027,  Batch Accuracy: 55.47  [42240/54000]\n",
            "Batch loss: 1.225248,  Batch Accuracy: 60.94  [43520/54000]\n",
            "Batch loss: 1.223364,  Batch Accuracy: 61.72  [44800/54000]\n",
            "Batch loss: 1.199006,  Batch Accuracy: 61.72  [46080/54000]\n",
            "Batch loss: 1.306265,  Batch Accuracy: 56.25  [47360/54000]\n",
            "Batch loss: 1.190459,  Batch Accuracy: 64.06  [48640/54000]\n",
            "Batch loss: 1.101520,  Batch Accuracy: 65.62  [49920/54000]\n",
            "Batch loss: 1.271185,  Batch Accuracy: 57.81  [51200/54000]\n",
            "Batch loss: 1.235413,  Batch Accuracy: 64.06  [52480/54000]\n",
            "Batch loss: 1.160533,  Batch Accuracy: 66.41  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 60.20%, Loss: 1.2641\n",
            "Validation performance:\n",
            " Accuracy: 62.10%, Loss: 1.2067\n",
            "Test performance: Accuracy:\n",
            " 62.11%, Loss: 1.2088\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Batch loss: 1.239062,  Batch Accuracy: 65.62  [ 1280/54000]\n",
            "Batch loss: 1.105417,  Batch Accuracy: 66.41  [ 2560/54000]\n",
            "Batch loss: 1.210596,  Batch Accuracy: 60.94  [ 3840/54000]\n",
            "Batch loss: 1.252002,  Batch Accuracy: 57.81  [ 5120/54000]\n",
            "Batch loss: 1.166492,  Batch Accuracy: 65.62  [ 6400/54000]\n",
            "Batch loss: 1.193662,  Batch Accuracy: 62.50  [ 7680/54000]\n",
            "Batch loss: 1.246539,  Batch Accuracy: 54.69  [ 8960/54000]\n",
            "Batch loss: 1.259908,  Batch Accuracy: 61.72  [10240/54000]\n",
            "Batch loss: 1.145154,  Batch Accuracy: 67.97  [11520/54000]\n",
            "Batch loss: 1.187222,  Batch Accuracy: 64.84  [12800/54000]\n",
            "Batch loss: 1.171248,  Batch Accuracy: 61.72  [14080/54000]\n",
            "Batch loss: 1.182169,  Batch Accuracy: 65.62  [15360/54000]\n",
            "Batch loss: 1.150946,  Batch Accuracy: 67.19  [16640/54000]\n",
            "Batch loss: 1.139443,  Batch Accuracy: 64.06  [17920/54000]\n",
            "Batch loss: 1.369048,  Batch Accuracy: 57.81  [19200/54000]\n",
            "Batch loss: 1.183959,  Batch Accuracy: 64.06  [20480/54000]\n",
            "Batch loss: 1.186943,  Batch Accuracy: 63.28  [21760/54000]\n",
            "Batch loss: 1.146224,  Batch Accuracy: 62.50  [23040/54000]\n",
            "Batch loss: 1.132188,  Batch Accuracy: 66.41  [24320/54000]\n",
            "Batch loss: 1.143340,  Batch Accuracy: 64.06  [25600/54000]\n",
            "Batch loss: 1.141272,  Batch Accuracy: 66.41  [26880/54000]\n",
            "Batch loss: 1.048626,  Batch Accuracy: 71.09  [28160/54000]\n",
            "Batch loss: 1.154796,  Batch Accuracy: 61.72  [29440/54000]\n",
            "Batch loss: 1.167801,  Batch Accuracy: 64.84  [30720/54000]\n",
            "Batch loss: 1.203379,  Batch Accuracy: 60.94  [32000/54000]\n",
            "Batch loss: 1.166683,  Batch Accuracy: 65.62  [33280/54000]\n",
            "Batch loss: 1.140689,  Batch Accuracy: 60.16  [34560/54000]\n",
            "Batch loss: 1.183331,  Batch Accuracy: 67.19  [35840/54000]\n",
            "Batch loss: 1.053088,  Batch Accuracy: 73.44  [37120/54000]\n",
            "Batch loss: 1.054921,  Batch Accuracy: 70.31  [38400/54000]\n",
            "Batch loss: 1.115793,  Batch Accuracy: 68.75  [39680/54000]\n",
            "Batch loss: 1.134288,  Batch Accuracy: 66.41  [40960/54000]\n",
            "Batch loss: 1.152904,  Batch Accuracy: 65.62  [42240/54000]\n",
            "Batch loss: 1.035726,  Batch Accuracy: 70.31  [43520/54000]\n",
            "Batch loss: 1.120620,  Batch Accuracy: 67.97  [44800/54000]\n",
            "Batch loss: 1.122251,  Batch Accuracy: 63.28  [46080/54000]\n",
            "Batch loss: 1.227311,  Batch Accuracy: 64.06  [47360/54000]\n",
            "Batch loss: 1.187757,  Batch Accuracy: 60.16  [48640/54000]\n",
            "Batch loss: 1.069788,  Batch Accuracy: 67.97  [49920/54000]\n",
            "Batch loss: 1.090146,  Batch Accuracy: 66.41  [51200/54000]\n",
            "Batch loss: 1.183855,  Batch Accuracy: 61.72  [52480/54000]\n",
            "Batch loss: 1.135180,  Batch Accuracy: 73.44  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 64.39%, Loss: 1.1613\n",
            "Validation performance:\n",
            " Accuracy: 66.72%, Loss: 1.1056\n",
            "Test performance: Accuracy:\n",
            " 67.13%, Loss: 1.1085\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Batch loss: 1.068737,  Batch Accuracy: 66.41  [ 1280/54000]\n",
            "Batch loss: 1.105685,  Batch Accuracy: 68.75  [ 2560/54000]\n",
            "Batch loss: 1.099434,  Batch Accuracy: 70.31  [ 3840/54000]\n",
            "Batch loss: 1.071342,  Batch Accuracy: 67.19  [ 5120/54000]\n",
            "Batch loss: 1.049504,  Batch Accuracy: 68.75  [ 6400/54000]\n",
            "Batch loss: 1.094285,  Batch Accuracy: 69.53  [ 7680/54000]\n",
            "Batch loss: 1.081233,  Batch Accuracy: 71.88  [ 8960/54000]\n",
            "Batch loss: 1.096816,  Batch Accuracy: 69.53  [10240/54000]\n",
            "Batch loss: 0.970685,  Batch Accuracy: 78.12  [11520/54000]\n",
            "Batch loss: 1.201348,  Batch Accuracy: 60.94  [12800/54000]\n",
            "Batch loss: 1.155987,  Batch Accuracy: 62.50  [14080/54000]\n",
            "Batch loss: 1.013507,  Batch Accuracy: 77.34  [15360/54000]\n",
            "Batch loss: 1.048136,  Batch Accuracy: 69.53  [16640/54000]\n",
            "Batch loss: 1.021413,  Batch Accuracy: 65.62  [17920/54000]\n",
            "Batch loss: 1.022575,  Batch Accuracy: 68.75  [19200/54000]\n",
            "Batch loss: 1.113326,  Batch Accuracy: 61.72  [20480/54000]\n",
            "Batch loss: 1.199033,  Batch Accuracy: 62.50  [21760/54000]\n",
            "Batch loss: 1.095507,  Batch Accuracy: 67.19  [23040/54000]\n",
            "Batch loss: 1.082096,  Batch Accuracy: 68.75  [24320/54000]\n",
            "Batch loss: 1.138647,  Batch Accuracy: 68.75  [25600/54000]\n",
            "Batch loss: 1.056600,  Batch Accuracy: 68.75  [26880/54000]\n",
            "Batch loss: 1.031931,  Batch Accuracy: 74.22  [28160/54000]\n",
            "Batch loss: 1.050373,  Batch Accuracy: 70.31  [29440/54000]\n",
            "Batch loss: 1.078995,  Batch Accuracy: 67.97  [30720/54000]\n",
            "Batch loss: 1.087738,  Batch Accuracy: 73.44  [32000/54000]\n",
            "Batch loss: 1.146639,  Batch Accuracy: 64.06  [33280/54000]\n",
            "Batch loss: 1.126759,  Batch Accuracy: 60.94  [34560/54000]\n",
            "Batch loss: 1.087322,  Batch Accuracy: 66.41  [35840/54000]\n",
            "Batch loss: 1.038693,  Batch Accuracy: 71.88  [37120/54000]\n",
            "Batch loss: 1.110197,  Batch Accuracy: 67.19  [38400/54000]\n",
            "Batch loss: 1.054367,  Batch Accuracy: 68.75  [39680/54000]\n",
            "Batch loss: 1.118469,  Batch Accuracy: 60.16  [40960/54000]\n",
            "Batch loss: 1.027011,  Batch Accuracy: 74.22  [42240/54000]\n",
            "Batch loss: 0.987424,  Batch Accuracy: 70.31  [43520/54000]\n",
            "Batch loss: 1.007663,  Batch Accuracy: 75.78  [44800/54000]\n",
            "Batch loss: 1.072977,  Batch Accuracy: 67.19  [46080/54000]\n",
            "Batch loss: 0.987640,  Batch Accuracy: 71.09  [47360/54000]\n",
            "Batch loss: 1.005949,  Batch Accuracy: 74.22  [48640/54000]\n",
            "Batch loss: 1.124782,  Batch Accuracy: 64.06  [49920/54000]\n",
            "Batch loss: 0.988273,  Batch Accuracy: 73.44  [51200/54000]\n",
            "Batch loss: 1.025672,  Batch Accuracy: 67.97  [52480/54000]\n",
            "Batch loss: 0.994267,  Batch Accuracy: 70.31  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 68.99%, Loss: 1.0617\n",
            "Validation performance:\n",
            " Accuracy: 69.92%, Loss: 1.0099\n",
            "Test performance: Accuracy:\n",
            " 69.83%, Loss: 1.0126\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Batch loss: 1.096741,  Batch Accuracy: 63.28  [ 1280/54000]\n",
            "Batch loss: 0.993706,  Batch Accuracy: 65.62  [ 2560/54000]\n",
            "Batch loss: 0.905471,  Batch Accuracy: 74.22  [ 3840/54000]\n",
            "Batch loss: 0.954150,  Batch Accuracy: 67.19  [ 5120/54000]\n",
            "Batch loss: 0.948647,  Batch Accuracy: 73.44  [ 6400/54000]\n",
            "Batch loss: 1.062899,  Batch Accuracy: 67.97  [ 7680/54000]\n",
            "Batch loss: 0.985183,  Batch Accuracy: 71.88  [ 8960/54000]\n",
            "Batch loss: 0.963579,  Batch Accuracy: 69.53  [10240/54000]\n",
            "Batch loss: 1.013630,  Batch Accuracy: 72.66  [11520/54000]\n",
            "Batch loss: 1.032466,  Batch Accuracy: 70.31  [12800/54000]\n",
            "Batch loss: 0.957469,  Batch Accuracy: 70.31  [14080/54000]\n",
            "Batch loss: 1.028198,  Batch Accuracy: 71.09  [15360/54000]\n",
            "Batch loss: 1.044046,  Batch Accuracy: 67.19  [16640/54000]\n",
            "Batch loss: 0.973502,  Batch Accuracy: 71.88  [17920/54000]\n",
            "Batch loss: 0.935238,  Batch Accuracy: 78.12  [19200/54000]\n",
            "Batch loss: 0.881943,  Batch Accuracy: 74.22  [20480/54000]\n",
            "Batch loss: 1.028016,  Batch Accuracy: 69.53  [21760/54000]\n",
            "Batch loss: 0.947332,  Batch Accuracy: 73.44  [23040/54000]\n",
            "Batch loss: 0.982994,  Batch Accuracy: 71.88  [24320/54000]\n",
            "Batch loss: 0.918147,  Batch Accuracy: 77.34  [25600/54000]\n",
            "Batch loss: 1.008152,  Batch Accuracy: 74.22  [26880/54000]\n",
            "Batch loss: 0.959405,  Batch Accuracy: 70.31  [28160/54000]\n",
            "Batch loss: 0.851842,  Batch Accuracy: 76.56  [29440/54000]\n",
            "Batch loss: 0.907781,  Batch Accuracy: 77.34  [30720/54000]\n",
            "Batch loss: 0.987186,  Batch Accuracy: 71.88  [32000/54000]\n",
            "Batch loss: 1.015148,  Batch Accuracy: 73.44  [33280/54000]\n",
            "Batch loss: 1.016942,  Batch Accuracy: 66.41  [34560/54000]\n",
            "Batch loss: 1.006753,  Batch Accuracy: 75.78  [35840/54000]\n",
            "Batch loss: 0.875017,  Batch Accuracy: 78.91  [37120/54000]\n",
            "Batch loss: 0.993634,  Batch Accuracy: 69.53  [38400/54000]\n",
            "Batch loss: 1.062334,  Batch Accuracy: 69.53  [39680/54000]\n",
            "Batch loss: 0.963389,  Batch Accuracy: 78.12  [40960/54000]\n",
            "Batch loss: 1.030438,  Batch Accuracy: 71.88  [42240/54000]\n",
            "Batch loss: 0.998565,  Batch Accuracy: 73.44  [43520/54000]\n",
            "Batch loss: 0.984026,  Batch Accuracy: 74.22  [44800/54000]\n",
            "Batch loss: 0.876123,  Batch Accuracy: 77.34  [46080/54000]\n",
            "Batch loss: 0.854776,  Batch Accuracy: 80.47  [47360/54000]\n",
            "Batch loss: 0.933372,  Batch Accuracy: 75.00  [48640/54000]\n",
            "Batch loss: 0.930540,  Batch Accuracy: 71.09  [49920/54000]\n",
            "Batch loss: 0.943402,  Batch Accuracy: 75.78  [51200/54000]\n",
            "Batch loss: 1.045406,  Batch Accuracy: 66.41  [52480/54000]\n",
            "Batch loss: 1.003375,  Batch Accuracy: 75.00  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 72.97%, Loss: 0.9688\n",
            "Validation performance:\n",
            " Accuracy: 75.48%, Loss: 0.9216\n",
            "Test performance: Accuracy:\n",
            " 75.31%, Loss: 0.9239\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Batch loss: 1.006851,  Batch Accuracy: 70.31  [ 1280/54000]\n",
            "Batch loss: 0.917905,  Batch Accuracy: 82.03  [ 2560/54000]\n",
            "Batch loss: 1.044669,  Batch Accuracy: 60.94  [ 3840/54000]\n",
            "Batch loss: 0.873233,  Batch Accuracy: 75.00  [ 5120/54000]\n",
            "Batch loss: 0.879217,  Batch Accuracy: 80.47  [ 6400/54000]\n",
            "Batch loss: 0.752198,  Batch Accuracy: 85.94  [ 7680/54000]\n",
            "Batch loss: 0.976773,  Batch Accuracy: 74.22  [ 8960/54000]\n",
            "Batch loss: 0.900111,  Batch Accuracy: 75.00  [10240/54000]\n",
            "Batch loss: 0.959892,  Batch Accuracy: 75.78  [11520/54000]\n",
            "Batch loss: 0.845208,  Batch Accuracy: 75.00  [12800/54000]\n",
            "Batch loss: 0.862785,  Batch Accuracy: 78.91  [14080/54000]\n",
            "Batch loss: 0.984457,  Batch Accuracy: 70.31  [15360/54000]\n",
            "Batch loss: 0.953307,  Batch Accuracy: 74.22  [16640/54000]\n",
            "Batch loss: 0.958272,  Batch Accuracy: 71.88  [17920/54000]\n",
            "Batch loss: 0.930563,  Batch Accuracy: 72.66  [19200/54000]\n",
            "Batch loss: 0.828535,  Batch Accuracy: 77.34  [20480/54000]\n",
            "Batch loss: 0.864231,  Batch Accuracy: 73.44  [21760/54000]\n",
            "Batch loss: 0.851299,  Batch Accuracy: 81.25  [23040/54000]\n",
            "Batch loss: 0.885371,  Batch Accuracy: 74.22  [24320/54000]\n",
            "Batch loss: 0.848663,  Batch Accuracy: 80.47  [25600/54000]\n",
            "Batch loss: 1.029477,  Batch Accuracy: 68.75  [26880/54000]\n",
            "Batch loss: 0.861872,  Batch Accuracy: 82.03  [28160/54000]\n",
            "Batch loss: 0.878993,  Batch Accuracy: 79.69  [29440/54000]\n",
            "Batch loss: 0.820100,  Batch Accuracy: 76.56  [30720/54000]\n",
            "Batch loss: 0.878257,  Batch Accuracy: 78.91  [32000/54000]\n",
            "Batch loss: 0.797886,  Batch Accuracy: 79.69  [33280/54000]\n",
            "Batch loss: 0.944419,  Batch Accuracy: 75.00  [34560/54000]\n",
            "Batch loss: 0.919186,  Batch Accuracy: 75.78  [35840/54000]\n",
            "Batch loss: 0.765660,  Batch Accuracy: 81.25  [37120/54000]\n",
            "Batch loss: 0.872630,  Batch Accuracy: 77.34  [38400/54000]\n",
            "Batch loss: 0.806378,  Batch Accuracy: 81.25  [39680/54000]\n",
            "Batch loss: 0.814822,  Batch Accuracy: 78.91  [40960/54000]\n",
            "Batch loss: 0.948999,  Batch Accuracy: 71.88  [42240/54000]\n",
            "Batch loss: 0.850017,  Batch Accuracy: 80.47  [43520/54000]\n",
            "Batch loss: 1.050936,  Batch Accuracy: 75.00  [44800/54000]\n",
            "Batch loss: 0.885375,  Batch Accuracy: 77.34  [46080/54000]\n",
            "Batch loss: 0.932895,  Batch Accuracy: 74.22  [47360/54000]\n",
            "Batch loss: 0.940517,  Batch Accuracy: 72.66  [48640/54000]\n",
            "Batch loss: 0.918699,  Batch Accuracy: 81.25  [49920/54000]\n",
            "Batch loss: 0.872408,  Batch Accuracy: 77.34  [51200/54000]\n",
            "Batch loss: 0.816849,  Batch Accuracy: 83.59  [52480/54000]\n",
            "Batch loss: 0.776876,  Batch Accuracy: 85.16  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 77.05%, Loss: 0.8849\n",
            "Validation performance:\n",
            " Accuracy: 79.63%, Loss: 0.8428\n",
            "Test performance: Accuracy:\n",
            " 79.07%, Loss: 0.8457\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Batch loss: 0.785996,  Batch Accuracy: 80.47  [ 1280/54000]\n",
            "Batch loss: 0.863012,  Batch Accuracy: 81.25  [ 2560/54000]\n",
            "Batch loss: 0.852265,  Batch Accuracy: 82.81  [ 3840/54000]\n",
            "Batch loss: 0.756355,  Batch Accuracy: 82.03  [ 5120/54000]\n",
            "Batch loss: 0.842966,  Batch Accuracy: 81.25  [ 6400/54000]\n",
            "Batch loss: 0.667358,  Batch Accuracy: 86.72  [ 7680/54000]\n",
            "Batch loss: 0.843743,  Batch Accuracy: 78.91  [ 8960/54000]\n",
            "Batch loss: 0.906524,  Batch Accuracy: 75.00  [10240/54000]\n",
            "Batch loss: 0.698267,  Batch Accuracy: 84.38  [11520/54000]\n",
            "Batch loss: 0.824150,  Batch Accuracy: 78.91  [12800/54000]\n",
            "Batch loss: 0.909483,  Batch Accuracy: 71.09  [14080/54000]\n",
            "Batch loss: 0.723568,  Batch Accuracy: 85.16  [15360/54000]\n",
            "Batch loss: 0.798847,  Batch Accuracy: 81.25  [16640/54000]\n",
            "Batch loss: 0.837585,  Batch Accuracy: 76.56  [17920/54000]\n",
            "Batch loss: 0.829966,  Batch Accuracy: 77.34  [19200/54000]\n",
            "Batch loss: 0.775359,  Batch Accuracy: 80.47  [20480/54000]\n",
            "Batch loss: 0.882037,  Batch Accuracy: 78.91  [21760/54000]\n",
            "Batch loss: 0.762483,  Batch Accuracy: 84.38  [23040/54000]\n",
            "Batch loss: 0.941489,  Batch Accuracy: 69.53  [24320/54000]\n",
            "Batch loss: 0.820885,  Batch Accuracy: 80.47  [25600/54000]\n",
            "Batch loss: 0.844908,  Batch Accuracy: 78.12  [26880/54000]\n",
            "Batch loss: 0.900814,  Batch Accuracy: 75.78  [28160/54000]\n",
            "Batch loss: 0.838914,  Batch Accuracy: 83.59  [29440/54000]\n",
            "Batch loss: 0.717952,  Batch Accuracy: 83.59  [30720/54000]\n",
            "Batch loss: 0.814779,  Batch Accuracy: 77.34  [32000/54000]\n",
            "Batch loss: 0.756821,  Batch Accuracy: 84.38  [33280/54000]\n",
            "Batch loss: 0.801115,  Batch Accuracy: 79.69  [34560/54000]\n",
            "Batch loss: 0.802637,  Batch Accuracy: 85.16  [35840/54000]\n",
            "Batch loss: 0.822626,  Batch Accuracy: 78.91  [37120/54000]\n",
            "Batch loss: 0.744491,  Batch Accuracy: 80.47  [38400/54000]\n",
            "Batch loss: 0.753144,  Batch Accuracy: 82.03  [39680/54000]\n",
            "Batch loss: 0.804178,  Batch Accuracy: 81.25  [40960/54000]\n",
            "Batch loss: 0.736481,  Batch Accuracy: 85.16  [42240/54000]\n",
            "Batch loss: 0.758739,  Batch Accuracy: 85.94  [43520/54000]\n",
            "Batch loss: 0.734612,  Batch Accuracy: 81.25  [44800/54000]\n",
            "Batch loss: 0.710437,  Batch Accuracy: 85.94  [46080/54000]\n",
            "Batch loss: 0.757234,  Batch Accuracy: 85.16  [47360/54000]\n",
            "Batch loss: 0.918931,  Batch Accuracy: 75.00  [48640/54000]\n",
            "Batch loss: 0.767917,  Batch Accuracy: 82.03  [49920/54000]\n",
            "Batch loss: 0.556237,  Batch Accuracy: 89.84  [51200/54000]\n",
            "Batch loss: 0.859754,  Batch Accuracy: 80.47  [52480/54000]\n",
            "Batch loss: 0.695936,  Batch Accuracy: 84.38  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 80.58%, Loss: 0.8103\n",
            "Validation performance:\n",
            " Accuracy: 82.95%, Loss: 0.7746\n",
            "Test performance: Accuracy:\n",
            " 81.83%, Loss: 0.7774\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Batch loss: 0.764513,  Batch Accuracy: 82.03  [ 1280/54000]\n",
            "Batch loss: 0.766158,  Batch Accuracy: 82.81  [ 2560/54000]\n",
            "Batch loss: 0.708579,  Batch Accuracy: 85.16  [ 3840/54000]\n",
            "Batch loss: 0.755604,  Batch Accuracy: 83.59  [ 5120/54000]\n",
            "Batch loss: 0.763974,  Batch Accuracy: 81.25  [ 6400/54000]\n",
            "Batch loss: 0.737144,  Batch Accuracy: 80.47  [ 7680/54000]\n",
            "Batch loss: 0.784625,  Batch Accuracy: 78.91  [ 8960/54000]\n",
            "Batch loss: 0.853387,  Batch Accuracy: 78.91  [10240/54000]\n",
            "Batch loss: 0.743268,  Batch Accuracy: 83.59  [11520/54000]\n",
            "Batch loss: 0.752607,  Batch Accuracy: 85.94  [12800/54000]\n",
            "Batch loss: 0.714782,  Batch Accuracy: 85.16  [14080/54000]\n",
            "Batch loss: 0.768827,  Batch Accuracy: 80.47  [15360/54000]\n",
            "Batch loss: 0.767182,  Batch Accuracy: 84.38  [16640/54000]\n",
            "Batch loss: 0.819595,  Batch Accuracy: 84.38  [17920/54000]\n",
            "Batch loss: 0.664815,  Batch Accuracy: 86.72  [19200/54000]\n",
            "Batch loss: 0.753749,  Batch Accuracy: 82.81  [20480/54000]\n",
            "Batch loss: 0.780529,  Batch Accuracy: 80.47  [21760/54000]\n",
            "Batch loss: 0.720380,  Batch Accuracy: 88.28  [23040/54000]\n",
            "Batch loss: 0.778701,  Batch Accuracy: 81.25  [24320/54000]\n",
            "Batch loss: 0.656709,  Batch Accuracy: 87.50  [25600/54000]\n",
            "Batch loss: 0.733066,  Batch Accuracy: 82.03  [26880/54000]\n",
            "Batch loss: 0.591540,  Batch Accuracy: 89.06  [28160/54000]\n",
            "Batch loss: 0.802302,  Batch Accuracy: 82.03  [29440/54000]\n",
            "Batch loss: 0.781027,  Batch Accuracy: 84.38  [30720/54000]\n",
            "Batch loss: 0.751533,  Batch Accuracy: 81.25  [32000/54000]\n",
            "Batch loss: 0.739788,  Batch Accuracy: 79.69  [33280/54000]\n",
            "Batch loss: 0.677617,  Batch Accuracy: 83.59  [34560/54000]\n",
            "Batch loss: 0.708227,  Batch Accuracy: 84.38  [35840/54000]\n",
            "Batch loss: 0.783374,  Batch Accuracy: 79.69  [37120/54000]\n",
            "Batch loss: 0.763303,  Batch Accuracy: 82.03  [38400/54000]\n",
            "Batch loss: 0.709087,  Batch Accuracy: 80.47  [39680/54000]\n",
            "Batch loss: 0.670632,  Batch Accuracy: 84.38  [40960/54000]\n",
            "Batch loss: 0.719346,  Batch Accuracy: 86.72  [42240/54000]\n",
            "Batch loss: 0.633128,  Batch Accuracy: 85.94  [43520/54000]\n",
            "Batch loss: 0.691731,  Batch Accuracy: 85.94  [44800/54000]\n",
            "Batch loss: 0.654837,  Batch Accuracy: 88.28  [46080/54000]\n",
            "Batch loss: 0.776312,  Batch Accuracy: 85.16  [47360/54000]\n",
            "Batch loss: 0.733884,  Batch Accuracy: 82.03  [48640/54000]\n",
            "Batch loss: 0.750738,  Batch Accuracy: 81.25  [49920/54000]\n",
            "Batch loss: 0.645369,  Batch Accuracy: 88.28  [51200/54000]\n",
            "Batch loss: 0.772056,  Batch Accuracy: 83.59  [52480/54000]\n",
            "Batch loss: 0.693438,  Batch Accuracy: 86.72  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 83.18%, Loss: 0.7430\n",
            "Validation performance:\n",
            " Accuracy: 84.87%, Loss: 0.7110\n",
            "Test performance: Accuracy:\n",
            " 84.23%, Loss: 0.7148\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Batch loss: 0.770882,  Batch Accuracy: 85.16  [ 1280/54000]\n",
            "Batch loss: 0.635625,  Batch Accuracy: 83.59  [ 2560/54000]\n",
            "Batch loss: 0.721747,  Batch Accuracy: 83.59  [ 3840/54000]\n",
            "Batch loss: 0.712643,  Batch Accuracy: 83.59  [ 5120/54000]\n",
            "Batch loss: 0.752886,  Batch Accuracy: 81.25  [ 6400/54000]\n",
            "Batch loss: 0.700400,  Batch Accuracy: 87.50  [ 7680/54000]\n",
            "Batch loss: 0.862419,  Batch Accuracy: 82.81  [ 8960/54000]\n",
            "Batch loss: 0.715490,  Batch Accuracy: 85.16  [10240/54000]\n",
            "Batch loss: 0.615989,  Batch Accuracy: 90.62  [11520/54000]\n",
            "Batch loss: 0.729487,  Batch Accuracy: 84.38  [12800/54000]\n",
            "Batch loss: 0.696748,  Batch Accuracy: 82.03  [14080/54000]\n",
            "Batch loss: 0.684291,  Batch Accuracy: 85.16  [15360/54000]\n",
            "Batch loss: 0.624972,  Batch Accuracy: 86.72  [16640/54000]\n",
            "Batch loss: 0.768641,  Batch Accuracy: 82.81  [17920/54000]\n",
            "Batch loss: 0.684000,  Batch Accuracy: 82.03  [19200/54000]\n",
            "Batch loss: 0.581192,  Batch Accuracy: 89.84  [20480/54000]\n",
            "Batch loss: 0.724015,  Batch Accuracy: 81.25  [21760/54000]\n",
            "Batch loss: 0.723442,  Batch Accuracy: 85.94  [23040/54000]\n",
            "Batch loss: 0.760735,  Batch Accuracy: 82.03  [24320/54000]\n",
            "Batch loss: 0.674577,  Batch Accuracy: 84.38  [25600/54000]\n",
            "Batch loss: 0.650340,  Batch Accuracy: 84.38  [26880/54000]\n",
            "Batch loss: 0.552539,  Batch Accuracy: 88.28  [28160/54000]\n",
            "Batch loss: 0.799624,  Batch Accuracy: 82.81  [29440/54000]\n",
            "Batch loss: 0.730366,  Batch Accuracy: 82.03  [30720/54000]\n",
            "Batch loss: 0.742095,  Batch Accuracy: 84.38  [32000/54000]\n",
            "Batch loss: 0.733859,  Batch Accuracy: 82.03  [33280/54000]\n",
            "Batch loss: 0.568504,  Batch Accuracy: 90.62  [34560/54000]\n",
            "Batch loss: 0.665069,  Batch Accuracy: 82.81  [35840/54000]\n",
            "Batch loss: 0.777142,  Batch Accuracy: 87.50  [37120/54000]\n",
            "Batch loss: 0.583139,  Batch Accuracy: 87.50  [38400/54000]\n",
            "Batch loss: 0.711562,  Batch Accuracy: 88.28  [39680/54000]\n",
            "Batch loss: 0.647863,  Batch Accuracy: 88.28  [40960/54000]\n",
            "Batch loss: 0.699488,  Batch Accuracy: 85.16  [42240/54000]\n",
            "Batch loss: 0.690894,  Batch Accuracy: 85.94  [43520/54000]\n",
            "Batch loss: 0.707851,  Batch Accuracy: 82.81  [44800/54000]\n",
            "Batch loss: 0.637942,  Batch Accuracy: 85.16  [46080/54000]\n",
            "Batch loss: 0.662832,  Batch Accuracy: 87.50  [47360/54000]\n",
            "Batch loss: 0.554677,  Batch Accuracy: 86.72  [48640/54000]\n",
            "Batch loss: 0.636561,  Batch Accuracy: 86.72  [49920/54000]\n",
            "Batch loss: 0.630679,  Batch Accuracy: 86.72  [51200/54000]\n",
            "Batch loss: 0.707939,  Batch Accuracy: 83.59  [52480/54000]\n",
            "Batch loss: 0.738678,  Batch Accuracy: 83.59  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 85.30%, Loss: 0.6812\n",
            "Validation performance:\n",
            " Accuracy: 86.55%, Loss: 0.6547\n",
            "Test performance: Accuracy:\n",
            " 85.63%, Loss: 0.6580\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Batch loss: 0.700015,  Batch Accuracy: 85.94  [ 1280/54000]\n",
            "Batch loss: 0.562520,  Batch Accuracy: 88.28  [ 2560/54000]\n",
            "Batch loss: 0.625307,  Batch Accuracy: 85.94  [ 3840/54000]\n",
            "Batch loss: 0.647719,  Batch Accuracy: 88.28  [ 5120/54000]\n",
            "Batch loss: 0.737539,  Batch Accuracy: 85.94  [ 6400/54000]\n",
            "Batch loss: 0.670785,  Batch Accuracy: 89.06  [ 7680/54000]\n",
            "Batch loss: 0.654458,  Batch Accuracy: 85.94  [ 8960/54000]\n",
            "Batch loss: 0.627993,  Batch Accuracy: 89.84  [10240/54000]\n",
            "Batch loss: 0.596033,  Batch Accuracy: 90.62  [11520/54000]\n",
            "Batch loss: 0.834741,  Batch Accuracy: 82.03  [12800/54000]\n",
            "Batch loss: 0.587827,  Batch Accuracy: 85.16  [14080/54000]\n",
            "Batch loss: 0.620423,  Batch Accuracy: 83.59  [15360/54000]\n",
            "Batch loss: 0.606519,  Batch Accuracy: 87.50  [16640/54000]\n",
            "Batch loss: 0.605814,  Batch Accuracy: 86.72  [17920/54000]\n",
            "Batch loss: 0.600031,  Batch Accuracy: 89.06  [19200/54000]\n",
            "Batch loss: 0.638481,  Batch Accuracy: 85.94  [20480/54000]\n",
            "Batch loss: 0.634176,  Batch Accuracy: 88.28  [21760/54000]\n",
            "Batch loss: 0.700211,  Batch Accuracy: 84.38  [23040/54000]\n",
            "Batch loss: 0.577925,  Batch Accuracy: 87.50  [24320/54000]\n",
            "Batch loss: 0.646502,  Batch Accuracy: 85.16  [25600/54000]\n",
            "Batch loss: 0.608055,  Batch Accuracy: 88.28  [26880/54000]\n",
            "Batch loss: 0.665465,  Batch Accuracy: 83.59  [28160/54000]\n",
            "Batch loss: 0.616352,  Batch Accuracy: 85.94  [29440/54000]\n",
            "Batch loss: 0.669252,  Batch Accuracy: 85.94  [30720/54000]\n",
            "Batch loss: 0.694184,  Batch Accuracy: 88.28  [32000/54000]\n",
            "Batch loss: 0.695506,  Batch Accuracy: 88.28  [33280/54000]\n",
            "Batch loss: 0.672521,  Batch Accuracy: 89.06  [34560/54000]\n",
            "Batch loss: 0.533816,  Batch Accuracy: 89.84  [35840/54000]\n",
            "Batch loss: 0.757717,  Batch Accuracy: 78.12  [37120/54000]\n",
            "Batch loss: 0.630915,  Batch Accuracy: 88.28  [38400/54000]\n",
            "Batch loss: 0.681113,  Batch Accuracy: 85.94  [39680/54000]\n",
            "Batch loss: 0.678848,  Batch Accuracy: 84.38  [40960/54000]\n",
            "Batch loss: 0.610674,  Batch Accuracy: 86.72  [42240/54000]\n",
            "Batch loss: 0.621409,  Batch Accuracy: 85.16  [43520/54000]\n",
            "Batch loss: 0.490023,  Batch Accuracy: 89.06  [44800/54000]\n",
            "Batch loss: 0.560092,  Batch Accuracy: 89.06  [46080/54000]\n",
            "Batch loss: 0.664521,  Batch Accuracy: 82.81  [47360/54000]\n",
            "Batch loss: 0.533759,  Batch Accuracy: 91.41  [48640/54000]\n",
            "Batch loss: 0.546229,  Batch Accuracy: 90.62  [49920/54000]\n",
            "Batch loss: 0.589815,  Batch Accuracy: 86.72  [51200/54000]\n",
            "Batch loss: 0.547137,  Batch Accuracy: 91.41  [52480/54000]\n",
            "Batch loss: 0.544234,  Batch Accuracy: 92.19  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 86.99%, Loss: 0.6244\n",
            "Validation performance:\n",
            " Accuracy: 87.68%, Loss: 0.6021\n",
            "Test performance: Accuracy:\n",
            " 87.16%, Loss: 0.6055\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Batch loss: 0.665927,  Batch Accuracy: 88.28  [ 1280/54000]\n",
            "Batch loss: 0.586773,  Batch Accuracy: 90.62  [ 2560/54000]\n",
            "Batch loss: 0.521908,  Batch Accuracy: 89.84  [ 3840/54000]\n",
            "Batch loss: 0.668316,  Batch Accuracy: 82.81  [ 5120/54000]\n",
            "Batch loss: 0.600709,  Batch Accuracy: 90.62  [ 6400/54000]\n",
            "Batch loss: 0.513490,  Batch Accuracy: 92.97  [ 7680/54000]\n",
            "Batch loss: 0.532688,  Batch Accuracy: 89.84  [ 8960/54000]\n",
            "Batch loss: 0.592148,  Batch Accuracy: 89.84  [10240/54000]\n",
            "Batch loss: 0.631122,  Batch Accuracy: 87.50  [11520/54000]\n",
            "Batch loss: 0.612553,  Batch Accuracy: 85.16  [12800/54000]\n",
            "Batch loss: 0.554639,  Batch Accuracy: 88.28  [14080/54000]\n",
            "Batch loss: 0.479031,  Batch Accuracy: 91.41  [15360/54000]\n",
            "Batch loss: 0.630818,  Batch Accuracy: 87.50  [16640/54000]\n",
            "Batch loss: 0.507093,  Batch Accuracy: 93.75  [17920/54000]\n",
            "Batch loss: 0.555267,  Batch Accuracy: 87.50  [19200/54000]\n",
            "Batch loss: 0.581425,  Batch Accuracy: 87.50  [20480/54000]\n",
            "Batch loss: 0.590961,  Batch Accuracy: 84.38  [21760/54000]\n",
            "Batch loss: 0.523234,  Batch Accuracy: 89.84  [23040/54000]\n",
            "Batch loss: 0.474846,  Batch Accuracy: 90.62  [24320/54000]\n",
            "Batch loss: 0.636399,  Batch Accuracy: 90.62  [25600/54000]\n",
            "Batch loss: 0.540014,  Batch Accuracy: 89.06  [26880/54000]\n",
            "Batch loss: 0.546315,  Batch Accuracy: 92.19  [28160/54000]\n",
            "Batch loss: 0.415464,  Batch Accuracy: 98.44  [29440/54000]\n",
            "Batch loss: 0.567739,  Batch Accuracy: 88.28  [30720/54000]\n",
            "Batch loss: 0.606817,  Batch Accuracy: 88.28  [32000/54000]\n",
            "Batch loss: 0.561706,  Batch Accuracy: 84.38  [33280/54000]\n",
            "Batch loss: 0.470005,  Batch Accuracy: 92.97  [34560/54000]\n",
            "Batch loss: 0.504954,  Batch Accuracy: 92.19  [35840/54000]\n",
            "Batch loss: 0.506236,  Batch Accuracy: 89.84  [37120/54000]\n",
            "Batch loss: 0.548606,  Batch Accuracy: 88.28  [38400/54000]\n",
            "Batch loss: 0.587727,  Batch Accuracy: 86.72  [39680/54000]\n",
            "Batch loss: 0.545381,  Batch Accuracy: 85.94  [40960/54000]\n",
            "Batch loss: 0.523505,  Batch Accuracy: 89.84  [42240/54000]\n",
            "Batch loss: 0.564582,  Batch Accuracy: 91.41  [43520/54000]\n",
            "Batch loss: 0.507961,  Batch Accuracy: 88.28  [44800/54000]\n",
            "Batch loss: 0.506981,  Batch Accuracy: 89.84  [46080/54000]\n",
            "Batch loss: 0.576626,  Batch Accuracy: 89.06  [47360/54000]\n",
            "Batch loss: 0.770239,  Batch Accuracy: 85.16  [48640/54000]\n",
            "Batch loss: 0.523607,  Batch Accuracy: 90.62  [49920/54000]\n",
            "Batch loss: 0.488454,  Batch Accuracy: 93.75  [51200/54000]\n",
            "Batch loss: 0.588037,  Batch Accuracy: 86.72  [52480/54000]\n",
            "Batch loss: 0.486208,  Batch Accuracy: 92.19  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 88.43%, Loss: 0.5727\n",
            "Validation performance:\n",
            " Accuracy: 88.87%, Loss: 0.5534\n",
            "Test performance: Accuracy:\n",
            " 88.40%, Loss: 0.5569\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Batch loss: 0.651262,  Batch Accuracy: 82.81  [ 1280/54000]\n",
            "Batch loss: 0.680864,  Batch Accuracy: 85.94  [ 2560/54000]\n",
            "Batch loss: 0.524415,  Batch Accuracy: 92.19  [ 3840/54000]\n",
            "Batch loss: 0.479083,  Batch Accuracy: 89.06  [ 5120/54000]\n",
            "Batch loss: 0.505046,  Batch Accuracy: 88.28  [ 6400/54000]\n",
            "Batch loss: 0.544851,  Batch Accuracy: 86.72  [ 7680/54000]\n",
            "Batch loss: 0.444215,  Batch Accuracy: 92.19  [ 8960/54000]\n",
            "Batch loss: 0.525736,  Batch Accuracy: 89.06  [10240/54000]\n",
            "Batch loss: 0.578242,  Batch Accuracy: 86.72  [11520/54000]\n",
            "Batch loss: 0.514482,  Batch Accuracy: 89.84  [12800/54000]\n",
            "Batch loss: 0.575930,  Batch Accuracy: 90.62  [14080/54000]\n",
            "Batch loss: 0.570865,  Batch Accuracy: 88.28  [15360/54000]\n",
            "Batch loss: 0.539590,  Batch Accuracy: 86.72  [16640/54000]\n",
            "Batch loss: 0.536802,  Batch Accuracy: 86.72  [17920/54000]\n",
            "Batch loss: 0.531482,  Batch Accuracy: 86.72  [19200/54000]\n",
            "Batch loss: 0.432856,  Batch Accuracy: 95.31  [20480/54000]\n",
            "Batch loss: 0.456002,  Batch Accuracy: 92.97  [21760/54000]\n",
            "Batch loss: 0.514695,  Batch Accuracy: 90.62  [23040/54000]\n",
            "Batch loss: 0.457009,  Batch Accuracy: 93.75  [24320/54000]\n",
            "Batch loss: 0.496099,  Batch Accuracy: 86.72  [25600/54000]\n",
            "Batch loss: 0.630013,  Batch Accuracy: 86.72  [26880/54000]\n",
            "Batch loss: 0.479191,  Batch Accuracy: 89.84  [28160/54000]\n",
            "Batch loss: 0.521213,  Batch Accuracy: 89.06  [29440/54000]\n",
            "Batch loss: 0.481887,  Batch Accuracy: 90.62  [30720/54000]\n",
            "Batch loss: 0.483211,  Batch Accuracy: 85.94  [32000/54000]\n",
            "Batch loss: 0.394025,  Batch Accuracy: 95.31  [33280/54000]\n",
            "Batch loss: 0.512070,  Batch Accuracy: 88.28  [34560/54000]\n",
            "Batch loss: 0.520064,  Batch Accuracy: 89.84  [35840/54000]\n",
            "Batch loss: 0.536933,  Batch Accuracy: 85.94  [37120/54000]\n",
            "Batch loss: 0.442229,  Batch Accuracy: 91.41  [38400/54000]\n",
            "Batch loss: 0.634919,  Batch Accuracy: 85.94  [39680/54000]\n",
            "Batch loss: 0.597954,  Batch Accuracy: 87.50  [40960/54000]\n",
            "Batch loss: 0.536595,  Batch Accuracy: 84.38  [42240/54000]\n",
            "Batch loss: 0.421658,  Batch Accuracy: 90.62  [43520/54000]\n",
            "Batch loss: 0.505060,  Batch Accuracy: 92.19  [44800/54000]\n",
            "Batch loss: 0.455218,  Batch Accuracy: 92.97  [46080/54000]\n",
            "Batch loss: 0.533345,  Batch Accuracy: 88.28  [47360/54000]\n",
            "Batch loss: 0.626269,  Batch Accuracy: 87.50  [48640/54000]\n",
            "Batch loss: 0.531714,  Batch Accuracy: 86.72  [49920/54000]\n",
            "Batch loss: 0.523285,  Batch Accuracy: 89.84  [51200/54000]\n",
            "Batch loss: 0.432112,  Batch Accuracy: 90.62  [52480/54000]\n",
            "Batch loss: 0.424037,  Batch Accuracy: 92.97  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 89.64%, Loss: 0.5246\n",
            "Validation performance:\n",
            " Accuracy: 89.45%, Loss: 0.5114\n",
            "Test performance: Accuracy:\n",
            " 89.40%, Loss: 0.5125\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Batch loss: 0.502137,  Batch Accuracy: 90.62  [ 1280/54000]\n",
            "Batch loss: 0.547311,  Batch Accuracy: 89.84  [ 2560/54000]\n",
            "Batch loss: 0.567039,  Batch Accuracy: 91.41  [ 3840/54000]\n",
            "Batch loss: 0.391420,  Batch Accuracy: 94.53  [ 5120/54000]\n",
            "Batch loss: 0.481805,  Batch Accuracy: 89.84  [ 6400/54000]\n",
            "Batch loss: 0.512970,  Batch Accuracy: 85.94  [ 7680/54000]\n",
            "Batch loss: 0.524032,  Batch Accuracy: 88.28  [ 8960/54000]\n",
            "Batch loss: 0.489424,  Batch Accuracy: 91.41  [10240/54000]\n",
            "Batch loss: 0.474543,  Batch Accuracy: 86.72  [11520/54000]\n",
            "Batch loss: 0.532244,  Batch Accuracy: 90.62  [12800/54000]\n",
            "Batch loss: 0.498303,  Batch Accuracy: 90.62  [14080/54000]\n",
            "Batch loss: 0.440653,  Batch Accuracy: 91.41  [15360/54000]\n",
            "Batch loss: 0.463218,  Batch Accuracy: 92.97  [16640/54000]\n",
            "Batch loss: 0.403228,  Batch Accuracy: 92.19  [17920/54000]\n",
            "Batch loss: 0.563840,  Batch Accuracy: 85.94  [19200/54000]\n",
            "Batch loss: 0.519275,  Batch Accuracy: 89.06  [20480/54000]\n",
            "Batch loss: 0.526044,  Batch Accuracy: 88.28  [21760/54000]\n",
            "Batch loss: 0.449548,  Batch Accuracy: 89.84  [23040/54000]\n",
            "Batch loss: 0.435499,  Batch Accuracy: 92.19  [24320/54000]\n",
            "Batch loss: 0.634482,  Batch Accuracy: 85.16  [25600/54000]\n",
            "Batch loss: 0.501667,  Batch Accuracy: 92.19  [26880/54000]\n",
            "Batch loss: 0.564189,  Batch Accuracy: 87.50  [28160/54000]\n",
            "Batch loss: 0.440048,  Batch Accuracy: 89.06  [29440/54000]\n",
            "Batch loss: 0.493836,  Batch Accuracy: 91.41  [30720/54000]\n",
            "Batch loss: 0.395344,  Batch Accuracy: 93.75  [32000/54000]\n",
            "Batch loss: 0.501956,  Batch Accuracy: 90.62  [33280/54000]\n",
            "Batch loss: 0.442865,  Batch Accuracy: 94.53  [34560/54000]\n",
            "Batch loss: 0.370991,  Batch Accuracy: 92.97  [35840/54000]\n",
            "Batch loss: 0.427380,  Batch Accuracy: 93.75  [37120/54000]\n",
            "Batch loss: 0.387862,  Batch Accuracy: 92.97  [38400/54000]\n",
            "Batch loss: 0.415818,  Batch Accuracy: 92.97  [39680/54000]\n",
            "Batch loss: 0.368999,  Batch Accuracy: 93.75  [40960/54000]\n",
            "Batch loss: 0.389706,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.407269,  Batch Accuracy: 93.75  [43520/54000]\n",
            "Batch loss: 0.448710,  Batch Accuracy: 92.19  [44800/54000]\n",
            "Batch loss: 0.531058,  Batch Accuracy: 89.06  [46080/54000]\n",
            "Batch loss: 0.512720,  Batch Accuracy: 88.28  [47360/54000]\n",
            "Batch loss: 0.387818,  Batch Accuracy: 91.41  [48640/54000]\n",
            "Batch loss: 0.408635,  Batch Accuracy: 92.19  [49920/54000]\n",
            "Batch loss: 0.488161,  Batch Accuracy: 91.41  [51200/54000]\n",
            "Batch loss: 0.471545,  Batch Accuracy: 87.50  [52480/54000]\n",
            "Batch loss: 0.456013,  Batch Accuracy: 90.62  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 90.63%, Loss: 0.4814\n",
            "Validation performance:\n",
            " Accuracy: 90.33%, Loss: 0.4742\n",
            "Test performance: Accuracy:\n",
            " 90.06%, Loss: 0.4753\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Batch loss: 0.546712,  Batch Accuracy: 91.41  [ 1280/54000]\n",
            "Batch loss: 0.381423,  Batch Accuracy: 94.53  [ 2560/54000]\n",
            "Batch loss: 0.476235,  Batch Accuracy: 89.84  [ 3840/54000]\n",
            "Batch loss: 0.466800,  Batch Accuracy: 89.06  [ 5120/54000]\n",
            "Batch loss: 0.381498,  Batch Accuracy: 93.75  [ 6400/54000]\n",
            "Batch loss: 0.375407,  Batch Accuracy: 93.75  [ 7680/54000]\n",
            "Batch loss: 0.534314,  Batch Accuracy: 89.84  [ 8960/54000]\n",
            "Batch loss: 0.497397,  Batch Accuracy: 87.50  [10240/54000]\n",
            "Batch loss: 0.445388,  Batch Accuracy: 92.97  [11520/54000]\n",
            "Batch loss: 0.464210,  Batch Accuracy: 89.84  [12800/54000]\n",
            "Batch loss: 0.482028,  Batch Accuracy: 92.97  [14080/54000]\n",
            "Batch loss: 0.331023,  Batch Accuracy: 93.75  [15360/54000]\n",
            "Batch loss: 0.352901,  Batch Accuracy: 90.62  [16640/54000]\n",
            "Batch loss: 0.412539,  Batch Accuracy: 95.31  [17920/54000]\n",
            "Batch loss: 0.538280,  Batch Accuracy: 89.06  [19200/54000]\n",
            "Batch loss: 0.438376,  Batch Accuracy: 92.19  [20480/54000]\n",
            "Batch loss: 0.543868,  Batch Accuracy: 89.06  [21760/54000]\n",
            "Batch loss: 0.361143,  Batch Accuracy: 94.53  [23040/54000]\n",
            "Batch loss: 0.362253,  Batch Accuracy: 94.53  [24320/54000]\n",
            "Batch loss: 0.492596,  Batch Accuracy: 91.41  [25600/54000]\n",
            "Batch loss: 0.502627,  Batch Accuracy: 90.62  [26880/54000]\n",
            "Batch loss: 0.552576,  Batch Accuracy: 90.62  [28160/54000]\n",
            "Batch loss: 0.421553,  Batch Accuracy: 92.19  [29440/54000]\n",
            "Batch loss: 0.517581,  Batch Accuracy: 89.06  [30720/54000]\n",
            "Batch loss: 0.514059,  Batch Accuracy: 88.28  [32000/54000]\n",
            "Batch loss: 0.466202,  Batch Accuracy: 92.19  [33280/54000]\n",
            "Batch loss: 0.358549,  Batch Accuracy: 94.53  [34560/54000]\n",
            "Batch loss: 0.449834,  Batch Accuracy: 88.28  [35840/54000]\n",
            "Batch loss: 0.345160,  Batch Accuracy: 95.31  [37120/54000]\n",
            "Batch loss: 0.763200,  Batch Accuracy: 81.25  [38400/54000]\n",
            "Batch loss: 0.375425,  Batch Accuracy: 94.53  [39680/54000]\n",
            "Batch loss: 0.447026,  Batch Accuracy: 92.97  [40960/54000]\n",
            "Batch loss: 0.497090,  Batch Accuracy: 88.28  [42240/54000]\n",
            "Batch loss: 0.429371,  Batch Accuracy: 89.06  [43520/54000]\n",
            "Batch loss: 0.430910,  Batch Accuracy: 89.06  [44800/54000]\n",
            "Batch loss: 0.439754,  Batch Accuracy: 91.41  [46080/54000]\n",
            "Batch loss: 0.515848,  Batch Accuracy: 91.41  [47360/54000]\n",
            "Batch loss: 0.477034,  Batch Accuracy: 90.62  [48640/54000]\n",
            "Batch loss: 0.608401,  Batch Accuracy: 88.28  [49920/54000]\n",
            "Batch loss: 0.335674,  Batch Accuracy: 95.31  [51200/54000]\n",
            "Batch loss: 0.381635,  Batch Accuracy: 93.75  [52480/54000]\n",
            "Batch loss: 0.473097,  Batch Accuracy: 89.06  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 91.38%, Loss: 0.4448\n",
            "Validation performance:\n",
            " Accuracy: 90.67%, Loss: 0.4433\n",
            "Test performance: Accuracy:\n",
            " 90.49%, Loss: 0.4452\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Batch loss: 0.353953,  Batch Accuracy: 91.41  [ 1280/54000]\n",
            "Batch loss: 0.419303,  Batch Accuracy: 89.06  [ 2560/54000]\n",
            "Batch loss: 0.321835,  Batch Accuracy: 95.31  [ 3840/54000]\n",
            "Batch loss: 0.414525,  Batch Accuracy: 92.97  [ 5120/54000]\n",
            "Batch loss: 0.431561,  Batch Accuracy: 94.53  [ 6400/54000]\n",
            "Batch loss: 0.446783,  Batch Accuracy: 91.41  [ 7680/54000]\n",
            "Batch loss: 0.473230,  Batch Accuracy: 92.97  [ 8960/54000]\n",
            "Batch loss: 0.419359,  Batch Accuracy: 92.97  [10240/54000]\n",
            "Batch loss: 0.437094,  Batch Accuracy: 93.75  [11520/54000]\n",
            "Batch loss: 0.396298,  Batch Accuracy: 92.19  [12800/54000]\n",
            "Batch loss: 0.795355,  Batch Accuracy: 84.38  [14080/54000]\n",
            "Batch loss: 0.433029,  Batch Accuracy: 92.19  [15360/54000]\n",
            "Batch loss: 0.481325,  Batch Accuracy: 86.72  [16640/54000]\n",
            "Batch loss: 0.347919,  Batch Accuracy: 93.75  [17920/54000]\n",
            "Batch loss: 0.492448,  Batch Accuracy: 91.41  [19200/54000]\n",
            "Batch loss: 0.457343,  Batch Accuracy: 92.19  [20480/54000]\n",
            "Batch loss: 0.368535,  Batch Accuracy: 92.19  [21760/54000]\n",
            "Batch loss: 0.389371,  Batch Accuracy: 93.75  [23040/54000]\n",
            "Batch loss: 0.324589,  Batch Accuracy: 92.97  [24320/54000]\n",
            "Batch loss: 0.438366,  Batch Accuracy: 88.28  [25600/54000]\n",
            "Batch loss: 0.344328,  Batch Accuracy: 93.75  [26880/54000]\n",
            "Batch loss: 0.369827,  Batch Accuracy: 93.75  [28160/54000]\n",
            "Batch loss: 0.388422,  Batch Accuracy: 92.19  [29440/54000]\n",
            "Batch loss: 0.391661,  Batch Accuracy: 94.53  [30720/54000]\n",
            "Batch loss: 0.454334,  Batch Accuracy: 90.62  [32000/54000]\n",
            "Batch loss: 0.366664,  Batch Accuracy: 92.19  [33280/54000]\n",
            "Batch loss: 0.355562,  Batch Accuracy: 92.19  [34560/54000]\n",
            "Batch loss: 0.364827,  Batch Accuracy: 90.62  [35840/54000]\n",
            "Batch loss: 0.349301,  Batch Accuracy: 92.97  [37120/54000]\n",
            "Batch loss: 0.343412,  Batch Accuracy: 92.97  [38400/54000]\n",
            "Batch loss: 0.485000,  Batch Accuracy: 88.28  [39680/54000]\n",
            "Batch loss: 0.459639,  Batch Accuracy: 91.41  [40960/54000]\n",
            "Batch loss: 0.460590,  Batch Accuracy: 92.19  [42240/54000]\n",
            "Batch loss: 0.338590,  Batch Accuracy: 92.19  [43520/54000]\n",
            "Batch loss: 0.348795,  Batch Accuracy: 93.75  [44800/54000]\n",
            "Batch loss: 0.470062,  Batch Accuracy: 89.84  [46080/54000]\n",
            "Batch loss: 0.556378,  Batch Accuracy: 89.84  [47360/54000]\n",
            "Batch loss: 0.463353,  Batch Accuracy: 91.41  [48640/54000]\n",
            "Batch loss: 0.443375,  Batch Accuracy: 92.97  [49920/54000]\n",
            "Batch loss: 0.461606,  Batch Accuracy: 92.19  [51200/54000]\n",
            "Batch loss: 0.314541,  Batch Accuracy: 96.09  [52480/54000]\n",
            "Batch loss: 0.410183,  Batch Accuracy: 89.06  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 91.96%, Loss: 0.4142\n",
            "Validation performance:\n",
            " Accuracy: 91.20%, Loss: 0.4173\n",
            "Test performance: Accuracy:\n",
            " 91.00%, Loss: 0.4187\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Batch loss: 0.314072,  Batch Accuracy: 96.09  [ 1280/54000]\n",
            "Batch loss: 0.418439,  Batch Accuracy: 93.75  [ 2560/54000]\n",
            "Batch loss: 0.339010,  Batch Accuracy: 96.09  [ 3840/54000]\n",
            "Batch loss: 0.353972,  Batch Accuracy: 94.53  [ 5120/54000]\n",
            "Batch loss: 0.362508,  Batch Accuracy: 93.75  [ 6400/54000]\n",
            "Batch loss: 0.511803,  Batch Accuracy: 88.28  [ 7680/54000]\n",
            "Batch loss: 0.302968,  Batch Accuracy: 97.66  [ 8960/54000]\n",
            "Batch loss: 0.430098,  Batch Accuracy: 92.97  [10240/54000]\n",
            "Batch loss: 0.315093,  Batch Accuracy: 95.31  [11520/54000]\n",
            "Batch loss: 0.428278,  Batch Accuracy: 91.41  [12800/54000]\n",
            "Batch loss: 0.367723,  Batch Accuracy: 92.19  [14080/54000]\n",
            "Batch loss: 0.447751,  Batch Accuracy: 91.41  [15360/54000]\n",
            "Batch loss: 0.364440,  Batch Accuracy: 92.19  [16640/54000]\n",
            "Batch loss: 0.417235,  Batch Accuracy: 89.84  [17920/54000]\n",
            "Batch loss: 0.418909,  Batch Accuracy: 89.06  [19200/54000]\n",
            "Batch loss: 0.512044,  Batch Accuracy: 90.62  [20480/54000]\n",
            "Batch loss: 0.303213,  Batch Accuracy: 95.31  [21760/54000]\n",
            "Batch loss: 0.514910,  Batch Accuracy: 89.84  [23040/54000]\n",
            "Batch loss: 0.454204,  Batch Accuracy: 91.41  [24320/54000]\n",
            "Batch loss: 0.306311,  Batch Accuracy: 94.53  [25600/54000]\n",
            "Batch loss: 0.397763,  Batch Accuracy: 92.97  [26880/54000]\n",
            "Batch loss: 0.313035,  Batch Accuracy: 93.75  [28160/54000]\n",
            "Batch loss: 0.347809,  Batch Accuracy: 92.97  [29440/54000]\n",
            "Batch loss: 0.412010,  Batch Accuracy: 92.97  [30720/54000]\n",
            "Batch loss: 0.425380,  Batch Accuracy: 91.41  [32000/54000]\n",
            "Batch loss: 0.381115,  Batch Accuracy: 91.41  [33280/54000]\n",
            "Batch loss: 0.340387,  Batch Accuracy: 93.75  [34560/54000]\n",
            "Batch loss: 0.375247,  Batch Accuracy: 89.84  [35840/54000]\n",
            "Batch loss: 0.264495,  Batch Accuracy: 95.31  [37120/54000]\n",
            "Batch loss: 0.333793,  Batch Accuracy: 96.09  [38400/54000]\n",
            "Batch loss: 0.340112,  Batch Accuracy: 93.75  [39680/54000]\n",
            "Batch loss: 0.365410,  Batch Accuracy: 93.75  [40960/54000]\n",
            "Batch loss: 0.502673,  Batch Accuracy: 88.28  [42240/54000]\n",
            "Batch loss: 0.385718,  Batch Accuracy: 92.97  [43520/54000]\n",
            "Batch loss: 0.368944,  Batch Accuracy: 93.75  [44800/54000]\n",
            "Batch loss: 0.413854,  Batch Accuracy: 90.62  [46080/54000]\n",
            "Batch loss: 0.497096,  Batch Accuracy: 87.50  [47360/54000]\n",
            "Batch loss: 0.368806,  Batch Accuracy: 92.19  [48640/54000]\n",
            "Batch loss: 0.419412,  Batch Accuracy: 90.62  [49920/54000]\n",
            "Batch loss: 0.336847,  Batch Accuracy: 91.41  [51200/54000]\n",
            "Batch loss: 0.335997,  Batch Accuracy: 90.62  [52480/54000]\n",
            "Batch loss: 0.410488,  Batch Accuracy: 93.75  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 92.56%, Loss: 0.3876\n",
            "Validation performance:\n",
            " Accuracy: 91.40%, Loss: 0.3976\n",
            "Test performance: Accuracy:\n",
            " 91.23%, Loss: 0.3985\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Batch loss: 0.393713,  Batch Accuracy: 92.97  [ 1280/54000]\n",
            "Batch loss: 0.460159,  Batch Accuracy: 90.62  [ 2560/54000]\n",
            "Batch loss: 0.326327,  Batch Accuracy: 92.97  [ 3840/54000]\n",
            "Batch loss: 0.308446,  Batch Accuracy: 93.75  [ 5120/54000]\n",
            "Batch loss: 0.303643,  Batch Accuracy: 95.31  [ 6400/54000]\n",
            "Batch loss: 0.388233,  Batch Accuracy: 90.62  [ 7680/54000]\n",
            "Batch loss: 0.248945,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.451031,  Batch Accuracy: 86.72  [10240/54000]\n",
            "Batch loss: 0.274251,  Batch Accuracy: 96.09  [11520/54000]\n",
            "Batch loss: 0.402316,  Batch Accuracy: 91.41  [12800/54000]\n",
            "Batch loss: 0.432333,  Batch Accuracy: 90.62  [14080/54000]\n",
            "Batch loss: 0.286333,  Batch Accuracy: 95.31  [15360/54000]\n",
            "Batch loss: 0.378941,  Batch Accuracy: 90.62  [16640/54000]\n",
            "Batch loss: 0.381454,  Batch Accuracy: 92.19  [17920/54000]\n",
            "Batch loss: 0.570215,  Batch Accuracy: 86.72  [19200/54000]\n",
            "Batch loss: 0.268086,  Batch Accuracy: 95.31  [20480/54000]\n",
            "Batch loss: 0.416214,  Batch Accuracy: 89.84  [21760/54000]\n",
            "Batch loss: 0.379598,  Batch Accuracy: 92.97  [23040/54000]\n",
            "Batch loss: 0.270999,  Batch Accuracy: 96.88  [24320/54000]\n",
            "Batch loss: 0.320365,  Batch Accuracy: 92.19  [25600/54000]\n",
            "Batch loss: 0.278835,  Batch Accuracy: 93.75  [26880/54000]\n",
            "Batch loss: 0.348278,  Batch Accuracy: 91.41  [28160/54000]\n",
            "Batch loss: 0.303396,  Batch Accuracy: 95.31  [29440/54000]\n",
            "Batch loss: 0.419150,  Batch Accuracy: 92.19  [30720/54000]\n",
            "Batch loss: 0.365343,  Batch Accuracy: 92.97  [32000/54000]\n",
            "Batch loss: 0.336330,  Batch Accuracy: 93.75  [33280/54000]\n",
            "Batch loss: 0.358643,  Batch Accuracy: 91.41  [34560/54000]\n",
            "Batch loss: 0.454517,  Batch Accuracy: 95.31  [35840/54000]\n",
            "Batch loss: 0.222931,  Batch Accuracy: 98.44  [37120/54000]\n",
            "Batch loss: 0.286566,  Batch Accuracy: 96.88  [38400/54000]\n",
            "Batch loss: 0.392488,  Batch Accuracy: 92.97  [39680/54000]\n",
            "Batch loss: 0.482649,  Batch Accuracy: 92.97  [40960/54000]\n",
            "Batch loss: 0.355756,  Batch Accuracy: 93.75  [42240/54000]\n",
            "Batch loss: 0.342333,  Batch Accuracy: 93.75  [43520/54000]\n",
            "Batch loss: 0.317967,  Batch Accuracy: 92.19  [44800/54000]\n",
            "Batch loss: 0.357319,  Batch Accuracy: 90.62  [46080/54000]\n",
            "Batch loss: 0.384444,  Batch Accuracy: 92.19  [47360/54000]\n",
            "Batch loss: 0.256148,  Batch Accuracy: 96.88  [48640/54000]\n",
            "Batch loss: 0.300924,  Batch Accuracy: 93.75  [49920/54000]\n",
            "Batch loss: 0.220882,  Batch Accuracy: 97.66  [51200/54000]\n",
            "Batch loss: 0.354723,  Batch Accuracy: 92.19  [52480/54000]\n",
            "Batch loss: 0.351142,  Batch Accuracy: 92.19  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 93.05%, Loss: 0.3653\n",
            "Validation performance:\n",
            " Accuracy: 91.57%, Loss: 0.3799\n",
            "Test performance: Accuracy:\n",
            " 91.70%, Loss: 0.3798\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Batch loss: 0.271237,  Batch Accuracy: 96.09  [ 1280/54000]\n",
            "Batch loss: 0.295963,  Batch Accuracy: 94.53  [ 2560/54000]\n",
            "Batch loss: 0.312960,  Batch Accuracy: 94.53  [ 3840/54000]\n",
            "Batch loss: 0.312694,  Batch Accuracy: 95.31  [ 5120/54000]\n",
            "Batch loss: 0.390787,  Batch Accuracy: 93.75  [ 6400/54000]\n",
            "Batch loss: 0.394096,  Batch Accuracy: 91.41  [ 7680/54000]\n",
            "Batch loss: 0.306062,  Batch Accuracy: 95.31  [ 8960/54000]\n",
            "Batch loss: 0.284477,  Batch Accuracy: 96.09  [10240/54000]\n",
            "Batch loss: 0.260339,  Batch Accuracy: 95.31  [11520/54000]\n",
            "Batch loss: 0.349108,  Batch Accuracy: 92.97  [12800/54000]\n",
            "Batch loss: 0.383295,  Batch Accuracy: 93.75  [14080/54000]\n",
            "Batch loss: 0.419803,  Batch Accuracy: 91.41  [15360/54000]\n",
            "Batch loss: 0.314426,  Batch Accuracy: 95.31  [16640/54000]\n",
            "Batch loss: 0.511140,  Batch Accuracy: 89.84  [17920/54000]\n",
            "Batch loss: 0.230590,  Batch Accuracy: 95.31  [19200/54000]\n",
            "Batch loss: 0.280220,  Batch Accuracy: 94.53  [20480/54000]\n",
            "Batch loss: 0.311038,  Batch Accuracy: 93.75  [21760/54000]\n",
            "Batch loss: 0.417963,  Batch Accuracy: 93.75  [23040/54000]\n",
            "Batch loss: 0.294882,  Batch Accuracy: 96.09  [24320/54000]\n",
            "Batch loss: 0.348602,  Batch Accuracy: 94.53  [25600/54000]\n",
            "Batch loss: 0.401323,  Batch Accuracy: 91.41  [26880/54000]\n",
            "Batch loss: 0.282239,  Batch Accuracy: 93.75  [28160/54000]\n",
            "Batch loss: 0.423096,  Batch Accuracy: 92.19  [29440/54000]\n",
            "Batch loss: 0.426204,  Batch Accuracy: 95.31  [30720/54000]\n",
            "Batch loss: 0.365842,  Batch Accuracy: 92.97  [32000/54000]\n",
            "Batch loss: 0.423738,  Batch Accuracy: 90.62  [33280/54000]\n",
            "Batch loss: 0.407156,  Batch Accuracy: 91.41  [34560/54000]\n",
            "Batch loss: 0.602203,  Batch Accuracy: 90.62  [35840/54000]\n",
            "Batch loss: 0.265460,  Batch Accuracy: 96.09  [37120/54000]\n",
            "Batch loss: 0.390602,  Batch Accuracy: 92.97  [38400/54000]\n",
            "Batch loss: 0.446401,  Batch Accuracy: 93.75  [39680/54000]\n",
            "Batch loss: 0.270955,  Batch Accuracy: 94.53  [40960/54000]\n",
            "Batch loss: 0.377748,  Batch Accuracy: 93.75  [42240/54000]\n",
            "Batch loss: 0.346746,  Batch Accuracy: 93.75  [43520/54000]\n",
            "Batch loss: 0.234909,  Batch Accuracy: 96.88  [44800/54000]\n",
            "Batch loss: 0.454254,  Batch Accuracy: 91.41  [46080/54000]\n",
            "Batch loss: 0.289461,  Batch Accuracy: 92.97  [47360/54000]\n",
            "Batch loss: 0.336301,  Batch Accuracy: 95.31  [48640/54000]\n",
            "Batch loss: 0.232631,  Batch Accuracy: 96.09  [49920/54000]\n",
            "Batch loss: 0.323190,  Batch Accuracy: 96.09  [51200/54000]\n",
            "Batch loss: 0.230596,  Batch Accuracy: 97.66  [52480/54000]\n",
            "Batch loss: 0.376414,  Batch Accuracy: 92.97  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 93.52%, Loss: 0.3458\n",
            "Validation performance:\n",
            " Accuracy: 91.88%, Loss: 0.3659\n",
            "Test performance: Accuracy:\n",
            " 92.01%, Loss: 0.3645\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Batch loss: 0.406345,  Batch Accuracy: 92.19  [ 1280/54000]\n",
            "Batch loss: 0.313134,  Batch Accuracy: 93.75  [ 2560/54000]\n",
            "Batch loss: 0.310108,  Batch Accuracy: 91.41  [ 3840/54000]\n",
            "Batch loss: 0.543633,  Batch Accuracy: 85.94  [ 5120/54000]\n",
            "Batch loss: 0.384858,  Batch Accuracy: 94.53  [ 6400/54000]\n",
            "Batch loss: 0.241507,  Batch Accuracy: 96.88  [ 7680/54000]\n",
            "Batch loss: 0.258849,  Batch Accuracy: 96.88  [ 8960/54000]\n",
            "Batch loss: 0.328518,  Batch Accuracy: 94.53  [10240/54000]\n",
            "Batch loss: 0.357704,  Batch Accuracy: 92.19  [11520/54000]\n",
            "Batch loss: 0.304394,  Batch Accuracy: 92.19  [12800/54000]\n",
            "Batch loss: 0.377926,  Batch Accuracy: 91.41  [14080/54000]\n",
            "Batch loss: 0.403931,  Batch Accuracy: 92.97  [15360/54000]\n",
            "Batch loss: 0.303625,  Batch Accuracy: 92.97  [16640/54000]\n",
            "Batch loss: 0.329925,  Batch Accuracy: 94.53  [17920/54000]\n",
            "Batch loss: 0.379449,  Batch Accuracy: 91.41  [19200/54000]\n",
            "Batch loss: 0.360209,  Batch Accuracy: 92.19  [20480/54000]\n",
            "Batch loss: 0.384020,  Batch Accuracy: 89.84  [21760/54000]\n",
            "Batch loss: 0.364474,  Batch Accuracy: 91.41  [23040/54000]\n",
            "Batch loss: 0.330543,  Batch Accuracy: 93.75  [24320/54000]\n",
            "Batch loss: 0.305703,  Batch Accuracy: 94.53  [25600/54000]\n",
            "Batch loss: 0.332508,  Batch Accuracy: 92.97  [26880/54000]\n",
            "Batch loss: 0.226935,  Batch Accuracy: 97.66  [28160/54000]\n",
            "Batch loss: 0.300989,  Batch Accuracy: 94.53  [29440/54000]\n",
            "Batch loss: 0.317952,  Batch Accuracy: 96.88  [30720/54000]\n",
            "Batch loss: 0.272898,  Batch Accuracy: 95.31  [32000/54000]\n",
            "Batch loss: 0.330455,  Batch Accuracy: 96.09  [33280/54000]\n",
            "Batch loss: 0.303371,  Batch Accuracy: 92.97  [34560/54000]\n",
            "Batch loss: 0.332006,  Batch Accuracy: 93.75  [35840/54000]\n",
            "Batch loss: 0.256858,  Batch Accuracy: 95.31  [37120/54000]\n",
            "Batch loss: 0.296917,  Batch Accuracy: 93.75  [38400/54000]\n",
            "Batch loss: 0.313053,  Batch Accuracy: 95.31  [39680/54000]\n",
            "Batch loss: 0.235316,  Batch Accuracy: 97.66  [40960/54000]\n",
            "Batch loss: 0.242112,  Batch Accuracy: 97.66  [42240/54000]\n",
            "Batch loss: 0.382581,  Batch Accuracy: 92.19  [43520/54000]\n",
            "Batch loss: 0.272232,  Batch Accuracy: 95.31  [44800/54000]\n",
            "Batch loss: 0.418989,  Batch Accuracy: 88.28  [46080/54000]\n",
            "Batch loss: 0.276506,  Batch Accuracy: 93.75  [47360/54000]\n",
            "Batch loss: 0.375510,  Batch Accuracy: 92.19  [48640/54000]\n",
            "Batch loss: 0.331127,  Batch Accuracy: 93.75  [49920/54000]\n",
            "Batch loss: 0.193379,  Batch Accuracy: 97.66  [51200/54000]\n",
            "Batch loss: 0.343681,  Batch Accuracy: 94.53  [52480/54000]\n",
            "Batch loss: 0.233327,  Batch Accuracy: 95.31  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 93.92%, Loss: 0.3286\n",
            "Validation performance:\n",
            " Accuracy: 92.37%, Loss: 0.3500\n",
            "Test performance: Accuracy:\n",
            " 92.33%, Loss: 0.3511\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Batch loss: 0.285476,  Batch Accuracy: 93.75  [ 1280/54000]\n",
            "Batch loss: 0.492765,  Batch Accuracy: 91.41  [ 2560/54000]\n",
            "Batch loss: 0.421964,  Batch Accuracy: 92.19  [ 3840/54000]\n",
            "Batch loss: 0.305301,  Batch Accuracy: 93.75  [ 5120/54000]\n",
            "Batch loss: 0.368080,  Batch Accuracy: 94.53  [ 6400/54000]\n",
            "Batch loss: 0.298903,  Batch Accuracy: 96.09  [ 7680/54000]\n",
            "Batch loss: 0.392596,  Batch Accuracy: 92.97  [ 8960/54000]\n",
            "Batch loss: 0.252495,  Batch Accuracy: 95.31  [10240/54000]\n",
            "Batch loss: 0.299274,  Batch Accuracy: 95.31  [11520/54000]\n",
            "Batch loss: 0.261716,  Batch Accuracy: 96.09  [12800/54000]\n",
            "Batch loss: 0.314580,  Batch Accuracy: 94.53  [14080/54000]\n",
            "Batch loss: 0.328904,  Batch Accuracy: 92.97  [15360/54000]\n",
            "Batch loss: 0.342589,  Batch Accuracy: 94.53  [16640/54000]\n",
            "Batch loss: 0.251689,  Batch Accuracy: 96.09  [17920/54000]\n",
            "Batch loss: 0.444047,  Batch Accuracy: 89.84  [19200/54000]\n",
            "Batch loss: 0.267622,  Batch Accuracy: 94.53  [20480/54000]\n",
            "Batch loss: 0.242083,  Batch Accuracy: 96.09  [21760/54000]\n",
            "Batch loss: 0.288246,  Batch Accuracy: 95.31  [23040/54000]\n",
            "Batch loss: 0.424371,  Batch Accuracy: 90.62  [24320/54000]\n",
            "Batch loss: 0.246336,  Batch Accuracy: 93.75  [25600/54000]\n",
            "Batch loss: 0.379838,  Batch Accuracy: 91.41  [26880/54000]\n",
            "Batch loss: 0.236071,  Batch Accuracy: 96.88  [28160/54000]\n",
            "Batch loss: 0.312219,  Batch Accuracy: 92.97  [29440/54000]\n",
            "Batch loss: 0.291272,  Batch Accuracy: 95.31  [30720/54000]\n",
            "Batch loss: 0.300509,  Batch Accuracy: 94.53  [32000/54000]\n",
            "Batch loss: 0.395339,  Batch Accuracy: 92.97  [33280/54000]\n",
            "Batch loss: 0.238893,  Batch Accuracy: 96.88  [34560/54000]\n",
            "Batch loss: 0.335251,  Batch Accuracy: 94.53  [35840/54000]\n",
            "Batch loss: 0.292717,  Batch Accuracy: 92.19  [37120/54000]\n",
            "Batch loss: 0.442809,  Batch Accuracy: 89.06  [38400/54000]\n",
            "Batch loss: 0.434133,  Batch Accuracy: 93.75  [39680/54000]\n",
            "Batch loss: 0.301179,  Batch Accuracy: 94.53  [40960/54000]\n",
            "Batch loss: 0.179498,  Batch Accuracy: 99.22  [42240/54000]\n",
            "Batch loss: 0.268656,  Batch Accuracy: 97.66  [43520/54000]\n",
            "Batch loss: 0.331014,  Batch Accuracy: 93.75  [44800/54000]\n",
            "Batch loss: 0.350271,  Batch Accuracy: 94.53  [46080/54000]\n",
            "Batch loss: 0.330701,  Batch Accuracy: 92.97  [47360/54000]\n",
            "Batch loss: 0.288189,  Batch Accuracy: 94.53  [48640/54000]\n",
            "Batch loss: 0.297945,  Batch Accuracy: 90.62  [49920/54000]\n",
            "Batch loss: 0.337301,  Batch Accuracy: 91.41  [51200/54000]\n",
            "Batch loss: 0.255450,  Batch Accuracy: 94.53  [52480/54000]\n",
            "Batch loss: 0.374776,  Batch Accuracy: 89.06  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 94.39%, Loss: 0.3133\n",
            "Validation performance:\n",
            " Accuracy: 92.22%, Loss: 0.3402\n",
            "Test performance: Accuracy:\n",
            " 92.45%, Loss: 0.3422\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Batch loss: 0.303753,  Batch Accuracy: 96.88  [ 1280/54000]\n",
            "Batch loss: 0.466230,  Batch Accuracy: 92.19  [ 2560/54000]\n",
            "Batch loss: 0.337328,  Batch Accuracy: 94.53  [ 3840/54000]\n",
            "Batch loss: 0.213225,  Batch Accuracy: 95.31  [ 5120/54000]\n",
            "Batch loss: 0.305395,  Batch Accuracy: 93.75  [ 6400/54000]\n",
            "Batch loss: 0.308060,  Batch Accuracy: 94.53  [ 7680/54000]\n",
            "Batch loss: 0.255055,  Batch Accuracy: 94.53  [ 8960/54000]\n",
            "Batch loss: 0.222807,  Batch Accuracy: 96.09  [10240/54000]\n",
            "Batch loss: 0.577850,  Batch Accuracy: 90.62  [11520/54000]\n",
            "Batch loss: 0.299979,  Batch Accuracy: 96.09  [12800/54000]\n",
            "Batch loss: 0.302579,  Batch Accuracy: 93.75  [14080/54000]\n",
            "Batch loss: 0.219696,  Batch Accuracy: 97.66  [15360/54000]\n",
            "Batch loss: 0.308851,  Batch Accuracy: 93.75  [16640/54000]\n",
            "Batch loss: 0.206966,  Batch Accuracy: 96.09  [17920/54000]\n",
            "Batch loss: 0.243892,  Batch Accuracy: 95.31  [19200/54000]\n",
            "Batch loss: 0.409449,  Batch Accuracy: 93.75  [20480/54000]\n",
            "Batch loss: 0.261588,  Batch Accuracy: 96.09  [21760/54000]\n",
            "Batch loss: 0.243413,  Batch Accuracy: 93.75  [23040/54000]\n",
            "Batch loss: 0.239632,  Batch Accuracy: 94.53  [24320/54000]\n",
            "Batch loss: 0.167691,  Batch Accuracy: 98.44  [25600/54000]\n",
            "Batch loss: 0.290141,  Batch Accuracy: 92.19  [26880/54000]\n",
            "Batch loss: 0.187939,  Batch Accuracy: 96.88  [28160/54000]\n",
            "Batch loss: 0.288987,  Batch Accuracy: 96.88  [29440/54000]\n",
            "Batch loss: 0.389387,  Batch Accuracy: 93.75  [30720/54000]\n",
            "Batch loss: 0.274398,  Batch Accuracy: 96.09  [32000/54000]\n",
            "Batch loss: 0.315582,  Batch Accuracy: 95.31  [33280/54000]\n",
            "Batch loss: 0.256748,  Batch Accuracy: 94.53  [34560/54000]\n",
            "Batch loss: 0.312258,  Batch Accuracy: 92.97  [35840/54000]\n",
            "Batch loss: 0.324938,  Batch Accuracy: 92.97  [37120/54000]\n",
            "Batch loss: 0.329004,  Batch Accuracy: 95.31  [38400/54000]\n",
            "Batch loss: 0.347227,  Batch Accuracy: 91.41  [39680/54000]\n",
            "Batch loss: 0.342727,  Batch Accuracy: 96.88  [40960/54000]\n",
            "Batch loss: 0.229804,  Batch Accuracy: 94.53  [42240/54000]\n",
            "Batch loss: 0.361044,  Batch Accuracy: 94.53  [43520/54000]\n",
            "Batch loss: 0.184383,  Batch Accuracy: 96.09  [44800/54000]\n",
            "Batch loss: 0.176919,  Batch Accuracy: 96.88  [46080/54000]\n",
            "Batch loss: 0.356427,  Batch Accuracy: 94.53  [47360/54000]\n",
            "Batch loss: 0.302628,  Batch Accuracy: 96.88  [48640/54000]\n",
            "Batch loss: 0.433222,  Batch Accuracy: 91.41  [49920/54000]\n",
            "Batch loss: 0.382973,  Batch Accuracy: 92.97  [51200/54000]\n",
            "Batch loss: 0.291594,  Batch Accuracy: 94.53  [52480/54000]\n",
            "Batch loss: 0.290464,  Batch Accuracy: 94.53  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 94.66%, Loss: 0.3003\n",
            "Validation performance:\n",
            " Accuracy: 92.58%, Loss: 0.3302\n",
            "Test performance: Accuracy:\n",
            " 92.74%, Loss: 0.3310\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Batch loss: 0.270071,  Batch Accuracy: 96.09  [ 1280/54000]\n",
            "Batch loss: 0.379253,  Batch Accuracy: 90.62  [ 2560/54000]\n",
            "Batch loss: 0.381312,  Batch Accuracy: 91.41  [ 3840/54000]\n",
            "Batch loss: 0.245776,  Batch Accuracy: 94.53  [ 5120/54000]\n",
            "Batch loss: 0.299679,  Batch Accuracy: 94.53  [ 6400/54000]\n",
            "Batch loss: 0.255854,  Batch Accuracy: 95.31  [ 7680/54000]\n",
            "Batch loss: 0.200293,  Batch Accuracy: 97.66  [ 8960/54000]\n",
            "Batch loss: 0.228671,  Batch Accuracy: 97.66  [10240/54000]\n",
            "Batch loss: 0.326422,  Batch Accuracy: 96.09  [11520/54000]\n",
            "Batch loss: 0.221712,  Batch Accuracy: 97.66  [12800/54000]\n",
            "Batch loss: 0.371977,  Batch Accuracy: 92.19  [14080/54000]\n",
            "Batch loss: 0.369919,  Batch Accuracy: 94.53  [15360/54000]\n",
            "Batch loss: 0.282499,  Batch Accuracy: 94.53  [16640/54000]\n",
            "Batch loss: 0.285329,  Batch Accuracy: 96.09  [17920/54000]\n",
            "Batch loss: 0.221648,  Batch Accuracy: 96.09  [19200/54000]\n",
            "Batch loss: 0.224205,  Batch Accuracy: 94.53  [20480/54000]\n",
            "Batch loss: 0.255697,  Batch Accuracy: 96.09  [21760/54000]\n",
            "Batch loss: 0.298563,  Batch Accuracy: 96.88  [23040/54000]\n",
            "Batch loss: 0.204040,  Batch Accuracy: 96.88  [24320/54000]\n",
            "Batch loss: 0.377349,  Batch Accuracy: 92.97  [25600/54000]\n",
            "Batch loss: 0.232845,  Batch Accuracy: 96.88  [26880/54000]\n",
            "Batch loss: 0.257813,  Batch Accuracy: 96.88  [28160/54000]\n",
            "Batch loss: 0.254545,  Batch Accuracy: 92.19  [29440/54000]\n",
            "Batch loss: 0.468586,  Batch Accuracy: 92.19  [30720/54000]\n",
            "Batch loss: 0.333099,  Batch Accuracy: 92.19  [32000/54000]\n",
            "Batch loss: 0.331713,  Batch Accuracy: 93.75  [33280/54000]\n",
            "Batch loss: 0.332558,  Batch Accuracy: 94.53  [34560/54000]\n",
            "Batch loss: 0.322337,  Batch Accuracy: 92.97  [35840/54000]\n",
            "Batch loss: 0.263810,  Batch Accuracy: 95.31  [37120/54000]\n",
            "Batch loss: 0.327499,  Batch Accuracy: 92.97  [38400/54000]\n",
            "Batch loss: 0.268520,  Batch Accuracy: 96.09  [39680/54000]\n",
            "Batch loss: 0.240652,  Batch Accuracy: 96.88  [40960/54000]\n",
            "Batch loss: 0.259724,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.301238,  Batch Accuracy: 92.97  [43520/54000]\n",
            "Batch loss: 0.325205,  Batch Accuracy: 96.09  [44800/54000]\n",
            "Batch loss: 0.206049,  Batch Accuracy: 95.31  [46080/54000]\n",
            "Batch loss: 0.246654,  Batch Accuracy: 96.09  [47360/54000]\n",
            "Batch loss: 0.255810,  Batch Accuracy: 93.75  [48640/54000]\n",
            "Batch loss: 0.341066,  Batch Accuracy: 94.53  [49920/54000]\n",
            "Batch loss: 0.299516,  Batch Accuracy: 92.97  [51200/54000]\n",
            "Batch loss: 0.267906,  Batch Accuracy: 96.09  [52480/54000]\n",
            "Batch loss: 0.286051,  Batch Accuracy: 95.31  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 95.03%, Loss: 0.2878\n",
            "Validation performance:\n",
            " Accuracy: 92.93%, Loss: 0.3232\n",
            "Test performance: Accuracy:\n",
            " 92.75%, Loss: 0.3252\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Batch loss: 0.331553,  Batch Accuracy: 92.97  [ 1280/54000]\n",
            "Batch loss: 0.272460,  Batch Accuracy: 95.31  [ 2560/54000]\n",
            "Batch loss: 0.240324,  Batch Accuracy: 96.88  [ 3840/54000]\n",
            "Batch loss: 0.304791,  Batch Accuracy: 94.53  [ 5120/54000]\n",
            "Batch loss: 0.238110,  Batch Accuracy: 97.66  [ 6400/54000]\n",
            "Batch loss: 0.245391,  Batch Accuracy: 96.88  [ 7680/54000]\n",
            "Batch loss: 0.172792,  Batch Accuracy: 98.44  [ 8960/54000]\n",
            "Batch loss: 0.197871,  Batch Accuracy: 95.31  [10240/54000]\n",
            "Batch loss: 0.277241,  Batch Accuracy: 96.09  [11520/54000]\n",
            "Batch loss: 0.289238,  Batch Accuracy: 93.75  [12800/54000]\n",
            "Batch loss: 0.236965,  Batch Accuracy: 96.88  [14080/54000]\n",
            "Batch loss: 0.195850,  Batch Accuracy: 98.44  [15360/54000]\n",
            "Batch loss: 0.302192,  Batch Accuracy: 96.88  [16640/54000]\n",
            "Batch loss: 0.286302,  Batch Accuracy: 92.97  [17920/54000]\n",
            "Batch loss: 0.211344,  Batch Accuracy: 96.88  [19200/54000]\n",
            "Batch loss: 0.384079,  Batch Accuracy: 90.62  [20480/54000]\n",
            "Batch loss: 0.284150,  Batch Accuracy: 96.09  [21760/54000]\n",
            "Batch loss: 0.275343,  Batch Accuracy: 95.31  [23040/54000]\n",
            "Batch loss: 0.219617,  Batch Accuracy: 97.66  [24320/54000]\n",
            "Batch loss: 0.314644,  Batch Accuracy: 94.53  [25600/54000]\n",
            "Batch loss: 0.342188,  Batch Accuracy: 94.53  [26880/54000]\n",
            "Batch loss: 0.192590,  Batch Accuracy: 98.44  [28160/54000]\n",
            "Batch loss: 0.302766,  Batch Accuracy: 92.97  [29440/54000]\n",
            "Batch loss: 0.314538,  Batch Accuracy: 96.09  [30720/54000]\n",
            "Batch loss: 0.284350,  Batch Accuracy: 95.31  [32000/54000]\n",
            "Batch loss: 0.188345,  Batch Accuracy: 96.88  [33280/54000]\n",
            "Batch loss: 0.244295,  Batch Accuracy: 97.66  [34560/54000]\n",
            "Batch loss: 0.181246,  Batch Accuracy: 96.88  [35840/54000]\n",
            "Batch loss: 0.213565,  Batch Accuracy: 96.09  [37120/54000]\n",
            "Batch loss: 0.267312,  Batch Accuracy: 94.53  [38400/54000]\n",
            "Batch loss: 0.243274,  Batch Accuracy: 94.53  [39680/54000]\n",
            "Batch loss: 0.284848,  Batch Accuracy: 93.75  [40960/54000]\n",
            "Batch loss: 0.246412,  Batch Accuracy: 96.88  [42240/54000]\n",
            "Batch loss: 0.267184,  Batch Accuracy: 96.88  [43520/54000]\n",
            "Batch loss: 0.210185,  Batch Accuracy: 96.09  [44800/54000]\n",
            "Batch loss: 0.235490,  Batch Accuracy: 97.66  [46080/54000]\n",
            "Batch loss: 0.283728,  Batch Accuracy: 94.53  [47360/54000]\n",
            "Batch loss: 0.229450,  Batch Accuracy: 97.66  [48640/54000]\n",
            "Batch loss: 0.267293,  Batch Accuracy: 93.75  [49920/54000]\n",
            "Batch loss: 0.302905,  Batch Accuracy: 96.88  [51200/54000]\n",
            "Batch loss: 0.206879,  Batch Accuracy: 97.66  [52480/54000]\n",
            "Batch loss: 0.230855,  Batch Accuracy: 95.31  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 95.31%, Loss: 0.2764\n",
            "Validation performance:\n",
            " Accuracy: 93.02%, Loss: 0.3124\n",
            "Test performance: Accuracy:\n",
            " 92.97%, Loss: 0.3142\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Batch loss: 0.224813,  Batch Accuracy: 96.88  [ 1280/54000]\n",
            "Batch loss: 0.243757,  Batch Accuracy: 95.31  [ 2560/54000]\n",
            "Batch loss: 0.311732,  Batch Accuracy: 95.31  [ 3840/54000]\n",
            "Batch loss: 0.276252,  Batch Accuracy: 94.53  [ 5120/54000]\n",
            "Batch loss: 0.209767,  Batch Accuracy: 96.88  [ 6400/54000]\n",
            "Batch loss: 0.302938,  Batch Accuracy: 94.53  [ 7680/54000]\n",
            "Batch loss: 0.332379,  Batch Accuracy: 93.75  [ 8960/54000]\n",
            "Batch loss: 0.187062,  Batch Accuracy: 96.88  [10240/54000]\n",
            "Batch loss: 0.233041,  Batch Accuracy: 95.31  [11520/54000]\n",
            "Batch loss: 0.280681,  Batch Accuracy: 96.09  [12800/54000]\n",
            "Batch loss: 0.185839,  Batch Accuracy: 96.88  [14080/54000]\n",
            "Batch loss: 0.267573,  Batch Accuracy: 95.31  [15360/54000]\n",
            "Batch loss: 0.363254,  Batch Accuracy: 92.19  [16640/54000]\n",
            "Batch loss: 0.140302,  Batch Accuracy: 100.00  [17920/54000]\n",
            "Batch loss: 0.161346,  Batch Accuracy: 98.44  [19200/54000]\n",
            "Batch loss: 0.261346,  Batch Accuracy: 94.53  [20480/54000]\n",
            "Batch loss: 0.264342,  Batch Accuracy: 94.53  [21760/54000]\n",
            "Batch loss: 0.244226,  Batch Accuracy: 96.09  [23040/54000]\n",
            "Batch loss: 0.233810,  Batch Accuracy: 96.09  [24320/54000]\n",
            "Batch loss: 0.295081,  Batch Accuracy: 96.09  [25600/54000]\n",
            "Batch loss: 0.255449,  Batch Accuracy: 94.53  [26880/54000]\n",
            "Batch loss: 0.297115,  Batch Accuracy: 93.75  [28160/54000]\n",
            "Batch loss: 0.249688,  Batch Accuracy: 94.53  [29440/54000]\n",
            "Batch loss: 0.246439,  Batch Accuracy: 93.75  [30720/54000]\n",
            "Batch loss: 0.230053,  Batch Accuracy: 95.31  [32000/54000]\n",
            "Batch loss: 0.294800,  Batch Accuracy: 96.88  [33280/54000]\n",
            "Batch loss: 0.302522,  Batch Accuracy: 96.09  [34560/54000]\n",
            "Batch loss: 0.190656,  Batch Accuracy: 97.66  [35840/54000]\n",
            "Batch loss: 0.177233,  Batch Accuracy: 97.66  [37120/54000]\n",
            "Batch loss: 0.335483,  Batch Accuracy: 95.31  [38400/54000]\n",
            "Batch loss: 0.182360,  Batch Accuracy: 98.44  [39680/54000]\n",
            "Batch loss: 0.280390,  Batch Accuracy: 94.53  [40960/54000]\n",
            "Batch loss: 0.284081,  Batch Accuracy: 94.53  [42240/54000]\n",
            "Batch loss: 0.239384,  Batch Accuracy: 97.66  [43520/54000]\n",
            "Batch loss: 0.193198,  Batch Accuracy: 96.88  [44800/54000]\n",
            "Batch loss: 0.257063,  Batch Accuracy: 95.31  [46080/54000]\n",
            "Batch loss: 0.162811,  Batch Accuracy: 99.22  [47360/54000]\n",
            "Batch loss: 0.246805,  Batch Accuracy: 95.31  [48640/54000]\n",
            "Batch loss: 0.307645,  Batch Accuracy: 94.53  [49920/54000]\n",
            "Batch loss: 0.190697,  Batch Accuracy: 96.09  [51200/54000]\n",
            "Batch loss: 0.173498,  Batch Accuracy: 98.44  [52480/54000]\n",
            "Batch loss: 0.309687,  Batch Accuracy: 92.97  [53760/54000]\n",
            "Training performance:\n",
            " Accuracy: 95.64%, Loss: 0.2658\n",
            "Validation performance:\n",
            " Accuracy: 93.13%, Loss: 0.3061\n",
            "Test performance: Accuracy:\n",
            " 93.13%, Loss: 0.3075\n",
            "Total time taken to Train: 1.8952167272567748 mins\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train_Q4b(model_custom:MyNet, train_loader:DataLoader, sgd_optimizer:SGD, ce_loss:CrossEntropyLoss):\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        sgd_optimizer.zero_grad()\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        ce_loss.backward(model_custom, labels)\n",
        "        sgd_optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        batch_correct = (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        correct += batch_correct\n",
        "        batch_accuracy = 100 * batch_correct / len(images)\n",
        "        if (batch + 1) % 10 == 0:\n",
        "            current = (batch + 1) * len(images)\n",
        "            print(f\"Batch loss: {loss.item():>7f},  Batch Accuracy: {batch_accuracy:>0.2f}  [{current:>5d}/{len(train_sampler):>5d}]\")\n",
        "        batch += 1\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Training performance:\\n Accuracy: {accuracy:.2f}%, Loss: {train_loss:.4f}\")\n",
        "    return train_loss, accuracy\n",
        "\n",
        "# Validation loop\n",
        "def validate_Q4b(model_custom:MyNet, valid_loader:DataLoader, ce_loss:CrossEntropyLoss):\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in valid_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        val_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss /= len(valid_loader)\n",
        "    print(f\"Validation performance:\\n Accuracy: {accuracy:.2f}%, Loss: {val_loss:.4f}\")\n",
        "    return val_loss, accuracy\n",
        "\n",
        "# Testing loop\n",
        "def test_Q4b(model_custom:MyNet, test_loader:DataLoader, ce_loss:CrossEntropyLoss):\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.view(images.size(0), -1)\n",
        "        output = model_custom.forward(images)\n",
        "        loss = ce_loss.forward(output, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Test performance: Accuracy:\\n {accuracy:.2f}%, Loss: {test_loss:.4f}\")\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# Training, Validation, and Testing of the model_custom\n",
        "train_losses_q4b, train_accuracies_q4b = [], []\n",
        "val_losses_q4b, val_accuracies_q4b = [], []\n",
        "test_losses_q4b, test_accuracies_q4b = [], []\n",
        "start_time = time.time()\n",
        "num_epochs = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_Q4b(model_q4b, train_loader, sgd_optimizer_q4b, ce_loss_q4b)\n",
        "    val_loss, val_acc = validate_Q4b(model_q4b, valid_loader, ce_loss_q4b)\n",
        "    test_loss, test_acc = test_Q4b(model_q4b, test_loader, ce_loss_q4b)\n",
        "\n",
        "    train_losses_q4b.append(train_loss)\n",
        "    train_accuracies_q4b.append(train_acc)\n",
        "    val_losses_q4b.append(val_loss)\n",
        "    val_accuracies_q4b.append(val_acc)\n",
        "    test_losses_q4b.append(test_loss)\n",
        "    test_accuracies_q4b.append(test_acc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'Total time taken to Train: {(end_time - start_time) / 60} mins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "UeNxxORq_uYk",
        "outputId": "d2e038d4-9b8f-4f80-aed1-c508f99ffc1f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_losses_q4b, label='Train')\n",
        "plt.plot(range(num_epochs), val_losses_q4b, label='Validation')\n",
        "plt.plot(range(num_epochs), test_losses_q4b, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_accuracies_q4b, label='Train')\n",
        "plt.plot(range(num_epochs), val_accuracies_q4b, label='Validation')\n",
        "plt.plot(range(num_epochs), test_accuracies_q4b, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the custom implementation of the MLP network with sigmoid activation function, the model is not able to learn the features and thus performs poorly due to change in activation from ReLU (linear) to Sigmoid (weighted & scaled over outputs). However, i observed the with higher learning rate, the same model is able to learn the features and perform better beacuse of the faster speed of convergence. \n",
        "\n",
        "For the scratch implementation of the MLP network with sigmoid activation function, the model is learning the features and thus performing good. However, this is happening only after 20-30 epoches. It seems model is taking more time to train as compared to ReLU activation function. \n",
        "\n",
        "Also, the time taken for both the scratch and pytorch implementation to train (or completing 60 epoches) are same. \n",
        "Around 1.8 minutes for both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5zU9Wg3zoVA"
      },
      "source": [
        "# BONUS Question-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zYnDeiUzrPU"
      },
      "source": [
        "### Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ACUhyX4Rzr4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MLP_Bonus(nn.Module):\n",
        "    def __init__(self, in_features:int=28*28, out_features:int=10):\n",
        "        super(MLP_Bonus, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=512, bias=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=512, bias=True)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=512, out_features=1024, bias=True)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(in_features=1024, out_features=1024, bias=True)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc5 = nn.Linear(in_features=1024, out_features=2048, bias=True)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.fc6 = nn.Linear(in_features=2048, out_features=2048, bias=True)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        # self.fc7 = nn.Linear(in_features=2048, out_features=2048, bias=True)\n",
        "        # self.relu7 = nn.ReLU()\n",
        "        # self.fc8 = nn.Linear(in_features=1024, out_features=1024, bias=True)\n",
        "        # self.relu8 = nn.ReLU()\n",
        "        # self.fc9 = nn.Linear(in_features=1024, out_features=1024, bias=True)\n",
        "        # self.relu9 = nn.ReLU()\n",
        "        # self.fc10 = nn.Linear(in_features=1024, out_features=1024, bias=True)\n",
        "        # self.relu10 = nn.ReLU()\n",
        "        # self.fc11 = nn.Linear(in_features=1024, out_features=1024, bias=True)\n",
        "        # self.relu11 = nn.ReLU()\n",
        "        self.fc12 = nn.Linear(in_features=2048, out_features=2048, bias=True)\n",
        "        self.relu12 = nn.ReLU()\n",
        "        self.fc13 = nn.Linear(in_features=2048, out_features=1024, bias=True)\n",
        "        self.relu13 = nn.ReLU()\n",
        "        self.fc14 = nn.Linear(in_features=1024, out_features=512, bias=True)\n",
        "        self.relu14 = nn.ReLU()\n",
        "        self.fc15 = nn.Linear(in_features=512, out_features=512, bias=True)\n",
        "        self.relu15 = nn.ReLU()\n",
        "        self.fc16 = nn.Linear(in_features=512, out_features=out_features, bias=True)\n",
        "        self.softmax16 = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.relu3(self.fc3(x))\n",
        "        x = self.relu4(self.fc4(x))\n",
        "        x = self.relu5(self.fc5(x))\n",
        "        x = self.relu6(self.fc6(x))\n",
        "        # x = self.relu7(self.fc7(x))\n",
        "        # x = self.relu8(self.fc8(x))\n",
        "        # x = self.relu9(self.fc9(x))\n",
        "        # x = self.relu10(self.fc10(x))\n",
        "        # x = self.relu11(self.fc11(x))\n",
        "        x = self.relu12(self.fc12(x))\n",
        "        x = self.relu13(self.fc13(x))\n",
        "        x = self.relu14(self.fc14(x))\n",
        "        x = self.relu15(self.fc15(x))\n",
        "        logits = self.fc16(x)\n",
        "        probas = self.softmax16(logits)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOCNk1n71IlY"
      },
      "source": [
        "### Initialize DataSet and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taBndOHE1MlL",
        "outputId": "b2187f25-0293-45cf-f6b9-98865ba8dc07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 60000\n",
            "Dataset image shape: torch.Size([60000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([60000])\n",
            "\n",
            "MNIST Custom Dataset Initialized...\n",
            "MNIST Custom Dataset length: 10000\n",
            "Dataset image shape: torch.Size([10000, 1, 28, 28])\n",
            "Dataset label shape: torch.Size([10000])\n",
            "\n",
            "Train Dataset Length: 54000\n",
            "Validation Dataset Length: 6000\n",
            "Test Dataset Length: 10000\n"
          ]
        }
      ],
      "source": [
        "# Creating training and test datasets\n",
        "root = './data/MNIST/raw/'\n",
        "train_dataset = MNISTCustomDataset(root=root, train=True, transform=None)\n",
        "test_dataset = MNISTCustomDataset(root=root, train=False, transform=None)\n",
        "\n",
        "# splitting of training and validation set\n",
        "batch_size = 128\n",
        "valid_size = 0.1\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print('Train Dataset Length: {}'.format(len(train_sampler)))\n",
        "print('Validation Dataset Length: {}'.format(len(valid_sampler)))\n",
        "print('Test Dataset Length: {}'.format(len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZmVQLYk1V-K"
      },
      "source": [
        "### Initialization of Model and its parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZKy8bp41YfI",
        "outputId": "825ed5ea-3496-4880-aa27-355763af9f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model_bonus = MLP_Bonus()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "optimizer_bonus = optim.SGD(model_bonus.parameters(), lr=0.0003)\n",
        "criterion_bonus = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAufnDPE1ZZr"
      },
      "source": [
        "### Training of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTuNnd9N1clI",
        "outputId": "5c94578b-2ec3-4592-d9d5-7a24380cc85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Batch Loss: 2.304476,  Batch Accuracy: 10.16   [ 1280/54000]\n",
            "Batch Loss: 2.307714,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.303729,  Batch Accuracy: 10.16   [ 3840/54000]\n",
            "Batch Loss: 2.304481,  Batch Accuracy: 5.47   [ 5120/54000]\n",
            "Batch Loss: 2.301047,  Batch Accuracy: 14.84   [ 6400/54000]\n",
            "Batch Loss: 2.301868,  Batch Accuracy: 14.84   [ 7680/54000]\n",
            "Batch Loss: 2.301548,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.303400,  Batch Accuracy: 8.59   [10240/54000]\n",
            "Batch Loss: 2.304098,  Batch Accuracy: 10.94   [11520/54000]\n",
            "Batch Loss: 2.302260,  Batch Accuracy: 13.28   [12800/54000]\n",
            "Batch Loss: 2.302326,  Batch Accuracy: 7.03   [14080/54000]\n",
            "Batch Loss: 2.302458,  Batch Accuracy: 12.50   [15360/54000]\n",
            "Batch Loss: 2.302103,  Batch Accuracy: 9.38   [16640/54000]\n",
            "Batch Loss: 2.302757,  Batch Accuracy: 10.94   [17920/54000]\n",
            "Batch Loss: 2.303371,  Batch Accuracy: 10.94   [19200/54000]\n",
            "Batch Loss: 2.301843,  Batch Accuracy: 14.84   [20480/54000]\n",
            "Batch Loss: 2.303448,  Batch Accuracy: 13.28   [21760/54000]\n",
            "Batch Loss: 2.297887,  Batch Accuracy: 16.41   [23040/54000]\n",
            "Batch Loss: 2.304222,  Batch Accuracy: 10.94   [24320/54000]\n",
            "Batch Loss: 2.302729,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.303450,  Batch Accuracy: 6.25   [26880/54000]\n",
            "Batch Loss: 2.301819,  Batch Accuracy: 13.28   [28160/54000]\n",
            "Batch Loss: 2.303813,  Batch Accuracy: 10.16   [29440/54000]\n",
            "Batch Loss: 2.298795,  Batch Accuracy: 16.41   [30720/54000]\n",
            "Batch Loss: 2.299594,  Batch Accuracy: 14.84   [32000/54000]\n",
            "Batch Loss: 2.297366,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.298002,  Batch Accuracy: 10.16   [34560/54000]\n",
            "Batch Loss: 2.300200,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.305439,  Batch Accuracy: 9.38   [37120/54000]\n",
            "Batch Loss: 2.302544,  Batch Accuracy: 11.72   [38400/54000]\n",
            "Batch Loss: 2.301047,  Batch Accuracy: 10.16   [39680/54000]\n",
            "Batch Loss: 2.304416,  Batch Accuracy: 4.69   [40960/54000]\n",
            "Batch Loss: 2.300712,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.302604,  Batch Accuracy: 12.50   [43520/54000]\n",
            "Batch Loss: 2.300995,  Batch Accuracy: 10.94   [44800/54000]\n",
            "Batch Loss: 2.304029,  Batch Accuracy: 8.59   [46080/54000]\n",
            "Batch Loss: 2.300767,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.305351,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.298468,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.302889,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.302329,  Batch Accuracy: 10.94   [52480/54000]\n",
            "Batch Loss: 2.306861,  Batch Accuracy: 7.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 10.4%, Loss: 2.302932\n",
            "Validation performance: \n",
            " Accuracy: 11.1%, Loss: 2.302618\n",
            "Test performance: \n",
            " Accuracy: 11.4%, Loss: 2.302612 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Batch Loss: 2.304239,  Batch Accuracy: 11.72   [ 1280/54000]\n",
            "Batch Loss: 2.303406,  Batch Accuracy: 10.94   [ 2560/54000]\n",
            "Batch Loss: 2.303774,  Batch Accuracy: 8.59   [ 3840/54000]\n",
            "Batch Loss: 2.303148,  Batch Accuracy: 10.94   [ 5120/54000]\n",
            "Batch Loss: 2.301701,  Batch Accuracy: 14.06   [ 6400/54000]\n",
            "Batch Loss: 2.305418,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.302607,  Batch Accuracy: 7.81   [ 8960/54000]\n",
            "Batch Loss: 2.301312,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.305381,  Batch Accuracy: 7.81   [11520/54000]\n",
            "Batch Loss: 2.305599,  Batch Accuracy: 12.50   [12800/54000]\n",
            "Batch Loss: 2.300498,  Batch Accuracy: 12.50   [14080/54000]\n",
            "Batch Loss: 2.302139,  Batch Accuracy: 13.28   [15360/54000]\n",
            "Batch Loss: 2.304261,  Batch Accuracy: 11.72   [16640/54000]\n",
            "Batch Loss: 2.303199,  Batch Accuracy: 7.03   [17920/54000]\n",
            "Batch Loss: 2.302793,  Batch Accuracy: 14.84   [19200/54000]\n",
            "Batch Loss: 2.302644,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.309335,  Batch Accuracy: 7.03   [21760/54000]\n",
            "Batch Loss: 2.305485,  Batch Accuracy: 6.25   [23040/54000]\n",
            "Batch Loss: 2.299924,  Batch Accuracy: 15.62   [24320/54000]\n",
            "Batch Loss: 2.304830,  Batch Accuracy: 8.59   [25600/54000]\n",
            "Batch Loss: 2.298321,  Batch Accuracy: 10.94   [26880/54000]\n",
            "Batch Loss: 2.301871,  Batch Accuracy: 12.50   [28160/54000]\n",
            "Batch Loss: 2.298923,  Batch Accuracy: 18.75   [29440/54000]\n",
            "Batch Loss: 2.300591,  Batch Accuracy: 14.84   [30720/54000]\n",
            "Batch Loss: 2.298215,  Batch Accuracy: 12.50   [32000/54000]\n",
            "Batch Loss: 2.306555,  Batch Accuracy: 10.16   [33280/54000]\n",
            "Batch Loss: 2.302809,  Batch Accuracy: 8.59   [34560/54000]\n",
            "Batch Loss: 2.300518,  Batch Accuracy: 10.16   [35840/54000]\n",
            "Batch Loss: 2.299847,  Batch Accuracy: 14.84   [37120/54000]\n",
            "Batch Loss: 2.300344,  Batch Accuracy: 10.94   [38400/54000]\n",
            "Batch Loss: 2.304031,  Batch Accuracy: 8.59   [39680/54000]\n",
            "Batch Loss: 2.301285,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.302832,  Batch Accuracy: 7.81   [42240/54000]\n",
            "Batch Loss: 2.302536,  Batch Accuracy: 10.94   [43520/54000]\n",
            "Batch Loss: 2.298064,  Batch Accuracy: 15.62   [44800/54000]\n",
            "Batch Loss: 2.298190,  Batch Accuracy: 13.28   [46080/54000]\n",
            "Batch Loss: 2.302801,  Batch Accuracy: 9.38   [47360/54000]\n",
            "Batch Loss: 2.302644,  Batch Accuracy: 10.16   [48640/54000]\n",
            "Batch Loss: 2.304528,  Batch Accuracy: 9.38   [49920/54000]\n",
            "Batch Loss: 2.304967,  Batch Accuracy: 10.94   [51200/54000]\n",
            "Batch Loss: 2.297936,  Batch Accuracy: 14.84   [52480/54000]\n",
            "Batch Loss: 2.297396,  Batch Accuracy: 15.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 11.3%, Loss: 2.302362\n",
            "Validation performance: \n",
            " Accuracy: 12.0%, Loss: 2.302077\n",
            "Test performance: \n",
            " Accuracy: 12.3%, Loss: 2.302027 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Batch Loss: 2.299967,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.306561,  Batch Accuracy: 9.38   [ 2560/54000]\n",
            "Batch Loss: 2.304266,  Batch Accuracy: 15.62   [ 3840/54000]\n",
            "Batch Loss: 2.303428,  Batch Accuracy: 15.62   [ 5120/54000]\n",
            "Batch Loss: 2.303069,  Batch Accuracy: 7.81   [ 6400/54000]\n",
            "Batch Loss: 2.303883,  Batch Accuracy: 10.16   [ 7680/54000]\n",
            "Batch Loss: 2.303949,  Batch Accuracy: 8.59   [ 8960/54000]\n",
            "Batch Loss: 2.304557,  Batch Accuracy: 12.50   [10240/54000]\n",
            "Batch Loss: 2.299345,  Batch Accuracy: 18.75   [11520/54000]\n",
            "Batch Loss: 2.300490,  Batch Accuracy: 17.97   [12800/54000]\n",
            "Batch Loss: 2.302369,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.301750,  Batch Accuracy: 9.38   [15360/54000]\n",
            "Batch Loss: 2.303999,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.301028,  Batch Accuracy: 14.06   [17920/54000]\n",
            "Batch Loss: 2.302583,  Batch Accuracy: 10.16   [19200/54000]\n",
            "Batch Loss: 2.303040,  Batch Accuracy: 10.16   [20480/54000]\n",
            "Batch Loss: 2.302314,  Batch Accuracy: 9.38   [21760/54000]\n",
            "Batch Loss: 2.302446,  Batch Accuracy: 7.81   [23040/54000]\n",
            "Batch Loss: 2.299720,  Batch Accuracy: 7.81   [24320/54000]\n",
            "Batch Loss: 2.301469,  Batch Accuracy: 15.62   [25600/54000]\n",
            "Batch Loss: 2.301560,  Batch Accuracy: 14.06   [26880/54000]\n",
            "Batch Loss: 2.302978,  Batch Accuracy: 10.16   [28160/54000]\n",
            "Batch Loss: 2.299941,  Batch Accuracy: 13.28   [29440/54000]\n",
            "Batch Loss: 2.298945,  Batch Accuracy: 14.84   [30720/54000]\n",
            "Batch Loss: 2.300373,  Batch Accuracy: 14.06   [32000/54000]\n",
            "Batch Loss: 2.300047,  Batch Accuracy: 14.84   [33280/54000]\n",
            "Batch Loss: 2.303819,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.299289,  Batch Accuracy: 17.97   [35840/54000]\n",
            "Batch Loss: 2.298644,  Batch Accuracy: 11.72   [37120/54000]\n",
            "Batch Loss: 2.301749,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.297186,  Batch Accuracy: 9.38   [39680/54000]\n",
            "Batch Loss: 2.303090,  Batch Accuracy: 12.50   [40960/54000]\n",
            "Batch Loss: 2.300626,  Batch Accuracy: 12.50   [42240/54000]\n",
            "Batch Loss: 2.299847,  Batch Accuracy: 11.72   [43520/54000]\n",
            "Batch Loss: 2.301008,  Batch Accuracy: 11.72   [44800/54000]\n",
            "Batch Loss: 2.305611,  Batch Accuracy: 10.16   [46080/54000]\n",
            "Batch Loss: 2.302398,  Batch Accuracy: 16.41   [47360/54000]\n",
            "Batch Loss: 2.301676,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.304964,  Batch Accuracy: 10.94   [49920/54000]\n",
            "Batch Loss: 2.302236,  Batch Accuracy: 10.16   [51200/54000]\n",
            "Batch Loss: 2.298604,  Batch Accuracy: 19.53   [52480/54000]\n",
            "Batch Loss: 2.304661,  Batch Accuracy: 12.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 12.3%, Loss: 2.301792\n",
            "Validation performance: \n",
            " Accuracy: 12.9%, Loss: 2.301525\n",
            "Test performance: \n",
            " Accuracy: 13.6%, Loss: 2.301436 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Batch Loss: 2.298472,  Batch Accuracy: 14.84   [ 1280/54000]\n",
            "Batch Loss: 2.301795,  Batch Accuracy: 11.72   [ 2560/54000]\n",
            "Batch Loss: 2.299630,  Batch Accuracy: 12.50   [ 3840/54000]\n",
            "Batch Loss: 2.303782,  Batch Accuracy: 11.72   [ 5120/54000]\n",
            "Batch Loss: 2.297768,  Batch Accuracy: 15.62   [ 6400/54000]\n",
            "Batch Loss: 2.303051,  Batch Accuracy: 14.06   [ 7680/54000]\n",
            "Batch Loss: 2.299774,  Batch Accuracy: 16.41   [ 8960/54000]\n",
            "Batch Loss: 2.299865,  Batch Accuracy: 17.19   [10240/54000]\n",
            "Batch Loss: 2.304682,  Batch Accuracy: 14.06   [11520/54000]\n",
            "Batch Loss: 2.301565,  Batch Accuracy: 15.62   [12800/54000]\n",
            "Batch Loss: 2.303854,  Batch Accuracy: 9.38   [14080/54000]\n",
            "Batch Loss: 2.300722,  Batch Accuracy: 15.62   [15360/54000]\n",
            "Batch Loss: 2.305767,  Batch Accuracy: 10.16   [16640/54000]\n",
            "Batch Loss: 2.300567,  Batch Accuracy: 13.28   [17920/54000]\n",
            "Batch Loss: 2.297577,  Batch Accuracy: 21.88   [19200/54000]\n",
            "Batch Loss: 2.303237,  Batch Accuracy: 15.62   [20480/54000]\n",
            "Batch Loss: 2.304071,  Batch Accuracy: 12.50   [21760/54000]\n",
            "Batch Loss: 2.299973,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.301774,  Batch Accuracy: 14.84   [24320/54000]\n",
            "Batch Loss: 2.305660,  Batch Accuracy: 7.81   [25600/54000]\n",
            "Batch Loss: 2.296954,  Batch Accuracy: 17.97   [26880/54000]\n",
            "Batch Loss: 2.304660,  Batch Accuracy: 11.72   [28160/54000]\n",
            "Batch Loss: 2.302619,  Batch Accuracy: 14.84   [29440/54000]\n",
            "Batch Loss: 2.302810,  Batch Accuracy: 11.72   [30720/54000]\n",
            "Batch Loss: 2.302061,  Batch Accuracy: 14.84   [32000/54000]\n",
            "Batch Loss: 2.301505,  Batch Accuracy: 11.72   [33280/54000]\n",
            "Batch Loss: 2.304719,  Batch Accuracy: 12.50   [34560/54000]\n",
            "Batch Loss: 2.303821,  Batch Accuracy: 12.50   [35840/54000]\n",
            "Batch Loss: 2.301057,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.303846,  Batch Accuracy: 12.50   [38400/54000]\n",
            "Batch Loss: 2.303936,  Batch Accuracy: 10.94   [39680/54000]\n",
            "Batch Loss: 2.302543,  Batch Accuracy: 11.72   [40960/54000]\n",
            "Batch Loss: 2.299625,  Batch Accuracy: 17.97   [42240/54000]\n",
            "Batch Loss: 2.299671,  Batch Accuracy: 14.84   [43520/54000]\n",
            "Batch Loss: 2.300564,  Batch Accuracy: 16.41   [44800/54000]\n",
            "Batch Loss: 2.299325,  Batch Accuracy: 15.62   [46080/54000]\n",
            "Batch Loss: 2.303863,  Batch Accuracy: 15.62   [47360/54000]\n",
            "Batch Loss: 2.301728,  Batch Accuracy: 13.28   [48640/54000]\n",
            "Batch Loss: 2.300365,  Batch Accuracy: 12.50   [49920/54000]\n",
            "Batch Loss: 2.300652,  Batch Accuracy: 19.53   [51200/54000]\n",
            "Batch Loss: 2.298633,  Batch Accuracy: 21.09   [52480/54000]\n",
            "Batch Loss: 2.299747,  Batch Accuracy: 17.19   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 13.7%, Loss: 2.301210\n",
            "Validation performance: \n",
            " Accuracy: 14.5%, Loss: 2.300950\n",
            "Test performance: \n",
            " Accuracy: 15.4%, Loss: 2.300832 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Batch Loss: 2.305411,  Batch Accuracy: 10.94   [ 1280/54000]\n",
            "Batch Loss: 2.303297,  Batch Accuracy: 15.62   [ 2560/54000]\n",
            "Batch Loss: 2.297948,  Batch Accuracy: 17.97   [ 3840/54000]\n",
            "Batch Loss: 2.299648,  Batch Accuracy: 17.19   [ 5120/54000]\n",
            "Batch Loss: 2.304378,  Batch Accuracy: 6.25   [ 6400/54000]\n",
            "Batch Loss: 2.302921,  Batch Accuracy: 9.38   [ 7680/54000]\n",
            "Batch Loss: 2.299557,  Batch Accuracy: 15.62   [ 8960/54000]\n",
            "Batch Loss: 2.299038,  Batch Accuracy: 16.41   [10240/54000]\n",
            "Batch Loss: 2.298739,  Batch Accuracy: 15.62   [11520/54000]\n",
            "Batch Loss: 2.298761,  Batch Accuracy: 15.62   [12800/54000]\n",
            "Batch Loss: 2.296907,  Batch Accuracy: 23.44   [14080/54000]\n",
            "Batch Loss: 2.299634,  Batch Accuracy: 14.84   [15360/54000]\n",
            "Batch Loss: 2.297540,  Batch Accuracy: 22.66   [16640/54000]\n",
            "Batch Loss: 2.301906,  Batch Accuracy: 16.41   [17920/54000]\n",
            "Batch Loss: 2.301590,  Batch Accuracy: 15.62   [19200/54000]\n",
            "Batch Loss: 2.300650,  Batch Accuracy: 13.28   [20480/54000]\n",
            "Batch Loss: 2.296429,  Batch Accuracy: 18.75   [21760/54000]\n",
            "Batch Loss: 2.298601,  Batch Accuracy: 17.19   [23040/54000]\n",
            "Batch Loss: 2.301628,  Batch Accuracy: 9.38   [24320/54000]\n",
            "Batch Loss: 2.298430,  Batch Accuracy: 21.09   [25600/54000]\n",
            "Batch Loss: 2.300867,  Batch Accuracy: 14.84   [26880/54000]\n",
            "Batch Loss: 2.299123,  Batch Accuracy: 20.31   [28160/54000]\n",
            "Batch Loss: 2.304032,  Batch Accuracy: 17.97   [29440/54000]\n",
            "Batch Loss: 2.306080,  Batch Accuracy: 10.94   [30720/54000]\n",
            "Batch Loss: 2.300340,  Batch Accuracy: 17.97   [32000/54000]\n",
            "Batch Loss: 2.299133,  Batch Accuracy: 15.62   [33280/54000]\n",
            "Batch Loss: 2.300084,  Batch Accuracy: 17.19   [34560/54000]\n",
            "Batch Loss: 2.294810,  Batch Accuracy: 21.88   [35840/54000]\n",
            "Batch Loss: 2.300548,  Batch Accuracy: 17.19   [37120/54000]\n",
            "Batch Loss: 2.302576,  Batch Accuracy: 9.38   [38400/54000]\n",
            "Batch Loss: 2.304141,  Batch Accuracy: 14.84   [39680/54000]\n",
            "Batch Loss: 2.297248,  Batch Accuracy: 21.09   [40960/54000]\n",
            "Batch Loss: 2.296740,  Batch Accuracy: 19.53   [42240/54000]\n",
            "Batch Loss: 2.300781,  Batch Accuracy: 13.28   [43520/54000]\n",
            "Batch Loss: 2.298810,  Batch Accuracy: 17.97   [44800/54000]\n",
            "Batch Loss: 2.299051,  Batch Accuracy: 21.88   [46080/54000]\n",
            "Batch Loss: 2.300246,  Batch Accuracy: 16.41   [47360/54000]\n",
            "Batch Loss: 2.296977,  Batch Accuracy: 18.75   [48640/54000]\n",
            "Batch Loss: 2.296815,  Batch Accuracy: 18.75   [49920/54000]\n",
            "Batch Loss: 2.299913,  Batch Accuracy: 19.53   [51200/54000]\n",
            "Batch Loss: 2.299868,  Batch Accuracy: 14.06   [52480/54000]\n",
            "Batch Loss: 2.301311,  Batch Accuracy: 17.19   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 15.6%, Loss: 2.300619\n",
            "Validation performance: \n",
            " Accuracy: 16.6%, Loss: 2.300371\n",
            "Test performance: \n",
            " Accuracy: 17.1%, Loss: 2.300213 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Batch Loss: 2.300700,  Batch Accuracy: 14.06   [ 1280/54000]\n",
            "Batch Loss: 2.300620,  Batch Accuracy: 14.84   [ 2560/54000]\n",
            "Batch Loss: 2.300607,  Batch Accuracy: 15.62   [ 3840/54000]\n",
            "Batch Loss: 2.299674,  Batch Accuracy: 18.75   [ 5120/54000]\n",
            "Batch Loss: 2.302289,  Batch Accuracy: 18.75   [ 6400/54000]\n",
            "Batch Loss: 2.302633,  Batch Accuracy: 16.41   [ 7680/54000]\n",
            "Batch Loss: 2.300035,  Batch Accuracy: 17.97   [ 8960/54000]\n",
            "Batch Loss: 2.297985,  Batch Accuracy: 20.31   [10240/54000]\n",
            "Batch Loss: 2.300830,  Batch Accuracy: 14.84   [11520/54000]\n",
            "Batch Loss: 2.295096,  Batch Accuracy: 22.66   [12800/54000]\n",
            "Batch Loss: 2.302548,  Batch Accuracy: 14.84   [14080/54000]\n",
            "Batch Loss: 2.301255,  Batch Accuracy: 13.28   [15360/54000]\n",
            "Batch Loss: 2.300888,  Batch Accuracy: 17.97   [16640/54000]\n",
            "Batch Loss: 2.297715,  Batch Accuracy: 21.09   [17920/54000]\n",
            "Batch Loss: 2.303528,  Batch Accuracy: 11.72   [19200/54000]\n",
            "Batch Loss: 2.299106,  Batch Accuracy: 17.19   [20480/54000]\n",
            "Batch Loss: 2.298460,  Batch Accuracy: 19.53   [21760/54000]\n",
            "Batch Loss: 2.300347,  Batch Accuracy: 12.50   [23040/54000]\n",
            "Batch Loss: 2.296094,  Batch Accuracy: 21.09   [24320/54000]\n",
            "Batch Loss: 2.298948,  Batch Accuracy: 17.97   [25600/54000]\n",
            "Batch Loss: 2.298433,  Batch Accuracy: 18.75   [26880/54000]\n",
            "Batch Loss: 2.297101,  Batch Accuracy: 20.31   [28160/54000]\n",
            "Batch Loss: 2.300981,  Batch Accuracy: 12.50   [29440/54000]\n",
            "Batch Loss: 2.302042,  Batch Accuracy: 13.28   [30720/54000]\n",
            "Batch Loss: 2.299997,  Batch Accuracy: 23.44   [32000/54000]\n",
            "Batch Loss: 2.301444,  Batch Accuracy: 14.06   [33280/54000]\n",
            "Batch Loss: 2.303142,  Batch Accuracy: 11.72   [34560/54000]\n",
            "Batch Loss: 2.301966,  Batch Accuracy: 17.19   [35840/54000]\n",
            "Batch Loss: 2.299524,  Batch Accuracy: 14.06   [37120/54000]\n",
            "Batch Loss: 2.297673,  Batch Accuracy: 19.53   [38400/54000]\n",
            "Batch Loss: 2.298652,  Batch Accuracy: 17.19   [39680/54000]\n",
            "Batch Loss: 2.298677,  Batch Accuracy: 20.31   [40960/54000]\n",
            "Batch Loss: 2.299453,  Batch Accuracy: 20.31   [42240/54000]\n",
            "Batch Loss: 2.299551,  Batch Accuracy: 18.75   [43520/54000]\n",
            "Batch Loss: 2.300378,  Batch Accuracy: 13.28   [44800/54000]\n",
            "Batch Loss: 2.298586,  Batch Accuracy: 14.06   [46080/54000]\n",
            "Batch Loss: 2.301959,  Batch Accuracy: 12.50   [47360/54000]\n",
            "Batch Loss: 2.302957,  Batch Accuracy: 11.72   [48640/54000]\n",
            "Batch Loss: 2.302505,  Batch Accuracy: 17.97   [49920/54000]\n",
            "Batch Loss: 2.300871,  Batch Accuracy: 17.97   [51200/54000]\n",
            "Batch Loss: 2.299112,  Batch Accuracy: 19.53   [52480/54000]\n",
            "Batch Loss: 2.302073,  Batch Accuracy: 16.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 17.6%, Loss: 2.300008\n",
            "Validation performance: \n",
            " Accuracy: 18.8%, Loss: 2.299779\n",
            "Test performance: \n",
            " Accuracy: 18.9%, Loss: 2.299576 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Batch Loss: 2.302983,  Batch Accuracy: 17.19   [ 1280/54000]\n",
            "Batch Loss: 2.298695,  Batch Accuracy: 22.66   [ 2560/54000]\n",
            "Batch Loss: 2.296397,  Batch Accuracy: 20.31   [ 3840/54000]\n",
            "Batch Loss: 2.297617,  Batch Accuracy: 24.22   [ 5120/54000]\n",
            "Batch Loss: 2.299867,  Batch Accuracy: 20.31   [ 6400/54000]\n",
            "Batch Loss: 2.299779,  Batch Accuracy: 18.75   [ 7680/54000]\n",
            "Batch Loss: 2.299559,  Batch Accuracy: 24.22   [ 8960/54000]\n",
            "Batch Loss: 2.303353,  Batch Accuracy: 14.84   [10240/54000]\n",
            "Batch Loss: 2.299258,  Batch Accuracy: 17.19   [11520/54000]\n",
            "Batch Loss: 2.301696,  Batch Accuracy: 17.19   [12800/54000]\n",
            "Batch Loss: 2.300429,  Batch Accuracy: 18.75   [14080/54000]\n",
            "Batch Loss: 2.294902,  Batch Accuracy: 21.09   [15360/54000]\n",
            "Batch Loss: 2.296598,  Batch Accuracy: 21.88   [16640/54000]\n",
            "Batch Loss: 2.295871,  Batch Accuracy: 16.41   [17920/54000]\n",
            "Batch Loss: 2.297770,  Batch Accuracy: 20.31   [19200/54000]\n",
            "Batch Loss: 2.303272,  Batch Accuracy: 15.62   [20480/54000]\n",
            "Batch Loss: 2.298956,  Batch Accuracy: 18.75   [21760/54000]\n",
            "Batch Loss: 2.295602,  Batch Accuracy: 25.00   [23040/54000]\n",
            "Batch Loss: 2.295819,  Batch Accuracy: 27.34   [24320/54000]\n",
            "Batch Loss: 2.302980,  Batch Accuracy: 14.06   [25600/54000]\n",
            "Batch Loss: 2.297860,  Batch Accuracy: 21.88   [26880/54000]\n",
            "Batch Loss: 2.303811,  Batch Accuracy: 11.72   [28160/54000]\n",
            "Batch Loss: 2.296822,  Batch Accuracy: 25.00   [29440/54000]\n",
            "Batch Loss: 2.298315,  Batch Accuracy: 21.88   [30720/54000]\n",
            "Batch Loss: 2.303719,  Batch Accuracy: 14.06   [32000/54000]\n",
            "Batch Loss: 2.298011,  Batch Accuracy: 22.66   [33280/54000]\n",
            "Batch Loss: 2.302239,  Batch Accuracy: 13.28   [34560/54000]\n",
            "Batch Loss: 2.299959,  Batch Accuracy: 19.53   [35840/54000]\n",
            "Batch Loss: 2.295550,  Batch Accuracy: 25.78   [37120/54000]\n",
            "Batch Loss: 2.299866,  Batch Accuracy: 17.97   [38400/54000]\n",
            "Batch Loss: 2.296823,  Batch Accuracy: 20.31   [39680/54000]\n",
            "Batch Loss: 2.299935,  Batch Accuracy: 14.84   [40960/54000]\n",
            "Batch Loss: 2.295897,  Batch Accuracy: 15.62   [42240/54000]\n",
            "Batch Loss: 2.302083,  Batch Accuracy: 16.41   [43520/54000]\n",
            "Batch Loss: 2.299240,  Batch Accuracy: 21.88   [44800/54000]\n",
            "Batch Loss: 2.299367,  Batch Accuracy: 20.31   [46080/54000]\n",
            "Batch Loss: 2.303985,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.298409,  Batch Accuracy: 24.22   [48640/54000]\n",
            "Batch Loss: 2.302035,  Batch Accuracy: 15.62   [49920/54000]\n",
            "Batch Loss: 2.297201,  Batch Accuracy: 20.31   [51200/54000]\n",
            "Batch Loss: 2.296947,  Batch Accuracy: 22.66   [52480/54000]\n",
            "Batch Loss: 2.300793,  Batch Accuracy: 20.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 19.4%, Loss: 2.299378\n",
            "Validation performance: \n",
            " Accuracy: 20.7%, Loss: 2.299168\n",
            "Test performance: \n",
            " Accuracy: 20.4%, Loss: 2.298917 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Batch Loss: 2.297649,  Batch Accuracy: 25.00   [ 1280/54000]\n",
            "Batch Loss: 2.299763,  Batch Accuracy: 21.88   [ 2560/54000]\n",
            "Batch Loss: 2.297157,  Batch Accuracy: 22.66   [ 3840/54000]\n",
            "Batch Loss: 2.299205,  Batch Accuracy: 22.66   [ 5120/54000]\n",
            "Batch Loss: 2.298920,  Batch Accuracy: 22.66   [ 6400/54000]\n",
            "Batch Loss: 2.298541,  Batch Accuracy: 21.88   [ 7680/54000]\n",
            "Batch Loss: 2.298193,  Batch Accuracy: 17.97   [ 8960/54000]\n",
            "Batch Loss: 2.296906,  Batch Accuracy: 21.88   [10240/54000]\n",
            "Batch Loss: 2.298421,  Batch Accuracy: 22.66   [11520/54000]\n",
            "Batch Loss: 2.298505,  Batch Accuracy: 22.66   [12800/54000]\n",
            "Batch Loss: 2.299309,  Batch Accuracy: 17.19   [14080/54000]\n",
            "Batch Loss: 2.299223,  Batch Accuracy: 17.19   [15360/54000]\n",
            "Batch Loss: 2.301128,  Batch Accuracy: 15.62   [16640/54000]\n",
            "Batch Loss: 2.296153,  Batch Accuracy: 24.22   [17920/54000]\n",
            "Batch Loss: 2.302454,  Batch Accuracy: 15.62   [19200/54000]\n",
            "Batch Loss: 2.300617,  Batch Accuracy: 14.84   [20480/54000]\n",
            "Batch Loss: 2.300870,  Batch Accuracy: 19.53   [21760/54000]\n",
            "Batch Loss: 2.296871,  Batch Accuracy: 23.44   [23040/54000]\n",
            "Batch Loss: 2.297779,  Batch Accuracy: 20.31   [24320/54000]\n",
            "Batch Loss: 2.300177,  Batch Accuracy: 19.53   [25600/54000]\n",
            "Batch Loss: 2.299412,  Batch Accuracy: 20.31   [26880/54000]\n",
            "Batch Loss: 2.298473,  Batch Accuracy: 24.22   [28160/54000]\n",
            "Batch Loss: 2.297101,  Batch Accuracy: 20.31   [29440/54000]\n",
            "Batch Loss: 2.298369,  Batch Accuracy: 18.75   [30720/54000]\n",
            "Batch Loss: 2.299755,  Batch Accuracy: 23.44   [32000/54000]\n",
            "Batch Loss: 2.298261,  Batch Accuracy: 21.88   [33280/54000]\n",
            "Batch Loss: 2.299145,  Batch Accuracy: 18.75   [34560/54000]\n",
            "Batch Loss: 2.297982,  Batch Accuracy: 19.53   [35840/54000]\n",
            "Batch Loss: 2.293922,  Batch Accuracy: 28.91   [37120/54000]\n",
            "Batch Loss: 2.295944,  Batch Accuracy: 21.88   [38400/54000]\n",
            "Batch Loss: 2.296002,  Batch Accuracy: 26.56   [39680/54000]\n",
            "Batch Loss: 2.297496,  Batch Accuracy: 20.31   [40960/54000]\n",
            "Batch Loss: 2.298290,  Batch Accuracy: 26.56   [42240/54000]\n",
            "Batch Loss: 2.301287,  Batch Accuracy: 17.19   [43520/54000]\n",
            "Batch Loss: 2.298284,  Batch Accuracy: 21.88   [44800/54000]\n",
            "Batch Loss: 2.295196,  Batch Accuracy: 23.44   [46080/54000]\n",
            "Batch Loss: 2.298925,  Batch Accuracy: 23.44   [47360/54000]\n",
            "Batch Loss: 2.300668,  Batch Accuracy: 16.41   [48640/54000]\n",
            "Batch Loss: 2.298453,  Batch Accuracy: 21.09   [49920/54000]\n",
            "Batch Loss: 2.304152,  Batch Accuracy: 16.41   [51200/54000]\n",
            "Batch Loss: 2.300236,  Batch Accuracy: 18.75   [52480/54000]\n",
            "Batch Loss: 2.300220,  Batch Accuracy: 20.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 20.9%, Loss: 2.298726\n",
            "Validation performance: \n",
            " Accuracy: 22.0%, Loss: 2.298531\n",
            "Test performance: \n",
            " Accuracy: 21.7%, Loss: 2.298231 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Batch Loss: 2.297572,  Batch Accuracy: 22.66   [ 1280/54000]\n",
            "Batch Loss: 2.298733,  Batch Accuracy: 21.09   [ 2560/54000]\n",
            "Batch Loss: 2.294152,  Batch Accuracy: 23.44   [ 3840/54000]\n",
            "Batch Loss: 2.299481,  Batch Accuracy: 20.31   [ 5120/54000]\n",
            "Batch Loss: 2.299222,  Batch Accuracy: 22.66   [ 6400/54000]\n",
            "Batch Loss: 2.297469,  Batch Accuracy: 25.00   [ 7680/54000]\n",
            "Batch Loss: 2.295588,  Batch Accuracy: 25.78   [ 8960/54000]\n",
            "Batch Loss: 2.297545,  Batch Accuracy: 23.44   [10240/54000]\n",
            "Batch Loss: 2.296516,  Batch Accuracy: 21.09   [11520/54000]\n",
            "Batch Loss: 2.301366,  Batch Accuracy: 15.62   [12800/54000]\n",
            "Batch Loss: 2.295879,  Batch Accuracy: 27.34   [14080/54000]\n",
            "Batch Loss: 2.299592,  Batch Accuracy: 22.66   [15360/54000]\n",
            "Batch Loss: 2.296481,  Batch Accuracy: 24.22   [16640/54000]\n",
            "Batch Loss: 2.298883,  Batch Accuracy: 21.88   [17920/54000]\n",
            "Batch Loss: 2.297303,  Batch Accuracy: 21.09   [19200/54000]\n",
            "Batch Loss: 2.295929,  Batch Accuracy: 28.12   [20480/54000]\n",
            "Batch Loss: 2.300194,  Batch Accuracy: 21.88   [21760/54000]\n",
            "Batch Loss: 2.299984,  Batch Accuracy: 22.66   [23040/54000]\n",
            "Batch Loss: 2.304968,  Batch Accuracy: 14.06   [24320/54000]\n",
            "Batch Loss: 2.294573,  Batch Accuracy: 24.22   [25600/54000]\n",
            "Batch Loss: 2.299236,  Batch Accuracy: 21.88   [26880/54000]\n",
            "Batch Loss: 2.299223,  Batch Accuracy: 23.44   [28160/54000]\n",
            "Batch Loss: 2.298287,  Batch Accuracy: 22.66   [29440/54000]\n",
            "Batch Loss: 2.296575,  Batch Accuracy: 23.44   [30720/54000]\n",
            "Batch Loss: 2.298801,  Batch Accuracy: 18.75   [32000/54000]\n",
            "Batch Loss: 2.296346,  Batch Accuracy: 23.44   [33280/54000]\n",
            "Batch Loss: 2.297351,  Batch Accuracy: 24.22   [34560/54000]\n",
            "Batch Loss: 2.297107,  Batch Accuracy: 27.34   [35840/54000]\n",
            "Batch Loss: 2.296770,  Batch Accuracy: 27.34   [37120/54000]\n",
            "Batch Loss: 2.304545,  Batch Accuracy: 13.28   [38400/54000]\n",
            "Batch Loss: 2.297209,  Batch Accuracy: 21.09   [39680/54000]\n",
            "Batch Loss: 2.301068,  Batch Accuracy: 22.66   [40960/54000]\n",
            "Batch Loss: 2.302559,  Batch Accuracy: 17.19   [42240/54000]\n",
            "Batch Loss: 2.298074,  Batch Accuracy: 22.66   [43520/54000]\n",
            "Batch Loss: 2.299151,  Batch Accuracy: 22.66   [44800/54000]\n",
            "Batch Loss: 2.297348,  Batch Accuracy: 25.00   [46080/54000]\n",
            "Batch Loss: 2.299196,  Batch Accuracy: 26.56   [47360/54000]\n",
            "Batch Loss: 2.295511,  Batch Accuracy: 24.22   [48640/54000]\n",
            "Batch Loss: 2.298467,  Batch Accuracy: 22.66   [49920/54000]\n",
            "Batch Loss: 2.299288,  Batch Accuracy: 21.09   [51200/54000]\n",
            "Batch Loss: 2.298766,  Batch Accuracy: 24.22   [52480/54000]\n",
            "Batch Loss: 2.300469,  Batch Accuracy: 20.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 22.2%, Loss: 2.298043\n",
            "Validation performance: \n",
            " Accuracy: 23.1%, Loss: 2.297832\n",
            "Test performance: \n",
            " Accuracy: 22.6%, Loss: 2.297510 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Batch Loss: 2.295411,  Batch Accuracy: 29.69   [ 1280/54000]\n",
            "Batch Loss: 2.298233,  Batch Accuracy: 20.31   [ 2560/54000]\n",
            "Batch Loss: 2.296628,  Batch Accuracy: 21.09   [ 3840/54000]\n",
            "Batch Loss: 2.300349,  Batch Accuracy: 19.53   [ 5120/54000]\n",
            "Batch Loss: 2.296134,  Batch Accuracy: 26.56   [ 6400/54000]\n",
            "Batch Loss: 2.296387,  Batch Accuracy: 21.88   [ 7680/54000]\n",
            "Batch Loss: 2.299734,  Batch Accuracy: 17.97   [ 8960/54000]\n",
            "Batch Loss: 2.296386,  Batch Accuracy: 25.78   [10240/54000]\n",
            "Batch Loss: 2.298883,  Batch Accuracy: 25.00   [11520/54000]\n",
            "Batch Loss: 2.294582,  Batch Accuracy: 24.22   [12800/54000]\n",
            "Batch Loss: 2.299454,  Batch Accuracy: 21.09   [14080/54000]\n",
            "Batch Loss: 2.296384,  Batch Accuracy: 18.75   [15360/54000]\n",
            "Batch Loss: 2.294283,  Batch Accuracy: 25.78   [16640/54000]\n",
            "Batch Loss: 2.297238,  Batch Accuracy: 24.22   [17920/54000]\n",
            "Batch Loss: 2.295134,  Batch Accuracy: 25.00   [19200/54000]\n",
            "Batch Loss: 2.302930,  Batch Accuracy: 17.19   [20480/54000]\n",
            "Batch Loss: 2.294706,  Batch Accuracy: 27.34   [21760/54000]\n",
            "Batch Loss: 2.296250,  Batch Accuracy: 20.31   [23040/54000]\n",
            "Batch Loss: 2.299380,  Batch Accuracy: 22.66   [24320/54000]\n",
            "Batch Loss: 2.299747,  Batch Accuracy: 19.53   [25600/54000]\n",
            "Batch Loss: 2.296884,  Batch Accuracy: 25.00   [26880/54000]\n",
            "Batch Loss: 2.296277,  Batch Accuracy: 25.00   [28160/54000]\n",
            "Batch Loss: 2.298616,  Batch Accuracy: 19.53   [29440/54000]\n",
            "Batch Loss: 2.297200,  Batch Accuracy: 25.00   [30720/54000]\n",
            "Batch Loss: 2.294490,  Batch Accuracy: 26.56   [32000/54000]\n",
            "Batch Loss: 2.295261,  Batch Accuracy: 25.78   [33280/54000]\n",
            "Batch Loss: 2.295594,  Batch Accuracy: 26.56   [34560/54000]\n",
            "Batch Loss: 2.298355,  Batch Accuracy: 21.88   [35840/54000]\n",
            "Batch Loss: 2.297249,  Batch Accuracy: 18.75   [37120/54000]\n",
            "Batch Loss: 2.295796,  Batch Accuracy: 26.56   [38400/54000]\n",
            "Batch Loss: 2.300033,  Batch Accuracy: 21.88   [39680/54000]\n",
            "Batch Loss: 2.300681,  Batch Accuracy: 23.44   [40960/54000]\n",
            "Batch Loss: 2.298280,  Batch Accuracy: 21.88   [42240/54000]\n",
            "Batch Loss: 2.297296,  Batch Accuracy: 25.78   [43520/54000]\n",
            "Batch Loss: 2.299424,  Batch Accuracy: 20.31   [44800/54000]\n",
            "Batch Loss: 2.297743,  Batch Accuracy: 17.19   [46080/54000]\n",
            "Batch Loss: 2.297691,  Batch Accuracy: 22.66   [47360/54000]\n",
            "Batch Loss: 2.299452,  Batch Accuracy: 20.31   [48640/54000]\n",
            "Batch Loss: 2.295445,  Batch Accuracy: 21.88   [49920/54000]\n",
            "Batch Loss: 2.300611,  Batch Accuracy: 17.97   [51200/54000]\n",
            "Batch Loss: 2.298565,  Batch Accuracy: 21.88   [52480/54000]\n",
            "Batch Loss: 2.303486,  Batch Accuracy: 20.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 22.9%, Loss: 2.297319\n",
            "Validation performance: \n",
            " Accuracy: 23.7%, Loss: 2.297119\n",
            "Test performance: \n",
            " Accuracy: 23.2%, Loss: 2.296743 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Batch Loss: 2.296824,  Batch Accuracy: 21.09   [ 1280/54000]\n",
            "Batch Loss: 2.301423,  Batch Accuracy: 19.53   [ 2560/54000]\n",
            "Batch Loss: 2.294446,  Batch Accuracy: 21.09   [ 3840/54000]\n",
            "Batch Loss: 2.298298,  Batch Accuracy: 16.41   [ 5120/54000]\n",
            "Batch Loss: 2.293222,  Batch Accuracy: 27.34   [ 6400/54000]\n",
            "Batch Loss: 2.296506,  Batch Accuracy: 25.78   [ 7680/54000]\n",
            "Batch Loss: 2.296771,  Batch Accuracy: 19.53   [ 8960/54000]\n",
            "Batch Loss: 2.301976,  Batch Accuracy: 20.31   [10240/54000]\n",
            "Batch Loss: 2.296750,  Batch Accuracy: 26.56   [11520/54000]\n",
            "Batch Loss: 2.295201,  Batch Accuracy: 19.53   [12800/54000]\n",
            "Batch Loss: 2.298134,  Batch Accuracy: 23.44   [14080/54000]\n",
            "Batch Loss: 2.293904,  Batch Accuracy: 26.56   [15360/54000]\n",
            "Batch Loss: 2.295035,  Batch Accuracy: 24.22   [16640/54000]\n",
            "Batch Loss: 2.297764,  Batch Accuracy: 22.66   [17920/54000]\n",
            "Batch Loss: 2.294580,  Batch Accuracy: 25.00   [19200/54000]\n",
            "Batch Loss: 2.298506,  Batch Accuracy: 18.75   [20480/54000]\n",
            "Batch Loss: 2.299142,  Batch Accuracy: 17.97   [21760/54000]\n",
            "Batch Loss: 2.293776,  Batch Accuracy: 26.56   [23040/54000]\n",
            "Batch Loss: 2.295008,  Batch Accuracy: 21.88   [24320/54000]\n",
            "Batch Loss: 2.296150,  Batch Accuracy: 23.44   [25600/54000]\n",
            "Batch Loss: 2.301258,  Batch Accuracy: 20.31   [26880/54000]\n",
            "Batch Loss: 2.294734,  Batch Accuracy: 29.69   [28160/54000]\n",
            "Batch Loss: 2.298120,  Batch Accuracy: 28.12   [29440/54000]\n",
            "Batch Loss: 2.296391,  Batch Accuracy: 27.34   [30720/54000]\n",
            "Batch Loss: 2.296171,  Batch Accuracy: 27.34   [32000/54000]\n",
            "Batch Loss: 2.299563,  Batch Accuracy: 19.53   [33280/54000]\n",
            "Batch Loss: 2.294632,  Batch Accuracy: 24.22   [34560/54000]\n",
            "Batch Loss: 2.301616,  Batch Accuracy: 15.62   [35840/54000]\n",
            "Batch Loss: 2.301748,  Batch Accuracy: 23.44   [37120/54000]\n",
            "Batch Loss: 2.293622,  Batch Accuracy: 24.22   [38400/54000]\n",
            "Batch Loss: 2.300026,  Batch Accuracy: 20.31   [39680/54000]\n",
            "Batch Loss: 2.299477,  Batch Accuracy: 19.53   [40960/54000]\n",
            "Batch Loss: 2.296962,  Batch Accuracy: 24.22   [42240/54000]\n",
            "Batch Loss: 2.294696,  Batch Accuracy: 21.88   [43520/54000]\n",
            "Batch Loss: 2.296581,  Batch Accuracy: 27.34   [44800/54000]\n",
            "Batch Loss: 2.296047,  Batch Accuracy: 22.66   [46080/54000]\n",
            "Batch Loss: 2.298837,  Batch Accuracy: 17.19   [47360/54000]\n",
            "Batch Loss: 2.295254,  Batch Accuracy: 28.12   [48640/54000]\n",
            "Batch Loss: 2.296321,  Batch Accuracy: 20.31   [49920/54000]\n",
            "Batch Loss: 2.297935,  Batch Accuracy: 18.75   [51200/54000]\n",
            "Batch Loss: 2.293941,  Batch Accuracy: 28.91   [52480/54000]\n",
            "Batch Loss: 2.298215,  Batch Accuracy: 20.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.3%, Loss: 2.296546\n",
            "Validation performance: \n",
            " Accuracy: 24.1%, Loss: 2.296346\n",
            "Test performance: \n",
            " Accuracy: 23.6%, Loss: 2.295918 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Batch Loss: 2.293147,  Batch Accuracy: 28.12   [ 1280/54000]\n",
            "Batch Loss: 2.293027,  Batch Accuracy: 27.34   [ 2560/54000]\n",
            "Batch Loss: 2.294226,  Batch Accuracy: 24.22   [ 3840/54000]\n",
            "Batch Loss: 2.293358,  Batch Accuracy: 25.78   [ 5120/54000]\n",
            "Batch Loss: 2.295208,  Batch Accuracy: 21.09   [ 6400/54000]\n",
            "Batch Loss: 2.292987,  Batch Accuracy: 25.78   [ 7680/54000]\n",
            "Batch Loss: 2.295951,  Batch Accuracy: 22.66   [ 8960/54000]\n",
            "Batch Loss: 2.296679,  Batch Accuracy: 21.88   [10240/54000]\n",
            "Batch Loss: 2.296196,  Batch Accuracy: 27.34   [11520/54000]\n",
            "Batch Loss: 2.287969,  Batch Accuracy: 38.28   [12800/54000]\n",
            "Batch Loss: 2.297529,  Batch Accuracy: 21.09   [14080/54000]\n",
            "Batch Loss: 2.296965,  Batch Accuracy: 21.09   [15360/54000]\n",
            "Batch Loss: 2.300118,  Batch Accuracy: 17.19   [16640/54000]\n",
            "Batch Loss: 2.293963,  Batch Accuracy: 21.09   [17920/54000]\n",
            "Batch Loss: 2.298736,  Batch Accuracy: 18.75   [19200/54000]\n",
            "Batch Loss: 2.295651,  Batch Accuracy: 24.22   [20480/54000]\n",
            "Batch Loss: 2.296638,  Batch Accuracy: 24.22   [21760/54000]\n",
            "Batch Loss: 2.297034,  Batch Accuracy: 23.44   [23040/54000]\n",
            "Batch Loss: 2.294722,  Batch Accuracy: 25.00   [24320/54000]\n",
            "Batch Loss: 2.298599,  Batch Accuracy: 21.09   [25600/54000]\n",
            "Batch Loss: 2.295833,  Batch Accuracy: 23.44   [26880/54000]\n",
            "Batch Loss: 2.292129,  Batch Accuracy: 27.34   [28160/54000]\n",
            "Batch Loss: 2.294115,  Batch Accuracy: 22.66   [29440/54000]\n",
            "Batch Loss: 2.293605,  Batch Accuracy: 25.78   [30720/54000]\n",
            "Batch Loss: 2.293504,  Batch Accuracy: 28.12   [32000/54000]\n",
            "Batch Loss: 2.293944,  Batch Accuracy: 24.22   [33280/54000]\n",
            "Batch Loss: 2.300250,  Batch Accuracy: 23.44   [34560/54000]\n",
            "Batch Loss: 2.295421,  Batch Accuracy: 22.66   [35840/54000]\n",
            "Batch Loss: 2.292291,  Batch Accuracy: 30.47   [37120/54000]\n",
            "Batch Loss: 2.295603,  Batch Accuracy: 22.66   [38400/54000]\n",
            "Batch Loss: 2.294838,  Batch Accuracy: 21.09   [39680/54000]\n",
            "Batch Loss: 2.296593,  Batch Accuracy: 21.88   [40960/54000]\n",
            "Batch Loss: 2.293206,  Batch Accuracy: 21.09   [42240/54000]\n",
            "Batch Loss: 2.298343,  Batch Accuracy: 17.19   [43520/54000]\n",
            "Batch Loss: 2.293579,  Batch Accuracy: 24.22   [44800/54000]\n",
            "Batch Loss: 2.295326,  Batch Accuracy: 25.00   [46080/54000]\n",
            "Batch Loss: 2.296926,  Batch Accuracy: 23.44   [47360/54000]\n",
            "Batch Loss: 2.290666,  Batch Accuracy: 32.81   [48640/54000]\n",
            "Batch Loss: 2.291443,  Batch Accuracy: 28.91   [49920/54000]\n",
            "Batch Loss: 2.294693,  Batch Accuracy: 28.12   [51200/54000]\n",
            "Batch Loss: 2.298398,  Batch Accuracy: 22.66   [52480/54000]\n",
            "Batch Loss: 2.295237,  Batch Accuracy: 22.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.6%, Loss: 2.295712\n",
            "Validation performance: \n",
            " Accuracy: 24.4%, Loss: 2.295486\n",
            "Test performance: \n",
            " Accuracy: 23.8%, Loss: 2.295021 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Batch Loss: 2.298253,  Batch Accuracy: 17.97   [ 1280/54000]\n",
            "Batch Loss: 2.297678,  Batch Accuracy: 24.22   [ 2560/54000]\n",
            "Batch Loss: 2.301340,  Batch Accuracy: 17.19   [ 3840/54000]\n",
            "Batch Loss: 2.292562,  Batch Accuracy: 24.22   [ 5120/54000]\n",
            "Batch Loss: 2.295530,  Batch Accuracy: 23.44   [ 6400/54000]\n",
            "Batch Loss: 2.295135,  Batch Accuracy: 25.78   [ 7680/54000]\n",
            "Batch Loss: 2.294791,  Batch Accuracy: 23.44   [ 8960/54000]\n",
            "Batch Loss: 2.296586,  Batch Accuracy: 23.44   [10240/54000]\n",
            "Batch Loss: 2.294063,  Batch Accuracy: 23.44   [11520/54000]\n",
            "Batch Loss: 2.295763,  Batch Accuracy: 23.44   [12800/54000]\n",
            "Batch Loss: 2.294448,  Batch Accuracy: 26.56   [14080/54000]\n",
            "Batch Loss: 2.298171,  Batch Accuracy: 20.31   [15360/54000]\n",
            "Batch Loss: 2.297055,  Batch Accuracy: 23.44   [16640/54000]\n",
            "Batch Loss: 2.294658,  Batch Accuracy: 23.44   [17920/54000]\n",
            "Batch Loss: 2.298912,  Batch Accuracy: 17.97   [19200/54000]\n",
            "Batch Loss: 2.292659,  Batch Accuracy: 23.44   [20480/54000]\n",
            "Batch Loss: 2.292243,  Batch Accuracy: 24.22   [21760/54000]\n",
            "Batch Loss: 2.296420,  Batch Accuracy: 29.69   [23040/54000]\n",
            "Batch Loss: 2.301709,  Batch Accuracy: 22.66   [24320/54000]\n",
            "Batch Loss: 2.297133,  Batch Accuracy: 18.75   [25600/54000]\n",
            "Batch Loss: 2.295200,  Batch Accuracy: 21.09   [26880/54000]\n",
            "Batch Loss: 2.297115,  Batch Accuracy: 19.53   [28160/54000]\n",
            "Batch Loss: 2.291184,  Batch Accuracy: 28.91   [29440/54000]\n",
            "Batch Loss: 2.290040,  Batch Accuracy: 25.00   [30720/54000]\n",
            "Batch Loss: 2.292181,  Batch Accuracy: 27.34   [32000/54000]\n",
            "Batch Loss: 2.291038,  Batch Accuracy: 31.25   [33280/54000]\n",
            "Batch Loss: 2.292085,  Batch Accuracy: 22.66   [34560/54000]\n",
            "Batch Loss: 2.300012,  Batch Accuracy: 17.97   [35840/54000]\n",
            "Batch Loss: 2.293684,  Batch Accuracy: 26.56   [37120/54000]\n",
            "Batch Loss: 2.292121,  Batch Accuracy: 28.12   [38400/54000]\n",
            "Batch Loss: 2.291476,  Batch Accuracy: 32.03   [39680/54000]\n",
            "Batch Loss: 2.293840,  Batch Accuracy: 25.00   [40960/54000]\n",
            "Batch Loss: 2.296179,  Batch Accuracy: 26.56   [42240/54000]\n",
            "Batch Loss: 2.294204,  Batch Accuracy: 23.44   [43520/54000]\n",
            "Batch Loss: 2.295688,  Batch Accuracy: 19.53   [44800/54000]\n",
            "Batch Loss: 2.292746,  Batch Accuracy: 28.91   [46080/54000]\n",
            "Batch Loss: 2.297684,  Batch Accuracy: 20.31   [47360/54000]\n",
            "Batch Loss: 2.297858,  Batch Accuracy: 17.19   [48640/54000]\n",
            "Batch Loss: 2.292460,  Batch Accuracy: 25.78   [49920/54000]\n",
            "Batch Loss: 2.293579,  Batch Accuracy: 29.69   [51200/54000]\n",
            "Batch Loss: 2.289761,  Batch Accuracy: 28.91   [52480/54000]\n",
            "Batch Loss: 2.294028,  Batch Accuracy: 22.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.7%, Loss: 2.294800\n",
            "Validation performance: \n",
            " Accuracy: 24.4%, Loss: 2.294560\n",
            "Test performance: \n",
            " Accuracy: 23.9%, Loss: 2.294037 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Batch Loss: 2.294844,  Batch Accuracy: 21.09   [ 1280/54000]\n",
            "Batch Loss: 2.293149,  Batch Accuracy: 25.00   [ 2560/54000]\n",
            "Batch Loss: 2.295845,  Batch Accuracy: 21.09   [ 3840/54000]\n",
            "Batch Loss: 2.291773,  Batch Accuracy: 31.25   [ 5120/54000]\n",
            "Batch Loss: 2.294084,  Batch Accuracy: 26.56   [ 6400/54000]\n",
            "Batch Loss: 2.293714,  Batch Accuracy: 27.34   [ 7680/54000]\n",
            "Batch Loss: 2.296563,  Batch Accuracy: 25.78   [ 8960/54000]\n",
            "Batch Loss: 2.294842,  Batch Accuracy: 21.09   [10240/54000]\n",
            "Batch Loss: 2.291031,  Batch Accuracy: 29.69   [11520/54000]\n",
            "Batch Loss: 2.294004,  Batch Accuracy: 23.44   [12800/54000]\n",
            "Batch Loss: 2.292404,  Batch Accuracy: 25.00   [14080/54000]\n",
            "Batch Loss: 2.294772,  Batch Accuracy: 24.22   [15360/54000]\n",
            "Batch Loss: 2.292279,  Batch Accuracy: 28.12   [16640/54000]\n",
            "Batch Loss: 2.295038,  Batch Accuracy: 21.88   [17920/54000]\n",
            "Batch Loss: 2.293707,  Batch Accuracy: 24.22   [19200/54000]\n",
            "Batch Loss: 2.289192,  Batch Accuracy: 31.25   [20480/54000]\n",
            "Batch Loss: 2.293482,  Batch Accuracy: 23.44   [21760/54000]\n",
            "Batch Loss: 2.293536,  Batch Accuracy: 27.34   [23040/54000]\n",
            "Batch Loss: 2.292747,  Batch Accuracy: 24.22   [24320/54000]\n",
            "Batch Loss: 2.295739,  Batch Accuracy: 19.53   [25600/54000]\n",
            "Batch Loss: 2.292267,  Batch Accuracy: 22.66   [26880/54000]\n",
            "Batch Loss: 2.292142,  Batch Accuracy: 24.22   [28160/54000]\n",
            "Batch Loss: 2.295612,  Batch Accuracy: 24.22   [29440/54000]\n",
            "Batch Loss: 2.295119,  Batch Accuracy: 21.88   [30720/54000]\n",
            "Batch Loss: 2.292207,  Batch Accuracy: 25.78   [32000/54000]\n",
            "Batch Loss: 2.291875,  Batch Accuracy: 25.78   [33280/54000]\n",
            "Batch Loss: 2.299955,  Batch Accuracy: 17.97   [34560/54000]\n",
            "Batch Loss: 2.297659,  Batch Accuracy: 24.22   [35840/54000]\n",
            "Batch Loss: 2.294428,  Batch Accuracy: 19.53   [37120/54000]\n",
            "Batch Loss: 2.294601,  Batch Accuracy: 23.44   [38400/54000]\n",
            "Batch Loss: 2.290215,  Batch Accuracy: 26.56   [39680/54000]\n",
            "Batch Loss: 2.293326,  Batch Accuracy: 28.91   [40960/54000]\n",
            "Batch Loss: 2.295319,  Batch Accuracy: 22.66   [42240/54000]\n",
            "Batch Loss: 2.296831,  Batch Accuracy: 20.31   [43520/54000]\n",
            "Batch Loss: 2.294961,  Batch Accuracy: 19.53   [44800/54000]\n",
            "Batch Loss: 2.298998,  Batch Accuracy: 19.53   [46080/54000]\n",
            "Batch Loss: 2.294245,  Batch Accuracy: 28.91   [47360/54000]\n",
            "Batch Loss: 2.296024,  Batch Accuracy: 20.31   [48640/54000]\n",
            "Batch Loss: 2.292846,  Batch Accuracy: 28.12   [49920/54000]\n",
            "Batch Loss: 2.297205,  Batch Accuracy: 25.78   [51200/54000]\n",
            "Batch Loss: 2.291553,  Batch Accuracy: 25.00   [52480/54000]\n",
            "Batch Loss: 2.293492,  Batch Accuracy: 22.66   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.8%, Loss: 2.293789\n",
            "Validation performance: \n",
            " Accuracy: 24.4%, Loss: 2.293522\n",
            "Test performance: \n",
            " Accuracy: 23.9%, Loss: 2.292942 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Batch Loss: 2.292367,  Batch Accuracy: 21.88   [ 1280/54000]\n",
            "Batch Loss: 2.295409,  Batch Accuracy: 24.22   [ 2560/54000]\n",
            "Batch Loss: 2.295712,  Batch Accuracy: 21.09   [ 3840/54000]\n",
            "Batch Loss: 2.299157,  Batch Accuracy: 17.19   [ 5120/54000]\n",
            "Batch Loss: 2.294862,  Batch Accuracy: 22.66   [ 6400/54000]\n",
            "Batch Loss: 2.292862,  Batch Accuracy: 27.34   [ 7680/54000]\n",
            "Batch Loss: 2.292256,  Batch Accuracy: 22.66   [ 8960/54000]\n",
            "Batch Loss: 2.293247,  Batch Accuracy: 21.09   [10240/54000]\n",
            "Batch Loss: 2.291974,  Batch Accuracy: 18.75   [11520/54000]\n",
            "Batch Loss: 2.289895,  Batch Accuracy: 28.12   [12800/54000]\n",
            "Batch Loss: 2.293734,  Batch Accuracy: 18.75   [14080/54000]\n",
            "Batch Loss: 2.293866,  Batch Accuracy: 21.88   [15360/54000]\n",
            "Batch Loss: 2.292853,  Batch Accuracy: 21.09   [16640/54000]\n",
            "Batch Loss: 2.287762,  Batch Accuracy: 31.25   [17920/54000]\n",
            "Batch Loss: 2.292608,  Batch Accuracy: 27.34   [19200/54000]\n",
            "Batch Loss: 2.291958,  Batch Accuracy: 25.78   [20480/54000]\n",
            "Batch Loss: 2.290302,  Batch Accuracy: 32.03   [21760/54000]\n",
            "Batch Loss: 2.292407,  Batch Accuracy: 24.22   [23040/54000]\n",
            "Batch Loss: 2.286379,  Batch Accuracy: 33.59   [24320/54000]\n",
            "Batch Loss: 2.298904,  Batch Accuracy: 18.75   [25600/54000]\n",
            "Batch Loss: 2.296440,  Batch Accuracy: 22.66   [26880/54000]\n",
            "Batch Loss: 2.289958,  Batch Accuracy: 28.12   [28160/54000]\n",
            "Batch Loss: 2.296959,  Batch Accuracy: 21.88   [29440/54000]\n",
            "Batch Loss: 2.293706,  Batch Accuracy: 25.00   [30720/54000]\n",
            "Batch Loss: 2.292958,  Batch Accuracy: 21.09   [32000/54000]\n",
            "Batch Loss: 2.294278,  Batch Accuracy: 22.66   [33280/54000]\n",
            "Batch Loss: 2.293686,  Batch Accuracy: 25.78   [34560/54000]\n",
            "Batch Loss: 2.292275,  Batch Accuracy: 24.22   [35840/54000]\n",
            "Batch Loss: 2.292148,  Batch Accuracy: 25.00   [37120/54000]\n",
            "Batch Loss: 2.295949,  Batch Accuracy: 18.75   [38400/54000]\n",
            "Batch Loss: 2.295143,  Batch Accuracy: 25.00   [39680/54000]\n",
            "Batch Loss: 2.288512,  Batch Accuracy: 29.69   [40960/54000]\n",
            "Batch Loss: 2.296309,  Batch Accuracy: 14.06   [42240/54000]\n",
            "Batch Loss: 2.287054,  Batch Accuracy: 31.25   [43520/54000]\n",
            "Batch Loss: 2.287835,  Batch Accuracy: 30.47   [44800/54000]\n",
            "Batch Loss: 2.291464,  Batch Accuracy: 21.88   [46080/54000]\n",
            "Batch Loss: 2.288692,  Batch Accuracy: 26.56   [47360/54000]\n",
            "Batch Loss: 2.292458,  Batch Accuracy: 28.91   [48640/54000]\n",
            "Batch Loss: 2.292082,  Batch Accuracy: 24.22   [49920/54000]\n",
            "Batch Loss: 2.290023,  Batch Accuracy: 25.00   [51200/54000]\n",
            "Batch Loss: 2.293045,  Batch Accuracy: 24.22   [52480/54000]\n",
            "Batch Loss: 2.293017,  Batch Accuracy: 23.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.8%, Loss: 2.292659\n",
            "Validation performance: \n",
            " Accuracy: 24.2%, Loss: 2.292348\n",
            "Test performance: \n",
            " Accuracy: 23.8%, Loss: 2.291717 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Batch Loss: 2.291961,  Batch Accuracy: 25.78   [ 1280/54000]\n",
            "Batch Loss: 2.286877,  Batch Accuracy: 29.69   [ 2560/54000]\n",
            "Batch Loss: 2.295197,  Batch Accuracy: 22.66   [ 3840/54000]\n",
            "Batch Loss: 2.288084,  Batch Accuracy: 26.56   [ 5120/54000]\n",
            "Batch Loss: 2.294228,  Batch Accuracy: 20.31   [ 6400/54000]\n",
            "Batch Loss: 2.294024,  Batch Accuracy: 18.75   [ 7680/54000]\n",
            "Batch Loss: 2.291533,  Batch Accuracy: 21.09   [ 8960/54000]\n",
            "Batch Loss: 2.291421,  Batch Accuracy: 23.44   [10240/54000]\n",
            "Batch Loss: 2.294794,  Batch Accuracy: 22.66   [11520/54000]\n",
            "Batch Loss: 2.290769,  Batch Accuracy: 23.44   [12800/54000]\n",
            "Batch Loss: 2.293663,  Batch Accuracy: 22.66   [14080/54000]\n",
            "Batch Loss: 2.294163,  Batch Accuracy: 22.66   [15360/54000]\n",
            "Batch Loss: 2.294842,  Batch Accuracy: 18.75   [16640/54000]\n",
            "Batch Loss: 2.290965,  Batch Accuracy: 22.66   [17920/54000]\n",
            "Batch Loss: 2.295296,  Batch Accuracy: 16.41   [19200/54000]\n",
            "Batch Loss: 2.288767,  Batch Accuracy: 24.22   [20480/54000]\n",
            "Batch Loss: 2.291049,  Batch Accuracy: 21.88   [21760/54000]\n",
            "Batch Loss: 2.296264,  Batch Accuracy: 16.41   [23040/54000]\n",
            "Batch Loss: 2.289957,  Batch Accuracy: 25.00   [24320/54000]\n",
            "Batch Loss: 2.289256,  Batch Accuracy: 25.00   [25600/54000]\n",
            "Batch Loss: 2.294483,  Batch Accuracy: 19.53   [26880/54000]\n",
            "Batch Loss: 2.292857,  Batch Accuracy: 17.97   [28160/54000]\n",
            "Batch Loss: 2.293109,  Batch Accuracy: 17.19   [29440/54000]\n",
            "Batch Loss: 2.286433,  Batch Accuracy: 25.78   [30720/54000]\n",
            "Batch Loss: 2.289829,  Batch Accuracy: 27.34   [32000/54000]\n",
            "Batch Loss: 2.291432,  Batch Accuracy: 15.62   [33280/54000]\n",
            "Batch Loss: 2.295180,  Batch Accuracy: 20.31   [34560/54000]\n",
            "Batch Loss: 2.291557,  Batch Accuracy: 21.88   [35840/54000]\n",
            "Batch Loss: 2.291833,  Batch Accuracy: 25.78   [37120/54000]\n",
            "Batch Loss: 2.295623,  Batch Accuracy: 20.31   [38400/54000]\n",
            "Batch Loss: 2.288171,  Batch Accuracy: 29.69   [39680/54000]\n",
            "Batch Loss: 2.289914,  Batch Accuracy: 25.00   [40960/54000]\n",
            "Batch Loss: 2.291918,  Batch Accuracy: 18.75   [42240/54000]\n",
            "Batch Loss: 2.295417,  Batch Accuracy: 20.31   [43520/54000]\n",
            "Batch Loss: 2.294719,  Batch Accuracy: 21.09   [44800/54000]\n",
            "Batch Loss: 2.293393,  Batch Accuracy: 17.97   [46080/54000]\n",
            "Batch Loss: 2.290735,  Batch Accuracy: 27.34   [47360/54000]\n",
            "Batch Loss: 2.290444,  Batch Accuracy: 25.00   [48640/54000]\n",
            "Batch Loss: 2.290401,  Batch Accuracy: 26.56   [49920/54000]\n",
            "Batch Loss: 2.289080,  Batch Accuracy: 25.00   [51200/54000]\n",
            "Batch Loss: 2.286233,  Batch Accuracy: 25.78   [52480/54000]\n",
            "Batch Loss: 2.294694,  Batch Accuracy: 25.78   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 23.5%, Loss: 2.291393\n",
            "Validation performance: \n",
            " Accuracy: 24.1%, Loss: 2.291023\n",
            "Test performance: \n",
            " Accuracy: 23.6%, Loss: 2.290332 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Batch Loss: 2.292242,  Batch Accuracy: 25.00   [ 1280/54000]\n",
            "Batch Loss: 2.290557,  Batch Accuracy: 21.88   [ 2560/54000]\n",
            "Batch Loss: 2.290518,  Batch Accuracy: 20.31   [ 3840/54000]\n",
            "Batch Loss: 2.291009,  Batch Accuracy: 25.00   [ 5120/54000]\n",
            "Batch Loss: 2.290223,  Batch Accuracy: 25.78   [ 6400/54000]\n",
            "Batch Loss: 2.289764,  Batch Accuracy: 32.81   [ 7680/54000]\n",
            "Batch Loss: 2.289347,  Batch Accuracy: 26.56   [ 8960/54000]\n",
            "Batch Loss: 2.288262,  Batch Accuracy: 26.56   [10240/54000]\n",
            "Batch Loss: 2.288031,  Batch Accuracy: 25.78   [11520/54000]\n",
            "Batch Loss: 2.291587,  Batch Accuracy: 21.88   [12800/54000]\n",
            "Batch Loss: 2.293599,  Batch Accuracy: 17.97   [14080/54000]\n",
            "Batch Loss: 2.289077,  Batch Accuracy: 28.12   [15360/54000]\n",
            "Batch Loss: 2.292113,  Batch Accuracy: 25.78   [16640/54000]\n",
            "Batch Loss: 2.289094,  Batch Accuracy: 22.66   [17920/54000]\n",
            "Batch Loss: 2.290734,  Batch Accuracy: 24.22   [19200/54000]\n",
            "Batch Loss: 2.292345,  Batch Accuracy: 21.88   [20480/54000]\n",
            "Batch Loss: 2.283259,  Batch Accuracy: 32.81   [21760/54000]\n",
            "Batch Loss: 2.293638,  Batch Accuracy: 17.97   [23040/54000]\n",
            "Batch Loss: 2.290796,  Batch Accuracy: 23.44   [24320/54000]\n",
            "Batch Loss: 2.289213,  Batch Accuracy: 24.22   [25600/54000]\n",
            "Batch Loss: 2.291134,  Batch Accuracy: 23.44   [26880/54000]\n",
            "Batch Loss: 2.293069,  Batch Accuracy: 22.66   [28160/54000]\n",
            "Batch Loss: 2.289037,  Batch Accuracy: 26.56   [29440/54000]\n",
            "Batch Loss: 2.291964,  Batch Accuracy: 20.31   [30720/54000]\n",
            "Batch Loss: 2.288785,  Batch Accuracy: 21.09   [32000/54000]\n",
            "Batch Loss: 2.293780,  Batch Accuracy: 24.22   [33280/54000]\n",
            "Batch Loss: 2.290601,  Batch Accuracy: 24.22   [34560/54000]\n",
            "Batch Loss: 2.293133,  Batch Accuracy: 21.88   [35840/54000]\n",
            "Batch Loss: 2.287138,  Batch Accuracy: 21.88   [37120/54000]\n",
            "Batch Loss: 2.285070,  Batch Accuracy: 36.72   [38400/54000]\n",
            "Batch Loss: 2.287883,  Batch Accuracy: 26.56   [39680/54000]\n",
            "Batch Loss: 2.283378,  Batch Accuracy: 32.81   [40960/54000]\n",
            "Batch Loss: 2.292971,  Batch Accuracy: 22.66   [42240/54000]\n",
            "Batch Loss: 2.285362,  Batch Accuracy: 28.91   [43520/54000]\n",
            "Batch Loss: 2.289397,  Batch Accuracy: 21.09   [44800/54000]\n",
            "Batch Loss: 2.292537,  Batch Accuracy: 23.44   [46080/54000]\n",
            "Batch Loss: 2.288063,  Batch Accuracy: 18.75   [47360/54000]\n",
            "Batch Loss: 2.289144,  Batch Accuracy: 26.56   [48640/54000]\n",
            "Batch Loss: 2.287845,  Batch Accuracy: 27.34   [49920/54000]\n",
            "Batch Loss: 2.289097,  Batch Accuracy: 27.34   [51200/54000]\n",
            "Batch Loss: 2.288043,  Batch Accuracy: 30.47   [52480/54000]\n",
            "Batch Loss: 2.288951,  Batch Accuracy: 25.78   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 24.2%, Loss: 2.289951\n",
            "Validation performance: \n",
            " Accuracy: 25.4%, Loss: 2.289521\n",
            "Test performance: \n",
            " Accuracy: 25.1%, Loss: 2.288752 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Batch Loss: 2.286489,  Batch Accuracy: 27.34   [ 1280/54000]\n",
            "Batch Loss: 2.289577,  Batch Accuracy: 21.09   [ 2560/54000]\n",
            "Batch Loss: 2.287916,  Batch Accuracy: 28.91   [ 3840/54000]\n",
            "Batch Loss: 2.287045,  Batch Accuracy: 27.34   [ 5120/54000]\n",
            "Batch Loss: 2.291040,  Batch Accuracy: 25.78   [ 6400/54000]\n",
            "Batch Loss: 2.282614,  Batch Accuracy: 34.38   [ 7680/54000]\n",
            "Batch Loss: 2.291067,  Batch Accuracy: 21.88   [ 8960/54000]\n",
            "Batch Loss: 2.285546,  Batch Accuracy: 27.34   [10240/54000]\n",
            "Batch Loss: 2.282550,  Batch Accuracy: 34.38   [11520/54000]\n",
            "Batch Loss: 2.290220,  Batch Accuracy: 21.09   [12800/54000]\n",
            "Batch Loss: 2.290433,  Batch Accuracy: 26.56   [14080/54000]\n",
            "Batch Loss: 2.286828,  Batch Accuracy: 25.00   [15360/54000]\n",
            "Batch Loss: 2.288441,  Batch Accuracy: 21.88   [16640/54000]\n",
            "Batch Loss: 2.287007,  Batch Accuracy: 32.03   [17920/54000]\n",
            "Batch Loss: 2.290258,  Batch Accuracy: 17.19   [19200/54000]\n",
            "Batch Loss: 2.286994,  Batch Accuracy: 28.12   [20480/54000]\n",
            "Batch Loss: 2.287358,  Batch Accuracy: 23.44   [21760/54000]\n",
            "Batch Loss: 2.290440,  Batch Accuracy: 24.22   [23040/54000]\n",
            "Batch Loss: 2.292901,  Batch Accuracy: 21.88   [24320/54000]\n",
            "Batch Loss: 2.289288,  Batch Accuracy: 26.56   [25600/54000]\n",
            "Batch Loss: 2.290290,  Batch Accuracy: 28.12   [26880/54000]\n",
            "Batch Loss: 2.282374,  Batch Accuracy: 31.25   [28160/54000]\n",
            "Batch Loss: 2.293059,  Batch Accuracy: 21.88   [29440/54000]\n",
            "Batch Loss: 2.288387,  Batch Accuracy: 22.66   [30720/54000]\n",
            "Batch Loss: 2.288182,  Batch Accuracy: 30.47   [32000/54000]\n",
            "Batch Loss: 2.288309,  Batch Accuracy: 27.34   [33280/54000]\n",
            "Batch Loss: 2.285658,  Batch Accuracy: 24.22   [34560/54000]\n",
            "Batch Loss: 2.293495,  Batch Accuracy: 23.44   [35840/54000]\n",
            "Batch Loss: 2.285168,  Batch Accuracy: 27.34   [37120/54000]\n",
            "Batch Loss: 2.287258,  Batch Accuracy: 26.56   [38400/54000]\n",
            "Batch Loss: 2.288999,  Batch Accuracy: 24.22   [39680/54000]\n",
            "Batch Loss: 2.286896,  Batch Accuracy: 28.91   [40960/54000]\n",
            "Batch Loss: 2.287900,  Batch Accuracy: 25.00   [42240/54000]\n",
            "Batch Loss: 2.288604,  Batch Accuracy: 26.56   [43520/54000]\n",
            "Batch Loss: 2.286653,  Batch Accuracy: 26.56   [44800/54000]\n",
            "Batch Loss: 2.291667,  Batch Accuracy: 25.00   [46080/54000]\n",
            "Batch Loss: 2.288675,  Batch Accuracy: 28.91   [47360/54000]\n",
            "Batch Loss: 2.289008,  Batch Accuracy: 21.88   [48640/54000]\n",
            "Batch Loss: 2.286207,  Batch Accuracy: 30.47   [49920/54000]\n",
            "Batch Loss: 2.286113,  Batch Accuracy: 34.38   [51200/54000]\n",
            "Batch Loss: 2.288378,  Batch Accuracy: 28.91   [52480/54000]\n",
            "Batch Loss: 2.289731,  Batch Accuracy: 25.00   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 26.9%, Loss: 2.288301\n",
            "Validation performance: \n",
            " Accuracy: 28.7%, Loss: 2.287783\n",
            "Test performance: \n",
            " Accuracy: 29.0%, Loss: 2.286928 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Batch Loss: 2.292099,  Batch Accuracy: 26.56   [ 1280/54000]\n",
            "Batch Loss: 2.285276,  Batch Accuracy: 31.25   [ 2560/54000]\n",
            "Batch Loss: 2.285775,  Batch Accuracy: 31.25   [ 3840/54000]\n",
            "Batch Loss: 2.288037,  Batch Accuracy: 28.12   [ 5120/54000]\n",
            "Batch Loss: 2.284533,  Batch Accuracy: 30.47   [ 6400/54000]\n",
            "Batch Loss: 2.284737,  Batch Accuracy: 34.38   [ 7680/54000]\n",
            "Batch Loss: 2.283566,  Batch Accuracy: 28.12   [ 8960/54000]\n",
            "Batch Loss: 2.287092,  Batch Accuracy: 30.47   [10240/54000]\n",
            "Batch Loss: 2.282514,  Batch Accuracy: 31.25   [11520/54000]\n",
            "Batch Loss: 2.288556,  Batch Accuracy: 28.91   [12800/54000]\n",
            "Batch Loss: 2.281305,  Batch Accuracy: 35.94   [14080/54000]\n",
            "Batch Loss: 2.287141,  Batch Accuracy: 31.25   [15360/54000]\n",
            "Batch Loss: 2.290149,  Batch Accuracy: 23.44   [16640/54000]\n",
            "Batch Loss: 2.284769,  Batch Accuracy: 30.47   [17920/54000]\n",
            "Batch Loss: 2.280554,  Batch Accuracy: 35.94   [19200/54000]\n",
            "Batch Loss: 2.287345,  Batch Accuracy: 27.34   [20480/54000]\n",
            "Batch Loss: 2.284400,  Batch Accuracy: 32.81   [21760/54000]\n",
            "Batch Loss: 2.288052,  Batch Accuracy: 32.03   [23040/54000]\n",
            "Batch Loss: 2.289202,  Batch Accuracy: 26.56   [24320/54000]\n",
            "Batch Loss: 2.285098,  Batch Accuracy: 34.38   [25600/54000]\n",
            "Batch Loss: 2.289805,  Batch Accuracy: 24.22   [26880/54000]\n",
            "Batch Loss: 2.284407,  Batch Accuracy: 34.38   [28160/54000]\n",
            "Batch Loss: 2.285088,  Batch Accuracy: 35.94   [29440/54000]\n",
            "Batch Loss: 2.286573,  Batch Accuracy: 26.56   [30720/54000]\n",
            "Batch Loss: 2.285290,  Batch Accuracy: 32.03   [32000/54000]\n",
            "Batch Loss: 2.284826,  Batch Accuracy: 30.47   [33280/54000]\n",
            "Batch Loss: 2.282864,  Batch Accuracy: 32.81   [34560/54000]\n",
            "Batch Loss: 2.290944,  Batch Accuracy: 23.44   [35840/54000]\n",
            "Batch Loss: 2.284934,  Batch Accuracy: 35.16   [37120/54000]\n",
            "Batch Loss: 2.286679,  Batch Accuracy: 32.81   [38400/54000]\n",
            "Batch Loss: 2.279713,  Batch Accuracy: 34.38   [39680/54000]\n",
            "Batch Loss: 2.289913,  Batch Accuracy: 25.78   [40960/54000]\n",
            "Batch Loss: 2.284774,  Batch Accuracy: 34.38   [42240/54000]\n",
            "Batch Loss: 2.287705,  Batch Accuracy: 38.28   [43520/54000]\n",
            "Batch Loss: 2.285936,  Batch Accuracy: 32.81   [44800/54000]\n",
            "Batch Loss: 2.284034,  Batch Accuracy: 34.38   [46080/54000]\n",
            "Batch Loss: 2.285854,  Batch Accuracy: 27.34   [47360/54000]\n",
            "Batch Loss: 2.287490,  Batch Accuracy: 28.12   [48640/54000]\n",
            "Batch Loss: 2.288100,  Batch Accuracy: 26.56   [49920/54000]\n",
            "Batch Loss: 2.283288,  Batch Accuracy: 29.69   [51200/54000]\n",
            "Batch Loss: 2.290265,  Batch Accuracy: 30.47   [52480/54000]\n",
            "Batch Loss: 2.281696,  Batch Accuracy: 34.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 30.4%, Loss: 2.286385\n",
            "Validation performance: \n",
            " Accuracy: 30.8%, Loss: 2.285765\n",
            "Test performance: \n",
            " Accuracy: 31.8%, Loss: 2.284798 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Batch Loss: 2.287084,  Batch Accuracy: 29.69   [ 1280/54000]\n",
            "Batch Loss: 2.283910,  Batch Accuracy: 38.28   [ 2560/54000]\n",
            "Batch Loss: 2.283947,  Batch Accuracy: 30.47   [ 3840/54000]\n",
            "Batch Loss: 2.288675,  Batch Accuracy: 29.69   [ 5120/54000]\n",
            "Batch Loss: 2.280658,  Batch Accuracy: 36.72   [ 6400/54000]\n",
            "Batch Loss: 2.280213,  Batch Accuracy: 33.59   [ 7680/54000]\n",
            "Batch Loss: 2.287524,  Batch Accuracy: 31.25   [ 8960/54000]\n",
            "Batch Loss: 2.283911,  Batch Accuracy: 33.59   [10240/54000]\n",
            "Batch Loss: 2.285621,  Batch Accuracy: 33.59   [11520/54000]\n",
            "Batch Loss: 2.282584,  Batch Accuracy: 38.28   [12800/54000]\n",
            "Batch Loss: 2.287077,  Batch Accuracy: 29.69   [14080/54000]\n",
            "Batch Loss: 2.281582,  Batch Accuracy: 35.16   [15360/54000]\n",
            "Batch Loss: 2.287427,  Batch Accuracy: 33.59   [16640/54000]\n",
            "Batch Loss: 2.280787,  Batch Accuracy: 39.06   [17920/54000]\n",
            "Batch Loss: 2.288594,  Batch Accuracy: 25.78   [19200/54000]\n",
            "Batch Loss: 2.281555,  Batch Accuracy: 32.81   [20480/54000]\n",
            "Batch Loss: 2.283431,  Batch Accuracy: 37.50   [21760/54000]\n",
            "Batch Loss: 2.289083,  Batch Accuracy: 32.03   [23040/54000]\n",
            "Batch Loss: 2.282757,  Batch Accuracy: 38.28   [24320/54000]\n",
            "Batch Loss: 2.280757,  Batch Accuracy: 31.25   [25600/54000]\n",
            "Batch Loss: 2.279769,  Batch Accuracy: 34.38   [26880/54000]\n",
            "Batch Loss: 2.285337,  Batch Accuracy: 30.47   [28160/54000]\n",
            "Batch Loss: 2.287441,  Batch Accuracy: 29.69   [29440/54000]\n",
            "Batch Loss: 2.282222,  Batch Accuracy: 32.81   [30720/54000]\n",
            "Batch Loss: 2.281628,  Batch Accuracy: 35.94   [32000/54000]\n",
            "Batch Loss: 2.288910,  Batch Accuracy: 30.47   [33280/54000]\n",
            "Batch Loss: 2.286748,  Batch Accuracy: 32.03   [34560/54000]\n",
            "Batch Loss: 2.283933,  Batch Accuracy: 31.25   [35840/54000]\n",
            "Batch Loss: 2.286191,  Batch Accuracy: 30.47   [37120/54000]\n",
            "Batch Loss: 2.284555,  Batch Accuracy: 33.59   [38400/54000]\n",
            "Batch Loss: 2.283002,  Batch Accuracy: 36.72   [39680/54000]\n",
            "Batch Loss: 2.282704,  Batch Accuracy: 36.72   [40960/54000]\n",
            "Batch Loss: 2.280551,  Batch Accuracy: 35.16   [42240/54000]\n",
            "Batch Loss: 2.283216,  Batch Accuracy: 31.25   [43520/54000]\n",
            "Batch Loss: 2.281252,  Batch Accuracy: 35.94   [44800/54000]\n",
            "Batch Loss: 2.274191,  Batch Accuracy: 38.28   [46080/54000]\n",
            "Batch Loss: 2.281880,  Batch Accuracy: 37.50   [47360/54000]\n",
            "Batch Loss: 2.278966,  Batch Accuracy: 36.72   [48640/54000]\n",
            "Batch Loss: 2.287779,  Batch Accuracy: 28.12   [49920/54000]\n",
            "Batch Loss: 2.286070,  Batch Accuracy: 29.69   [51200/54000]\n",
            "Batch Loss: 2.281559,  Batch Accuracy: 32.81   [52480/54000]\n",
            "Batch Loss: 2.279013,  Batch Accuracy: 33.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 32.5%, Loss: 2.284142\n",
            "Validation performance: \n",
            " Accuracy: 33.0%, Loss: 2.283347\n",
            "Test performance: \n",
            " Accuracy: 34.1%, Loss: 2.282288 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Batch Loss: 2.280752,  Batch Accuracy: 45.31   [ 1280/54000]\n",
            "Batch Loss: 2.275889,  Batch Accuracy: 42.19   [ 2560/54000]\n",
            "Batch Loss: 2.287486,  Batch Accuracy: 33.59   [ 3840/54000]\n",
            "Batch Loss: 2.290854,  Batch Accuracy: 29.69   [ 5120/54000]\n",
            "Batch Loss: 2.282636,  Batch Accuracy: 34.38   [ 6400/54000]\n",
            "Batch Loss: 2.282385,  Batch Accuracy: 34.38   [ 7680/54000]\n",
            "Batch Loss: 2.279817,  Batch Accuracy: 40.62   [ 8960/54000]\n",
            "Batch Loss: 2.285221,  Batch Accuracy: 33.59   [10240/54000]\n",
            "Batch Loss: 2.281090,  Batch Accuracy: 38.28   [11520/54000]\n",
            "Batch Loss: 2.288279,  Batch Accuracy: 28.12   [12800/54000]\n",
            "Batch Loss: 2.280412,  Batch Accuracy: 38.28   [14080/54000]\n",
            "Batch Loss: 2.284710,  Batch Accuracy: 32.81   [15360/54000]\n",
            "Batch Loss: 2.285632,  Batch Accuracy: 38.28   [16640/54000]\n",
            "Batch Loss: 2.284676,  Batch Accuracy: 26.56   [17920/54000]\n",
            "Batch Loss: 2.280499,  Batch Accuracy: 32.03   [19200/54000]\n",
            "Batch Loss: 2.280216,  Batch Accuracy: 34.38   [20480/54000]\n",
            "Batch Loss: 2.283491,  Batch Accuracy: 29.69   [21760/54000]\n",
            "Batch Loss: 2.286701,  Batch Accuracy: 32.03   [23040/54000]\n",
            "Batch Loss: 2.284688,  Batch Accuracy: 28.12   [24320/54000]\n",
            "Batch Loss: 2.278789,  Batch Accuracy: 37.50   [25600/54000]\n",
            "Batch Loss: 2.283903,  Batch Accuracy: 28.91   [26880/54000]\n",
            "Batch Loss: 2.282449,  Batch Accuracy: 34.38   [28160/54000]\n",
            "Batch Loss: 2.283560,  Batch Accuracy: 28.12   [29440/54000]\n",
            "Batch Loss: 2.282618,  Batch Accuracy: 35.16   [30720/54000]\n",
            "Batch Loss: 2.281394,  Batch Accuracy: 40.62   [32000/54000]\n",
            "Batch Loss: 2.279671,  Batch Accuracy: 32.81   [33280/54000]\n",
            "Batch Loss: 2.278396,  Batch Accuracy: 39.06   [34560/54000]\n",
            "Batch Loss: 2.280791,  Batch Accuracy: 35.94   [35840/54000]\n",
            "Batch Loss: 2.283227,  Batch Accuracy: 31.25   [37120/54000]\n",
            "Batch Loss: 2.278424,  Batch Accuracy: 38.28   [38400/54000]\n",
            "Batch Loss: 2.277797,  Batch Accuracy: 36.72   [39680/54000]\n",
            "Batch Loss: 2.276372,  Batch Accuracy: 44.53   [40960/54000]\n",
            "Batch Loss: 2.281271,  Batch Accuracy: 32.81   [42240/54000]\n",
            "Batch Loss: 2.280746,  Batch Accuracy: 36.72   [43520/54000]\n",
            "Batch Loss: 2.285748,  Batch Accuracy: 32.81   [44800/54000]\n",
            "Batch Loss: 2.275518,  Batch Accuracy: 39.06   [46080/54000]\n",
            "Batch Loss: 2.277683,  Batch Accuracy: 38.28   [47360/54000]\n",
            "Batch Loss: 2.278625,  Batch Accuracy: 41.41   [48640/54000]\n",
            "Batch Loss: 2.278664,  Batch Accuracy: 37.50   [49920/54000]\n",
            "Batch Loss: 2.285718,  Batch Accuracy: 34.38   [51200/54000]\n",
            "Batch Loss: 2.283818,  Batch Accuracy: 28.91   [52480/54000]\n",
            "Batch Loss: 2.279650,  Batch Accuracy: 33.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 34.7%, Loss: 2.281483\n",
            "Validation performance: \n",
            " Accuracy: 35.1%, Loss: 2.280500\n",
            "Test performance: \n",
            " Accuracy: 36.0%, Loss: 2.279298 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Batch Loss: 2.283195,  Batch Accuracy: 35.16   [ 1280/54000]\n",
            "Batch Loss: 2.275702,  Batch Accuracy: 39.84   [ 2560/54000]\n",
            "Batch Loss: 2.275605,  Batch Accuracy: 40.62   [ 3840/54000]\n",
            "Batch Loss: 2.279001,  Batch Accuracy: 34.38   [ 5120/54000]\n",
            "Batch Loss: 2.276407,  Batch Accuracy: 37.50   [ 6400/54000]\n",
            "Batch Loss: 2.278960,  Batch Accuracy: 39.06   [ 7680/54000]\n",
            "Batch Loss: 2.285240,  Batch Accuracy: 31.25   [ 8960/54000]\n",
            "Batch Loss: 2.285372,  Batch Accuracy: 38.28   [10240/54000]\n",
            "Batch Loss: 2.274096,  Batch Accuracy: 42.97   [11520/54000]\n",
            "Batch Loss: 2.277470,  Batch Accuracy: 42.97   [12800/54000]\n",
            "Batch Loss: 2.280816,  Batch Accuracy: 34.38   [14080/54000]\n",
            "Batch Loss: 2.278629,  Batch Accuracy: 37.50   [15360/54000]\n",
            "Batch Loss: 2.279463,  Batch Accuracy: 36.72   [16640/54000]\n",
            "Batch Loss: 2.282181,  Batch Accuracy: 34.38   [17920/54000]\n",
            "Batch Loss: 2.275236,  Batch Accuracy: 39.06   [19200/54000]\n",
            "Batch Loss: 2.277011,  Batch Accuracy: 35.16   [20480/54000]\n",
            "Batch Loss: 2.281163,  Batch Accuracy: 28.91   [21760/54000]\n",
            "Batch Loss: 2.275218,  Batch Accuracy: 39.06   [23040/54000]\n",
            "Batch Loss: 2.277076,  Batch Accuracy: 44.53   [24320/54000]\n",
            "Batch Loss: 2.285069,  Batch Accuracy: 30.47   [25600/54000]\n",
            "Batch Loss: 2.278312,  Batch Accuracy: 33.59   [26880/54000]\n",
            "Batch Loss: 2.280489,  Batch Accuracy: 40.62   [28160/54000]\n",
            "Batch Loss: 2.274572,  Batch Accuracy: 33.59   [29440/54000]\n",
            "Batch Loss: 2.268942,  Batch Accuracy: 45.31   [30720/54000]\n",
            "Batch Loss: 2.275663,  Batch Accuracy: 42.19   [32000/54000]\n",
            "Batch Loss: 2.279725,  Batch Accuracy: 33.59   [33280/54000]\n",
            "Batch Loss: 2.279554,  Batch Accuracy: 32.03   [34560/54000]\n",
            "Batch Loss: 2.276188,  Batch Accuracy: 38.28   [35840/54000]\n",
            "Batch Loss: 2.278139,  Batch Accuracy: 30.47   [37120/54000]\n",
            "Batch Loss: 2.277831,  Batch Accuracy: 36.72   [38400/54000]\n",
            "Batch Loss: 2.274079,  Batch Accuracy: 40.62   [39680/54000]\n",
            "Batch Loss: 2.277798,  Batch Accuracy: 35.94   [40960/54000]\n",
            "Batch Loss: 2.276072,  Batch Accuracy: 39.84   [42240/54000]\n",
            "Batch Loss: 2.275543,  Batch Accuracy: 38.28   [43520/54000]\n",
            "Batch Loss: 2.276866,  Batch Accuracy: 40.62   [44800/54000]\n",
            "Batch Loss: 2.274601,  Batch Accuracy: 41.41   [46080/54000]\n",
            "Batch Loss: 2.274301,  Batch Accuracy: 42.97   [47360/54000]\n",
            "Batch Loss: 2.275378,  Batch Accuracy: 36.72   [48640/54000]\n",
            "Batch Loss: 2.277142,  Batch Accuracy: 38.28   [49920/54000]\n",
            "Batch Loss: 2.279586,  Batch Accuracy: 34.38   [51200/54000]\n",
            "Batch Loss: 2.275044,  Batch Accuracy: 38.28   [52480/54000]\n",
            "Batch Loss: 2.276734,  Batch Accuracy: 38.28   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 36.6%, Loss: 2.278309\n",
            "Validation performance: \n",
            " Accuracy: 36.9%, Loss: 2.277066\n",
            "Test performance: \n",
            " Accuracy: 37.7%, Loss: 2.275704 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Batch Loss: 2.266408,  Batch Accuracy: 42.19   [ 1280/54000]\n",
            "Batch Loss: 2.271061,  Batch Accuracy: 42.97   [ 2560/54000]\n",
            "Batch Loss: 2.271078,  Batch Accuracy: 47.66   [ 3840/54000]\n",
            "Batch Loss: 2.278662,  Batch Accuracy: 36.72   [ 5120/54000]\n",
            "Batch Loss: 2.271721,  Batch Accuracy: 42.97   [ 6400/54000]\n",
            "Batch Loss: 2.276833,  Batch Accuracy: 42.19   [ 7680/54000]\n",
            "Batch Loss: 2.277129,  Batch Accuracy: 37.50   [ 8960/54000]\n",
            "Batch Loss: 2.277183,  Batch Accuracy: 33.59   [10240/54000]\n",
            "Batch Loss: 2.275514,  Batch Accuracy: 37.50   [11520/54000]\n",
            "Batch Loss: 2.274151,  Batch Accuracy: 40.62   [12800/54000]\n",
            "Batch Loss: 2.275244,  Batch Accuracy: 38.28   [14080/54000]\n",
            "Batch Loss: 2.273772,  Batch Accuracy: 45.31   [15360/54000]\n",
            "Batch Loss: 2.271371,  Batch Accuracy: 36.72   [16640/54000]\n",
            "Batch Loss: 2.273902,  Batch Accuracy: 42.97   [17920/54000]\n",
            "Batch Loss: 2.279207,  Batch Accuracy: 32.81   [19200/54000]\n",
            "Batch Loss: 2.274920,  Batch Accuracy: 40.62   [20480/54000]\n",
            "Batch Loss: 2.274682,  Batch Accuracy: 42.97   [21760/54000]\n",
            "Batch Loss: 2.271599,  Batch Accuracy: 42.97   [23040/54000]\n",
            "Batch Loss: 2.269430,  Batch Accuracy: 46.09   [24320/54000]\n",
            "Batch Loss: 2.276766,  Batch Accuracy: 34.38   [25600/54000]\n",
            "Batch Loss: 2.272076,  Batch Accuracy: 39.06   [26880/54000]\n",
            "Batch Loss: 2.266214,  Batch Accuracy: 46.09   [28160/54000]\n",
            "Batch Loss: 2.268600,  Batch Accuracy: 42.19   [29440/54000]\n",
            "Batch Loss: 2.272384,  Batch Accuracy: 43.75   [30720/54000]\n",
            "Batch Loss: 2.267559,  Batch Accuracy: 46.88   [32000/54000]\n",
            "Batch Loss: 2.274427,  Batch Accuracy: 39.06   [33280/54000]\n",
            "Batch Loss: 2.276702,  Batch Accuracy: 35.94   [34560/54000]\n",
            "Batch Loss: 2.283850,  Batch Accuracy: 32.03   [35840/54000]\n",
            "Batch Loss: 2.280002,  Batch Accuracy: 38.28   [37120/54000]\n",
            "Batch Loss: 2.281954,  Batch Accuracy: 30.47   [38400/54000]\n",
            "Batch Loss: 2.270833,  Batch Accuracy: 40.62   [39680/54000]\n",
            "Batch Loss: 2.277061,  Batch Accuracy: 37.50   [40960/54000]\n",
            "Batch Loss: 2.266702,  Batch Accuracy: 42.19   [42240/54000]\n",
            "Batch Loss: 2.270559,  Batch Accuracy: 42.19   [43520/54000]\n",
            "Batch Loss: 2.277720,  Batch Accuracy: 36.72   [44800/54000]\n",
            "Batch Loss: 2.283805,  Batch Accuracy: 26.56   [46080/54000]\n",
            "Batch Loss: 2.272455,  Batch Accuracy: 46.09   [47360/54000]\n",
            "Batch Loss: 2.278886,  Batch Accuracy: 32.81   [48640/54000]\n",
            "Batch Loss: 2.273736,  Batch Accuracy: 31.25   [49920/54000]\n",
            "Batch Loss: 2.275302,  Batch Accuracy: 35.94   [51200/54000]\n",
            "Batch Loss: 2.271753,  Batch Accuracy: 39.06   [52480/54000]\n",
            "Batch Loss: 2.277719,  Batch Accuracy: 39.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 38.3%, Loss: 2.274457\n",
            "Validation performance: \n",
            " Accuracy: 38.0%, Loss: 2.272860\n",
            "Test performance: \n",
            " Accuracy: 39.3%, Loss: 2.271300 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Batch Loss: 2.276621,  Batch Accuracy: 40.62   [ 1280/54000]\n",
            "Batch Loss: 2.271960,  Batch Accuracy: 43.75   [ 2560/54000]\n",
            "Batch Loss: 2.270634,  Batch Accuracy: 42.97   [ 3840/54000]\n",
            "Batch Loss: 2.274382,  Batch Accuracy: 37.50   [ 5120/54000]\n",
            "Batch Loss: 2.275234,  Batch Accuracy: 34.38   [ 6400/54000]\n",
            "Batch Loss: 2.276591,  Batch Accuracy: 32.81   [ 7680/54000]\n",
            "Batch Loss: 2.271945,  Batch Accuracy: 33.59   [ 8960/54000]\n",
            "Batch Loss: 2.273325,  Batch Accuracy: 38.28   [10240/54000]\n",
            "Batch Loss: 2.261573,  Batch Accuracy: 38.28   [11520/54000]\n",
            "Batch Loss: 2.270380,  Batch Accuracy: 37.50   [12800/54000]\n",
            "Batch Loss: 2.266310,  Batch Accuracy: 39.06   [14080/54000]\n",
            "Batch Loss: 2.272159,  Batch Accuracy: 32.81   [15360/54000]\n",
            "Batch Loss: 2.261145,  Batch Accuracy: 47.66   [16640/54000]\n",
            "Batch Loss: 2.276166,  Batch Accuracy: 38.28   [17920/54000]\n",
            "Batch Loss: 2.273780,  Batch Accuracy: 39.84   [19200/54000]\n",
            "Batch Loss: 2.268084,  Batch Accuracy: 40.62   [20480/54000]\n",
            "Batch Loss: 2.273036,  Batch Accuracy: 42.97   [21760/54000]\n",
            "Batch Loss: 2.274183,  Batch Accuracy: 41.41   [23040/54000]\n",
            "Batch Loss: 2.265562,  Batch Accuracy: 42.19   [24320/54000]\n",
            "Batch Loss: 2.272986,  Batch Accuracy: 40.62   [25600/54000]\n",
            "Batch Loss: 2.274704,  Batch Accuracy: 41.41   [26880/54000]\n",
            "Batch Loss: 2.267717,  Batch Accuracy: 41.41   [28160/54000]\n",
            "Batch Loss: 2.263901,  Batch Accuracy: 41.41   [29440/54000]\n",
            "Batch Loss: 2.272878,  Batch Accuracy: 37.50   [30720/54000]\n",
            "Batch Loss: 2.264079,  Batch Accuracy: 48.44   [32000/54000]\n",
            "Batch Loss: 2.275996,  Batch Accuracy: 35.94   [33280/54000]\n",
            "Batch Loss: 2.267436,  Batch Accuracy: 35.94   [34560/54000]\n",
            "Batch Loss: 2.266759,  Batch Accuracy: 43.75   [35840/54000]\n",
            "Batch Loss: 2.273028,  Batch Accuracy: 38.28   [37120/54000]\n",
            "Batch Loss: 2.270920,  Batch Accuracy: 41.41   [38400/54000]\n",
            "Batch Loss: 2.266702,  Batch Accuracy: 41.41   [39680/54000]\n",
            "Batch Loss: 2.268741,  Batch Accuracy: 28.91   [40960/54000]\n",
            "Batch Loss: 2.266513,  Batch Accuracy: 45.31   [42240/54000]\n",
            "Batch Loss: 2.270911,  Batch Accuracy: 40.62   [43520/54000]\n",
            "Batch Loss: 2.268779,  Batch Accuracy: 42.97   [44800/54000]\n",
            "Batch Loss: 2.268547,  Batch Accuracy: 39.84   [46080/54000]\n",
            "Batch Loss: 2.268697,  Batch Accuracy: 39.06   [47360/54000]\n",
            "Batch Loss: 2.263997,  Batch Accuracy: 46.88   [48640/54000]\n",
            "Batch Loss: 2.270196,  Batch Accuracy: 37.50   [49920/54000]\n",
            "Batch Loss: 2.260673,  Batch Accuracy: 44.53   [51200/54000]\n",
            "Batch Loss: 2.266425,  Batch Accuracy: 35.94   [52480/54000]\n",
            "Batch Loss: 2.264686,  Batch Accuracy: 38.28   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 39.2%, Loss: 2.269670\n",
            "Validation performance: \n",
            " Accuracy: 38.7%, Loss: 2.267561\n",
            "Test performance: \n",
            " Accuracy: 40.2%, Loss: 2.265748 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Batch Loss: 2.262280,  Batch Accuracy: 42.19   [ 1280/54000]\n",
            "Batch Loss: 2.263021,  Batch Accuracy: 39.84   [ 2560/54000]\n",
            "Batch Loss: 2.278284,  Batch Accuracy: 29.69   [ 3840/54000]\n",
            "Batch Loss: 2.270738,  Batch Accuracy: 32.03   [ 5120/54000]\n",
            "Batch Loss: 2.269356,  Batch Accuracy: 41.41   [ 6400/54000]\n",
            "Batch Loss: 2.265826,  Batch Accuracy: 36.72   [ 7680/54000]\n",
            "Batch Loss: 2.255848,  Batch Accuracy: 50.78   [ 8960/54000]\n",
            "Batch Loss: 2.271713,  Batch Accuracy: 33.59   [10240/54000]\n",
            "Batch Loss: 2.273393,  Batch Accuracy: 29.69   [11520/54000]\n",
            "Batch Loss: 2.269989,  Batch Accuracy: 35.94   [12800/54000]\n",
            "Batch Loss: 2.270744,  Batch Accuracy: 35.94   [14080/54000]\n",
            "Batch Loss: 2.263345,  Batch Accuracy: 42.97   [15360/54000]\n",
            "Batch Loss: 2.268276,  Batch Accuracy: 38.28   [16640/54000]\n",
            "Batch Loss: 2.255010,  Batch Accuracy: 43.75   [17920/54000]\n",
            "Batch Loss: 2.253330,  Batch Accuracy: 47.66   [19200/54000]\n",
            "Batch Loss: 2.264937,  Batch Accuracy: 40.62   [20480/54000]\n",
            "Batch Loss: 2.271323,  Batch Accuracy: 35.16   [21760/54000]\n",
            "Batch Loss: 2.258292,  Batch Accuracy: 40.62   [23040/54000]\n",
            "Batch Loss: 2.262964,  Batch Accuracy: 38.28   [24320/54000]\n",
            "Batch Loss: 2.267782,  Batch Accuracy: 35.94   [25600/54000]\n",
            "Batch Loss: 2.257459,  Batch Accuracy: 49.22   [26880/54000]\n",
            "Batch Loss: 2.268608,  Batch Accuracy: 36.72   [28160/54000]\n",
            "Batch Loss: 2.267665,  Batch Accuracy: 34.38   [29440/54000]\n",
            "Batch Loss: 2.261603,  Batch Accuracy: 36.72   [30720/54000]\n",
            "Batch Loss: 2.262999,  Batch Accuracy: 40.62   [32000/54000]\n",
            "Batch Loss: 2.261427,  Batch Accuracy: 41.41   [33280/54000]\n",
            "Batch Loss: 2.262964,  Batch Accuracy: 35.94   [34560/54000]\n",
            "Batch Loss: 2.257751,  Batch Accuracy: 40.62   [35840/54000]\n",
            "Batch Loss: 2.267360,  Batch Accuracy: 32.03   [37120/54000]\n",
            "Batch Loss: 2.262902,  Batch Accuracy: 45.31   [38400/54000]\n",
            "Batch Loss: 2.258920,  Batch Accuracy: 36.72   [39680/54000]\n",
            "Batch Loss: 2.257355,  Batch Accuracy: 42.97   [40960/54000]\n",
            "Batch Loss: 2.265639,  Batch Accuracy: 37.50   [42240/54000]\n",
            "Batch Loss: 2.269848,  Batch Accuracy: 28.12   [43520/54000]\n",
            "Batch Loss: 2.257148,  Batch Accuracy: 39.84   [44800/54000]\n",
            "Batch Loss: 2.268416,  Batch Accuracy: 40.62   [46080/54000]\n",
            "Batch Loss: 2.258537,  Batch Accuracy: 39.06   [47360/54000]\n",
            "Batch Loss: 2.261696,  Batch Accuracy: 43.75   [48640/54000]\n",
            "Batch Loss: 2.266277,  Batch Accuracy: 39.84   [49920/54000]\n",
            "Batch Loss: 2.259983,  Batch Accuracy: 35.16   [51200/54000]\n",
            "Batch Loss: 2.266536,  Batch Accuracy: 34.38   [52480/54000]\n",
            "Batch Loss: 2.257098,  Batch Accuracy: 40.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 39.8%, Loss: 2.263540\n",
            "Validation performance: \n",
            " Accuracy: 38.7%, Loss: 2.260667\n",
            "Test performance: \n",
            " Accuracy: 40.1%, Loss: 2.258547 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Batch Loss: 2.249513,  Batch Accuracy: 48.44   [ 1280/54000]\n",
            "Batch Loss: 2.254282,  Batch Accuracy: 42.97   [ 2560/54000]\n",
            "Batch Loss: 2.262815,  Batch Accuracy: 38.28   [ 3840/54000]\n",
            "Batch Loss: 2.256827,  Batch Accuracy: 44.53   [ 5120/54000]\n",
            "Batch Loss: 2.250072,  Batch Accuracy: 45.31   [ 6400/54000]\n",
            "Batch Loss: 2.264046,  Batch Accuracy: 39.06   [ 7680/54000]\n",
            "Batch Loss: 2.250626,  Batch Accuracy: 44.53   [ 8960/54000]\n",
            "Batch Loss: 2.261522,  Batch Accuracy: 29.69   [10240/54000]\n",
            "Batch Loss: 2.256742,  Batch Accuracy: 46.88   [11520/54000]\n",
            "Batch Loss: 2.261207,  Batch Accuracy: 43.75   [12800/54000]\n",
            "Batch Loss: 2.255759,  Batch Accuracy: 41.41   [14080/54000]\n",
            "Batch Loss: 2.257264,  Batch Accuracy: 38.28   [15360/54000]\n",
            "Batch Loss: 2.251164,  Batch Accuracy: 41.41   [16640/54000]\n",
            "Batch Loss: 2.254031,  Batch Accuracy: 42.19   [17920/54000]\n",
            "Batch Loss: 2.262813,  Batch Accuracy: 35.16   [19200/54000]\n",
            "Batch Loss: 2.263809,  Batch Accuracy: 39.06   [20480/54000]\n",
            "Batch Loss: 2.246980,  Batch Accuracy: 42.19   [21760/54000]\n",
            "Batch Loss: 2.255566,  Batch Accuracy: 39.06   [23040/54000]\n",
            "Batch Loss: 2.252021,  Batch Accuracy: 39.84   [24320/54000]\n",
            "Batch Loss: 2.248738,  Batch Accuracy: 50.00   [25600/54000]\n",
            "Batch Loss: 2.246975,  Batch Accuracy: 42.19   [26880/54000]\n",
            "Batch Loss: 2.240382,  Batch Accuracy: 45.31   [28160/54000]\n",
            "Batch Loss: 2.262425,  Batch Accuracy: 36.72   [29440/54000]\n",
            "Batch Loss: 2.253543,  Batch Accuracy: 44.53   [30720/54000]\n",
            "Batch Loss: 2.252535,  Batch Accuracy: 39.06   [32000/54000]\n",
            "Batch Loss: 2.262640,  Batch Accuracy: 35.94   [33280/54000]\n",
            "Batch Loss: 2.257814,  Batch Accuracy: 35.94   [34560/54000]\n",
            "Batch Loss: 2.249731,  Batch Accuracy: 42.19   [35840/54000]\n",
            "Batch Loss: 2.243720,  Batch Accuracy: 37.50   [37120/54000]\n",
            "Batch Loss: 2.252567,  Batch Accuracy: 39.06   [38400/54000]\n",
            "Batch Loss: 2.240124,  Batch Accuracy: 42.97   [39680/54000]\n",
            "Batch Loss: 2.256251,  Batch Accuracy: 38.28   [40960/54000]\n",
            "Batch Loss: 2.254066,  Batch Accuracy: 39.06   [42240/54000]\n",
            "Batch Loss: 2.253427,  Batch Accuracy: 35.94   [43520/54000]\n",
            "Batch Loss: 2.247560,  Batch Accuracy: 41.41   [44800/54000]\n",
            "Batch Loss: 2.259740,  Batch Accuracy: 39.84   [46080/54000]\n",
            "Batch Loss: 2.251832,  Batch Accuracy: 42.97   [47360/54000]\n",
            "Batch Loss: 2.257145,  Batch Accuracy: 36.72   [48640/54000]\n",
            "Batch Loss: 2.244132,  Batch Accuracy: 48.44   [49920/54000]\n",
            "Batch Loss: 2.250885,  Batch Accuracy: 39.84   [51200/54000]\n",
            "Batch Loss: 2.255780,  Batch Accuracy: 44.53   [52480/54000]\n",
            "Batch Loss: 2.253603,  Batch Accuracy: 39.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 39.5%, Loss: 2.255473\n",
            "Validation performance: \n",
            " Accuracy: 38.1%, Loss: 2.251456\n",
            "Test performance: \n",
            " Accuracy: 39.6%, Loss: 2.248988 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Batch Loss: 2.245863,  Batch Accuracy: 46.09   [ 1280/54000]\n",
            "Batch Loss: 2.240661,  Batch Accuracy: 48.44   [ 2560/54000]\n",
            "Batch Loss: 2.248627,  Batch Accuracy: 39.84   [ 3840/54000]\n",
            "Batch Loss: 2.241896,  Batch Accuracy: 42.19   [ 5120/54000]\n",
            "Batch Loss: 2.237423,  Batch Accuracy: 42.97   [ 6400/54000]\n",
            "Batch Loss: 2.245073,  Batch Accuracy: 37.50   [ 7680/54000]\n",
            "Batch Loss: 2.241957,  Batch Accuracy: 42.19   [ 8960/54000]\n",
            "Batch Loss: 2.248529,  Batch Accuracy: 37.50   [10240/54000]\n",
            "Batch Loss: 2.245579,  Batch Accuracy: 48.44   [11520/54000]\n",
            "Batch Loss: 2.245445,  Batch Accuracy: 39.06   [12800/54000]\n",
            "Batch Loss: 2.256072,  Batch Accuracy: 30.47   [14080/54000]\n",
            "Batch Loss: 2.244730,  Batch Accuracy: 39.06   [15360/54000]\n",
            "Batch Loss: 2.242754,  Batch Accuracy: 46.88   [16640/54000]\n",
            "Batch Loss: 2.254385,  Batch Accuracy: 30.47   [17920/54000]\n",
            "Batch Loss: 2.249044,  Batch Accuracy: 30.47   [19200/54000]\n",
            "Batch Loss: 2.253989,  Batch Accuracy: 38.28   [20480/54000]\n",
            "Batch Loss: 2.245508,  Batch Accuracy: 42.19   [21760/54000]\n",
            "Batch Loss: 2.247023,  Batch Accuracy: 42.19   [23040/54000]\n",
            "Batch Loss: 2.250848,  Batch Accuracy: 38.28   [24320/54000]\n",
            "Batch Loss: 2.248092,  Batch Accuracy: 39.84   [25600/54000]\n",
            "Batch Loss: 2.243052,  Batch Accuracy: 33.59   [26880/54000]\n",
            "Batch Loss: 2.243298,  Batch Accuracy: 41.41   [28160/54000]\n",
            "Batch Loss: 2.247568,  Batch Accuracy: 34.38   [29440/54000]\n",
            "Batch Loss: 2.238744,  Batch Accuracy: 33.59   [30720/54000]\n",
            "Batch Loss: 2.244514,  Batch Accuracy: 39.06   [32000/54000]\n",
            "Batch Loss: 2.242918,  Batch Accuracy: 30.47   [33280/54000]\n",
            "Batch Loss: 2.242346,  Batch Accuracy: 41.41   [34560/54000]\n",
            "Batch Loss: 2.246234,  Batch Accuracy: 39.84   [35840/54000]\n",
            "Batch Loss: 2.246895,  Batch Accuracy: 36.72   [37120/54000]\n",
            "Batch Loss: 2.241992,  Batch Accuracy: 41.41   [38400/54000]\n",
            "Batch Loss: 2.233511,  Batch Accuracy: 44.53   [39680/54000]\n",
            "Batch Loss: 2.236923,  Batch Accuracy: 42.19   [40960/54000]\n",
            "Batch Loss: 2.230954,  Batch Accuracy: 46.88   [42240/54000]\n",
            "Batch Loss: 2.250710,  Batch Accuracy: 32.03   [43520/54000]\n",
            "Batch Loss: 2.245020,  Batch Accuracy: 38.28   [44800/54000]\n",
            "Batch Loss: 2.238868,  Batch Accuracy: 39.06   [46080/54000]\n",
            "Batch Loss: 2.246571,  Batch Accuracy: 36.72   [47360/54000]\n",
            "Batch Loss: 2.243146,  Batch Accuracy: 33.59   [48640/54000]\n",
            "Batch Loss: 2.236968,  Batch Accuracy: 38.28   [49920/54000]\n",
            "Batch Loss: 2.236998,  Batch Accuracy: 42.19   [51200/54000]\n",
            "Batch Loss: 2.234264,  Batch Accuracy: 38.28   [52480/54000]\n",
            "Batch Loss: 2.236655,  Batch Accuracy: 39.06   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 38.8%, Loss: 2.244618\n",
            "Validation performance: \n",
            " Accuracy: 37.3%, Loss: 2.238908\n",
            "Test performance: \n",
            " Accuracy: 38.6%, Loss: 2.235964 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Batch Loss: 2.236131,  Batch Accuracy: 37.50   [ 1280/54000]\n",
            "Batch Loss: 2.232084,  Batch Accuracy: 39.84   [ 2560/54000]\n",
            "Batch Loss: 2.236558,  Batch Accuracy: 37.50   [ 3840/54000]\n",
            "Batch Loss: 2.232239,  Batch Accuracy: 35.94   [ 5120/54000]\n",
            "Batch Loss: 2.237774,  Batch Accuracy: 33.59   [ 6400/54000]\n",
            "Batch Loss: 2.219499,  Batch Accuracy: 43.75   [ 7680/54000]\n",
            "Batch Loss: 2.246802,  Batch Accuracy: 35.16   [ 8960/54000]\n",
            "Batch Loss: 2.235754,  Batch Accuracy: 39.06   [10240/54000]\n",
            "Batch Loss: 2.238499,  Batch Accuracy: 35.94   [11520/54000]\n",
            "Batch Loss: 2.242400,  Batch Accuracy: 35.16   [12800/54000]\n",
            "Batch Loss: 2.236598,  Batch Accuracy: 35.94   [14080/54000]\n",
            "Batch Loss: 2.235286,  Batch Accuracy: 35.16   [15360/54000]\n",
            "Batch Loss: 2.247445,  Batch Accuracy: 32.81   [16640/54000]\n",
            "Batch Loss: 2.220261,  Batch Accuracy: 49.22   [17920/54000]\n",
            "Batch Loss: 2.235996,  Batch Accuracy: 37.50   [19200/54000]\n",
            "Batch Loss: 2.241201,  Batch Accuracy: 28.91   [20480/54000]\n",
            "Batch Loss: 2.244601,  Batch Accuracy: 31.25   [21760/54000]\n",
            "Batch Loss: 2.221586,  Batch Accuracy: 36.72   [23040/54000]\n",
            "Batch Loss: 2.230480,  Batch Accuracy: 36.72   [24320/54000]\n",
            "Batch Loss: 2.227470,  Batch Accuracy: 39.84   [25600/54000]\n",
            "Batch Loss: 2.237645,  Batch Accuracy: 33.59   [26880/54000]\n",
            "Batch Loss: 2.241781,  Batch Accuracy: 30.47   [28160/54000]\n",
            "Batch Loss: 2.212749,  Batch Accuracy: 39.06   [29440/54000]\n",
            "Batch Loss: 2.224478,  Batch Accuracy: 33.59   [30720/54000]\n",
            "Batch Loss: 2.240623,  Batch Accuracy: 38.28   [32000/54000]\n",
            "Batch Loss: 2.240869,  Batch Accuracy: 35.94   [33280/54000]\n",
            "Batch Loss: 2.223756,  Batch Accuracy: 41.41   [34560/54000]\n",
            "Batch Loss: 2.225758,  Batch Accuracy: 37.50   [35840/54000]\n",
            "Batch Loss: 2.225099,  Batch Accuracy: 34.38   [37120/54000]\n",
            "Batch Loss: 2.217228,  Batch Accuracy: 46.88   [38400/54000]\n",
            "Batch Loss: 2.217934,  Batch Accuracy: 38.28   [39680/54000]\n",
            "Batch Loss: 2.255450,  Batch Accuracy: 25.00   [40960/54000]\n",
            "Batch Loss: 2.216120,  Batch Accuracy: 36.72   [42240/54000]\n",
            "Batch Loss: 2.227239,  Batch Accuracy: 39.06   [43520/54000]\n",
            "Batch Loss: 2.226672,  Batch Accuracy: 39.84   [44800/54000]\n",
            "Batch Loss: 2.215323,  Batch Accuracy: 33.59   [46080/54000]\n",
            "Batch Loss: 2.228124,  Batch Accuracy: 36.72   [47360/54000]\n",
            "Batch Loss: 2.223232,  Batch Accuracy: 39.06   [48640/54000]\n",
            "Batch Loss: 2.231865,  Batch Accuracy: 35.16   [49920/54000]\n",
            "Batch Loss: 2.223754,  Batch Accuracy: 35.16   [51200/54000]\n",
            "Batch Loss: 2.222770,  Batch Accuracy: 35.94   [52480/54000]\n",
            "Batch Loss: 2.212938,  Batch Accuracy: 48.44   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 37.9%, Loss: 2.229522\n",
            "Validation performance: \n",
            " Accuracy: 36.1%, Loss: 2.221091\n",
            "Test performance: \n",
            " Accuracy: 37.5%, Loss: 2.217524 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Batch Loss: 2.227784,  Batch Accuracy: 32.03   [ 1280/54000]\n",
            "Batch Loss: 2.220166,  Batch Accuracy: 35.16   [ 2560/54000]\n",
            "Batch Loss: 2.215708,  Batch Accuracy: 34.38   [ 3840/54000]\n",
            "Batch Loss: 2.218868,  Batch Accuracy: 33.59   [ 5120/54000]\n",
            "Batch Loss: 2.229285,  Batch Accuracy: 39.84   [ 6400/54000]\n",
            "Batch Loss: 2.231827,  Batch Accuracy: 34.38   [ 7680/54000]\n",
            "Batch Loss: 2.220497,  Batch Accuracy: 39.84   [ 8960/54000]\n",
            "Batch Loss: 2.215837,  Batch Accuracy: 40.62   [10240/54000]\n",
            "Batch Loss: 2.211627,  Batch Accuracy: 39.84   [11520/54000]\n",
            "Batch Loss: 2.207420,  Batch Accuracy: 41.41   [12800/54000]\n",
            "Batch Loss: 2.212078,  Batch Accuracy: 34.38   [14080/54000]\n",
            "Batch Loss: 2.197826,  Batch Accuracy: 46.09   [15360/54000]\n",
            "Batch Loss: 2.227709,  Batch Accuracy: 29.69   [16640/54000]\n",
            "Batch Loss: 2.214123,  Batch Accuracy: 32.81   [17920/54000]\n",
            "Batch Loss: 2.216992,  Batch Accuracy: 27.34   [19200/54000]\n",
            "Batch Loss: 2.213677,  Batch Accuracy: 39.84   [20480/54000]\n",
            "Batch Loss: 2.206304,  Batch Accuracy: 37.50   [21760/54000]\n",
            "Batch Loss: 2.205351,  Batch Accuracy: 41.41   [23040/54000]\n",
            "Batch Loss: 2.210496,  Batch Accuracy: 34.38   [24320/54000]\n",
            "Batch Loss: 2.222189,  Batch Accuracy: 32.81   [25600/54000]\n",
            "Batch Loss: 2.208540,  Batch Accuracy: 38.28   [26880/54000]\n",
            "Batch Loss: 2.201974,  Batch Accuracy: 40.62   [28160/54000]\n",
            "Batch Loss: 2.211769,  Batch Accuracy: 37.50   [29440/54000]\n",
            "Batch Loss: 2.215887,  Batch Accuracy: 38.28   [30720/54000]\n",
            "Batch Loss: 2.213355,  Batch Accuracy: 32.81   [32000/54000]\n",
            "Batch Loss: 2.217890,  Batch Accuracy: 27.34   [33280/54000]\n",
            "Batch Loss: 2.173228,  Batch Accuracy: 47.66   [34560/54000]\n",
            "Batch Loss: 2.215896,  Batch Accuracy: 35.16   [35840/54000]\n",
            "Batch Loss: 2.200504,  Batch Accuracy: 34.38   [37120/54000]\n",
            "Batch Loss: 2.205413,  Batch Accuracy: 33.59   [38400/54000]\n",
            "Batch Loss: 2.224804,  Batch Accuracy: 27.34   [39680/54000]\n",
            "Batch Loss: 2.195998,  Batch Accuracy: 38.28   [40960/54000]\n",
            "Batch Loss: 2.191005,  Batch Accuracy: 40.62   [42240/54000]\n",
            "Batch Loss: 2.206155,  Batch Accuracy: 33.59   [43520/54000]\n",
            "Batch Loss: 2.216341,  Batch Accuracy: 35.16   [44800/54000]\n",
            "Batch Loss: 2.204100,  Batch Accuracy: 35.16   [46080/54000]\n",
            "Batch Loss: 2.185678,  Batch Accuracy: 34.38   [47360/54000]\n",
            "Batch Loss: 2.215034,  Batch Accuracy: 32.03   [48640/54000]\n",
            "Batch Loss: 2.206180,  Batch Accuracy: 33.59   [49920/54000]\n",
            "Batch Loss: 2.194946,  Batch Accuracy: 38.28   [51200/54000]\n",
            "Batch Loss: 2.199878,  Batch Accuracy: 35.94   [52480/54000]\n",
            "Batch Loss: 2.183161,  Batch Accuracy: 41.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 36.7%, Loss: 2.207565\n",
            "Validation performance: \n",
            " Accuracy: 34.3%, Loss: 2.194589\n",
            "Test performance: \n",
            " Accuracy: 35.9%, Loss: 2.190059 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Batch Loss: 2.191892,  Batch Accuracy: 36.72   [ 1280/54000]\n",
            "Batch Loss: 2.193324,  Batch Accuracy: 36.72   [ 2560/54000]\n",
            "Batch Loss: 2.180868,  Batch Accuracy: 38.28   [ 3840/54000]\n",
            "Batch Loss: 2.188562,  Batch Accuracy: 35.16   [ 5120/54000]\n",
            "Batch Loss: 2.191239,  Batch Accuracy: 37.50   [ 6400/54000]\n",
            "Batch Loss: 2.168837,  Batch Accuracy: 40.62   [ 7680/54000]\n",
            "Batch Loss: 2.188010,  Batch Accuracy: 39.06   [ 8960/54000]\n",
            "Batch Loss: 2.173858,  Batch Accuracy: 41.41   [10240/54000]\n",
            "Batch Loss: 2.193904,  Batch Accuracy: 37.50   [11520/54000]\n",
            "Batch Loss: 2.169706,  Batch Accuracy: 42.19   [12800/54000]\n",
            "Batch Loss: 2.194833,  Batch Accuracy: 33.59   [14080/54000]\n",
            "Batch Loss: 2.179266,  Batch Accuracy: 36.72   [15360/54000]\n",
            "Batch Loss: 2.189455,  Batch Accuracy: 38.28   [16640/54000]\n",
            "Batch Loss: 2.179295,  Batch Accuracy: 39.84   [17920/54000]\n",
            "Batch Loss: 2.200637,  Batch Accuracy: 30.47   [19200/54000]\n",
            "Batch Loss: 2.182566,  Batch Accuracy: 30.47   [20480/54000]\n",
            "Batch Loss: 2.157550,  Batch Accuracy: 33.59   [21760/54000]\n",
            "Batch Loss: 2.173019,  Batch Accuracy: 32.03   [23040/54000]\n",
            "Batch Loss: 2.178130,  Batch Accuracy: 35.94   [24320/54000]\n",
            "Batch Loss: 2.189609,  Batch Accuracy: 34.38   [25600/54000]\n",
            "Batch Loss: 2.178247,  Batch Accuracy: 30.47   [26880/54000]\n",
            "Batch Loss: 2.181227,  Batch Accuracy: 29.69   [28160/54000]\n",
            "Batch Loss: 2.188914,  Batch Accuracy: 29.69   [29440/54000]\n",
            "Batch Loss: 2.172844,  Batch Accuracy: 31.25   [30720/54000]\n",
            "Batch Loss: 2.180079,  Batch Accuracy: 33.59   [32000/54000]\n",
            "Batch Loss: 2.181127,  Batch Accuracy: 29.69   [33280/54000]\n",
            "Batch Loss: 2.181648,  Batch Accuracy: 25.78   [34560/54000]\n",
            "Batch Loss: 2.156313,  Batch Accuracy: 37.50   [35840/54000]\n",
            "Batch Loss: 2.145735,  Batch Accuracy: 35.16   [37120/54000]\n",
            "Batch Loss: 2.195059,  Batch Accuracy: 25.00   [38400/54000]\n",
            "Batch Loss: 2.163687,  Batch Accuracy: 38.28   [39680/54000]\n",
            "Batch Loss: 2.174814,  Batch Accuracy: 32.03   [40960/54000]\n",
            "Batch Loss: 2.192051,  Batch Accuracy: 26.56   [42240/54000]\n",
            "Batch Loss: 2.156695,  Batch Accuracy: 34.38   [43520/54000]\n",
            "Batch Loss: 2.153782,  Batch Accuracy: 40.62   [44800/54000]\n",
            "Batch Loss: 2.159812,  Batch Accuracy: 33.59   [46080/54000]\n",
            "Batch Loss: 2.147629,  Batch Accuracy: 34.38   [47360/54000]\n",
            "Batch Loss: 2.144043,  Batch Accuracy: 39.84   [48640/54000]\n",
            "Batch Loss: 2.160522,  Batch Accuracy: 32.03   [49920/54000]\n",
            "Batch Loss: 2.135001,  Batch Accuracy: 35.16   [51200/54000]\n",
            "Batch Loss: 2.170627,  Batch Accuracy: 30.47   [52480/54000]\n",
            "Batch Loss: 2.143196,  Batch Accuracy: 33.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 34.6%, Loss: 2.173910\n",
            "Validation performance: \n",
            " Accuracy: 32.5%, Loss: 2.152911\n",
            "Test performance: \n",
            " Accuracy: 34.0%, Loss: 2.146864 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Batch Loss: 2.132281,  Batch Accuracy: 39.06   [ 1280/54000]\n",
            "Batch Loss: 2.154489,  Batch Accuracy: 33.59   [ 2560/54000]\n",
            "Batch Loss: 2.130812,  Batch Accuracy: 35.94   [ 3840/54000]\n",
            "Batch Loss: 2.120778,  Batch Accuracy: 39.84   [ 5120/54000]\n",
            "Batch Loss: 2.135587,  Batch Accuracy: 38.28   [ 6400/54000]\n",
            "Batch Loss: 2.139907,  Batch Accuracy: 32.81   [ 7680/54000]\n",
            "Batch Loss: 2.153018,  Batch Accuracy: 30.47   [ 8960/54000]\n",
            "Batch Loss: 2.138217,  Batch Accuracy: 37.50   [10240/54000]\n",
            "Batch Loss: 2.156911,  Batch Accuracy: 32.03   [11520/54000]\n",
            "Batch Loss: 2.140182,  Batch Accuracy: 35.94   [12800/54000]\n",
            "Batch Loss: 2.112009,  Batch Accuracy: 35.94   [14080/54000]\n",
            "Batch Loss: 2.135733,  Batch Accuracy: 33.59   [15360/54000]\n",
            "Batch Loss: 2.133173,  Batch Accuracy: 35.16   [16640/54000]\n",
            "Batch Loss: 2.130826,  Batch Accuracy: 32.81   [17920/54000]\n",
            "Batch Loss: 2.133313,  Batch Accuracy: 30.47   [19200/54000]\n",
            "Batch Loss: 2.139988,  Batch Accuracy: 34.38   [20480/54000]\n",
            "Batch Loss: 2.147405,  Batch Accuracy: 27.34   [21760/54000]\n",
            "Batch Loss: 2.101022,  Batch Accuracy: 37.50   [23040/54000]\n",
            "Batch Loss: 2.125093,  Batch Accuracy: 28.91   [24320/54000]\n",
            "Batch Loss: 2.073268,  Batch Accuracy: 36.72   [25600/54000]\n",
            "Batch Loss: 2.088918,  Batch Accuracy: 34.38   [26880/54000]\n",
            "Batch Loss: 2.112435,  Batch Accuracy: 39.06   [28160/54000]\n",
            "Batch Loss: 2.083318,  Batch Accuracy: 35.94   [29440/54000]\n",
            "Batch Loss: 2.134108,  Batch Accuracy: 27.34   [30720/54000]\n",
            "Batch Loss: 2.126799,  Batch Accuracy: 35.16   [32000/54000]\n",
            "Batch Loss: 2.121902,  Batch Accuracy: 28.12   [33280/54000]\n",
            "Batch Loss: 2.101904,  Batch Accuracy: 35.16   [34560/54000]\n",
            "Batch Loss: 2.135387,  Batch Accuracy: 25.78   [35840/54000]\n",
            "Batch Loss: 2.086663,  Batch Accuracy: 33.59   [37120/54000]\n",
            "Batch Loss: 2.076222,  Batch Accuracy: 35.16   [38400/54000]\n",
            "Batch Loss: 2.083139,  Batch Accuracy: 39.84   [39680/54000]\n",
            "Batch Loss: 2.079573,  Batch Accuracy: 35.94   [40960/54000]\n",
            "Batch Loss: 2.132428,  Batch Accuracy: 26.56   [42240/54000]\n",
            "Batch Loss: 2.124426,  Batch Accuracy: 21.88   [43520/54000]\n",
            "Batch Loss: 2.060797,  Batch Accuracy: 29.69   [44800/54000]\n",
            "Batch Loss: 2.071808,  Batch Accuracy: 30.47   [46080/54000]\n",
            "Batch Loss: 2.066163,  Batch Accuracy: 28.91   [47360/54000]\n",
            "Batch Loss: 2.116207,  Batch Accuracy: 29.69   [48640/54000]\n",
            "Batch Loss: 2.094896,  Batch Accuracy: 29.69   [49920/54000]\n",
            "Batch Loss: 2.076033,  Batch Accuracy: 28.12   [51200/54000]\n",
            "Batch Loss: 2.074801,  Batch Accuracy: 33.59   [52480/54000]\n",
            "Batch Loss: 2.092820,  Batch Accuracy: 25.78   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 32.0%, Loss: 2.119179\n",
            "Validation performance: \n",
            " Accuracy: 29.7%, Loss: 2.083120\n",
            "Test performance: \n",
            " Accuracy: 30.6%, Loss: 2.074726 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Batch Loss: 2.087225,  Batch Accuracy: 30.47   [ 1280/54000]\n",
            "Batch Loss: 2.127559,  Batch Accuracy: 21.09   [ 2560/54000]\n",
            "Batch Loss: 2.085150,  Batch Accuracy: 28.91   [ 3840/54000]\n",
            "Batch Loss: 2.062344,  Batch Accuracy: 37.50   [ 5120/54000]\n",
            "Batch Loss: 2.091815,  Batch Accuracy: 31.25   [ 6400/54000]\n",
            "Batch Loss: 2.073783,  Batch Accuracy: 32.81   [ 7680/54000]\n",
            "Batch Loss: 2.086592,  Batch Accuracy: 28.12   [ 8960/54000]\n",
            "Batch Loss: 2.095661,  Batch Accuracy: 25.00   [10240/54000]\n",
            "Batch Loss: 2.069536,  Batch Accuracy: 21.88   [11520/54000]\n",
            "Batch Loss: 2.033508,  Batch Accuracy: 32.81   [12800/54000]\n",
            "Batch Loss: 2.057313,  Batch Accuracy: 35.16   [14080/54000]\n",
            "Batch Loss: 2.045054,  Batch Accuracy: 28.91   [15360/54000]\n",
            "Batch Loss: 2.044741,  Batch Accuracy: 29.69   [16640/54000]\n",
            "Batch Loss: 2.053697,  Batch Accuracy: 30.47   [17920/54000]\n",
            "Batch Loss: 2.035746,  Batch Accuracy: 33.59   [19200/54000]\n",
            "Batch Loss: 2.064758,  Batch Accuracy: 25.00   [20480/54000]\n",
            "Batch Loss: 2.044404,  Batch Accuracy: 28.91   [21760/54000]\n",
            "Batch Loss: 2.007395,  Batch Accuracy: 34.38   [23040/54000]\n",
            "Batch Loss: 2.043076,  Batch Accuracy: 28.12   [24320/54000]\n",
            "Batch Loss: 2.078314,  Batch Accuracy: 28.12   [25600/54000]\n",
            "Batch Loss: 2.032729,  Batch Accuracy: 31.25   [26880/54000]\n",
            "Batch Loss: 1.996820,  Batch Accuracy: 35.16   [28160/54000]\n",
            "Batch Loss: 2.023606,  Batch Accuracy: 27.34   [29440/54000]\n",
            "Batch Loss: 2.050430,  Batch Accuracy: 25.78   [30720/54000]\n",
            "Batch Loss: 2.044974,  Batch Accuracy: 28.12   [32000/54000]\n",
            "Batch Loss: 1.974620,  Batch Accuracy: 32.81   [33280/54000]\n",
            "Batch Loss: 2.052739,  Batch Accuracy: 25.00   [34560/54000]\n",
            "Batch Loss: 1.991318,  Batch Accuracy: 32.81   [35840/54000]\n",
            "Batch Loss: 1.991138,  Batch Accuracy: 29.69   [37120/54000]\n",
            "Batch Loss: 1.969512,  Batch Accuracy: 35.94   [38400/54000]\n",
            "Batch Loss: 1.997378,  Batch Accuracy: 32.03   [39680/54000]\n",
            "Batch Loss: 1.981118,  Batch Accuracy: 32.03   [40960/54000]\n",
            "Batch Loss: 2.018542,  Batch Accuracy: 28.91   [42240/54000]\n",
            "Batch Loss: 1.996594,  Batch Accuracy: 32.81   [43520/54000]\n",
            "Batch Loss: 1.946583,  Batch Accuracy: 31.25   [44800/54000]\n",
            "Batch Loss: 2.019658,  Batch Accuracy: 26.56   [46080/54000]\n",
            "Batch Loss: 1.902779,  Batch Accuracy: 31.25   [47360/54000]\n",
            "Batch Loss: 1.973162,  Batch Accuracy: 28.91   [48640/54000]\n",
            "Batch Loss: 2.029009,  Batch Accuracy: 24.22   [49920/54000]\n",
            "Batch Loss: 2.034485,  Batch Accuracy: 21.09   [51200/54000]\n",
            "Batch Loss: 1.986704,  Batch Accuracy: 32.81   [52480/54000]\n",
            "Batch Loss: 1.999911,  Batch Accuracy: 26.56   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 29.6%, Loss: 2.025873\n",
            "Validation performance: \n",
            " Accuracy: 29.1%, Loss: 1.963871\n",
            "Test performance: \n",
            " Accuracy: 29.8%, Loss: 1.951166 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Batch Loss: 1.929873,  Batch Accuracy: 37.50   [ 1280/54000]\n",
            "Batch Loss: 1.905887,  Batch Accuracy: 34.38   [ 2560/54000]\n",
            "Batch Loss: 1.935148,  Batch Accuracy: 28.91   [ 3840/54000]\n",
            "Batch Loss: 1.930620,  Batch Accuracy: 32.81   [ 5120/54000]\n",
            "Batch Loss: 2.008603,  Batch Accuracy: 28.91   [ 6400/54000]\n",
            "Batch Loss: 1.935323,  Batch Accuracy: 28.91   [ 7680/54000]\n",
            "Batch Loss: 1.883874,  Batch Accuracy: 35.16   [ 8960/54000]\n",
            "Batch Loss: 1.907550,  Batch Accuracy: 34.38   [10240/54000]\n",
            "Batch Loss: 1.938623,  Batch Accuracy: 29.69   [11520/54000]\n",
            "Batch Loss: 1.897961,  Batch Accuracy: 30.47   [12800/54000]\n",
            "Batch Loss: 1.952853,  Batch Accuracy: 18.75   [14080/54000]\n",
            "Batch Loss: 1.916031,  Batch Accuracy: 28.91   [15360/54000]\n",
            "Batch Loss: 1.906947,  Batch Accuracy: 30.47   [16640/54000]\n",
            "Batch Loss: 1.860088,  Batch Accuracy: 35.16   [17920/54000]\n",
            "Batch Loss: 1.927121,  Batch Accuracy: 26.56   [19200/54000]\n",
            "Batch Loss: 1.996975,  Batch Accuracy: 23.44   [20480/54000]\n",
            "Batch Loss: 1.952198,  Batch Accuracy: 26.56   [21760/54000]\n",
            "Batch Loss: 1.893820,  Batch Accuracy: 32.03   [23040/54000]\n",
            "Batch Loss: 1.847721,  Batch Accuracy: 35.94   [24320/54000]\n",
            "Batch Loss: 1.873151,  Batch Accuracy: 28.91   [25600/54000]\n",
            "Batch Loss: 1.888587,  Batch Accuracy: 31.25   [26880/54000]\n",
            "Batch Loss: 1.866399,  Batch Accuracy: 30.47   [28160/54000]\n",
            "Batch Loss: 1.832139,  Batch Accuracy: 32.81   [29440/54000]\n",
            "Batch Loss: 1.894431,  Batch Accuracy: 32.03   [30720/54000]\n",
            "Batch Loss: 1.828348,  Batch Accuracy: 32.81   [32000/54000]\n",
            "Batch Loss: 1.891567,  Batch Accuracy: 30.47   [33280/54000]\n",
            "Batch Loss: 1.796380,  Batch Accuracy: 36.72   [34560/54000]\n",
            "Batch Loss: 1.874282,  Batch Accuracy: 24.22   [35840/54000]\n",
            "Batch Loss: 1.891014,  Batch Accuracy: 27.34   [37120/54000]\n",
            "Batch Loss: 1.871959,  Batch Accuracy: 21.88   [38400/54000]\n",
            "Batch Loss: 1.800801,  Batch Accuracy: 32.81   [39680/54000]\n",
            "Batch Loss: 1.834119,  Batch Accuracy: 34.38   [40960/54000]\n",
            "Batch Loss: 1.818915,  Batch Accuracy: 29.69   [42240/54000]\n",
            "Batch Loss: 1.743010,  Batch Accuracy: 37.50   [43520/54000]\n",
            "Batch Loss: 1.783059,  Batch Accuracy: 35.94   [44800/54000]\n",
            "Batch Loss: 1.778494,  Batch Accuracy: 35.94   [46080/54000]\n",
            "Batch Loss: 1.780093,  Batch Accuracy: 29.69   [47360/54000]\n",
            "Batch Loss: 1.786022,  Batch Accuracy: 28.91   [48640/54000]\n",
            "Batch Loss: 1.732409,  Batch Accuracy: 32.03   [49920/54000]\n",
            "Batch Loss: 1.801884,  Batch Accuracy: 33.59   [51200/54000]\n",
            "Batch Loss: 1.799062,  Batch Accuracy: 31.25   [52480/54000]\n",
            "Batch Loss: 1.781586,  Batch Accuracy: 33.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 30.6%, Loss: 1.868958\n",
            "Validation performance: \n",
            " Accuracy: 33.1%, Loss: 1.769581\n",
            "Test performance: \n",
            " Accuracy: 33.6%, Loss: 1.751238 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Batch Loss: 1.678622,  Batch Accuracy: 35.94   [ 1280/54000]\n",
            "Batch Loss: 1.742026,  Batch Accuracy: 35.94   [ 2560/54000]\n",
            "Batch Loss: 1.739693,  Batch Accuracy: 40.62   [ 3840/54000]\n",
            "Batch Loss: 1.789060,  Batch Accuracy: 36.72   [ 5120/54000]\n",
            "Batch Loss: 1.684326,  Batch Accuracy: 39.84   [ 6400/54000]\n",
            "Batch Loss: 1.712128,  Batch Accuracy: 37.50   [ 7680/54000]\n",
            "Batch Loss: 1.717253,  Batch Accuracy: 43.75   [ 8960/54000]\n",
            "Batch Loss: 1.655894,  Batch Accuracy: 38.28   [10240/54000]\n",
            "Batch Loss: 1.707781,  Batch Accuracy: 36.72   [11520/54000]\n",
            "Batch Loss: 1.726775,  Batch Accuracy: 36.72   [12800/54000]\n",
            "Batch Loss: 1.739991,  Batch Accuracy: 29.69   [14080/54000]\n",
            "Batch Loss: 1.692914,  Batch Accuracy: 35.94   [15360/54000]\n",
            "Batch Loss: 1.627957,  Batch Accuracy: 36.72   [16640/54000]\n",
            "Batch Loss: 1.632695,  Batch Accuracy: 39.84   [17920/54000]\n",
            "Batch Loss: 1.639317,  Batch Accuracy: 36.72   [19200/54000]\n",
            "Batch Loss: 1.671748,  Batch Accuracy: 39.06   [20480/54000]\n",
            "Batch Loss: 1.729993,  Batch Accuracy: 38.28   [21760/54000]\n",
            "Batch Loss: 1.632731,  Batch Accuracy: 41.41   [23040/54000]\n",
            "Batch Loss: 1.657106,  Batch Accuracy: 37.50   [24320/54000]\n",
            "Batch Loss: 1.667904,  Batch Accuracy: 41.41   [25600/54000]\n",
            "Batch Loss: 1.652129,  Batch Accuracy: 35.94   [26880/54000]\n",
            "Batch Loss: 1.634019,  Batch Accuracy: 39.84   [28160/54000]\n",
            "Batch Loss: 1.578026,  Batch Accuracy: 46.09   [29440/54000]\n",
            "Batch Loss: 1.689257,  Batch Accuracy: 38.28   [30720/54000]\n",
            "Batch Loss: 1.625517,  Batch Accuracy: 46.88   [32000/54000]\n",
            "Batch Loss: 1.625174,  Batch Accuracy: 39.84   [33280/54000]\n",
            "Batch Loss: 1.584800,  Batch Accuracy: 40.62   [34560/54000]\n",
            "Batch Loss: 1.575889,  Batch Accuracy: 43.75   [35840/54000]\n",
            "Batch Loss: 1.669146,  Batch Accuracy: 39.06   [37120/54000]\n",
            "Batch Loss: 1.659842,  Batch Accuracy: 40.62   [38400/54000]\n",
            "Batch Loss: 1.582074,  Batch Accuracy: 45.31   [39680/54000]\n",
            "Batch Loss: 1.595385,  Batch Accuracy: 48.44   [40960/54000]\n",
            "Batch Loss: 1.615751,  Batch Accuracy: 41.41   [42240/54000]\n",
            "Batch Loss: 1.532332,  Batch Accuracy: 51.56   [43520/54000]\n",
            "Batch Loss: 1.526206,  Batch Accuracy: 53.12   [44800/54000]\n",
            "Batch Loss: 1.500910,  Batch Accuracy: 56.25   [46080/54000]\n",
            "Batch Loss: 1.605303,  Batch Accuracy: 43.75   [47360/54000]\n",
            "Batch Loss: 1.561629,  Batch Accuracy: 47.66   [48640/54000]\n",
            "Batch Loss: 1.576129,  Batch Accuracy: 51.56   [49920/54000]\n",
            "Batch Loss: 1.495453,  Batch Accuracy: 54.69   [51200/54000]\n",
            "Batch Loss: 1.462129,  Batch Accuracy: 55.47   [52480/54000]\n",
            "Batch Loss: 1.525835,  Batch Accuracy: 54.69   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 41.9%, Loss: 1.639148\n",
            "Validation performance: \n",
            " Accuracy: 50.6%, Loss: 1.516631\n",
            "Test performance: \n",
            " Accuracy: 51.5%, Loss: 1.493465 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Batch Loss: 1.549080,  Batch Accuracy: 56.25   [ 1280/54000]\n",
            "Batch Loss: 1.450280,  Batch Accuracy: 55.47   [ 2560/54000]\n",
            "Batch Loss: 1.504905,  Batch Accuracy: 46.09   [ 3840/54000]\n",
            "Batch Loss: 1.462906,  Batch Accuracy: 54.69   [ 5120/54000]\n",
            "Batch Loss: 1.513761,  Batch Accuracy: 51.56   [ 6400/54000]\n",
            "Batch Loss: 1.338391,  Batch Accuracy: 55.47   [ 7680/54000]\n",
            "Batch Loss: 1.518429,  Batch Accuracy: 51.56   [ 8960/54000]\n",
            "Batch Loss: 1.449898,  Batch Accuracy: 53.12   [10240/54000]\n",
            "Batch Loss: 1.379647,  Batch Accuracy: 49.22   [11520/54000]\n",
            "Batch Loss: 1.419805,  Batch Accuracy: 53.91   [12800/54000]\n",
            "Batch Loss: 1.447843,  Batch Accuracy: 54.69   [14080/54000]\n",
            "Batch Loss: 1.440977,  Batch Accuracy: 53.12   [15360/54000]\n",
            "Batch Loss: 1.478180,  Batch Accuracy: 49.22   [16640/54000]\n",
            "Batch Loss: 1.406478,  Batch Accuracy: 56.25   [17920/54000]\n",
            "Batch Loss: 1.407788,  Batch Accuracy: 55.47   [19200/54000]\n",
            "Batch Loss: 1.469880,  Batch Accuracy: 55.47   [20480/54000]\n",
            "Batch Loss: 1.427468,  Batch Accuracy: 56.25   [21760/54000]\n",
            "Batch Loss: 1.421724,  Batch Accuracy: 46.88   [23040/54000]\n",
            "Batch Loss: 1.396598,  Batch Accuracy: 54.69   [24320/54000]\n",
            "Batch Loss: 1.506423,  Batch Accuracy: 48.44   [25600/54000]\n",
            "Batch Loss: 1.480285,  Batch Accuracy: 45.31   [26880/54000]\n",
            "Batch Loss: 1.383347,  Batch Accuracy: 56.25   [28160/54000]\n",
            "Batch Loss: 1.423611,  Batch Accuracy: 56.25   [29440/54000]\n",
            "Batch Loss: 1.365195,  Batch Accuracy: 60.94   [30720/54000]\n",
            "Batch Loss: 1.392857,  Batch Accuracy: 53.12   [32000/54000]\n",
            "Batch Loss: 1.352929,  Batch Accuracy: 57.81   [33280/54000]\n",
            "Batch Loss: 1.323715,  Batch Accuracy: 53.12   [34560/54000]\n",
            "Batch Loss: 1.388404,  Batch Accuracy: 56.25   [35840/54000]\n",
            "Batch Loss: 1.430410,  Batch Accuracy: 54.69   [37120/54000]\n",
            "Batch Loss: 1.259289,  Batch Accuracy: 60.16   [38400/54000]\n",
            "Batch Loss: 1.334077,  Batch Accuracy: 60.16   [39680/54000]\n",
            "Batch Loss: 1.442316,  Batch Accuracy: 51.56   [40960/54000]\n",
            "Batch Loss: 1.326065,  Batch Accuracy: 59.38   [42240/54000]\n",
            "Batch Loss: 1.300832,  Batch Accuracy: 59.38   [43520/54000]\n",
            "Batch Loss: 1.439130,  Batch Accuracy: 46.88   [44800/54000]\n",
            "Batch Loss: 1.315655,  Batch Accuracy: 53.12   [46080/54000]\n",
            "Batch Loss: 1.210222,  Batch Accuracy: 62.50   [47360/54000]\n",
            "Batch Loss: 1.300437,  Batch Accuracy: 54.69   [48640/54000]\n",
            "Batch Loss: 1.235361,  Batch Accuracy: 62.50   [49920/54000]\n",
            "Batch Loss: 1.269900,  Batch Accuracy: 62.50   [51200/54000]\n",
            "Batch Loss: 1.333733,  Batch Accuracy: 59.38   [52480/54000]\n",
            "Batch Loss: 1.316486,  Batch Accuracy: 56.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 55.4%, Loss: 1.390438\n",
            "Validation performance: \n",
            " Accuracy: 59.8%, Loss: 1.289518\n",
            "Test performance: \n",
            " Accuracy: 59.7%, Loss: 1.260948 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Batch Loss: 1.272716,  Batch Accuracy: 57.03   [ 1280/54000]\n",
            "Batch Loss: 1.348104,  Batch Accuracy: 52.34   [ 2560/54000]\n",
            "Batch Loss: 1.256886,  Batch Accuracy: 59.38   [ 3840/54000]\n",
            "Batch Loss: 1.330445,  Batch Accuracy: 56.25   [ 5120/54000]\n",
            "Batch Loss: 1.268170,  Batch Accuracy: 57.03   [ 6400/54000]\n",
            "Batch Loss: 1.282449,  Batch Accuracy: 59.38   [ 7680/54000]\n",
            "Batch Loss: 1.296023,  Batch Accuracy: 58.59   [ 8960/54000]\n",
            "Batch Loss: 1.179373,  Batch Accuracy: 62.50   [10240/54000]\n",
            "Batch Loss: 1.210066,  Batch Accuracy: 64.84   [11520/54000]\n",
            "Batch Loss: 1.356214,  Batch Accuracy: 53.91   [12800/54000]\n",
            "Batch Loss: 1.212226,  Batch Accuracy: 67.97   [14080/54000]\n",
            "Batch Loss: 1.264589,  Batch Accuracy: 53.91   [15360/54000]\n",
            "Batch Loss: 1.223304,  Batch Accuracy: 57.81   [16640/54000]\n",
            "Batch Loss: 1.172829,  Batch Accuracy: 64.84   [17920/54000]\n",
            "Batch Loss: 1.202548,  Batch Accuracy: 57.03   [19200/54000]\n",
            "Batch Loss: 1.133667,  Batch Accuracy: 67.19   [20480/54000]\n",
            "Batch Loss: 1.286754,  Batch Accuracy: 62.50   [21760/54000]\n",
            "Batch Loss: 1.166708,  Batch Accuracy: 58.59   [23040/54000]\n",
            "Batch Loss: 1.144795,  Batch Accuracy: 57.81   [24320/54000]\n",
            "Batch Loss: 1.209032,  Batch Accuracy: 58.59   [25600/54000]\n",
            "Batch Loss: 1.210796,  Batch Accuracy: 59.38   [26880/54000]\n",
            "Batch Loss: 1.268852,  Batch Accuracy: 57.81   [28160/54000]\n",
            "Batch Loss: 1.244462,  Batch Accuracy: 53.12   [29440/54000]\n",
            "Batch Loss: 1.133797,  Batch Accuracy: 62.50   [30720/54000]\n",
            "Batch Loss: 1.031716,  Batch Accuracy: 68.75   [32000/54000]\n",
            "Batch Loss: 1.150316,  Batch Accuracy: 61.72   [33280/54000]\n",
            "Batch Loss: 1.135556,  Batch Accuracy: 61.72   [34560/54000]\n",
            "Batch Loss: 1.074045,  Batch Accuracy: 65.62   [35840/54000]\n",
            "Batch Loss: 1.174923,  Batch Accuracy: 57.81   [37120/54000]\n",
            "Batch Loss: 1.142221,  Batch Accuracy: 59.38   [38400/54000]\n",
            "Batch Loss: 1.147372,  Batch Accuracy: 68.75   [39680/54000]\n",
            "Batch Loss: 1.101844,  Batch Accuracy: 65.62   [40960/54000]\n",
            "Batch Loss: 1.116012,  Batch Accuracy: 64.06   [42240/54000]\n",
            "Batch Loss: 1.116438,  Batch Accuracy: 57.81   [43520/54000]\n",
            "Batch Loss: 1.207668,  Batch Accuracy: 56.25   [44800/54000]\n",
            "Batch Loss: 1.167666,  Batch Accuracy: 64.06   [46080/54000]\n",
            "Batch Loss: 1.150693,  Batch Accuracy: 64.84   [47360/54000]\n",
            "Batch Loss: 1.080031,  Batch Accuracy: 62.50   [48640/54000]\n",
            "Batch Loss: 1.150427,  Batch Accuracy: 59.38   [49920/54000]\n",
            "Batch Loss: 1.126301,  Batch Accuracy: 68.75   [51200/54000]\n",
            "Batch Loss: 1.151180,  Batch Accuracy: 60.16   [52480/54000]\n",
            "Batch Loss: 1.112843,  Batch Accuracy: 62.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 62.1%, Loss: 1.187526\n",
            "Validation performance: \n",
            " Accuracy: 65.5%, Loss: 1.115579\n",
            "Test performance: \n",
            " Accuracy: 65.3%, Loss: 1.086318 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Batch Loss: 1.044021,  Batch Accuracy: 66.41   [ 1280/54000]\n",
            "Batch Loss: 1.009860,  Batch Accuracy: 68.75   [ 2560/54000]\n",
            "Batch Loss: 0.961165,  Batch Accuracy: 64.84   [ 3840/54000]\n",
            "Batch Loss: 1.045733,  Batch Accuracy: 68.75   [ 5120/54000]\n",
            "Batch Loss: 0.935007,  Batch Accuracy: 65.62   [ 6400/54000]\n",
            "Batch Loss: 1.106400,  Batch Accuracy: 60.16   [ 7680/54000]\n",
            "Batch Loss: 1.023405,  Batch Accuracy: 68.75   [ 8960/54000]\n",
            "Batch Loss: 1.015349,  Batch Accuracy: 67.97   [10240/54000]\n",
            "Batch Loss: 1.034799,  Batch Accuracy: 73.44   [11520/54000]\n",
            "Batch Loss: 1.079242,  Batch Accuracy: 70.31   [12800/54000]\n",
            "Batch Loss: 1.130068,  Batch Accuracy: 63.28   [14080/54000]\n",
            "Batch Loss: 0.998931,  Batch Accuracy: 63.28   [15360/54000]\n",
            "Batch Loss: 1.032396,  Batch Accuracy: 67.97   [16640/54000]\n",
            "Batch Loss: 1.078777,  Batch Accuracy: 60.94   [17920/54000]\n",
            "Batch Loss: 1.013209,  Batch Accuracy: 65.62   [19200/54000]\n",
            "Batch Loss: 1.067768,  Batch Accuracy: 67.97   [20480/54000]\n",
            "Batch Loss: 1.101594,  Batch Accuracy: 62.50   [21760/54000]\n",
            "Batch Loss: 1.040290,  Batch Accuracy: 70.31   [23040/54000]\n",
            "Batch Loss: 1.015170,  Batch Accuracy: 61.72   [24320/54000]\n",
            "Batch Loss: 0.959775,  Batch Accuracy: 65.62   [25600/54000]\n",
            "Batch Loss: 1.005339,  Batch Accuracy: 67.19   [26880/54000]\n",
            "Batch Loss: 1.078382,  Batch Accuracy: 64.84   [28160/54000]\n",
            "Batch Loss: 1.041866,  Batch Accuracy: 64.84   [29440/54000]\n",
            "Batch Loss: 1.069803,  Batch Accuracy: 64.84   [30720/54000]\n",
            "Batch Loss: 0.943510,  Batch Accuracy: 67.97   [32000/54000]\n",
            "Batch Loss: 1.055014,  Batch Accuracy: 58.59   [33280/54000]\n",
            "Batch Loss: 1.042321,  Batch Accuracy: 70.31   [34560/54000]\n",
            "Batch Loss: 0.997147,  Batch Accuracy: 69.53   [35840/54000]\n",
            "Batch Loss: 1.084348,  Batch Accuracy: 60.16   [37120/54000]\n",
            "Batch Loss: 1.052040,  Batch Accuracy: 64.84   [38400/54000]\n",
            "Batch Loss: 1.077646,  Batch Accuracy: 67.97   [39680/54000]\n",
            "Batch Loss: 1.020442,  Batch Accuracy: 64.84   [40960/54000]\n",
            "Batch Loss: 0.900157,  Batch Accuracy: 75.78   [42240/54000]\n",
            "Batch Loss: 0.905535,  Batch Accuracy: 75.78   [43520/54000]\n",
            "Batch Loss: 0.968200,  Batch Accuracy: 71.09   [44800/54000]\n",
            "Batch Loss: 0.990562,  Batch Accuracy: 67.97   [46080/54000]\n",
            "Batch Loss: 0.925160,  Batch Accuracy: 72.66   [47360/54000]\n",
            "Batch Loss: 0.961061,  Batch Accuracy: 75.00   [48640/54000]\n",
            "Batch Loss: 0.924008,  Batch Accuracy: 75.00   [49920/54000]\n",
            "Batch Loss: 1.047323,  Batch Accuracy: 65.62   [51200/54000]\n",
            "Batch Loss: 1.015954,  Batch Accuracy: 64.84   [52480/54000]\n",
            "Batch Loss: 0.910713,  Batch Accuracy: 70.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 67.1%, Loss: 1.032171\n",
            "Validation performance: \n",
            " Accuracy: 69.3%, Loss: 0.977466\n",
            "Test performance: \n",
            " Accuracy: 69.1%, Loss: 0.950554 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Batch Loss: 1.033813,  Batch Accuracy: 71.09   [ 1280/54000]\n",
            "Batch Loss: 0.953269,  Batch Accuracy: 64.84   [ 2560/54000]\n",
            "Batch Loss: 0.866637,  Batch Accuracy: 78.12   [ 3840/54000]\n",
            "Batch Loss: 0.841894,  Batch Accuracy: 72.66   [ 5120/54000]\n",
            "Batch Loss: 0.928417,  Batch Accuracy: 74.22   [ 6400/54000]\n",
            "Batch Loss: 0.913814,  Batch Accuracy: 67.97   [ 7680/54000]\n",
            "Batch Loss: 0.935982,  Batch Accuracy: 67.97   [ 8960/54000]\n",
            "Batch Loss: 0.923090,  Batch Accuracy: 69.53   [10240/54000]\n",
            "Batch Loss: 0.955482,  Batch Accuracy: 61.72   [11520/54000]\n",
            "Batch Loss: 0.790290,  Batch Accuracy: 78.91   [12800/54000]\n",
            "Batch Loss: 0.887251,  Batch Accuracy: 67.19   [14080/54000]\n",
            "Batch Loss: 0.933853,  Batch Accuracy: 73.44   [15360/54000]\n",
            "Batch Loss: 0.888471,  Batch Accuracy: 67.97   [16640/54000]\n",
            "Batch Loss: 0.839606,  Batch Accuracy: 72.66   [17920/54000]\n",
            "Batch Loss: 0.999766,  Batch Accuracy: 71.09   [19200/54000]\n",
            "Batch Loss: 0.921392,  Batch Accuracy: 69.53   [20480/54000]\n",
            "Batch Loss: 0.996442,  Batch Accuracy: 67.97   [21760/54000]\n",
            "Batch Loss: 1.012688,  Batch Accuracy: 66.41   [23040/54000]\n",
            "Batch Loss: 0.926949,  Batch Accuracy: 71.09   [24320/54000]\n",
            "Batch Loss: 0.915632,  Batch Accuracy: 75.78   [25600/54000]\n",
            "Batch Loss: 0.795446,  Batch Accuracy: 71.09   [26880/54000]\n",
            "Batch Loss: 0.917186,  Batch Accuracy: 67.97   [28160/54000]\n",
            "Batch Loss: 0.771941,  Batch Accuracy: 79.69   [29440/54000]\n",
            "Batch Loss: 0.966202,  Batch Accuracy: 72.66   [30720/54000]\n",
            "Batch Loss: 0.761886,  Batch Accuracy: 72.66   [32000/54000]\n",
            "Batch Loss: 0.964128,  Batch Accuracy: 71.88   [33280/54000]\n",
            "Batch Loss: 0.937718,  Batch Accuracy: 68.75   [34560/54000]\n",
            "Batch Loss: 0.954338,  Batch Accuracy: 72.66   [35840/54000]\n",
            "Batch Loss: 0.799748,  Batch Accuracy: 75.78   [37120/54000]\n",
            "Batch Loss: 0.770585,  Batch Accuracy: 70.31   [38400/54000]\n",
            "Batch Loss: 0.816822,  Batch Accuracy: 75.78   [39680/54000]\n",
            "Batch Loss: 0.774291,  Batch Accuracy: 76.56   [40960/54000]\n",
            "Batch Loss: 0.827499,  Batch Accuracy: 73.44   [42240/54000]\n",
            "Batch Loss: 0.834068,  Batch Accuracy: 72.66   [43520/54000]\n",
            "Batch Loss: 0.910261,  Batch Accuracy: 64.06   [44800/54000]\n",
            "Batch Loss: 0.866908,  Batch Accuracy: 76.56   [46080/54000]\n",
            "Batch Loss: 0.834556,  Batch Accuracy: 73.44   [47360/54000]\n",
            "Batch Loss: 0.816980,  Batch Accuracy: 75.78   [48640/54000]\n",
            "Batch Loss: 1.028167,  Batch Accuracy: 71.88   [49920/54000]\n",
            "Batch Loss: 0.853928,  Batch Accuracy: 70.31   [51200/54000]\n",
            "Batch Loss: 0.811184,  Batch Accuracy: 75.00   [52480/54000]\n",
            "Batch Loss: 0.725405,  Batch Accuracy: 79.69   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 71.3%, Loss: 0.905896\n",
            "Validation performance: \n",
            " Accuracy: 72.5%, Loss: 0.866008\n",
            "Test performance: \n",
            " Accuracy: 73.2%, Loss: 0.836419 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Batch Loss: 1.073963,  Batch Accuracy: 67.19   [ 1280/54000]\n",
            "Batch Loss: 0.780725,  Batch Accuracy: 76.56   [ 2560/54000]\n",
            "Batch Loss: 0.882909,  Batch Accuracy: 70.31   [ 3840/54000]\n",
            "Batch Loss: 0.854507,  Batch Accuracy: 74.22   [ 5120/54000]\n",
            "Batch Loss: 0.753388,  Batch Accuracy: 77.34   [ 6400/54000]\n",
            "Batch Loss: 0.727884,  Batch Accuracy: 75.78   [ 7680/54000]\n",
            "Batch Loss: 0.769380,  Batch Accuracy: 75.00   [ 8960/54000]\n",
            "Batch Loss: 0.843859,  Batch Accuracy: 72.66   [10240/54000]\n",
            "Batch Loss: 0.757011,  Batch Accuracy: 76.56   [11520/54000]\n",
            "Batch Loss: 1.011355,  Batch Accuracy: 70.31   [12800/54000]\n",
            "Batch Loss: 0.805288,  Batch Accuracy: 78.12   [14080/54000]\n",
            "Batch Loss: 0.728871,  Batch Accuracy: 76.56   [15360/54000]\n",
            "Batch Loss: 0.688235,  Batch Accuracy: 78.91   [16640/54000]\n",
            "Batch Loss: 0.895863,  Batch Accuracy: 71.88   [17920/54000]\n",
            "Batch Loss: 0.916490,  Batch Accuracy: 67.97   [19200/54000]\n",
            "Batch Loss: 0.812240,  Batch Accuracy: 75.78   [20480/54000]\n",
            "Batch Loss: 0.826652,  Batch Accuracy: 74.22   [21760/54000]\n",
            "Batch Loss: 0.907576,  Batch Accuracy: 69.53   [23040/54000]\n",
            "Batch Loss: 0.707845,  Batch Accuracy: 80.47   [24320/54000]\n",
            "Batch Loss: 0.744526,  Batch Accuracy: 78.91   [25600/54000]\n",
            "Batch Loss: 0.866625,  Batch Accuracy: 67.19   [26880/54000]\n",
            "Batch Loss: 0.756515,  Batch Accuracy: 77.34   [28160/54000]\n",
            "Batch Loss: 0.805671,  Batch Accuracy: 74.22   [29440/54000]\n",
            "Batch Loss: 0.811209,  Batch Accuracy: 80.47   [30720/54000]\n",
            "Batch Loss: 0.747261,  Batch Accuracy: 77.34   [32000/54000]\n",
            "Batch Loss: 0.785638,  Batch Accuracy: 75.00   [33280/54000]\n",
            "Batch Loss: 0.851110,  Batch Accuracy: 72.66   [34560/54000]\n",
            "Batch Loss: 0.744187,  Batch Accuracy: 73.44   [35840/54000]\n",
            "Batch Loss: 0.723283,  Batch Accuracy: 78.12   [37120/54000]\n",
            "Batch Loss: 0.743693,  Batch Accuracy: 79.69   [38400/54000]\n",
            "Batch Loss: 1.015134,  Batch Accuracy: 77.34   [39680/54000]\n",
            "Batch Loss: 0.690619,  Batch Accuracy: 78.91   [40960/54000]\n",
            "Batch Loss: 0.746200,  Batch Accuracy: 78.91   [42240/54000]\n",
            "Batch Loss: 0.843795,  Batch Accuracy: 77.34   [43520/54000]\n",
            "Batch Loss: 0.743129,  Batch Accuracy: 72.66   [44800/54000]\n",
            "Batch Loss: 0.771105,  Batch Accuracy: 76.56   [46080/54000]\n",
            "Batch Loss: 0.797106,  Batch Accuracy: 77.34   [47360/54000]\n",
            "Batch Loss: 0.837591,  Batch Accuracy: 72.66   [48640/54000]\n",
            "Batch Loss: 0.640472,  Batch Accuracy: 81.25   [49920/54000]\n",
            "Batch Loss: 0.798296,  Batch Accuracy: 72.66   [51200/54000]\n",
            "Batch Loss: 0.792877,  Batch Accuracy: 79.69   [52480/54000]\n",
            "Batch Loss: 0.776768,  Batch Accuracy: 70.31   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 74.5%, Loss: 0.807410\n",
            "Validation performance: \n",
            " Accuracy: 75.2%, Loss: 0.780704\n",
            "Test performance: \n",
            " Accuracy: 76.3%, Loss: 0.752588 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Batch Loss: 0.852781,  Batch Accuracy: 73.44   [ 1280/54000]\n",
            "Batch Loss: 0.823545,  Batch Accuracy: 66.41   [ 2560/54000]\n",
            "Batch Loss: 0.767843,  Batch Accuracy: 79.69   [ 3840/54000]\n",
            "Batch Loss: 0.868450,  Batch Accuracy: 73.44   [ 5120/54000]\n",
            "Batch Loss: 0.751387,  Batch Accuracy: 74.22   [ 6400/54000]\n",
            "Batch Loss: 0.767983,  Batch Accuracy: 80.47   [ 7680/54000]\n",
            "Batch Loss: 0.730752,  Batch Accuracy: 80.47   [ 8960/54000]\n",
            "Batch Loss: 0.715881,  Batch Accuracy: 77.34   [10240/54000]\n",
            "Batch Loss: 0.632644,  Batch Accuracy: 79.69   [11520/54000]\n",
            "Batch Loss: 0.795552,  Batch Accuracy: 79.69   [12800/54000]\n",
            "Batch Loss: 0.635077,  Batch Accuracy: 81.25   [14080/54000]\n",
            "Batch Loss: 0.880738,  Batch Accuracy: 78.91   [15360/54000]\n",
            "Batch Loss: 0.739104,  Batch Accuracy: 74.22   [16640/54000]\n",
            "Batch Loss: 0.833971,  Batch Accuracy: 74.22   [17920/54000]\n",
            "Batch Loss: 0.749185,  Batch Accuracy: 80.47   [19200/54000]\n",
            "Batch Loss: 0.649434,  Batch Accuracy: 75.00   [20480/54000]\n",
            "Batch Loss: 0.706794,  Batch Accuracy: 77.34   [21760/54000]\n",
            "Batch Loss: 0.682553,  Batch Accuracy: 81.25   [23040/54000]\n",
            "Batch Loss: 0.601224,  Batch Accuracy: 79.69   [24320/54000]\n",
            "Batch Loss: 0.667358,  Batch Accuracy: 75.78   [25600/54000]\n",
            "Batch Loss: 0.740202,  Batch Accuracy: 73.44   [26880/54000]\n",
            "Batch Loss: 0.829758,  Batch Accuracy: 72.66   [28160/54000]\n",
            "Batch Loss: 0.694558,  Batch Accuracy: 79.69   [29440/54000]\n",
            "Batch Loss: 0.743785,  Batch Accuracy: 77.34   [30720/54000]\n",
            "Batch Loss: 0.703371,  Batch Accuracy: 76.56   [32000/54000]\n",
            "Batch Loss: 0.818951,  Batch Accuracy: 74.22   [33280/54000]\n",
            "Batch Loss: 0.763421,  Batch Accuracy: 75.00   [34560/54000]\n",
            "Batch Loss: 0.713000,  Batch Accuracy: 82.81   [35840/54000]\n",
            "Batch Loss: 0.781215,  Batch Accuracy: 77.34   [37120/54000]\n",
            "Batch Loss: 0.710253,  Batch Accuracy: 75.00   [38400/54000]\n",
            "Batch Loss: 0.785823,  Batch Accuracy: 72.66   [39680/54000]\n",
            "Batch Loss: 0.770350,  Batch Accuracy: 78.12   [40960/54000]\n",
            "Batch Loss: 0.702411,  Batch Accuracy: 78.91   [42240/54000]\n",
            "Batch Loss: 0.643053,  Batch Accuracy: 84.38   [43520/54000]\n",
            "Batch Loss: 0.751654,  Batch Accuracy: 72.66   [44800/54000]\n",
            "Batch Loss: 0.622299,  Batch Accuracy: 83.59   [46080/54000]\n",
            "Batch Loss: 0.705299,  Batch Accuracy: 78.91   [47360/54000]\n",
            "Batch Loss: 0.735139,  Batch Accuracy: 78.12   [48640/54000]\n",
            "Batch Loss: 0.789955,  Batch Accuracy: 73.44   [49920/54000]\n",
            "Batch Loss: 0.730978,  Batch Accuracy: 75.78   [51200/54000]\n",
            "Batch Loss: 0.764992,  Batch Accuracy: 76.56   [52480/54000]\n",
            "Batch Loss: 0.694835,  Batch Accuracy: 78.91   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 77.0%, Loss: 0.736768\n",
            "Validation performance: \n",
            " Accuracy: 77.1%, Loss: 0.720291\n",
            "Test performance: \n",
            " Accuracy: 78.3%, Loss: 0.693225 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Batch Loss: 0.638082,  Batch Accuracy: 85.16   [ 1280/54000]\n",
            "Batch Loss: 0.734207,  Batch Accuracy: 73.44   [ 2560/54000]\n",
            "Batch Loss: 0.798036,  Batch Accuracy: 75.00   [ 3840/54000]\n",
            "Batch Loss: 0.694503,  Batch Accuracy: 76.56   [ 5120/54000]\n",
            "Batch Loss: 0.785423,  Batch Accuracy: 75.00   [ 6400/54000]\n",
            "Batch Loss: 0.758969,  Batch Accuracy: 76.56   [ 7680/54000]\n",
            "Batch Loss: 0.827600,  Batch Accuracy: 75.00   [ 8960/54000]\n",
            "Batch Loss: 0.467968,  Batch Accuracy: 85.16   [10240/54000]\n",
            "Batch Loss: 0.569975,  Batch Accuracy: 84.38   [11520/54000]\n",
            "Batch Loss: 0.788384,  Batch Accuracy: 71.88   [12800/54000]\n",
            "Batch Loss: 0.652072,  Batch Accuracy: 79.69   [14080/54000]\n",
            "Batch Loss: 0.681431,  Batch Accuracy: 76.56   [15360/54000]\n",
            "Batch Loss: 0.679853,  Batch Accuracy: 78.12   [16640/54000]\n",
            "Batch Loss: 0.820421,  Batch Accuracy: 75.00   [17920/54000]\n",
            "Batch Loss: 0.563690,  Batch Accuracy: 81.25   [19200/54000]\n",
            "Batch Loss: 0.626281,  Batch Accuracy: 80.47   [20480/54000]\n",
            "Batch Loss: 0.768733,  Batch Accuracy: 75.78   [21760/54000]\n",
            "Batch Loss: 0.735489,  Batch Accuracy: 78.12   [23040/54000]\n",
            "Batch Loss: 0.784473,  Batch Accuracy: 75.78   [24320/54000]\n",
            "Batch Loss: 0.713691,  Batch Accuracy: 77.34   [25600/54000]\n",
            "Batch Loss: 0.735417,  Batch Accuracy: 72.66   [26880/54000]\n",
            "Batch Loss: 0.567108,  Batch Accuracy: 84.38   [28160/54000]\n",
            "Batch Loss: 0.670415,  Batch Accuracy: 82.03   [29440/54000]\n",
            "Batch Loss: 0.600217,  Batch Accuracy: 85.94   [30720/54000]\n",
            "Batch Loss: 0.825382,  Batch Accuracy: 75.78   [32000/54000]\n",
            "Batch Loss: 0.908509,  Batch Accuracy: 77.34   [33280/54000]\n",
            "Batch Loss: 0.663418,  Batch Accuracy: 84.38   [34560/54000]\n",
            "Batch Loss: 0.612437,  Batch Accuracy: 77.34   [35840/54000]\n",
            "Batch Loss: 0.711616,  Batch Accuracy: 78.91   [37120/54000]\n",
            "Batch Loss: 0.735377,  Batch Accuracy: 80.47   [38400/54000]\n",
            "Batch Loss: 0.645564,  Batch Accuracy: 82.03   [39680/54000]\n",
            "Batch Loss: 0.614061,  Batch Accuracy: 84.38   [40960/54000]\n",
            "Batch Loss: 0.705249,  Batch Accuracy: 76.56   [42240/54000]\n",
            "Batch Loss: 0.686067,  Batch Accuracy: 78.91   [43520/54000]\n",
            "Batch Loss: 0.604479,  Batch Accuracy: 79.69   [44800/54000]\n",
            "Batch Loss: 0.785252,  Batch Accuracy: 76.56   [46080/54000]\n",
            "Batch Loss: 0.553132,  Batch Accuracy: 86.72   [47360/54000]\n",
            "Batch Loss: 0.679634,  Batch Accuracy: 81.25   [48640/54000]\n",
            "Batch Loss: 0.589363,  Batch Accuracy: 85.94   [49920/54000]\n",
            "Batch Loss: 0.535650,  Batch Accuracy: 85.16   [51200/54000]\n",
            "Batch Loss: 0.676336,  Batch Accuracy: 81.25   [52480/54000]\n",
            "Batch Loss: 0.732677,  Batch Accuracy: 78.91   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 78.7%, Loss: 0.684570\n",
            "Validation performance: \n",
            " Accuracy: 78.4%, Loss: 0.683760\n",
            "Test performance: \n",
            " Accuracy: 79.6%, Loss: 0.652208 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Batch Loss: 0.672875,  Batch Accuracy: 78.12   [ 1280/54000]\n",
            "Batch Loss: 0.794938,  Batch Accuracy: 76.56   [ 2560/54000]\n",
            "Batch Loss: 0.579698,  Batch Accuracy: 83.59   [ 3840/54000]\n",
            "Batch Loss: 0.494916,  Batch Accuracy: 84.38   [ 5120/54000]\n",
            "Batch Loss: 0.693855,  Batch Accuracy: 79.69   [ 6400/54000]\n",
            "Batch Loss: 0.625284,  Batch Accuracy: 80.47   [ 7680/54000]\n",
            "Batch Loss: 0.679991,  Batch Accuracy: 78.91   [ 8960/54000]\n",
            "Batch Loss: 0.665757,  Batch Accuracy: 83.59   [10240/54000]\n",
            "Batch Loss: 0.716712,  Batch Accuracy: 77.34   [11520/54000]\n",
            "Batch Loss: 0.597469,  Batch Accuracy: 83.59   [12800/54000]\n",
            "Batch Loss: 0.689735,  Batch Accuracy: 78.12   [14080/54000]\n",
            "Batch Loss: 0.674238,  Batch Accuracy: 77.34   [15360/54000]\n",
            "Batch Loss: 0.642117,  Batch Accuracy: 82.03   [16640/54000]\n",
            "Batch Loss: 0.627208,  Batch Accuracy: 78.91   [17920/54000]\n",
            "Batch Loss: 0.697424,  Batch Accuracy: 80.47   [19200/54000]\n",
            "Batch Loss: 0.815942,  Batch Accuracy: 75.00   [20480/54000]\n",
            "Batch Loss: 0.552008,  Batch Accuracy: 83.59   [21760/54000]\n",
            "Batch Loss: 0.661509,  Batch Accuracy: 80.47   [23040/54000]\n",
            "Batch Loss: 0.535922,  Batch Accuracy: 79.69   [24320/54000]\n",
            "Batch Loss: 0.744517,  Batch Accuracy: 79.69   [25600/54000]\n",
            "Batch Loss: 0.608717,  Batch Accuracy: 78.91   [26880/54000]\n",
            "Batch Loss: 0.700119,  Batch Accuracy: 81.25   [28160/54000]\n",
            "Batch Loss: 0.673097,  Batch Accuracy: 78.12   [29440/54000]\n",
            "Batch Loss: 0.559135,  Batch Accuracy: 82.03   [30720/54000]\n",
            "Batch Loss: 0.545471,  Batch Accuracy: 83.59   [32000/54000]\n",
            "Batch Loss: 0.555475,  Batch Accuracy: 83.59   [33280/54000]\n",
            "Batch Loss: 0.698116,  Batch Accuracy: 79.69   [34560/54000]\n",
            "Batch Loss: 0.719478,  Batch Accuracy: 77.34   [35840/54000]\n",
            "Batch Loss: 0.609341,  Batch Accuracy: 79.69   [37120/54000]\n",
            "Batch Loss: 0.586248,  Batch Accuracy: 82.03   [38400/54000]\n",
            "Batch Loss: 0.565654,  Batch Accuracy: 83.59   [39680/54000]\n",
            "Batch Loss: 0.707001,  Batch Accuracy: 77.34   [40960/54000]\n",
            "Batch Loss: 0.516534,  Batch Accuracy: 82.03   [42240/54000]\n",
            "Batch Loss: 0.721983,  Batch Accuracy: 77.34   [43520/54000]\n",
            "Batch Loss: 0.697256,  Batch Accuracy: 76.56   [44800/54000]\n",
            "Batch Loss: 0.814377,  Batch Accuracy: 75.00   [46080/54000]\n",
            "Batch Loss: 0.726188,  Batch Accuracy: 80.47   [47360/54000]\n",
            "Batch Loss: 0.512985,  Batch Accuracy: 85.16   [48640/54000]\n",
            "Batch Loss: 0.832090,  Batch Accuracy: 73.44   [49920/54000]\n",
            "Batch Loss: 0.572114,  Batch Accuracy: 84.38   [51200/54000]\n",
            "Batch Loss: 0.612796,  Batch Accuracy: 78.91   [52480/54000]\n",
            "Batch Loss: 0.621926,  Batch Accuracy: 81.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 80.1%, Loss: 0.644783\n",
            "Validation performance: \n",
            " Accuracy: 80.1%, Loss: 0.640792\n",
            "Test performance: \n",
            " Accuracy: 81.0%, Loss: 0.615968 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Batch Loss: 0.597739,  Batch Accuracy: 82.81   [ 1280/54000]\n",
            "Batch Loss: 0.676866,  Batch Accuracy: 74.22   [ 2560/54000]\n",
            "Batch Loss: 0.575604,  Batch Accuracy: 81.25   [ 3840/54000]\n",
            "Batch Loss: 0.639397,  Batch Accuracy: 80.47   [ 5120/54000]\n",
            "Batch Loss: 0.586164,  Batch Accuracy: 82.81   [ 6400/54000]\n",
            "Batch Loss: 0.591027,  Batch Accuracy: 77.34   [ 7680/54000]\n",
            "Batch Loss: 0.678306,  Batch Accuracy: 75.00   [ 8960/54000]\n",
            "Batch Loss: 0.587521,  Batch Accuracy: 79.69   [10240/54000]\n",
            "Batch Loss: 0.694155,  Batch Accuracy: 78.12   [11520/54000]\n",
            "Batch Loss: 0.585075,  Batch Accuracy: 85.16   [12800/54000]\n",
            "Batch Loss: 0.583745,  Batch Accuracy: 79.69   [14080/54000]\n",
            "Batch Loss: 0.631858,  Batch Accuracy: 73.44   [15360/54000]\n",
            "Batch Loss: 0.707063,  Batch Accuracy: 76.56   [16640/54000]\n",
            "Batch Loss: 0.589048,  Batch Accuracy: 79.69   [17920/54000]\n",
            "Batch Loss: 0.676835,  Batch Accuracy: 78.91   [19200/54000]\n",
            "Batch Loss: 0.493686,  Batch Accuracy: 88.28   [20480/54000]\n",
            "Batch Loss: 0.572378,  Batch Accuracy: 82.03   [21760/54000]\n",
            "Batch Loss: 0.650221,  Batch Accuracy: 76.56   [23040/54000]\n",
            "Batch Loss: 0.672945,  Batch Accuracy: 75.78   [24320/54000]\n",
            "Batch Loss: 0.555907,  Batch Accuracy: 80.47   [25600/54000]\n",
            "Batch Loss: 0.642581,  Batch Accuracy: 79.69   [26880/54000]\n",
            "Batch Loss: 0.503540,  Batch Accuracy: 85.94   [28160/54000]\n",
            "Batch Loss: 0.499619,  Batch Accuracy: 85.94   [29440/54000]\n",
            "Batch Loss: 0.644017,  Batch Accuracy: 82.81   [30720/54000]\n",
            "Batch Loss: 0.686572,  Batch Accuracy: 76.56   [32000/54000]\n",
            "Batch Loss: 0.906295,  Batch Accuracy: 76.56   [33280/54000]\n",
            "Batch Loss: 0.718821,  Batch Accuracy: 80.47   [34560/54000]\n",
            "Batch Loss: 0.617680,  Batch Accuracy: 80.47   [35840/54000]\n",
            "Batch Loss: 0.606696,  Batch Accuracy: 78.91   [37120/54000]\n",
            "Batch Loss: 0.637204,  Batch Accuracy: 76.56   [38400/54000]\n",
            "Batch Loss: 0.731735,  Batch Accuracy: 78.91   [39680/54000]\n",
            "Batch Loss: 0.515838,  Batch Accuracy: 82.03   [40960/54000]\n",
            "Batch Loss: 0.601567,  Batch Accuracy: 76.56   [42240/54000]\n",
            "Batch Loss: 0.573222,  Batch Accuracy: 82.03   [43520/54000]\n",
            "Batch Loss: 0.587085,  Batch Accuracy: 82.81   [44800/54000]\n",
            "Batch Loss: 0.505009,  Batch Accuracy: 83.59   [46080/54000]\n",
            "Batch Loss: 0.711226,  Batch Accuracy: 75.00   [47360/54000]\n",
            "Batch Loss: 0.428586,  Batch Accuracy: 86.72   [48640/54000]\n",
            "Batch Loss: 0.605917,  Batch Accuracy: 79.69   [49920/54000]\n",
            "Batch Loss: 0.636744,  Batch Accuracy: 81.25   [51200/54000]\n",
            "Batch Loss: 0.438562,  Batch Accuracy: 85.94   [52480/54000]\n",
            "Batch Loss: 0.545082,  Batch Accuracy: 84.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 81.2%, Loss: 0.611921\n",
            "Validation performance: \n",
            " Accuracy: 81.2%, Loss: 0.611545\n",
            "Test performance: \n",
            " Accuracy: 82.3%, Loss: 0.585475 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Batch Loss: 0.598027,  Batch Accuracy: 82.03   [ 1280/54000]\n",
            "Batch Loss: 0.721984,  Batch Accuracy: 77.34   [ 2560/54000]\n",
            "Batch Loss: 0.585002,  Batch Accuracy: 80.47   [ 3840/54000]\n",
            "Batch Loss: 0.480210,  Batch Accuracy: 89.84   [ 5120/54000]\n",
            "Batch Loss: 0.519329,  Batch Accuracy: 83.59   [ 6400/54000]\n",
            "Batch Loss: 0.587484,  Batch Accuracy: 83.59   [ 7680/54000]\n",
            "Batch Loss: 0.599037,  Batch Accuracy: 83.59   [ 8960/54000]\n",
            "Batch Loss: 0.592017,  Batch Accuracy: 81.25   [10240/54000]\n",
            "Batch Loss: 0.794026,  Batch Accuracy: 76.56   [11520/54000]\n",
            "Batch Loss: 0.673242,  Batch Accuracy: 81.25   [12800/54000]\n",
            "Batch Loss: 0.697625,  Batch Accuracy: 82.81   [14080/54000]\n",
            "Batch Loss: 0.591863,  Batch Accuracy: 81.25   [15360/54000]\n",
            "Batch Loss: 0.565330,  Batch Accuracy: 81.25   [16640/54000]\n",
            "Batch Loss: 0.534381,  Batch Accuracy: 83.59   [17920/54000]\n",
            "Batch Loss: 0.525681,  Batch Accuracy: 82.03   [19200/54000]\n",
            "Batch Loss: 0.434629,  Batch Accuracy: 86.72   [20480/54000]\n",
            "Batch Loss: 0.528932,  Batch Accuracy: 81.25   [21760/54000]\n",
            "Batch Loss: 0.721578,  Batch Accuracy: 80.47   [23040/54000]\n",
            "Batch Loss: 0.530681,  Batch Accuracy: 85.94   [24320/54000]\n",
            "Batch Loss: 0.573147,  Batch Accuracy: 82.03   [25600/54000]\n",
            "Batch Loss: 0.570262,  Batch Accuracy: 82.81   [26880/54000]\n",
            "Batch Loss: 0.753316,  Batch Accuracy: 83.59   [28160/54000]\n",
            "Batch Loss: 0.692784,  Batch Accuracy: 81.25   [29440/54000]\n",
            "Batch Loss: 0.491236,  Batch Accuracy: 83.59   [30720/54000]\n",
            "Batch Loss: 0.507831,  Batch Accuracy: 85.16   [32000/54000]\n",
            "Batch Loss: 0.660075,  Batch Accuracy: 77.34   [33280/54000]\n",
            "Batch Loss: 0.610310,  Batch Accuracy: 85.16   [34560/54000]\n",
            "Batch Loss: 0.612084,  Batch Accuracy: 77.34   [35840/54000]\n",
            "Batch Loss: 0.632937,  Batch Accuracy: 78.12   [37120/54000]\n",
            "Batch Loss: 0.582487,  Batch Accuracy: 79.69   [38400/54000]\n",
            "Batch Loss: 0.455235,  Batch Accuracy: 85.16   [39680/54000]\n",
            "Batch Loss: 0.526945,  Batch Accuracy: 82.81   [40960/54000]\n",
            "Batch Loss: 0.536476,  Batch Accuracy: 82.03   [42240/54000]\n",
            "Batch Loss: 0.612672,  Batch Accuracy: 84.38   [43520/54000]\n",
            "Batch Loss: 0.561558,  Batch Accuracy: 79.69   [44800/54000]\n",
            "Batch Loss: 0.503066,  Batch Accuracy: 84.38   [46080/54000]\n",
            "Batch Loss: 0.556545,  Batch Accuracy: 78.91   [47360/54000]\n",
            "Batch Loss: 0.646291,  Batch Accuracy: 78.91   [48640/54000]\n",
            "Batch Loss: 0.566725,  Batch Accuracy: 82.03   [49920/54000]\n",
            "Batch Loss: 0.501825,  Batch Accuracy: 86.72   [51200/54000]\n",
            "Batch Loss: 0.507972,  Batch Accuracy: 82.81   [52480/54000]\n",
            "Batch Loss: 0.633432,  Batch Accuracy: 82.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 82.2%, Loss: 0.584149\n",
            "Validation performance: \n",
            " Accuracy: 82.0%, Loss: 0.589216\n",
            "Test performance: \n",
            " Accuracy: 83.3%, Loss: 0.559439 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Batch Loss: 0.713126,  Batch Accuracy: 80.47   [ 1280/54000]\n",
            "Batch Loss: 0.624128,  Batch Accuracy: 78.91   [ 2560/54000]\n",
            "Batch Loss: 0.719837,  Batch Accuracy: 82.03   [ 3840/54000]\n",
            "Batch Loss: 0.536531,  Batch Accuracy: 82.81   [ 5120/54000]\n",
            "Batch Loss: 0.564819,  Batch Accuracy: 79.69   [ 6400/54000]\n",
            "Batch Loss: 0.533148,  Batch Accuracy: 86.72   [ 7680/54000]\n",
            "Batch Loss: 0.673787,  Batch Accuracy: 82.03   [ 8960/54000]\n",
            "Batch Loss: 0.602757,  Batch Accuracy: 78.12   [10240/54000]\n",
            "Batch Loss: 0.629965,  Batch Accuracy: 79.69   [11520/54000]\n",
            "Batch Loss: 0.557916,  Batch Accuracy: 84.38   [12800/54000]\n",
            "Batch Loss: 0.510298,  Batch Accuracy: 88.28   [14080/54000]\n",
            "Batch Loss: 0.499854,  Batch Accuracy: 84.38   [15360/54000]\n",
            "Batch Loss: 0.535783,  Batch Accuracy: 82.81   [16640/54000]\n",
            "Batch Loss: 0.602854,  Batch Accuracy: 78.91   [17920/54000]\n",
            "Batch Loss: 0.594956,  Batch Accuracy: 84.38   [19200/54000]\n",
            "Batch Loss: 0.426834,  Batch Accuracy: 87.50   [20480/54000]\n",
            "Batch Loss: 0.433671,  Batch Accuracy: 84.38   [21760/54000]\n",
            "Batch Loss: 0.506680,  Batch Accuracy: 85.16   [23040/54000]\n",
            "Batch Loss: 0.612313,  Batch Accuracy: 81.25   [24320/54000]\n",
            "Batch Loss: 0.670785,  Batch Accuracy: 78.12   [25600/54000]\n",
            "Batch Loss: 0.475557,  Batch Accuracy: 85.94   [26880/54000]\n",
            "Batch Loss: 0.610614,  Batch Accuracy: 83.59   [28160/54000]\n",
            "Batch Loss: 0.439511,  Batch Accuracy: 88.28   [29440/54000]\n",
            "Batch Loss: 0.587545,  Batch Accuracy: 82.81   [30720/54000]\n",
            "Batch Loss: 0.881907,  Batch Accuracy: 78.12   [32000/54000]\n",
            "Batch Loss: 0.626677,  Batch Accuracy: 86.72   [33280/54000]\n",
            "Batch Loss: 0.454664,  Batch Accuracy: 82.81   [34560/54000]\n",
            "Batch Loss: 0.498134,  Batch Accuracy: 86.72   [35840/54000]\n",
            "Batch Loss: 0.575642,  Batch Accuracy: 83.59   [37120/54000]\n",
            "Batch Loss: 0.440566,  Batch Accuracy: 88.28   [38400/54000]\n",
            "Batch Loss: 0.613134,  Batch Accuracy: 84.38   [39680/54000]\n",
            "Batch Loss: 0.609683,  Batch Accuracy: 81.25   [40960/54000]\n",
            "Batch Loss: 0.601486,  Batch Accuracy: 84.38   [42240/54000]\n",
            "Batch Loss: 0.475657,  Batch Accuracy: 88.28   [43520/54000]\n",
            "Batch Loss: 0.593317,  Batch Accuracy: 84.38   [44800/54000]\n",
            "Batch Loss: 0.493336,  Batch Accuracy: 88.28   [46080/54000]\n",
            "Batch Loss: 0.608437,  Batch Accuracy: 79.69   [47360/54000]\n",
            "Batch Loss: 0.492518,  Batch Accuracy: 84.38   [48640/54000]\n",
            "Batch Loss: 0.622180,  Batch Accuracy: 82.03   [49920/54000]\n",
            "Batch Loss: 0.506342,  Batch Accuracy: 85.16   [51200/54000]\n",
            "Batch Loss: 0.444437,  Batch Accuracy: 89.06   [52480/54000]\n",
            "Batch Loss: 0.440934,  Batch Accuracy: 84.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 83.1%, Loss: 0.560224\n",
            "Validation performance: \n",
            " Accuracy: 82.6%, Loss: 0.569088\n",
            "Test performance: \n",
            " Accuracy: 84.1%, Loss: 0.535592 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Batch Loss: 0.494703,  Batch Accuracy: 81.25   [ 1280/54000]\n",
            "Batch Loss: 0.413940,  Batch Accuracy: 86.72   [ 2560/54000]\n",
            "Batch Loss: 0.542287,  Batch Accuracy: 83.59   [ 3840/54000]\n",
            "Batch Loss: 0.540268,  Batch Accuracy: 85.94   [ 5120/54000]\n",
            "Batch Loss: 0.563842,  Batch Accuracy: 84.38   [ 6400/54000]\n",
            "Batch Loss: 0.553842,  Batch Accuracy: 86.72   [ 7680/54000]\n",
            "Batch Loss: 0.509669,  Batch Accuracy: 85.16   [ 8960/54000]\n",
            "Batch Loss: 0.504569,  Batch Accuracy: 82.81   [10240/54000]\n",
            "Batch Loss: 0.512457,  Batch Accuracy: 86.72   [11520/54000]\n",
            "Batch Loss: 0.497525,  Batch Accuracy: 86.72   [12800/54000]\n",
            "Batch Loss: 0.414359,  Batch Accuracy: 84.38   [14080/54000]\n",
            "Batch Loss: 0.454076,  Batch Accuracy: 89.06   [15360/54000]\n",
            "Batch Loss: 0.541363,  Batch Accuracy: 82.81   [16640/54000]\n",
            "Batch Loss: 0.519848,  Batch Accuracy: 85.94   [17920/54000]\n",
            "Batch Loss: 0.475948,  Batch Accuracy: 85.16   [19200/54000]\n",
            "Batch Loss: 0.531917,  Batch Accuracy: 81.25   [20480/54000]\n",
            "Batch Loss: 0.586130,  Batch Accuracy: 81.25   [21760/54000]\n",
            "Batch Loss: 0.535953,  Batch Accuracy: 85.94   [23040/54000]\n",
            "Batch Loss: 0.560601,  Batch Accuracy: 85.16   [24320/54000]\n",
            "Batch Loss: 0.528893,  Batch Accuracy: 83.59   [25600/54000]\n",
            "Batch Loss: 0.690253,  Batch Accuracy: 79.69   [26880/54000]\n",
            "Batch Loss: 0.653594,  Batch Accuracy: 82.81   [28160/54000]\n",
            "Batch Loss: 0.547639,  Batch Accuracy: 79.69   [29440/54000]\n",
            "Batch Loss: 0.561877,  Batch Accuracy: 84.38   [30720/54000]\n",
            "Batch Loss: 0.532954,  Batch Accuracy: 85.94   [32000/54000]\n",
            "Batch Loss: 0.482921,  Batch Accuracy: 85.94   [33280/54000]\n",
            "Batch Loss: 0.534145,  Batch Accuracy: 85.16   [34560/54000]\n",
            "Batch Loss: 0.495417,  Batch Accuracy: 84.38   [35840/54000]\n",
            "Batch Loss: 0.425712,  Batch Accuracy: 85.94   [37120/54000]\n",
            "Batch Loss: 0.523776,  Batch Accuracy: 85.16   [38400/54000]\n",
            "Batch Loss: 0.691327,  Batch Accuracy: 78.12   [39680/54000]\n",
            "Batch Loss: 0.489217,  Batch Accuracy: 84.38   [40960/54000]\n",
            "Batch Loss: 0.437902,  Batch Accuracy: 83.59   [42240/54000]\n",
            "Batch Loss: 0.526076,  Batch Accuracy: 88.28   [43520/54000]\n",
            "Batch Loss: 0.637134,  Batch Accuracy: 79.69   [44800/54000]\n",
            "Batch Loss: 0.544833,  Batch Accuracy: 84.38   [46080/54000]\n",
            "Batch Loss: 0.338548,  Batch Accuracy: 92.19   [47360/54000]\n",
            "Batch Loss: 0.597545,  Batch Accuracy: 82.03   [48640/54000]\n",
            "Batch Loss: 0.424616,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.655137,  Batch Accuracy: 79.69   [51200/54000]\n",
            "Batch Loss: 0.497499,  Batch Accuracy: 82.03   [52480/54000]\n",
            "Batch Loss: 0.627913,  Batch Accuracy: 81.25   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 83.8%, Loss: 0.539614\n",
            "Validation performance: \n",
            " Accuracy: 83.7%, Loss: 0.545958\n",
            "Test performance: \n",
            " Accuracy: 84.8%, Loss: 0.516427 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Batch Loss: 0.511992,  Batch Accuracy: 86.72   [ 1280/54000]\n",
            "Batch Loss: 0.461149,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.642440,  Batch Accuracy: 79.69   [ 3840/54000]\n",
            "Batch Loss: 0.523111,  Batch Accuracy: 85.94   [ 5120/54000]\n",
            "Batch Loss: 0.520695,  Batch Accuracy: 82.03   [ 6400/54000]\n",
            "Batch Loss: 0.685585,  Batch Accuracy: 84.38   [ 7680/54000]\n",
            "Batch Loss: 0.404237,  Batch Accuracy: 91.41   [ 8960/54000]\n",
            "Batch Loss: 0.630894,  Batch Accuracy: 79.69   [10240/54000]\n",
            "Batch Loss: 0.678180,  Batch Accuracy: 82.81   [11520/54000]\n",
            "Batch Loss: 0.512211,  Batch Accuracy: 82.03   [12800/54000]\n",
            "Batch Loss: 0.470281,  Batch Accuracy: 90.62   [14080/54000]\n",
            "Batch Loss: 0.404035,  Batch Accuracy: 88.28   [15360/54000]\n",
            "Batch Loss: 0.423095,  Batch Accuracy: 86.72   [16640/54000]\n",
            "Batch Loss: 0.445216,  Batch Accuracy: 84.38   [17920/54000]\n",
            "Batch Loss: 0.494087,  Batch Accuracy: 83.59   [19200/54000]\n",
            "Batch Loss: 0.557395,  Batch Accuracy: 85.94   [20480/54000]\n",
            "Batch Loss: 0.492984,  Batch Accuracy: 81.25   [21760/54000]\n",
            "Batch Loss: 0.468906,  Batch Accuracy: 83.59   [23040/54000]\n",
            "Batch Loss: 0.624903,  Batch Accuracy: 83.59   [24320/54000]\n",
            "Batch Loss: 0.552788,  Batch Accuracy: 83.59   [25600/54000]\n",
            "Batch Loss: 0.600400,  Batch Accuracy: 85.16   [26880/54000]\n",
            "Batch Loss: 0.583691,  Batch Accuracy: 80.47   [28160/54000]\n",
            "Batch Loss: 0.611367,  Batch Accuracy: 82.81   [29440/54000]\n",
            "Batch Loss: 0.465800,  Batch Accuracy: 85.94   [30720/54000]\n",
            "Batch Loss: 0.551605,  Batch Accuracy: 83.59   [32000/54000]\n",
            "Batch Loss: 0.506014,  Batch Accuracy: 86.72   [33280/54000]\n",
            "Batch Loss: 0.600102,  Batch Accuracy: 85.16   [34560/54000]\n",
            "Batch Loss: 0.580750,  Batch Accuracy: 81.25   [35840/54000]\n",
            "Batch Loss: 0.476888,  Batch Accuracy: 85.94   [37120/54000]\n",
            "Batch Loss: 0.601070,  Batch Accuracy: 81.25   [38400/54000]\n",
            "Batch Loss: 0.599463,  Batch Accuracy: 82.81   [39680/54000]\n",
            "Batch Loss: 0.619701,  Batch Accuracy: 82.03   [40960/54000]\n",
            "Batch Loss: 0.507401,  Batch Accuracy: 82.81   [42240/54000]\n",
            "Batch Loss: 0.563521,  Batch Accuracy: 85.16   [43520/54000]\n",
            "Batch Loss: 0.436718,  Batch Accuracy: 82.03   [44800/54000]\n",
            "Batch Loss: 0.469845,  Batch Accuracy: 84.38   [46080/54000]\n",
            "Batch Loss: 0.702305,  Batch Accuracy: 81.25   [47360/54000]\n",
            "Batch Loss: 0.408885,  Batch Accuracy: 85.94   [48640/54000]\n",
            "Batch Loss: 0.582544,  Batch Accuracy: 79.69   [49920/54000]\n",
            "Batch Loss: 0.582125,  Batch Accuracy: 84.38   [51200/54000]\n",
            "Batch Loss: 0.631241,  Batch Accuracy: 85.94   [52480/54000]\n",
            "Batch Loss: 0.505098,  Batch Accuracy: 85.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 84.6%, Loss: 0.519875\n",
            "Validation performance: \n",
            " Accuracy: 84.2%, Loss: 0.532267\n",
            "Test performance: \n",
            " Accuracy: 85.6%, Loss: 0.496430 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Batch Loss: 0.428794,  Batch Accuracy: 88.28   [ 1280/54000]\n",
            "Batch Loss: 0.470666,  Batch Accuracy: 89.06   [ 2560/54000]\n",
            "Batch Loss: 0.574682,  Batch Accuracy: 82.03   [ 3840/54000]\n",
            "Batch Loss: 0.368433,  Batch Accuracy: 89.84   [ 5120/54000]\n",
            "Batch Loss: 0.508858,  Batch Accuracy: 87.50   [ 6400/54000]\n",
            "Batch Loss: 0.439037,  Batch Accuracy: 85.94   [ 7680/54000]\n",
            "Batch Loss: 0.438762,  Batch Accuracy: 85.16   [ 8960/54000]\n",
            "Batch Loss: 0.432635,  Batch Accuracy: 83.59   [10240/54000]\n",
            "Batch Loss: 0.509887,  Batch Accuracy: 80.47   [11520/54000]\n",
            "Batch Loss: 0.417713,  Batch Accuracy: 88.28   [12800/54000]\n",
            "Batch Loss: 0.477705,  Batch Accuracy: 84.38   [14080/54000]\n",
            "Batch Loss: 0.612977,  Batch Accuracy: 83.59   [15360/54000]\n",
            "Batch Loss: 0.514507,  Batch Accuracy: 86.72   [16640/54000]\n",
            "Batch Loss: 0.447364,  Batch Accuracy: 84.38   [17920/54000]\n",
            "Batch Loss: 0.495045,  Batch Accuracy: 85.16   [19200/54000]\n",
            "Batch Loss: 0.457680,  Batch Accuracy: 79.69   [20480/54000]\n",
            "Batch Loss: 0.410840,  Batch Accuracy: 85.94   [21760/54000]\n",
            "Batch Loss: 0.539017,  Batch Accuracy: 82.81   [23040/54000]\n",
            "Batch Loss: 0.577155,  Batch Accuracy: 85.16   [24320/54000]\n",
            "Batch Loss: 0.710441,  Batch Accuracy: 75.78   [25600/54000]\n",
            "Batch Loss: 0.560301,  Batch Accuracy: 85.94   [26880/54000]\n",
            "Batch Loss: 0.657310,  Batch Accuracy: 84.38   [28160/54000]\n",
            "Batch Loss: 0.459343,  Batch Accuracy: 87.50   [29440/54000]\n",
            "Batch Loss: 0.487568,  Batch Accuracy: 82.81   [30720/54000]\n",
            "Batch Loss: 0.491975,  Batch Accuracy: 83.59   [32000/54000]\n",
            "Batch Loss: 0.552932,  Batch Accuracy: 84.38   [33280/54000]\n",
            "Batch Loss: 0.466209,  Batch Accuracy: 84.38   [34560/54000]\n",
            "Batch Loss: 0.461581,  Batch Accuracy: 86.72   [35840/54000]\n",
            "Batch Loss: 0.499421,  Batch Accuracy: 86.72   [37120/54000]\n",
            "Batch Loss: 0.481315,  Batch Accuracy: 85.16   [38400/54000]\n",
            "Batch Loss: 0.438780,  Batch Accuracy: 88.28   [39680/54000]\n",
            "Batch Loss: 0.569469,  Batch Accuracy: 82.81   [40960/54000]\n",
            "Batch Loss: 0.575167,  Batch Accuracy: 82.03   [42240/54000]\n",
            "Batch Loss: 0.475762,  Batch Accuracy: 87.50   [43520/54000]\n",
            "Batch Loss: 0.351135,  Batch Accuracy: 89.84   [44800/54000]\n",
            "Batch Loss: 0.434604,  Batch Accuracy: 85.16   [46080/54000]\n",
            "Batch Loss: 0.454630,  Batch Accuracy: 86.72   [47360/54000]\n",
            "Batch Loss: 0.490980,  Batch Accuracy: 85.16   [48640/54000]\n",
            "Batch Loss: 0.389837,  Batch Accuracy: 92.97   [49920/54000]\n",
            "Batch Loss: 0.629726,  Batch Accuracy: 82.03   [51200/54000]\n",
            "Batch Loss: 0.597198,  Batch Accuracy: 82.81   [52480/54000]\n",
            "Batch Loss: 0.520441,  Batch Accuracy: 83.59   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 85.1%, Loss: 0.502309\n",
            "Validation performance: \n",
            " Accuracy: 84.8%, Loss: 0.513229\n",
            "Test performance: \n",
            " Accuracy: 86.2%, Loss: 0.479638 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Batch Loss: 0.490989,  Batch Accuracy: 90.62   [ 1280/54000]\n",
            "Batch Loss: 0.651917,  Batch Accuracy: 78.91   [ 2560/54000]\n",
            "Batch Loss: 0.456847,  Batch Accuracy: 85.94   [ 3840/54000]\n",
            "Batch Loss: 0.456568,  Batch Accuracy: 86.72   [ 5120/54000]\n",
            "Batch Loss: 0.294225,  Batch Accuracy: 92.97   [ 6400/54000]\n",
            "Batch Loss: 0.487884,  Batch Accuracy: 87.50   [ 7680/54000]\n",
            "Batch Loss: 0.698618,  Batch Accuracy: 80.47   [ 8960/54000]\n",
            "Batch Loss: 0.455330,  Batch Accuracy: 87.50   [10240/54000]\n",
            "Batch Loss: 0.386743,  Batch Accuracy: 87.50   [11520/54000]\n",
            "Batch Loss: 0.468173,  Batch Accuracy: 85.94   [12800/54000]\n",
            "Batch Loss: 0.393067,  Batch Accuracy: 82.81   [14080/54000]\n",
            "Batch Loss: 0.357960,  Batch Accuracy: 89.06   [15360/54000]\n",
            "Batch Loss: 0.411974,  Batch Accuracy: 85.94   [16640/54000]\n",
            "Batch Loss: 0.461368,  Batch Accuracy: 83.59   [17920/54000]\n",
            "Batch Loss: 0.611349,  Batch Accuracy: 81.25   [19200/54000]\n",
            "Batch Loss: 0.387349,  Batch Accuracy: 90.62   [20480/54000]\n",
            "Batch Loss: 0.445485,  Batch Accuracy: 88.28   [21760/54000]\n",
            "Batch Loss: 0.394523,  Batch Accuracy: 89.84   [23040/54000]\n",
            "Batch Loss: 0.440487,  Batch Accuracy: 85.16   [24320/54000]\n",
            "Batch Loss: 0.447383,  Batch Accuracy: 86.72   [25600/54000]\n",
            "Batch Loss: 0.447033,  Batch Accuracy: 84.38   [26880/54000]\n",
            "Batch Loss: 0.536602,  Batch Accuracy: 82.03   [28160/54000]\n",
            "Batch Loss: 0.482379,  Batch Accuracy: 85.16   [29440/54000]\n",
            "Batch Loss: 0.430505,  Batch Accuracy: 89.06   [30720/54000]\n",
            "Batch Loss: 0.443400,  Batch Accuracy: 86.72   [32000/54000]\n",
            "Batch Loss: 0.465703,  Batch Accuracy: 85.16   [33280/54000]\n",
            "Batch Loss: 0.375535,  Batch Accuracy: 87.50   [34560/54000]\n",
            "Batch Loss: 0.486418,  Batch Accuracy: 82.81   [35840/54000]\n",
            "Batch Loss: 0.426283,  Batch Accuracy: 88.28   [37120/54000]\n",
            "Batch Loss: 0.538572,  Batch Accuracy: 85.94   [38400/54000]\n",
            "Batch Loss: 0.527230,  Batch Accuracy: 83.59   [39680/54000]\n",
            "Batch Loss: 0.515348,  Batch Accuracy: 84.38   [40960/54000]\n",
            "Batch Loss: 0.431040,  Batch Accuracy: 89.06   [42240/54000]\n",
            "Batch Loss: 0.574797,  Batch Accuracy: 85.16   [43520/54000]\n",
            "Batch Loss: 0.423238,  Batch Accuracy: 85.94   [44800/54000]\n",
            "Batch Loss: 0.467832,  Batch Accuracy: 85.94   [46080/54000]\n",
            "Batch Loss: 0.743999,  Batch Accuracy: 79.69   [47360/54000]\n",
            "Batch Loss: 0.403400,  Batch Accuracy: 86.72   [48640/54000]\n",
            "Batch Loss: 0.390419,  Batch Accuracy: 86.72   [49920/54000]\n",
            "Batch Loss: 0.535286,  Batch Accuracy: 85.94   [51200/54000]\n",
            "Batch Loss: 0.597816,  Batch Accuracy: 85.94   [52480/54000]\n",
            "Batch Loss: 0.458695,  Batch Accuracy: 89.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 85.7%, Loss: 0.485548\n",
            "Validation performance: \n",
            " Accuracy: 85.4%, Loss: 0.495715\n",
            "Test performance: \n",
            " Accuracy: 86.6%, Loss: 0.465749 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Batch Loss: 0.434899,  Batch Accuracy: 88.28   [ 1280/54000]\n",
            "Batch Loss: 0.368752,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.571501,  Batch Accuracy: 83.59   [ 3840/54000]\n",
            "Batch Loss: 0.479459,  Batch Accuracy: 83.59   [ 5120/54000]\n",
            "Batch Loss: 0.453354,  Batch Accuracy: 89.06   [ 6400/54000]\n",
            "Batch Loss: 0.499692,  Batch Accuracy: 87.50   [ 7680/54000]\n",
            "Batch Loss: 0.473122,  Batch Accuracy: 85.94   [ 8960/54000]\n",
            "Batch Loss: 0.425112,  Batch Accuracy: 87.50   [10240/54000]\n",
            "Batch Loss: 0.481386,  Batch Accuracy: 82.81   [11520/54000]\n",
            "Batch Loss: 0.466159,  Batch Accuracy: 84.38   [12800/54000]\n",
            "Batch Loss: 0.426672,  Batch Accuracy: 88.28   [14080/54000]\n",
            "Batch Loss: 0.633028,  Batch Accuracy: 80.47   [15360/54000]\n",
            "Batch Loss: 0.464378,  Batch Accuracy: 80.47   [16640/54000]\n",
            "Batch Loss: 0.478158,  Batch Accuracy: 85.16   [17920/54000]\n",
            "Batch Loss: 0.469465,  Batch Accuracy: 85.94   [19200/54000]\n",
            "Batch Loss: 0.572292,  Batch Accuracy: 85.16   [20480/54000]\n",
            "Batch Loss: 0.423957,  Batch Accuracy: 85.16   [21760/54000]\n",
            "Batch Loss: 0.438972,  Batch Accuracy: 85.94   [23040/54000]\n",
            "Batch Loss: 0.409296,  Batch Accuracy: 87.50   [24320/54000]\n",
            "Batch Loss: 0.408595,  Batch Accuracy: 88.28   [25600/54000]\n",
            "Batch Loss: 0.414434,  Batch Accuracy: 85.16   [26880/54000]\n",
            "Batch Loss: 0.386379,  Batch Accuracy: 85.94   [28160/54000]\n",
            "Batch Loss: 0.641047,  Batch Accuracy: 80.47   [29440/54000]\n",
            "Batch Loss: 0.438616,  Batch Accuracy: 90.62   [30720/54000]\n",
            "Batch Loss: 0.375979,  Batch Accuracy: 89.06   [32000/54000]\n",
            "Batch Loss: 0.382069,  Batch Accuracy: 89.84   [33280/54000]\n",
            "Batch Loss: 0.442993,  Batch Accuracy: 87.50   [34560/54000]\n",
            "Batch Loss: 0.423936,  Batch Accuracy: 88.28   [35840/54000]\n",
            "Batch Loss: 0.418122,  Batch Accuracy: 85.94   [37120/54000]\n",
            "Batch Loss: 0.391159,  Batch Accuracy: 86.72   [38400/54000]\n",
            "Batch Loss: 0.428370,  Batch Accuracy: 87.50   [39680/54000]\n",
            "Batch Loss: 0.426351,  Batch Accuracy: 84.38   [40960/54000]\n",
            "Batch Loss: 0.388757,  Batch Accuracy: 88.28   [42240/54000]\n",
            "Batch Loss: 0.492241,  Batch Accuracy: 85.94   [43520/54000]\n",
            "Batch Loss: 0.393781,  Batch Accuracy: 85.94   [44800/54000]\n",
            "Batch Loss: 0.399781,  Batch Accuracy: 86.72   [46080/54000]\n",
            "Batch Loss: 0.459604,  Batch Accuracy: 83.59   [47360/54000]\n",
            "Batch Loss: 0.347080,  Batch Accuracy: 91.41   [48640/54000]\n",
            "Batch Loss: 0.386006,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.445518,  Batch Accuracy: 89.06   [51200/54000]\n",
            "Batch Loss: 0.432946,  Batch Accuracy: 88.28   [52480/54000]\n",
            "Batch Loss: 0.398255,  Batch Accuracy: 84.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 86.1%, Loss: 0.470148\n",
            "Validation performance: \n",
            " Accuracy: 85.7%, Loss: 0.488924\n",
            "Test performance: \n",
            " Accuracy: 86.9%, Loss: 0.456977 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Batch Loss: 0.383718,  Batch Accuracy: 90.62   [ 1280/54000]\n",
            "Batch Loss: 0.538214,  Batch Accuracy: 83.59   [ 2560/54000]\n",
            "Batch Loss: 0.578776,  Batch Accuracy: 82.03   [ 3840/54000]\n",
            "Batch Loss: 0.483304,  Batch Accuracy: 84.38   [ 5120/54000]\n",
            "Batch Loss: 0.285395,  Batch Accuracy: 92.19   [ 6400/54000]\n",
            "Batch Loss: 0.707487,  Batch Accuracy: 87.50   [ 7680/54000]\n",
            "Batch Loss: 0.316281,  Batch Accuracy: 91.41   [ 8960/54000]\n",
            "Batch Loss: 0.516868,  Batch Accuracy: 85.16   [10240/54000]\n",
            "Batch Loss: 0.431474,  Batch Accuracy: 85.94   [11520/54000]\n",
            "Batch Loss: 0.465114,  Batch Accuracy: 85.94   [12800/54000]\n",
            "Batch Loss: 0.366826,  Batch Accuracy: 89.06   [14080/54000]\n",
            "Batch Loss: 0.393530,  Batch Accuracy: 90.62   [15360/54000]\n",
            "Batch Loss: 0.412359,  Batch Accuracy: 85.94   [16640/54000]\n",
            "Batch Loss: 0.585722,  Batch Accuracy: 82.03   [17920/54000]\n",
            "Batch Loss: 0.464081,  Batch Accuracy: 85.16   [19200/54000]\n",
            "Batch Loss: 0.364327,  Batch Accuracy: 89.84   [20480/54000]\n",
            "Batch Loss: 0.453844,  Batch Accuracy: 86.72   [21760/54000]\n",
            "Batch Loss: 0.588827,  Batch Accuracy: 82.03   [23040/54000]\n",
            "Batch Loss: 0.317940,  Batch Accuracy: 89.84   [24320/54000]\n",
            "Batch Loss: 0.543995,  Batch Accuracy: 85.94   [25600/54000]\n",
            "Batch Loss: 0.416926,  Batch Accuracy: 87.50   [26880/54000]\n",
            "Batch Loss: 0.369108,  Batch Accuracy: 92.97   [28160/54000]\n",
            "Batch Loss: 0.541701,  Batch Accuracy: 83.59   [29440/54000]\n",
            "Batch Loss: 0.435389,  Batch Accuracy: 88.28   [30720/54000]\n",
            "Batch Loss: 0.462068,  Batch Accuracy: 85.16   [32000/54000]\n",
            "Batch Loss: 0.548707,  Batch Accuracy: 87.50   [33280/54000]\n",
            "Batch Loss: 0.422477,  Batch Accuracy: 89.06   [34560/54000]\n",
            "Batch Loss: 0.442952,  Batch Accuracy: 86.72   [35840/54000]\n",
            "Batch Loss: 0.321099,  Batch Accuracy: 90.62   [37120/54000]\n",
            "Batch Loss: 0.287503,  Batch Accuracy: 91.41   [38400/54000]\n",
            "Batch Loss: 0.380800,  Batch Accuracy: 88.28   [39680/54000]\n",
            "Batch Loss: 0.414835,  Batch Accuracy: 85.16   [40960/54000]\n",
            "Batch Loss: 0.543546,  Batch Accuracy: 82.03   [42240/54000]\n",
            "Batch Loss: 0.460259,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.467203,  Batch Accuracy: 86.72   [44800/54000]\n",
            "Batch Loss: 0.311925,  Batch Accuracy: 85.94   [46080/54000]\n",
            "Batch Loss: 0.458630,  Batch Accuracy: 89.06   [47360/54000]\n",
            "Batch Loss: 0.413623,  Batch Accuracy: 90.62   [48640/54000]\n",
            "Batch Loss: 0.311888,  Batch Accuracy: 89.06   [49920/54000]\n",
            "Batch Loss: 0.469458,  Batch Accuracy: 84.38   [51200/54000]\n",
            "Batch Loss: 0.390028,  Batch Accuracy: 86.72   [52480/54000]\n",
            "Batch Loss: 0.541558,  Batch Accuracy: 86.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 86.7%, Loss: 0.455126\n",
            "Validation performance: \n",
            " Accuracy: 86.4%, Loss: 0.467390\n",
            "Test performance: \n",
            " Accuracy: 87.5%, Loss: 0.435314 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Batch Loss: 0.365949,  Batch Accuracy: 90.62   [ 1280/54000]\n",
            "Batch Loss: 0.335270,  Batch Accuracy: 89.06   [ 2560/54000]\n",
            "Batch Loss: 0.438760,  Batch Accuracy: 85.94   [ 3840/54000]\n",
            "Batch Loss: 0.378626,  Batch Accuracy: 90.62   [ 5120/54000]\n",
            "Batch Loss: 0.515128,  Batch Accuracy: 85.94   [ 6400/54000]\n",
            "Batch Loss: 0.429949,  Batch Accuracy: 89.06   [ 7680/54000]\n",
            "Batch Loss: 0.652634,  Batch Accuracy: 78.91   [ 8960/54000]\n",
            "Batch Loss: 0.387116,  Batch Accuracy: 86.72   [10240/54000]\n",
            "Batch Loss: 0.397057,  Batch Accuracy: 88.28   [11520/54000]\n",
            "Batch Loss: 0.303317,  Batch Accuracy: 90.62   [12800/54000]\n",
            "Batch Loss: 0.368395,  Batch Accuracy: 89.06   [14080/54000]\n",
            "Batch Loss: 0.483569,  Batch Accuracy: 88.28   [15360/54000]\n",
            "Batch Loss: 0.472616,  Batch Accuracy: 88.28   [16640/54000]\n",
            "Batch Loss: 0.606291,  Batch Accuracy: 82.03   [17920/54000]\n",
            "Batch Loss: 0.406969,  Batch Accuracy: 85.16   [19200/54000]\n",
            "Batch Loss: 0.324878,  Batch Accuracy: 89.06   [20480/54000]\n",
            "Batch Loss: 0.544118,  Batch Accuracy: 82.81   [21760/54000]\n",
            "Batch Loss: 0.375978,  Batch Accuracy: 89.84   [23040/54000]\n",
            "Batch Loss: 0.427019,  Batch Accuracy: 94.53   [24320/54000]\n",
            "Batch Loss: 0.391776,  Batch Accuracy: 89.84   [25600/54000]\n",
            "Batch Loss: 0.481125,  Batch Accuracy: 85.16   [26880/54000]\n",
            "Batch Loss: 0.561805,  Batch Accuracy: 82.03   [28160/54000]\n",
            "Batch Loss: 0.602766,  Batch Accuracy: 83.59   [29440/54000]\n",
            "Batch Loss: 0.564794,  Batch Accuracy: 85.94   [30720/54000]\n",
            "Batch Loss: 0.413954,  Batch Accuracy: 89.06   [32000/54000]\n",
            "Batch Loss: 0.417325,  Batch Accuracy: 89.84   [33280/54000]\n",
            "Batch Loss: 0.416530,  Batch Accuracy: 91.41   [34560/54000]\n",
            "Batch Loss: 0.521197,  Batch Accuracy: 85.16   [35840/54000]\n",
            "Batch Loss: 0.493687,  Batch Accuracy: 86.72   [37120/54000]\n",
            "Batch Loss: 0.484397,  Batch Accuracy: 83.59   [38400/54000]\n",
            "Batch Loss: 0.378963,  Batch Accuracy: 88.28   [39680/54000]\n",
            "Batch Loss: 0.521883,  Batch Accuracy: 87.50   [40960/54000]\n",
            "Batch Loss: 0.463186,  Batch Accuracy: 84.38   [42240/54000]\n",
            "Batch Loss: 0.582036,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.544158,  Batch Accuracy: 85.16   [44800/54000]\n",
            "Batch Loss: 0.389750,  Batch Accuracy: 87.50   [46080/54000]\n",
            "Batch Loss: 0.307745,  Batch Accuracy: 89.84   [47360/54000]\n",
            "Batch Loss: 0.508930,  Batch Accuracy: 85.94   [48640/54000]\n",
            "Batch Loss: 0.627979,  Batch Accuracy: 87.50   [49920/54000]\n",
            "Batch Loss: 0.407956,  Batch Accuracy: 86.72   [51200/54000]\n",
            "Batch Loss: 0.495113,  Batch Accuracy: 84.38   [52480/54000]\n",
            "Batch Loss: 0.479301,  Batch Accuracy: 82.81   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 87.2%, Loss: 0.440290\n",
            "Validation performance: \n",
            " Accuracy: 86.8%, Loss: 0.454917\n",
            "Test performance: \n",
            " Accuracy: 87.7%, Loss: 0.422809 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Batch Loss: 0.602686,  Batch Accuracy: 84.38   [ 1280/54000]\n",
            "Batch Loss: 0.527824,  Batch Accuracy: 87.50   [ 2560/54000]\n",
            "Batch Loss: 0.427868,  Batch Accuracy: 85.94   [ 3840/54000]\n",
            "Batch Loss: 0.404735,  Batch Accuracy: 88.28   [ 5120/54000]\n",
            "Batch Loss: 0.504543,  Batch Accuracy: 85.94   [ 6400/54000]\n",
            "Batch Loss: 0.278701,  Batch Accuracy: 92.97   [ 7680/54000]\n",
            "Batch Loss: 0.549914,  Batch Accuracy: 83.59   [ 8960/54000]\n",
            "Batch Loss: 0.505203,  Batch Accuracy: 84.38   [10240/54000]\n",
            "Batch Loss: 0.369902,  Batch Accuracy: 89.84   [11520/54000]\n",
            "Batch Loss: 0.474462,  Batch Accuracy: 84.38   [12800/54000]\n",
            "Batch Loss: 0.507055,  Batch Accuracy: 87.50   [14080/54000]\n",
            "Batch Loss: 0.292764,  Batch Accuracy: 92.19   [15360/54000]\n",
            "Batch Loss: 0.390275,  Batch Accuracy: 88.28   [16640/54000]\n",
            "Batch Loss: 0.344436,  Batch Accuracy: 87.50   [17920/54000]\n",
            "Batch Loss: 0.405552,  Batch Accuracy: 88.28   [19200/54000]\n",
            "Batch Loss: 0.432007,  Batch Accuracy: 90.62   [20480/54000]\n",
            "Batch Loss: 0.402622,  Batch Accuracy: 87.50   [21760/54000]\n",
            "Batch Loss: 0.407375,  Batch Accuracy: 85.16   [23040/54000]\n",
            "Batch Loss: 0.465895,  Batch Accuracy: 85.94   [24320/54000]\n",
            "Batch Loss: 0.487069,  Batch Accuracy: 85.94   [25600/54000]\n",
            "Batch Loss: 0.455219,  Batch Accuracy: 85.16   [26880/54000]\n",
            "Batch Loss: 0.551651,  Batch Accuracy: 83.59   [28160/54000]\n",
            "Batch Loss: 0.384928,  Batch Accuracy: 88.28   [29440/54000]\n",
            "Batch Loss: 0.455788,  Batch Accuracy: 86.72   [30720/54000]\n",
            "Batch Loss: 0.525504,  Batch Accuracy: 83.59   [32000/54000]\n",
            "Batch Loss: 0.527598,  Batch Accuracy: 82.03   [33280/54000]\n",
            "Batch Loss: 0.551394,  Batch Accuracy: 85.16   [34560/54000]\n",
            "Batch Loss: 0.342042,  Batch Accuracy: 89.84   [35840/54000]\n",
            "Batch Loss: 0.347997,  Batch Accuracy: 88.28   [37120/54000]\n",
            "Batch Loss: 0.335426,  Batch Accuracy: 90.62   [38400/54000]\n",
            "Batch Loss: 0.845562,  Batch Accuracy: 81.25   [39680/54000]\n",
            "Batch Loss: 0.299554,  Batch Accuracy: 90.62   [40960/54000]\n",
            "Batch Loss: 0.465682,  Batch Accuracy: 85.94   [42240/54000]\n",
            "Batch Loss: 0.493348,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.376758,  Batch Accuracy: 86.72   [44800/54000]\n",
            "Batch Loss: 0.481584,  Batch Accuracy: 90.62   [46080/54000]\n",
            "Batch Loss: 0.400393,  Batch Accuracy: 87.50   [47360/54000]\n",
            "Batch Loss: 0.439754,  Batch Accuracy: 87.50   [48640/54000]\n",
            "Batch Loss: 0.367050,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.281267,  Batch Accuracy: 92.19   [51200/54000]\n",
            "Batch Loss: 0.365693,  Batch Accuracy: 90.62   [52480/54000]\n",
            "Batch Loss: 0.438276,  Batch Accuracy: 85.16   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 87.6%, Loss: 0.426691\n",
            "Validation performance: \n",
            " Accuracy: 87.2%, Loss: 0.440115\n",
            "Test performance: \n",
            " Accuracy: 88.2%, Loss: 0.409308 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Batch Loss: 0.371307,  Batch Accuracy: 88.28   [ 1280/54000]\n",
            "Batch Loss: 0.531835,  Batch Accuracy: 86.72   [ 2560/54000]\n",
            "Batch Loss: 0.564107,  Batch Accuracy: 86.72   [ 3840/54000]\n",
            "Batch Loss: 0.399177,  Batch Accuracy: 88.28   [ 5120/54000]\n",
            "Batch Loss: 0.543209,  Batch Accuracy: 84.38   [ 6400/54000]\n",
            "Batch Loss: 0.333897,  Batch Accuracy: 89.84   [ 7680/54000]\n",
            "Batch Loss: 0.470424,  Batch Accuracy: 85.16   [ 8960/54000]\n",
            "Batch Loss: 0.487624,  Batch Accuracy: 83.59   [10240/54000]\n",
            "Batch Loss: 0.420117,  Batch Accuracy: 90.62   [11520/54000]\n",
            "Batch Loss: 0.331332,  Batch Accuracy: 89.84   [12800/54000]\n",
            "Batch Loss: 0.366594,  Batch Accuracy: 89.84   [14080/54000]\n",
            "Batch Loss: 0.328997,  Batch Accuracy: 89.84   [15360/54000]\n",
            "Batch Loss: 0.387632,  Batch Accuracy: 88.28   [16640/54000]\n",
            "Batch Loss: 0.279503,  Batch Accuracy: 91.41   [17920/54000]\n",
            "Batch Loss: 0.561793,  Batch Accuracy: 85.94   [19200/54000]\n",
            "Batch Loss: 0.429384,  Batch Accuracy: 87.50   [20480/54000]\n",
            "Batch Loss: 0.418148,  Batch Accuracy: 88.28   [21760/54000]\n",
            "Batch Loss: 0.439729,  Batch Accuracy: 87.50   [23040/54000]\n",
            "Batch Loss: 0.358217,  Batch Accuracy: 90.62   [24320/54000]\n",
            "Batch Loss: 0.376886,  Batch Accuracy: 89.84   [25600/54000]\n",
            "Batch Loss: 0.362785,  Batch Accuracy: 89.06   [26880/54000]\n",
            "Batch Loss: 0.462353,  Batch Accuracy: 85.16   [28160/54000]\n",
            "Batch Loss: 0.396701,  Batch Accuracy: 86.72   [29440/54000]\n",
            "Batch Loss: 0.370679,  Batch Accuracy: 86.72   [30720/54000]\n",
            "Batch Loss: 0.484181,  Batch Accuracy: 87.50   [32000/54000]\n",
            "Batch Loss: 0.280624,  Batch Accuracy: 92.19   [33280/54000]\n",
            "Batch Loss: 0.461672,  Batch Accuracy: 84.38   [34560/54000]\n",
            "Batch Loss: 0.402980,  Batch Accuracy: 89.06   [35840/54000]\n",
            "Batch Loss: 0.486608,  Batch Accuracy: 83.59   [37120/54000]\n",
            "Batch Loss: 0.483961,  Batch Accuracy: 91.41   [38400/54000]\n",
            "Batch Loss: 0.311377,  Batch Accuracy: 90.62   [39680/54000]\n",
            "Batch Loss: 0.336055,  Batch Accuracy: 88.28   [40960/54000]\n",
            "Batch Loss: 0.299779,  Batch Accuracy: 92.19   [42240/54000]\n",
            "Batch Loss: 0.368074,  Batch Accuracy: 89.06   [43520/54000]\n",
            "Batch Loss: 0.433691,  Batch Accuracy: 84.38   [44800/54000]\n",
            "Batch Loss: 0.449650,  Batch Accuracy: 84.38   [46080/54000]\n",
            "Batch Loss: 0.529335,  Batch Accuracy: 84.38   [47360/54000]\n",
            "Batch Loss: 0.233558,  Batch Accuracy: 92.97   [48640/54000]\n",
            "Batch Loss: 0.360251,  Batch Accuracy: 88.28   [49920/54000]\n",
            "Batch Loss: 0.484606,  Batch Accuracy: 89.06   [51200/54000]\n",
            "Batch Loss: 0.438159,  Batch Accuracy: 87.50   [52480/54000]\n",
            "Batch Loss: 0.479736,  Batch Accuracy: 89.84   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 88.0%, Loss: 0.413571\n",
            "Validation performance: \n",
            " Accuracy: 87.7%, Loss: 0.433299\n",
            "Test performance: \n",
            " Accuracy: 88.2%, Loss: 0.407350 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Batch Loss: 0.406292,  Batch Accuracy: 85.16   [ 1280/54000]\n",
            "Batch Loss: 0.320032,  Batch Accuracy: 89.84   [ 2560/54000]\n",
            "Batch Loss: 0.437132,  Batch Accuracy: 87.50   [ 3840/54000]\n",
            "Batch Loss: 0.455520,  Batch Accuracy: 90.62   [ 5120/54000]\n",
            "Batch Loss: 0.359050,  Batch Accuracy: 88.28   [ 6400/54000]\n",
            "Batch Loss: 0.392332,  Batch Accuracy: 84.38   [ 7680/54000]\n",
            "Batch Loss: 0.381283,  Batch Accuracy: 90.62   [ 8960/54000]\n",
            "Batch Loss: 0.354204,  Batch Accuracy: 89.84   [10240/54000]\n",
            "Batch Loss: 0.399066,  Batch Accuracy: 88.28   [11520/54000]\n",
            "Batch Loss: 0.509406,  Batch Accuracy: 85.94   [12800/54000]\n",
            "Batch Loss: 0.344252,  Batch Accuracy: 90.62   [14080/54000]\n",
            "Batch Loss: 0.498708,  Batch Accuracy: 86.72   [15360/54000]\n",
            "Batch Loss: 0.429534,  Batch Accuracy: 87.50   [16640/54000]\n",
            "Batch Loss: 0.416075,  Batch Accuracy: 85.94   [17920/54000]\n",
            "Batch Loss: 0.404845,  Batch Accuracy: 85.94   [19200/54000]\n",
            "Batch Loss: 0.412686,  Batch Accuracy: 87.50   [20480/54000]\n",
            "Batch Loss: 0.452628,  Batch Accuracy: 88.28   [21760/54000]\n",
            "Batch Loss: 0.511750,  Batch Accuracy: 88.28   [23040/54000]\n",
            "Batch Loss: 0.461520,  Batch Accuracy: 89.06   [24320/54000]\n",
            "Batch Loss: 0.285552,  Batch Accuracy: 92.19   [25600/54000]\n",
            "Batch Loss: 0.635934,  Batch Accuracy: 83.59   [26880/54000]\n",
            "Batch Loss: 0.466499,  Batch Accuracy: 86.72   [28160/54000]\n",
            "Batch Loss: 0.390475,  Batch Accuracy: 87.50   [29440/54000]\n",
            "Batch Loss: 0.351244,  Batch Accuracy: 89.84   [30720/54000]\n",
            "Batch Loss: 0.459816,  Batch Accuracy: 85.16   [32000/54000]\n",
            "Batch Loss: 0.399762,  Batch Accuracy: 89.06   [33280/54000]\n",
            "Batch Loss: 0.402921,  Batch Accuracy: 87.50   [34560/54000]\n",
            "Batch Loss: 0.421947,  Batch Accuracy: 85.94   [35840/54000]\n",
            "Batch Loss: 0.432888,  Batch Accuracy: 87.50   [37120/54000]\n",
            "Batch Loss: 0.329349,  Batch Accuracy: 92.19   [38400/54000]\n",
            "Batch Loss: 0.340783,  Batch Accuracy: 89.84   [39680/54000]\n",
            "Batch Loss: 0.341989,  Batch Accuracy: 92.19   [40960/54000]\n",
            "Batch Loss: 0.418758,  Batch Accuracy: 89.06   [42240/54000]\n",
            "Batch Loss: 0.372114,  Batch Accuracy: 88.28   [43520/54000]\n",
            "Batch Loss: 0.592230,  Batch Accuracy: 86.72   [44800/54000]\n",
            "Batch Loss: 0.344616,  Batch Accuracy: 91.41   [46080/54000]\n",
            "Batch Loss: 0.518232,  Batch Accuracy: 89.84   [47360/54000]\n",
            "Batch Loss: 0.361149,  Batch Accuracy: 88.28   [48640/54000]\n",
            "Batch Loss: 0.372898,  Batch Accuracy: 89.84   [49920/54000]\n",
            "Batch Loss: 0.359032,  Batch Accuracy: 90.62   [51200/54000]\n",
            "Batch Loss: 0.430337,  Batch Accuracy: 85.16   [52480/54000]\n",
            "Batch Loss: 0.292404,  Batch Accuracy: 91.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 88.5%, Loss: 0.399954\n",
            "Validation performance: \n",
            " Accuracy: 88.3%, Loss: 0.420144\n",
            "Test performance: \n",
            " Accuracy: 88.8%, Loss: 0.388460 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Batch Loss: 0.336796,  Batch Accuracy: 91.41   [ 1280/54000]\n",
            "Batch Loss: 0.382986,  Batch Accuracy: 89.06   [ 2560/54000]\n",
            "Batch Loss: 0.443510,  Batch Accuracy: 85.94   [ 3840/54000]\n",
            "Batch Loss: 0.308852,  Batch Accuracy: 91.41   [ 5120/54000]\n",
            "Batch Loss: 0.328435,  Batch Accuracy: 90.62   [ 6400/54000]\n",
            "Batch Loss: 0.393405,  Batch Accuracy: 85.94   [ 7680/54000]\n",
            "Batch Loss: 0.340836,  Batch Accuracy: 89.06   [ 8960/54000]\n",
            "Batch Loss: 0.342095,  Batch Accuracy: 91.41   [10240/54000]\n",
            "Batch Loss: 0.362359,  Batch Accuracy: 87.50   [11520/54000]\n",
            "Batch Loss: 0.475857,  Batch Accuracy: 87.50   [12800/54000]\n",
            "Batch Loss: 0.391367,  Batch Accuracy: 89.06   [14080/54000]\n",
            "Batch Loss: 0.393172,  Batch Accuracy: 89.84   [15360/54000]\n",
            "Batch Loss: 0.518097,  Batch Accuracy: 84.38   [16640/54000]\n",
            "Batch Loss: 0.449362,  Batch Accuracy: 89.06   [17920/54000]\n",
            "Batch Loss: 0.446224,  Batch Accuracy: 90.62   [19200/54000]\n",
            "Batch Loss: 0.196099,  Batch Accuracy: 96.88   [20480/54000]\n",
            "Batch Loss: 0.373389,  Batch Accuracy: 93.75   [21760/54000]\n",
            "Batch Loss: 0.365701,  Batch Accuracy: 88.28   [23040/54000]\n",
            "Batch Loss: 0.516836,  Batch Accuracy: 89.84   [24320/54000]\n",
            "Batch Loss: 0.463669,  Batch Accuracy: 85.16   [25600/54000]\n",
            "Batch Loss: 0.306648,  Batch Accuracy: 92.19   [26880/54000]\n",
            "Batch Loss: 0.380633,  Batch Accuracy: 89.84   [28160/54000]\n",
            "Batch Loss: 0.398709,  Batch Accuracy: 89.06   [29440/54000]\n",
            "Batch Loss: 0.336516,  Batch Accuracy: 90.62   [30720/54000]\n",
            "Batch Loss: 0.387713,  Batch Accuracy: 88.28   [32000/54000]\n",
            "Batch Loss: 0.430238,  Batch Accuracy: 87.50   [33280/54000]\n",
            "Batch Loss: 0.405427,  Batch Accuracy: 88.28   [34560/54000]\n",
            "Batch Loss: 0.405814,  Batch Accuracy: 86.72   [35840/54000]\n",
            "Batch Loss: 0.293152,  Batch Accuracy: 92.97   [37120/54000]\n",
            "Batch Loss: 0.421986,  Batch Accuracy: 89.06   [38400/54000]\n",
            "Batch Loss: 0.298733,  Batch Accuracy: 92.19   [39680/54000]\n",
            "Batch Loss: 0.271634,  Batch Accuracy: 92.97   [40960/54000]\n",
            "Batch Loss: 0.318340,  Batch Accuracy: 90.62   [42240/54000]\n",
            "Batch Loss: 0.295588,  Batch Accuracy: 89.84   [43520/54000]\n",
            "Batch Loss: 0.309434,  Batch Accuracy: 92.19   [44800/54000]\n",
            "Batch Loss: 0.393857,  Batch Accuracy: 85.94   [46080/54000]\n",
            "Batch Loss: 0.346606,  Batch Accuracy: 92.97   [47360/54000]\n",
            "Batch Loss: 0.375191,  Batch Accuracy: 86.72   [48640/54000]\n",
            "Batch Loss: 0.625355,  Batch Accuracy: 86.72   [49920/54000]\n",
            "Batch Loss: 0.448700,  Batch Accuracy: 90.62   [51200/54000]\n",
            "Batch Loss: 0.375266,  Batch Accuracy: 88.28   [52480/54000]\n",
            "Batch Loss: 0.443093,  Batch Accuracy: 84.38   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 88.9%, Loss: 0.387237\n",
            "Validation performance: \n",
            " Accuracy: 88.8%, Loss: 0.404809\n",
            "Test performance: \n",
            " Accuracy: 89.1%, Loss: 0.373947 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Batch Loss: 0.398780,  Batch Accuracy: 91.41   [ 1280/54000]\n",
            "Batch Loss: 0.398570,  Batch Accuracy: 90.62   [ 2560/54000]\n",
            "Batch Loss: 0.395415,  Batch Accuracy: 87.50   [ 3840/54000]\n",
            "Batch Loss: 0.375957,  Batch Accuracy: 92.19   [ 5120/54000]\n",
            "Batch Loss: 0.434483,  Batch Accuracy: 88.28   [ 6400/54000]\n",
            "Batch Loss: 0.319892,  Batch Accuracy: 91.41   [ 7680/54000]\n",
            "Batch Loss: 0.434209,  Batch Accuracy: 89.06   [ 8960/54000]\n",
            "Batch Loss: 0.358949,  Batch Accuracy: 89.06   [10240/54000]\n",
            "Batch Loss: 0.280348,  Batch Accuracy: 92.97   [11520/54000]\n",
            "Batch Loss: 0.243055,  Batch Accuracy: 93.75   [12800/54000]\n",
            "Batch Loss: 0.448192,  Batch Accuracy: 87.50   [14080/54000]\n",
            "Batch Loss: 0.348780,  Batch Accuracy: 90.62   [15360/54000]\n",
            "Batch Loss: 0.335931,  Batch Accuracy: 92.97   [16640/54000]\n",
            "Batch Loss: 0.432937,  Batch Accuracy: 86.72   [17920/54000]\n",
            "Batch Loss: 0.321538,  Batch Accuracy: 91.41   [19200/54000]\n",
            "Batch Loss: 0.341626,  Batch Accuracy: 92.19   [20480/54000]\n",
            "Batch Loss: 0.371332,  Batch Accuracy: 87.50   [21760/54000]\n",
            "Batch Loss: 0.272512,  Batch Accuracy: 91.41   [23040/54000]\n",
            "Batch Loss: 0.356178,  Batch Accuracy: 92.19   [24320/54000]\n",
            "Batch Loss: 0.383113,  Batch Accuracy: 88.28   [25600/54000]\n",
            "Batch Loss: 0.524982,  Batch Accuracy: 87.50   [26880/54000]\n",
            "Batch Loss: 0.274252,  Batch Accuracy: 90.62   [28160/54000]\n",
            "Batch Loss: 0.378767,  Batch Accuracy: 86.72   [29440/54000]\n",
            "Batch Loss: 0.350123,  Batch Accuracy: 89.84   [30720/54000]\n",
            "Batch Loss: 0.457971,  Batch Accuracy: 80.47   [32000/54000]\n",
            "Batch Loss: 0.303104,  Batch Accuracy: 91.41   [33280/54000]\n",
            "Batch Loss: 0.364398,  Batch Accuracy: 89.84   [34560/54000]\n",
            "Batch Loss: 0.429517,  Batch Accuracy: 89.06   [35840/54000]\n",
            "Batch Loss: 0.322262,  Batch Accuracy: 89.84   [37120/54000]\n",
            "Batch Loss: 0.355009,  Batch Accuracy: 89.06   [38400/54000]\n",
            "Batch Loss: 0.378982,  Batch Accuracy: 89.84   [39680/54000]\n",
            "Batch Loss: 0.572023,  Batch Accuracy: 82.03   [40960/54000]\n",
            "Batch Loss: 0.362691,  Batch Accuracy: 87.50   [42240/54000]\n",
            "Batch Loss: 0.295131,  Batch Accuracy: 92.19   [43520/54000]\n",
            "Batch Loss: 0.417002,  Batch Accuracy: 89.06   [44800/54000]\n",
            "Batch Loss: 0.356953,  Batch Accuracy: 89.84   [46080/54000]\n",
            "Batch Loss: 0.535072,  Batch Accuracy: 86.72   [47360/54000]\n",
            "Batch Loss: 0.362970,  Batch Accuracy: 89.06   [48640/54000]\n",
            "Batch Loss: 0.298436,  Batch Accuracy: 90.62   [49920/54000]\n",
            "Batch Loss: 0.332035,  Batch Accuracy: 89.84   [51200/54000]\n",
            "Batch Loss: 0.270849,  Batch Accuracy: 95.31   [52480/54000]\n",
            "Batch Loss: 0.351940,  Batch Accuracy: 91.41   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 89.3%, Loss: 0.376018\n",
            "Validation performance: \n",
            " Accuracy: 89.2%, Loss: 0.392508\n",
            "Test performance: \n",
            " Accuracy: 89.5%, Loss: 0.362397 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Batch Loss: 0.429918,  Batch Accuracy: 89.06   [ 1280/54000]\n",
            "Batch Loss: 0.409385,  Batch Accuracy: 88.28   [ 2560/54000]\n",
            "Batch Loss: 0.323518,  Batch Accuracy: 87.50   [ 3840/54000]\n",
            "Batch Loss: 0.449907,  Batch Accuracy: 89.06   [ 5120/54000]\n",
            "Batch Loss: 0.434859,  Batch Accuracy: 86.72   [ 6400/54000]\n",
            "Batch Loss: 0.331527,  Batch Accuracy: 89.06   [ 7680/54000]\n",
            "Batch Loss: 0.381144,  Batch Accuracy: 90.62   [ 8960/54000]\n",
            "Batch Loss: 0.489355,  Batch Accuracy: 86.72   [10240/54000]\n",
            "Batch Loss: 0.276971,  Batch Accuracy: 89.84   [11520/54000]\n",
            "Batch Loss: 0.361915,  Batch Accuracy: 89.06   [12800/54000]\n",
            "Batch Loss: 0.427769,  Batch Accuracy: 84.38   [14080/54000]\n",
            "Batch Loss: 0.309882,  Batch Accuracy: 90.62   [15360/54000]\n",
            "Batch Loss: 0.345786,  Batch Accuracy: 89.84   [16640/54000]\n",
            "Batch Loss: 0.345988,  Batch Accuracy: 88.28   [17920/54000]\n",
            "Batch Loss: 0.292909,  Batch Accuracy: 89.84   [19200/54000]\n",
            "Batch Loss: 0.427412,  Batch Accuracy: 84.38   [20480/54000]\n",
            "Batch Loss: 0.327840,  Batch Accuracy: 91.41   [21760/54000]\n",
            "Batch Loss: 0.304602,  Batch Accuracy: 90.62   [23040/54000]\n",
            "Batch Loss: 0.367968,  Batch Accuracy: 89.84   [24320/54000]\n",
            "Batch Loss: 0.364565,  Batch Accuracy: 91.41   [25600/54000]\n",
            "Batch Loss: 0.303452,  Batch Accuracy: 88.28   [26880/54000]\n",
            "Batch Loss: 0.339224,  Batch Accuracy: 89.84   [28160/54000]\n",
            "Batch Loss: 0.324002,  Batch Accuracy: 89.84   [29440/54000]\n",
            "Batch Loss: 0.493946,  Batch Accuracy: 86.72   [30720/54000]\n",
            "Batch Loss: 0.502485,  Batch Accuracy: 86.72   [32000/54000]\n",
            "Batch Loss: 0.419028,  Batch Accuracy: 88.28   [33280/54000]\n",
            "Batch Loss: 0.353319,  Batch Accuracy: 88.28   [34560/54000]\n",
            "Batch Loss: 0.382053,  Batch Accuracy: 90.62   [35840/54000]\n",
            "Batch Loss: 0.385201,  Batch Accuracy: 86.72   [37120/54000]\n",
            "Batch Loss: 0.279219,  Batch Accuracy: 89.84   [38400/54000]\n",
            "Batch Loss: 0.464471,  Batch Accuracy: 85.16   [39680/54000]\n",
            "Batch Loss: 0.257134,  Batch Accuracy: 93.75   [40960/54000]\n",
            "Batch Loss: 0.360542,  Batch Accuracy: 88.28   [42240/54000]\n",
            "Batch Loss: 0.303650,  Batch Accuracy: 92.19   [43520/54000]\n",
            "Batch Loss: 0.381192,  Batch Accuracy: 89.84   [44800/54000]\n",
            "Batch Loss: 0.325575,  Batch Accuracy: 91.41   [46080/54000]\n",
            "Batch Loss: 0.359204,  Batch Accuracy: 89.84   [47360/54000]\n",
            "Batch Loss: 0.431475,  Batch Accuracy: 88.28   [48640/54000]\n",
            "Batch Loss: 0.368987,  Batch Accuracy: 90.62   [49920/54000]\n",
            "Batch Loss: 0.299742,  Batch Accuracy: 93.75   [51200/54000]\n",
            "Batch Loss: 0.259229,  Batch Accuracy: 91.41   [52480/54000]\n",
            "Batch Loss: 0.297354,  Batch Accuracy: 90.62   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 89.6%, Loss: 0.363532\n",
            "Validation performance: \n",
            " Accuracy: 89.4%, Loss: 0.381492\n",
            "Test performance: \n",
            " Accuracy: 89.8%, Loss: 0.354026 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Batch Loss: 0.334881,  Batch Accuracy: 86.72   [ 1280/54000]\n",
            "Batch Loss: 0.424907,  Batch Accuracy: 87.50   [ 2560/54000]\n",
            "Batch Loss: 0.359024,  Batch Accuracy: 87.50   [ 3840/54000]\n",
            "Batch Loss: 0.278598,  Batch Accuracy: 92.97   [ 5120/54000]\n",
            "Batch Loss: 0.450185,  Batch Accuracy: 87.50   [ 6400/54000]\n",
            "Batch Loss: 0.220468,  Batch Accuracy: 94.53   [ 7680/54000]\n",
            "Batch Loss: 0.367000,  Batch Accuracy: 90.62   [ 8960/54000]\n",
            "Batch Loss: 0.302839,  Batch Accuracy: 92.97   [10240/54000]\n",
            "Batch Loss: 0.338679,  Batch Accuracy: 89.84   [11520/54000]\n",
            "Batch Loss: 0.294135,  Batch Accuracy: 90.62   [12800/54000]\n",
            "Batch Loss: 0.330722,  Batch Accuracy: 89.84   [14080/54000]\n",
            "Batch Loss: 0.400605,  Batch Accuracy: 89.84   [15360/54000]\n",
            "Batch Loss: 0.410498,  Batch Accuracy: 88.28   [16640/54000]\n",
            "Batch Loss: 0.375222,  Batch Accuracy: 87.50   [17920/54000]\n",
            "Batch Loss: 0.359009,  Batch Accuracy: 87.50   [19200/54000]\n",
            "Batch Loss: 0.414863,  Batch Accuracy: 89.84   [20480/54000]\n",
            "Batch Loss: 0.476869,  Batch Accuracy: 85.94   [21760/54000]\n",
            "Batch Loss: 0.411491,  Batch Accuracy: 90.62   [23040/54000]\n",
            "Batch Loss: 0.455674,  Batch Accuracy: 86.72   [24320/54000]\n",
            "Batch Loss: 0.371752,  Batch Accuracy: 90.62   [25600/54000]\n",
            "Batch Loss: 0.423699,  Batch Accuracy: 92.19   [26880/54000]\n",
            "Batch Loss: 0.320880,  Batch Accuracy: 91.41   [28160/54000]\n",
            "Batch Loss: 0.287265,  Batch Accuracy: 90.62   [29440/54000]\n",
            "Batch Loss: 0.247574,  Batch Accuracy: 91.41   [30720/54000]\n",
            "Batch Loss: 0.390702,  Batch Accuracy: 89.06   [32000/54000]\n",
            "Batch Loss: 0.365141,  Batch Accuracy: 89.84   [33280/54000]\n",
            "Batch Loss: 0.394381,  Batch Accuracy: 93.75   [34560/54000]\n",
            "Batch Loss: 0.324680,  Batch Accuracy: 89.84   [35840/54000]\n",
            "Batch Loss: 0.375538,  Batch Accuracy: 91.41   [37120/54000]\n",
            "Batch Loss: 0.419447,  Batch Accuracy: 88.28   [38400/54000]\n",
            "Batch Loss: 0.211328,  Batch Accuracy: 93.75   [39680/54000]\n",
            "Batch Loss: 0.397216,  Batch Accuracy: 83.59   [40960/54000]\n",
            "Batch Loss: 0.548134,  Batch Accuracy: 85.16   [42240/54000]\n",
            "Batch Loss: 0.343743,  Batch Accuracy: 90.62   [43520/54000]\n",
            "Batch Loss: 0.344145,  Batch Accuracy: 87.50   [44800/54000]\n",
            "Batch Loss: 0.430214,  Batch Accuracy: 84.38   [46080/54000]\n",
            "Batch Loss: 0.367135,  Batch Accuracy: 86.72   [47360/54000]\n",
            "Batch Loss: 0.493546,  Batch Accuracy: 90.62   [48640/54000]\n",
            "Batch Loss: 0.302892,  Batch Accuracy: 92.19   [49920/54000]\n",
            "Batch Loss: 0.302051,  Batch Accuracy: 93.75   [51200/54000]\n",
            "Batch Loss: 0.280609,  Batch Accuracy: 90.62   [52480/54000]\n",
            "Batch Loss: 0.507570,  Batch Accuracy: 86.72   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 90.0%, Loss: 0.352216\n",
            "Validation performance: \n",
            " Accuracy: 89.8%, Loss: 0.373816\n",
            "Test performance: \n",
            " Accuracy: 90.2%, Loss: 0.341860 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Batch Loss: 0.321247,  Batch Accuracy: 89.84   [ 1280/54000]\n",
            "Batch Loss: 0.345613,  Batch Accuracy: 89.06   [ 2560/54000]\n",
            "Batch Loss: 0.300461,  Batch Accuracy: 92.97   [ 3840/54000]\n",
            "Batch Loss: 0.260418,  Batch Accuracy: 92.97   [ 5120/54000]\n",
            "Batch Loss: 0.351877,  Batch Accuracy: 88.28   [ 6400/54000]\n",
            "Batch Loss: 0.376624,  Batch Accuracy: 87.50   [ 7680/54000]\n",
            "Batch Loss: 0.289251,  Batch Accuracy: 89.06   [ 8960/54000]\n",
            "Batch Loss: 0.231281,  Batch Accuracy: 92.97   [10240/54000]\n",
            "Batch Loss: 0.388674,  Batch Accuracy: 88.28   [11520/54000]\n",
            "Batch Loss: 0.340952,  Batch Accuracy: 88.28   [12800/54000]\n",
            "Batch Loss: 0.364619,  Batch Accuracy: 86.72   [14080/54000]\n",
            "Batch Loss: 0.419984,  Batch Accuracy: 86.72   [15360/54000]\n",
            "Batch Loss: 0.359916,  Batch Accuracy: 84.38   [16640/54000]\n",
            "Batch Loss: 0.370667,  Batch Accuracy: 89.84   [17920/54000]\n",
            "Batch Loss: 0.342271,  Batch Accuracy: 92.19   [19200/54000]\n",
            "Batch Loss: 0.371933,  Batch Accuracy: 88.28   [20480/54000]\n",
            "Batch Loss: 0.435125,  Batch Accuracy: 87.50   [21760/54000]\n",
            "Batch Loss: 0.335914,  Batch Accuracy: 89.84   [23040/54000]\n",
            "Batch Loss: 0.368297,  Batch Accuracy: 90.62   [24320/54000]\n",
            "Batch Loss: 0.280849,  Batch Accuracy: 91.41   [25600/54000]\n",
            "Batch Loss: 0.400593,  Batch Accuracy: 89.84   [26880/54000]\n",
            "Batch Loss: 0.400629,  Batch Accuracy: 87.50   [28160/54000]\n",
            "Batch Loss: 0.260541,  Batch Accuracy: 95.31   [29440/54000]\n",
            "Batch Loss: 0.359233,  Batch Accuracy: 92.19   [30720/54000]\n",
            "Batch Loss: 0.208137,  Batch Accuracy: 95.31   [32000/54000]\n",
            "Batch Loss: 0.331118,  Batch Accuracy: 93.75   [33280/54000]\n",
            "Batch Loss: 0.297808,  Batch Accuracy: 91.41   [34560/54000]\n",
            "Batch Loss: 0.322753,  Batch Accuracy: 90.62   [35840/54000]\n",
            "Batch Loss: 0.381405,  Batch Accuracy: 88.28   [37120/54000]\n",
            "Batch Loss: 0.227997,  Batch Accuracy: 93.75   [38400/54000]\n",
            "Batch Loss: 0.306708,  Batch Accuracy: 93.75   [39680/54000]\n",
            "Batch Loss: 0.426034,  Batch Accuracy: 88.28   [40960/54000]\n",
            "Batch Loss: 0.383389,  Batch Accuracy: 92.19   [42240/54000]\n",
            "Batch Loss: 0.566973,  Batch Accuracy: 85.16   [43520/54000]\n",
            "Batch Loss: 0.392403,  Batch Accuracy: 89.06   [44800/54000]\n",
            "Batch Loss: 0.267111,  Batch Accuracy: 94.53   [46080/54000]\n",
            "Batch Loss: 0.288640,  Batch Accuracy: 90.62   [47360/54000]\n",
            "Batch Loss: 0.347944,  Batch Accuracy: 91.41   [48640/54000]\n",
            "Batch Loss: 0.369125,  Batch Accuracy: 86.72   [49920/54000]\n",
            "Batch Loss: 0.430122,  Batch Accuracy: 87.50   [51200/54000]\n",
            "Batch Loss: 0.453155,  Batch Accuracy: 87.50   [52480/54000]\n",
            "Batch Loss: 0.367623,  Batch Accuracy: 87.50   [53760/54000]\n",
            "Training performance: \n",
            " Accuracy: 90.2%, Loss: 0.341660\n",
            "Validation performance: \n",
            " Accuracy: 89.9%, Loss: 0.362216\n",
            "Test performance: \n",
            " Accuracy: 90.5%, Loss: 0.332875 \n",
            "\n",
            "Time taken to train the model: 3.0169188102086384 minutes\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train_bonus(model:nn.Module, train_loader:DataLoader, optimizer, criterion):\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        batch_correct = (predicted == labels).sum().item()\n",
        "        correct += batch_correct\n",
        "\n",
        "        if (batch + 1) % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(images)\n",
        "            print(f\"Batch Loss: {loss:>7f},  Batch Accuracy: {100*batch_correct/len(images):.2f}   [{current:>5d}/{len(train_sampler):>5d}]\")\n",
        "        batch += 1\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Training performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {train_loss:>8f}\")\n",
        "    return train_loss, accuracy\n",
        "\n",
        "\n",
        "# Validation loop\n",
        "def validate_bonus(model:nn.Module, valid_loader:DataLoader, loss_fn):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(valid_loader)\n",
        "    print(f\"Validation performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {val_loss:>8f}\")\n",
        "    return val_loss, accuracy\n",
        "\n",
        "\n",
        "# Testing loop\n",
        "def test_bonus(model:nn.Module, test_loader:DataLoader, loss_fn):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            test_loss += loss_fn(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test performance: \\n Accuracy: {accuracy:>0.1f}%, Loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "# Training, Validation and Testing of the model\n",
        "num_epochs = 60\n",
        "train_losses_bonus, train_accuracies_bonus = [], []\n",
        "val_losses_bonus, val_accuracies_bonus = [], []\n",
        "test_losses_bonus, test_accuracies_bonus = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_bonus(model_bonus, train_loader, optimizer_bonus, criterion_bonus)\n",
        "    val_loss, val_acc = validate_bonus(model_bonus, valid_loader, criterion_bonus)\n",
        "    test_loss, test_acc = test_bonus(model_bonus, test_loader, criterion_bonus)\n",
        "\n",
        "    train_losses_bonus.append(train_loss)\n",
        "    train_accuracies_bonus.append(train_acc)\n",
        "    val_losses_bonus.append(val_loss)\n",
        "    val_accuracies_bonus.append(val_acc)\n",
        "    test_losses_bonus.append(test_loss)\n",
        "    test_accuracies_bonus.append(test_acc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to train the model: {(end_time - start_time) / 60} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "FNPBG_oU1fYl",
        "outputId": "4f899170-f034-434d-9cef-f4a3621fc41f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_losses_bonus, label='Train')\n",
        "plt.plot(range(num_epochs), val_losses_bonus, label='Validation')\n",
        "plt.plot(range(num_epochs), test_losses_bonus, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_accuracies_bonus, label='Train')\n",
        "plt.plot(range(num_epochs), val_accuracies_bonus, label='Validation')\n",
        "plt.plot(range(num_epochs), test_accuracies_bonus, label='Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Highest value of 'n' achieved is 10. After 10 layers, the model is not able to learn the features and thus performs poorly due to increased complexity of the model and parameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DrtXlfRUWMEn",
        "CTxJNT1gWMEq",
        "oon9F9GGWMEr",
        "EvVBD72_WMEv",
        "1ib0D5q9WMEw",
        "0Lb6b8qUWMEx",
        "CAd5bF02WMEx",
        "6tKQt2TuWMEy",
        "4en5SL101baP",
        "NlIJMJ-e1UEN",
        "SECMexsl1vKW",
        "KPKujJt711Bz",
        "X4Bzsc_LP56m",
        "akNYhqnoP56p",
        "Q3TB-7TwP56p",
        "worO-fhEK3aI",
        "eGfFy9JE0mig",
        "cDghauDqRVZ2",
        "-DpJ7Zg4N1sZ",
        "ntNf1aR8YDMv",
        "K80pa1rdYIzM",
        "C6hpm-HzYRgL",
        "xMp4opl2YUJ7",
        "SR5kJRU-YXW8",
        "lEqEH14u5p_H",
        "oQrM9APF8IoZ",
        "wSHQc5qp-eAL",
        "fymcjcFs-qXj",
        "rhQOwvZn_CON"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
