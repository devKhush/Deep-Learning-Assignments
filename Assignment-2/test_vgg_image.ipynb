{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/MSA_BTP/env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/disk1/sumdev/MSA_BTP/env/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training VGG_Q2 Architecture on train split of ImageDataset\n",
      "Training Epoch: 0, [Loss: 2.0367816133671495, Accuracy: 23.705760542168676]\n",
      "Training Epoch: 1, [Loss: 1.7416877093085323, Accuracy: 35.19625376506024]\n",
      "Training Epoch: 2, [Loss: 1.6534161090132702, Accuracy: 39.027202560240966]\n",
      "Training Epoch: 3, [Loss: 1.582931970257357, Accuracy: 41.55449924698795]\n",
      "Training Epoch: 4, [Loss: 1.5419841336916729, Accuracy: 43.17347515060241]\n",
      "Training Epoch: 5, [Loss: 1.4921111633260566, Accuracy: 45.084243222891565]\n",
      "Training Epoch: 6, [Loss: 1.451936271894409, Accuracy: 46.85146837349398]\n",
      "Training Epoch: 7, [Loss: 1.4157396314373936, Accuracy: 48.3339608433735]\n",
      "Training Epoch: 8, [Loss: 1.3824175265898186, Accuracy: 49.42112198795181]\n",
      "Training Epoch: 9, [Loss: 1.3555135622800114, Accuracy: 50.6777108433735]\n",
      "Training Epoch: 10, [Loss: 1.326991884823305, Accuracy: 51.97900978915663]\n",
      "Training Epoch: 11, [Loss: 1.29060854843582, Accuracy: 52.97910391566265]\n",
      "Training Epoch: 12, [Loss: 1.2705875358667718, Accuracy: 54.115681475903614]\n",
      "Training Epoch: 13, [Loss: 1.2482165256178523, Accuracy: 54.96752635542169]\n",
      "Training Epoch: 14, [Loss: 1.2270104482949498, Accuracy: 56.1511671686747]\n",
      "Training Epoch: 15, [Loss: 1.2087944081748825, Accuracy: 56.55120481927711]\n",
      "Training Epoch: 16, [Loss: 1.1827040488820477, Accuracy: 57.6171875]\n",
      "Training Epoch: 17, [Loss: 1.161207802144878, Accuracy: 58.46903237951807]\n",
      "Training Epoch: 18, [Loss: 1.1447021444159817, Accuracy: 58.99378765060241]\n",
      "Training Epoch: 19, [Loss: 1.1328820370766053, Accuracy: 59.375]\n",
      "Training Epoch: 20, [Loss: 1.116166106369122, Accuracy: 60.142131024096386]\n",
      "Validating VGG_Q2 Architecture on val split of ImageDataset\n",
      "Validation Epoch: 0, [Loss: 1.183419757875903, Accuracy: 57.933728448275865]\n",
      "Testing VGG_Q2 Architecture on test split of ImageDataset\n",
      "Testing: [Loss: 1.150994225190236, Accuracy: 58.65384615384615]\n"
     ]
    }
   ],
   "source": [
    "from Pipeline._2020211A2 import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "imageDataset = [\n",
    "    ImageDataset(split=\"train\"),\n",
    "    ImageDataset(split=\"val\"),\n",
    "    ImageDataset(split=\"test\")    \n",
    "]\n",
    "audioDataset = [\n",
    "    # AudioDataset(split=\"train\"),\n",
    "    # AudioDataset(split=\"val\"),\n",
    "    # AudioDataset(split=\"test\")\n",
    "]\n",
    "   \n",
    "Architectures = [\n",
    "    # Resnet_Q1(),\n",
    "    VGG_Q2(),\n",
    "    # Inception_Q3(),\n",
    "    # CustomNetwork_Q4()\n",
    "]\n",
    "device = 'T'\n",
    "\n",
    "\n",
    "for network in Architectures:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=network.parameters(),\n",
    "        lr=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    for dataset in imageDataset + audioDataset:\n",
    "        if dataset.datasplit == \"train\":\n",
    "            print(\n",
    "                \"Training {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.train()\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            trainer(\n",
    "                gpu=device,\n",
    "                dataloader=train_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "        \n",
    "        elif dataset.datasplit == \"val\":\n",
    "            print(\n",
    "                \"Validating {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.train()\n",
    "            val_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            validator(\n",
    "                gpu=device,\n",
    "                dataloader=val_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "            \n",
    "        elif dataset.datasplit == \"test\":\n",
    "            print(\n",
    "                \"Testing {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.eval()\n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            evaluator(\n",
    "                dataloader=test_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
