{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/MSA_BTP/env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/disk1/sumdev/MSA_BTP/env/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training CustomNetwork_Q4 Architecture on train split of ImageDataset\n",
      "Training Epoch: 0, [Loss: 1.8654446792171662, Accuracy: 27.84262048192771]\n",
      "Training Epoch: 1, [Loss: 1.3004795095647674, Accuracy: 51.21893825301205]\n",
      "Training Epoch: 2, [Loss: 0.9883486879877297, Accuracy: 64.61784638554217]\n",
      "Validating CustomNetwork_Q4 Architecture on val split of ImageDataset\n",
      "Validation Epoch: 0, [Loss: 0.895836158045407, Accuracy: 68.07650862068965]\n",
      "Testing CustomNetwork_Q4 Architecture on test split of ImageDataset\n",
      "Testing: [Loss: 1.1493471020307295, Accuracy: 60.30649038461539]\n"
     ]
    }
   ],
   "source": [
    "from Pipeline._2020211A2 import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "imageDataset = [\n",
    "    ImageDataset(split=\"train\"),\n",
    "    ImageDataset(split=\"val\"),\n",
    "    ImageDataset(split=\"test\")    \n",
    "]\n",
    "audioDataset = [\n",
    "    # AudioDataset(split=\"train\"),\n",
    "    # AudioDataset(split=\"val\"),\n",
    "    # AudioDataset(split=\"test\")\n",
    "]\n",
    "   \n",
    "Architectures = [\n",
    "    # Resnet_Q1(),\n",
    "    # VGG_Q2(),\n",
    "    # Inception_Q3(),\n",
    "    CustomNetwork_Q4()\n",
    "]\n",
    "device = 'T'\n",
    "\n",
    "\n",
    "for network in Architectures:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=network.parameters(),\n",
    "        lr=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    for dataset in imageDataset + audioDataset:\n",
    "        if dataset.datasplit == \"train\":\n",
    "            print(\n",
    "                \"Training {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.train()\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            trainer(\n",
    "                gpu=device,\n",
    "                dataloader=train_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "        \n",
    "        elif dataset.datasplit == \"val\":\n",
    "            print(\n",
    "                \"Validating {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.train()\n",
    "            val_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            validator(\n",
    "                gpu=device,\n",
    "                dataloader=val_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "            \n",
    "        elif dataset.datasplit == \"test\":\n",
    "            print(\n",
    "                \"Testing {} Architecture on {} split of {}\".format(\n",
    "                    network.__class__.__name__,\n",
    "                    dataset.datasplit,\n",
    "                    dataset.__class__.__name__\n",
    "                )\n",
    "            )\n",
    "            network.eval()\n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            evaluator(\n",
    "                dataloader=test_dataloader,\n",
    "                network=network,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
